{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### PREAMPLE: INSTALL `protobuf==3.14.0`"
      ],
      "metadata": {
        "id": "c0K7gaqgnRkQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IP7rUdhs-S5",
        "outputId": "53a3e8f4-ee42-459e-b3aa-55edfca29c39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.14.0\n",
            "  Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.14.0) (1.15.0)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "proto-plus 1.22.2 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.14.0 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.18.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.14.0\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.14.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1: INSTALL FAIRSEQ \n"
      ],
      "metadata": {
        "id": "1cGE1bjeoZYY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nmRbzqfsK9r",
        "outputId": "506b09a2-6eb3-4426-9613-ece8f2dcf52a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34456, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 34456 (delta 13), reused 26 (delta 5), pack-reused 34391\u001b[K\n",
            "Receiving objects: 100% (34456/34456), 23.94 MiB | 2.44 MiB/s, done.\n",
            "Resolving deltas: 100% (25024/25024), done.\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.13.1+cu116)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.0.2)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (4.64.1)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.13.1+cu116)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.29.33)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (2022.6.2)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.8/264.8 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (5.10.2)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (3.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (3.12.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=7104909b66654bb41d87dff3de2006a7ca16f3f2717eae09f087a28b6a2ce070\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.0 colorama-0.4.6 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!python -m pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-iyf7IUhfhK",
        "outputId": "f4b0d98f-ea3d-4d41-dabf-1ac52942169f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.13.1+cu116)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.21.6)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.29.33)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.13.1+cu116)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.7.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.12.0)\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-0.12.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchaudio) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchaudio) (4.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/score.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/hydra_validate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/train.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/validate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/generate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/hydra_train.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/incremental_decoding_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/version.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/search.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/token_generation_constraints.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/nan_detector.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/hub_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_io.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/ngram_repeat_block.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/registry.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/binarizer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_chunker_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/pdb.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/quantization_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/speech_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/progress_bar.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/metrics.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/meters.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/megatron_trainer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_denoising.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_text.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/online_backtranslation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction_adapters.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/frm_text_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_ulm_task.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/nlu_finetuning.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_bart.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/text_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_multi_simple_epoch.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_language_modeling.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/simultaneous_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/hubert_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/audio_finetuning.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/span_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_dlm_task.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/add_class_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/shorten_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_concat_langpair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/bucket_pad_length_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/noising.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/span_mask_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/multi_corpus_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/fasta_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/add_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/codedataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/text_compressor.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/padding_mask_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/speech_dlm_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction_adapters.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_rdrop.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/ctc.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/speech_dlm_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_ctc.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/tacotron2_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/wav2vec_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/model_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/speech_to_speech_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/hubert_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/speech_ulm_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/fastspeech2_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/chrf.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/bleu.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/meteor.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/bertscore.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/wer.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_ulm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lstm_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_align.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/quant_noise.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/kmeans_vector_quantizer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/rotary_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_instance_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transpose_last.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/espnet_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/lstm_cell_with_zoneout.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer_aug.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/base_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/location_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/same_pad.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/ema_module.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fairseq_dropout.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/dynamic_crf_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_batch_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/checkpoint_activations.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/gumbel_vector_quantizer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/layer_drop.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/kmeans_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_group_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/positional_encoding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/conformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config\n",
            "copying fairseq/config/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/shard.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fused_adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/composite.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fused_lamb.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/amp_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/cpu_adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/dynamic_loss_scaler.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/utils.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/initialize.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/configs.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/constants.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "copying fairseq/examples/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_lm.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/benchmark_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_model.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_mt.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/utils.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/module_proxy_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/distributed_timeout_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/tpu_distributed_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/fully_sharded_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer_lm.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/model.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_mmap_indexed_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_coder.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/multi_modality_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/hubert_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/audio_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/data_cfg.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/text_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_joint_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/frm_text_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampling_method.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_data_manager.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/characters.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/bytes.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_byte_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/noiseaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/concataugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/noisyoverlapaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/delta_deltas.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/specaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/global_cmvn.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nat_crf_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/fairseq_nat_model.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/cmlm_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/insertion_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert_asr.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_translatotron2.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_unity.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_base.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder_aug.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_config.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_legacy.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "copying fairseq/models/ema/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "copying fairseq/models/ema/ema.py -> build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tacotron2.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hifigan.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/fastspeech2.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tts_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/vocoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/codehifigan.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/speech_dlm.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_asr.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_laser.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/convtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_wav_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer_unity.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/multi_modality_model.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/berard.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_conformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/hf_gpt2.py -> build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/transformer_layer_xmod.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/enc_dec.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_camembert.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_xlmr.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_gottbert.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/ctc_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_decoder_aug.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/stacked_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_search.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_dlm/sequence_generator\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/emformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/convolution.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/augmented_memory_attention.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/quantization_options.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/utils.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/ops.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/utils.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/pq.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/em.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qact.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qemb.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qlinear.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qconv.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qemb.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qlinear.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qconv.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/pass_through.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/step_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/generate_waveform.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/generate_waveform_from_code.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "copying fairseq/examples/rxf/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/libri_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_featurize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "copying fairseq/examples/simultaneous_translation/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/infer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "copying fairseq/examples/speech_text_joint_to_text/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/fb_convert_beit_cp.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_asr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_sp.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator_multi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/compute_asr_bleu.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_output_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/w2vu_generate.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/monotonic_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/functions.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/infer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/base_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder_config.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_denoise_pretrain.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/pair_denoising.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_compound.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputwavtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/joint_speech_text_pretrain_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/multimodal.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/audio_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_finetuning_image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/add_class_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/modality.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/path_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_vision.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec2.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/audio_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/modules.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/base.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/images.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth\n",
            "copying fairseq/examples/latent_depth/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/stories\n",
            "copying fairseq/examples/stories/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/stories\n",
            "copying fairseq/examples/speech_synthesis/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/vctk_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/common_voice_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/ljspeech_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/camembert\n",
            "copying fairseq/examples/camembert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/camembert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/preprocess.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/postprocess.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.xsum.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/train_lm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/update_ckpt.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/measure_teacher_quality.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune\n",
            "copying fairseq/examples/hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/ckpt\n",
            "copying fairseq/examples/hubert/config/finetune/ckpt/it1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/ckpt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/run\n",
            "copying fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/lm\n",
            "copying fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/lm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/run\n",
            "copying fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_kenlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_fsqlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_viterbi.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.hypo.word -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_finetuned_asr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.km500.km -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/6313-76958-0021.flac -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_feature_and_unit.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.hypo.word -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/adaptive_span/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/locallaunch.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/CONFIG.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/DATASET.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/videoclip.png -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/endtask.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/vlm.png -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/setup.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/predict.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/localjob.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt\n",
            "copying fairseq/examples/MMPT/mmpt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/nce.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/vlmtask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/milncetask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/retritask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/shardedtensor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/load_config.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/mmdataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2processor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/processor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dsprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors/models\n",
            "copying fairseq/examples/MMPT/mmpt/processors/models/s3dg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/transformermodel.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/retri.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/vectorpool.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/mm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/evaluator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/metric.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects\n",
            "copying fairseq/examples/MMPT/projects/mfmmlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoretri.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/default.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/ft.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "copying fairseq/examples/speech_to_speech/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/direct_s2st_discrete_units.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/data_augmentation.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/enhanced_direct_s2st_discrete_units.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/textless_s2st_real_data.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/asr_model_cfgs.json -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/requirements.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/core.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/get_metrics.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/mbart\n",
            "copying fairseq/examples/mbart/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/mbart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/synthesize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/requirements.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/process_km.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_translation_manifests.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km_tsv.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/extract_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/create_core_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_hifigan_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_emov_km_tsv_by_uttid.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/fairseq_models\n",
            "copying fairseq/examples/emotion_conversion/fairseq_models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/fairseq_models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt20\n",
            "copying fairseq/examples/wmt20/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt20\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xformers\n",
            "copying fairseq/examples/xformers/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xformers\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pay_less_attention_paper\n",
            "copying fairseq/examples/pay_less_attention_paper/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pay_less_attention_paper\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/query_occupations_from_wikidata.py -> build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/model_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/cross_lingual_language_model\n",
            "copying fairseq/examples/cross_lingual_language_model/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/cross_lingual_language_model\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/data_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/model_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/rxf/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "copying fairseq/examples/wav2vec/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws_v100.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_8.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_old.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_16.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/scripts/binarize_manifest.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/pca.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/vads.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio_v2.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr\n",
            "copying fairseq/examples/wav2vec/xlsr/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/config\n",
            "copying fairseq/examples/wav2vec/xlsr/config/finetune.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/eval_speaker_clf_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/gen_audio_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/ML50_langs.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/train_multilingual_model.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/binarize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/requirement.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/gru_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_bitext.py -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.summarization.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.glue.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/summarize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/tok.py -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/normalize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/paraphrase.py -> build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/generate_waveform.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/truncated_laplace.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/quantize_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/naive_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/prepare_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/inference_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/preprocess_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/sample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm\n",
            "copying fairseq/examples/textless_nlp/gslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/glow.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/sample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/img/fig.png -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/create_code_file.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/dgslm_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/sample_speech_dlm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "copying fairseq/examples/textless_nlp/dgslm/hubert_fisher/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/generate_stereo_waveform.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/generate_manifests.py -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/create_dict_stop.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu/configs\n",
            "copying fairseq/examples/audio_nlp/nlu/configs/nlu_finetuning.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/prepare-wikitext-103.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.adaptive_inputs.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.conv.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/scaling_nmt\n",
            "copying fairseq/examples/scaling_nmt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/scaling_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/deduplicate_lines.py -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/sacrebleu.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/tokenized_bleu.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/extract_bt_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/score.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/eval.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/normalize-punctuation.perl -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mustc_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/seg_mustc_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_covost_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/covost_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mustc_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/conv_seq2seq\n",
            "copying fairseq/examples/conv_seq2seq/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/conv_seq2seq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/save_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/unsupervised_mt\n",
            "copying fairseq/examples/criss/unsupervised_mt/eval.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/unsupervised_mt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine_example.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.finetuning.md -> build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/flores_logo.png -> build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "copying fairseq/examples/noisychannel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/laser\n",
            "copying fairseq/examples/laser/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/laser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_lstm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/fast_noisy_channel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/simultaneous_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/enja-waitk.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/ende-mma.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_alignment_train.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_text_models.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval/agents\n",
            "copying fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval/agents\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cpu.cpp -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/utils.h -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_kernel.cu -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.h -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.cpp -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection\n",
            "copying fairseq/examples/attention_head_selection/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_functional.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/gottbert\n",
            "copying fairseq/examples/gottbert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/gottbert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/scripts.md -> build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer\n",
            "copying fairseq/examples/linformer/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src\n",
            "copying fairseq/examples/linformer/linformer_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/install_dependecies.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/tok.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/dedup_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "copying fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "copying fairseq/examples/truncated_bptt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/speech_recognition/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi/config\n",
            "copying fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi/config\n",
            "copying fairseq/examples/speech_recognition/new/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf\n",
            "copying fairseq/examples/speech_recognition/new/conf/infer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_2g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax_sil.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/utils/wer_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt19\n",
            "copying fairseq/examples/wmt19/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt19\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/preprocess_nli.py -> build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xlmr\n",
            "copying fairseq/examples/xlmr/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xlmr\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2de.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt14.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/detok.py -> build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/speech_text_joint_to_text/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/pre-training.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/data\n",
            "copying fairseq/examples/speech_text_joint_to_text/data/pair_denoising_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/configs\n",
            "copying fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/convert_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.custom_classification.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.race.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.glue.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/fb_multilingual\n",
            "copying fairseq/examples/roberta/fb_multilingual/README.multilingual.pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/fb_multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining\n",
            "copying fairseq/examples/roberta/config/pretraining/base.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/cola.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/rte.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sts_b.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mrpc.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sst_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qqp.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/discriminative_reranking_nmt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/config\n",
            "copying fairseq/examples/discriminative_reranking_nmt/config/deen.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "copying fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/fully_sharded_data_parallel\n",
            "copying fairseq/examples/fully_sharded_data_parallel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/fully_sharded_data_parallel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/layerdrop/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/data2vec/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_mae_imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet_d2v1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_huge_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_large_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/audioset.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification\n",
            "copying fairseq/examples/data2vec/config/audio/classification/base_classification.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/base.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images14_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_text_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task_pgrp_1M.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_audio_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_audio_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/cola.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/rte.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sts_b.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mrpc.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sst_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qqp.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts\n",
            "copying fairseq/examples/data2vec/scripts/convert_audioset_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/valids.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr_nopos.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_char_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue_lr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_sst2_qnli_sweep_fair_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/unprocess_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/config/config.yaml -> build/lib.linux-x86_64-3.8/fairseq/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec\n",
            "copying fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/fb_run_config\n",
            "copying fairseq/config/fb_run_config/slurm.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/fb_run_config\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "skipping 'fairseq/data/data_utils_fast.cpp' Cython extension (up-to-date)\n",
            "skipping 'fairseq/data/token_block_utils_fast.cpp' Cython extension (up-to-date)\n",
            "running develop\n",
            "running egg_info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing entry points to fairseq.egg-info/entry_points.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so -> \n",
            "Creating /usr/local/lib/python3.8/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.12.2 to easy-install.pth file\n",
            "Installing fairseq-eval-lm script to /usr/local/bin\n",
            "Installing fairseq-generate script to /usr/local/bin\n",
            "Installing fairseq-hydra-train script to /usr/local/bin\n",
            "Installing fairseq-interactive script to /usr/local/bin\n",
            "Installing fairseq-preprocess script to /usr/local/bin\n",
            "Installing fairseq-score script to /usr/local/bin\n",
            "Installing fairseq-train script to /usr/local/bin\n",
            "Installing fairseq-validate script to /usr/local/bin\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.12.2\n",
            "Searching for packaging==23.0\n",
            "Best match: packaging 23.0\n",
            "Adding packaging 23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torchaudio==0.13.1+cu116\n",
            "Best match: torchaudio 0.13.1+cu116\n",
            "Adding torchaudio 0.13.1+cu116 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for bitarray==2.7.0\n",
            "Best match: bitarray 2.7.0\n",
            "Adding bitarray 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torch==1.13.1+cu116\n",
            "Best match: torch 1.13.1+cu116\n",
            "Adding torch 1.13.1+cu116 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for sacrebleu==2.3.1\n",
            "Best match: sacrebleu 2.3.1\n",
            "Adding sacrebleu 2.3.1 to easy-install.pth file\n",
            "Installing sacrebleu script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for regex==2022.6.2\n",
            "Best match: regex 2022.6.2\n",
            "Adding regex 2022.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for omegaconf==2.0.6\n",
            "Best match: omegaconf 2.0.6\n",
            "Adding omegaconf 2.0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for hydra-core==1.0.7\n",
            "Best match: hydra-core 1.0.7\n",
            "Adding hydra-core 1.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Cython==0.29.33\n",
            "Best match: Cython 0.29.33\n",
            "Adding Cython 0.29.33 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cffi==1.15.1\n",
            "Best match: cffi 1.15.1\n",
            "Adding cffi 1.15.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for typing-extensions==4.4.0\n",
            "Best match: typing-extensions 4.4.0\n",
            "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for portalocker==2.7.0\n",
            "Best match: portalocker 2.7.0\n",
            "Adding portalocker 2.7.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tabulate==0.8.10\n",
            "Best match: tabulate 0.8.10\n",
            "Adding tabulate 0.8.10 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for lxml==4.9.2\n",
            "Best match: lxml 4.9.2\n",
            "Adding lxml 4.9.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for colorama==0.4.6\n",
            "Best match: colorama 0.4.6\n",
            "Adding colorama 0.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for importlib-resources==5.10.2\n",
            "Best match: importlib-resources 5.10.2\n",
            "Adding importlib-resources 5.10.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for antlr4-python3-runtime==4.8\n",
            "Best match: antlr4-python3-runtime 4.8\n",
            "Adding antlr4-python3-runtime 4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pycparser==2.21\n",
            "Best match: pycparser 2.21\n",
            "Adding pycparser 2.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zipp==3.12.0\n",
            "Best match: zipp 3.12.0\n",
            "Adding zipp 3.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for fairseq==0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install fairseq\n",
        "!pip install pandas torchaudio sentencepiece\n",
        "!python setup.py build develop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2: DOWNLOAD THE DATASET"
      ],
      "metadata": {
        "id": "FfiKno6fp5ln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ynvbDVURyoV",
        "outputId": "5350396f-8943-4336-90a4-93f8ec51f16d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'zambezi-voice'...\n",
            "remote: Enumerating objects: 39980, done.\u001b[K\n",
            "remote: Counting objects: 100% (9862/9862), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9171/9171), done.\u001b[K\n",
            "remote: Total 39980 (delta 764), reused 9747 (delta 678), pack-reused 30118\n",
            "Receiving objects: 100% (39980/39980), 5.90 GiB | 10.79 MiB/s, done.\n",
            "Resolving deltas: 100% (15435/15435), done.\n",
            "Updating files: 100% (21475/21475), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/unza-speech-lab/zambezi-voice.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 3: ASR"
      ],
      "metadata": {
        "id": "XYdpLhQsuIyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Upload the `prepare_asr_data.py` in the `fairseq/examples/speech_to_text` folder"
      ],
      "metadata": {
        "id": "290xMuwxuC3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ie0969IeaYe",
        "outputId": "59efdaef-aea2-4a8a-9359-ca23166dddd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "Fetching split train...\n",
            "Extracting log mel filter bank features...\n",
            "100% 8117/8117 [01:09<00:00, 116.34it/s]\n",
            "Fetching split dev...\n",
            "Extracting log mel filter bank features...\n",
            "100% 622/622 [00:06<00:00, 95.18it/s] \n",
            "Fetching split test...\n",
            "Extracting log mel filter bank features...\n",
            "100% 428/428 [00:03<00:00, 111.70it/s]\n",
            "ZIPing features...\n",
            "100% 9167/9167 [00:21<00:00, 431.18it/s]\n",
            "Fetching ZIP manifest...\n",
            "100% 9167/9167 [00:03<00:00, 2650.24it/s]\n",
            "Generating manifest...\n",
            "100% 8117/8117 [00:21<00:00, 380.05it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, long speech (>3000 frames): 12, total 12 filtered, 8105 remained.\n",
            "100% 622/622 [00:02<00:00, 290.23it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 622 remained.\n",
            "100% 428/428 [00:01<00:00, 329.25it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 428 remained.\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/tmp/tmpb3xogpxd --model_prefix=/content/zambezi-voice/nyanja/nya/spm_char_asr_nya --model_type=char --vocab_size=1000 --character_coverage=1.0 --num_threads=2 --unk_id=3 --bos_id=0 --eos_id=2 --pad_id=1\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /tmp/tmpb3xogpxd\n",
            "  input_format: \n",
            "  model_prefix: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya\n",
            "  model_type: CHAR\n",
            "  vocab_size: 1000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 2\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 3\n",
            "  bos_id: 0\n",
            "  eos_id: 2\n",
            "  pad_id: 1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: /tmp/tmpb3xogpxd\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 8105 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=797143\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=74\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 8105 sentences.\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya.vocab\n"
          ]
        }
      ],
      "source": [
        "# Prepare ASR dataset\n",
        "%cd /content/fairseq\n",
        "!python examples/speech_to_text/prep_asr_data.py \\\n",
        "  --data-root /content/zambezi-voice/nyanja \\\n",
        "  --vocab-type char \\\n",
        "  --src-lang nya"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 4: TRAIN `S2T_TRANSFORMER` ASR MODEL"
      ],
      "metadata": {
        "id": "AVbEl-Ksuxwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Set `max-epoch`=`500`"
      ],
      "metadata": {
        "id": "IL66nnmgv2Eq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ph9CSRp4nl",
        "outputId": "95e0322e-7718-4b87-f505-9cb943febe96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 18:11:11 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': '/content/zambezi-voice/nyanja/nya/nya_asr_tensorboard', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_asr_nya', 'valid_subset': 'dev_asr_nya', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/zambezi-voice/nyanja/nya/nya_asr_checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 100, 'save_interval_updates': 5000, 'keep_interval_updates': 5, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='s2t_transformer_m', activation_dropout=0.15, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='s2t_transformer_m', attention_dropout=0.15, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, combine_valid_subsets=None, config_yaml='config_asr_nya.yaml', continue_once=None, conv_channels=1024, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='/content/zambezi-voice/nyanja/nya', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.15, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_freezing_updates=0, encoder_layers=12, encoder_normalize_before=True, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.002], lr_scheduler='inverse_sqrt', max_epoch=100, max_source_positions=6000, max_target_positions=1024, max_tokens=50000, max_tokens_valid=50000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=4, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/zambezi-voice/nyanja/nya/nya_asr_checkpoints', save_interval=100, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='speech_to_text', tensorboard_logdir='/content/zambezi-voice/nyanja/nya/nya_asr_tensorboard', threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train_asr_nya', unk=3, update_epoch_batch_itr=False, update_freq=[8], update_ordered_indices_seed=False, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='dev_asr_nya', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=10000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': Namespace(_name='speech_to_text', activation_dropout=0.15, activation_fn='relu', adam_betas=(0.9, 0.999), adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='s2t_transformer_m', attention_dropout=0.15, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=10.0, combine_valid_subsets=None, config_yaml='config_asr_nya.yaml', continue_once=None, conv_channels=1024, conv_kernel_sizes='5,5', cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='/content/zambezi-voice/nyanja/nya', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0.0, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.15, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_freezing_updates=0, encoder_layers=12, encoder_normalize_before=True, eos=2, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=5, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.002], lr_scheduler='inverse_sqrt', max_epoch=100, max_source_positions=6000, max_target_positions=1024, max_tokens=50000, max_tokens_valid=50000, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=4, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/content/zambezi-voice/nyanja/nya/nya_asr_checkpoints', save_interval=100, save_interval_updates=5000, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='speech_to_text', tensorboard_logdir='/content/zambezi-voice/nyanja/nya/nya_asr_tensorboard', threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train_asr_nya', unk=3, update_epoch_batch_itr=False, update_freq=[8], update_ordered_indices_seed=False, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='dev_asr_nya', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=10000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-02-06 18:11:11 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm_char_asr_nya.txt): 78\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | S2TTransformerModel(\n",
            "  (encoder): S2TTransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (subsample): Conv1dSubsampler(\n",
            "      (conv_layers): ModuleList(\n",
            "        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "        (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoderScriptable(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): Embedding(78, 512, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (output_projection): Linear(in_features=512, out_features=78, bias=False)\n",
            "  )\n",
            ")\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | task: SpeechToTextTask\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | model: S2TTransformerModel\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | num. shared model params: 103,971,840 (num. trained: 103,971,840)\n",
            "2023-02-06 18:11:12 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2023-02-06 18:11:12 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2023-02-06 18:11:12 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "2023-02-06 18:11:12 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev_asr_nya' has 0.00% OOV\n",
            "2023-02-06 18:11:12 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"dev_asr_nya\", n_samples=622, prepend_tgt_lang_tag=False, shuffle=False, transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "), n_frames_per_step=1\n",
            "2023-02-06 18:11:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-02-06 18:11:16 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n",
            "2023-02-06 18:11:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2023-02-06 18:11:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2023-02-06 18:11:16 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None\n",
            "2023-02-06 18:11:16 | INFO | fairseq.trainer | Preparing to load checkpoint /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_last.pt\n",
            "2023-02-06 18:11:16 | INFO | fairseq.trainer | No existing checkpoint found /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_last.pt\n",
            "2023-02-06 18:11:16 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2023-02-06 18:11:16 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2023-02-06 18:11:16 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "2023-02-06 18:11:16 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train_asr_nya' has 0.00% OOV\n",
            "2023-02-06 18:11:16 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"train_asr_nya\", n_samples=8_105, prepend_tgt_lang_tag=False, shuffle=False, transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), n_frames_per_step=1\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-02-06 18:11:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 001:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:11:16 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2023-02-06 18:11:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2023-02-06 18:11:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "epoch 001:   5% 1/22 [00:06<02:26,  6.96s/it]2023-02-06 18:11:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "epoch 001:   9% 2/22 [00:10<01:38,  4.93s/it]2023-02-06 18:11:30 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "epoch 001:  14% 3/22 [00:13<01:16,  4.00s/it]2023-02-06 18:11:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n",
            "epoch 001:  18% 4/22 [00:16<01:04,  3.57s/it]2023-02-06 18:11:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "epoch 001:  95% 21/22 [00:47<00:01,  1.44s/it]2023-02-06 18:12:04 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:13,  1.34it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:06,  2.56it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:04,  3.44it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.19it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.19it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.24it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  9.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 15.64it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 17.90it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:12:09 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2023-02-06 18:12:10 | INFO | dev_asr_nya | epoch 001 | valid on 'dev_asr_nya' subset | loss 5.482 | nll_loss 5.236 | ppl 37.7 | wps 45486.8 | wpb 3219.1 | bsz 32.7 | num_updates 17\n",
            "2023-02-06 18:12:11 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2023-02-06 18:12:11 | INFO | train | epoch 001 | loss 6.324 | nll_loss 6.243 | ppl 75.75 | wps 18520.6 | ups 0.51 | wpb 36480.1 | bsz 373.2 | num_updates 17 | lr 3.4e-06 | gnorm 10.136 | clip 58.8 | loss_scale 4 | train_wall 47 | gb_free 7.4 | wall 55\n",
            "2023-02-06 18:12:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 002:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:12:11 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2023-02-06 18:12:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002:  95% 21/22 [00:35<00:01,  1.51s/it]2023-02-06 18:12:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  4.15it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  5.04it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.21it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  6.26it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.15it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:01,  6.56it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.60it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  9.18it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.24it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.12it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.36it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:12:49 | INFO | dev_asr_nya | epoch 002 | valid on 'dev_asr_nya' subset | loss 4.699 | nll_loss 4.333 | ppl 20.15 | wps 41213.8 | wpb 3219.1 | bsz 32.7 | num_updates 39\n",
            "2023-02-06 18:12:49 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2023-02-06 18:12:49 | INFO | train | epoch 002 | loss 5.088 | nll_loss 4.805 | ppl 27.96 | wps 20865.7 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 39 | lr 7.8e-06 | gnorm 3.126 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5 | wall 94\n",
            "2023-02-06 18:12:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 003:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:12:49 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2023-02-06 18:12:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003:  95% 21/22 [00:35<00:01,  1.45s/it]2023-02-06 18:13:26 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  4.46it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.70it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.50it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  6.57it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.39it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.29it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  6.00it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 10.43it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 13.86it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.44it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.12it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:13:27 | INFO | dev_asr_nya | epoch 003 | valid on 'dev_asr_nya' subset | loss 4.399 | nll_loss 3.96 | ppl 15.56 | wps 40528.2 | wpb 3219.1 | bsz 32.7 | num_updates 61\n",
            "2023-02-06 18:13:27 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2023-02-06 18:13:27 | INFO | train | epoch 003 | loss 4.627 | nll_loss 4.253 | ppl 19.07 | wps 21087.5 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 61 | lr 1.22e-05 | gnorm 1.249 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.8 | wall 132\n",
            "2023-02-06 18:13:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 004:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:13:28 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2023-02-06 18:13:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004:  95% 21/22 [00:34<00:01,  1.39s/it]2023-02-06 18:14:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.25it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.87it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.46it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.17it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.38it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.68it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.08it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:02,  4.91it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  5.69it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00,  8.57it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 11.90it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 14.69it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:14:06 | INFO | dev_asr_nya | epoch 004 | valid on 'dev_asr_nya' subset | loss 3.944 | nll_loss 3.402 | ppl 10.57 | wps 29356.3 | wpb 3219.1 | bsz 32.7 | num_updates 83\n",
            "2023-02-06 18:14:06 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2023-02-06 18:14:06 | INFO | train | epoch 004 | loss 4.286 | nll_loss 3.843 | ppl 14.35 | wps 20982.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 83 | lr 1.66e-05 | gnorm 0.957 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.5 | wall 170\n",
            "2023-02-06 18:14:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 005:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:14:06 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2023-02-06 18:14:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005:  95% 21/22 [00:34<00:01,  1.47s/it, loss=4.824, nll_loss=4.48, ppl=22.32, wps=20636, ups=0.57, wpb=36538.7, bsz=369, num_updates=100, lr=2e-05, gnorm=3.02, clip=10, loss_scale=4, train_wall=180, gb_free=5.7, wall=199]2023-02-06 18:14:42 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.85it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.08it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.96it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.92it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.12it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:01,  6.57it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.22it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.36it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 16.10it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.44it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:14:43 | INFO | dev_asr_nya | epoch 005 | valid on 'dev_asr_nya' subset | loss 3.705 | nll_loss 3.074 | ppl 8.42 | wps 45863.1 | wpb 3219.1 | bsz 32.7 | num_updates 105\n",
            "2023-02-06 18:14:43 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2023-02-06 18:14:43 | INFO | train | epoch 005 | loss 3.916 | nll_loss 3.389 | ppl 10.47 | wps 21402.6 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 105 | lr 2.1e-05 | gnorm 0.682 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 7.8 | wall 208\n",
            "2023-02-06 18:14:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 006:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:14:43 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2023-02-06 18:14:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 006:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:15:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.83it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.14it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.84it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.05it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.54it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.37it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.58it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.77it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 16.56it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.72it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:15:20 | INFO | dev_asr_nya | epoch 006 | valid on 'dev_asr_nya' subset | loss 3.623 | nll_loss 2.985 | ppl 7.92 | wps 44913.3 | wpb 3219.1 | bsz 32.7 | num_updates 127\n",
            "2023-02-06 18:15:20 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2023-02-06 18:15:20 | INFO | train | epoch 006 | loss 3.752 | nll_loss 3.183 | ppl 9.08 | wps 21610.2 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 127 | lr 2.54e-05 | gnorm 0.45 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 5.7 | wall 245\n",
            "2023-02-06 18:15:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 007:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:15:21 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2023-02-06 18:15:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 007:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 18:15:56 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.54it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.55it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.40it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.67it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.28it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.99it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.00it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  6.82it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00,  9.22it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 12.55it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 14.97it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:15:58 | INFO | dev_asr_nya | epoch 007 | valid on 'dev_asr_nya' subset | loss 3.575 | nll_loss 2.936 | ppl 7.65 | wps 32853.7 | wpb 3219.1 | bsz 32.7 | num_updates 149\n",
            "2023-02-06 18:15:58 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2023-02-06 18:15:58 | INFO | train | epoch 007 | loss 3.682 | nll_loss 3.103 | ppl 8.59 | wps 21378.5 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 149 | lr 2.98e-05 | gnorm 0.432 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 8.4 | wall 282\n",
            "2023-02-06 18:15:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 008:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:15:58 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2023-02-06 18:15:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 008:  95% 21/22 [00:35<00:01,  1.46s/it]2023-02-06 18:16:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.04it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.34it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.74it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.02it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.32it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.93it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.39it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.90it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.49it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.56it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:16:36 | INFO | dev_asr_nya | epoch 008 | valid on 'dev_asr_nya' subset | loss 3.539 | nll_loss 2.899 | ppl 7.46 | wps 43424.2 | wpb 3219.1 | bsz 32.7 | num_updates 171\n",
            "2023-02-06 18:16:36 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2023-02-06 18:16:36 | INFO | train | epoch 008 | loss 3.636 | nll_loss 3.053 | ppl 8.3 | wps 20976.7 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 171 | lr 3.42e-05 | gnorm 0.393 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 321\n",
            "2023-02-06 18:16:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 009:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:16:36 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2023-02-06 18:16:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 009:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:17:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.95it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.09it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.65it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.94it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.24it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.70it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.89it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.01it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.30it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.60it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:17:14 | INFO | dev_asr_nya | epoch 009 | valid on 'dev_asr_nya' subset | loss 3.509 | nll_loss 2.867 | ppl 7.29 | wps 44163.4 | wpb 3219.1 | bsz 32.7 | num_updates 193\n",
            "2023-02-06 18:17:14 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2023-02-06 18:17:14 | INFO | train | epoch 009 | loss 3.599 | nll_loss 3.013 | ppl 8.08 | wps 21595.4 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 193 | lr 3.86e-05 | gnorm 0.44 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 6.8 | wall 358\n",
            "2023-02-06 18:17:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 010:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:17:14 | INFO | fairseq.trainer | begin training epoch 10\n",
            "2023-02-06 18:17:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 010:  95% 21/22 [00:34<00:01,  1.37s/it, loss=3.669, nll_loss=3.09, ppl=8.52, wps=21241.9, ups=0.58, wpb=36514.7, bsz=368.3, num_updates=200, lr=4e-05, gnorm=0.437, clip=0, loss_scale=4, train_wall=157, gb_free=7.6, wall=371]2023-02-06 18:17:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.35it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.24it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.08it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.53it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.31it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  3.95it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.50it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  6.90it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00,  9.40it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 12.49it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 14.97it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:17:52 | INFO | dev_asr_nya | epoch 010 | valid on 'dev_asr_nya' subset | loss 3.478 | nll_loss 2.833 | ppl 7.12 | wps 31712.4 | wpb 3219.1 | bsz 32.7 | num_updates 215\n",
            "2023-02-06 18:17:52 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2023-02-06 18:17:52 | INFO | train | epoch 010 | loss 3.567 | nll_loss 2.977 | ppl 7.87 | wps 21125.7 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 215 | lr 4.3e-05 | gnorm 0.463 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 396\n",
            "2023-02-06 18:17:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 011:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:17:52 | INFO | fairseq.trainer | begin training epoch 11\n",
            "2023-02-06 18:17:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 011:  95% 21/22 [00:34<00:01,  1.46s/it]2023-02-06 18:18:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.17it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.46it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.31it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.46it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.84it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.90it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.01it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.21it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 16.10it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:18:29 | INFO | dev_asr_nya | epoch 011 | valid on 'dev_asr_nya' subset | loss 3.449 | nll_loss 2.804 | ppl 6.98 | wps 44344.7 | wpb 3219.1 | bsz 32.7 | num_updates 237\n",
            "2023-02-06 18:18:29 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2023-02-06 18:18:29 | INFO | train | epoch 011 | loss 3.536 | nll_loss 2.942 | ppl 7.69 | wps 21552.5 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 237 | lr 4.74e-05 | gnorm 0.418 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 7.3 | wall 433\n",
            "2023-02-06 18:18:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 012:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:18:29 | INFO | fairseq.trainer | begin training epoch 12\n",
            "2023-02-06 18:18:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 012:  95% 21/22 [00:34<00:01,  1.35s/it]2023-02-06 18:19:04 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.65it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.02it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.36it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.80it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.72it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.38it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.47it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:02,  4.76it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  7.15it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:02<00:00, 10.77it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 12.64it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.32it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:19:07 | INFO | dev_asr_nya | epoch 012 | valid on 'dev_asr_nya' subset | loss 3.425 | nll_loss 2.774 | ppl 6.84 | wps 30649.2 | wpb 3219.1 | bsz 32.7 | num_updates 259\n",
            "2023-02-06 18:19:07 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2023-02-06 18:19:07 | INFO | train | epoch 012 | loss 3.507 | nll_loss 2.91 | ppl 7.51 | wps 21152.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 259 | lr 5.18e-05 | gnorm 0.424 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 8 | wall 471\n",
            "2023-02-06 18:19:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 013:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:19:07 | INFO | fairseq.trainer | begin training epoch 13\n",
            "2023-02-06 18:19:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 013:  95% 21/22 [00:35<00:01,  1.50s/it]2023-02-06 18:19:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  3.88it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.91it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.60it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.27it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.77it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.34it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 10.74it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.12it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.67it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:19:45 | INFO | dev_asr_nya | epoch 013 | valid on 'dev_asr_nya' subset | loss 3.398 | nll_loss 2.739 | ppl 6.68 | wps 42116.5 | wpb 3219.1 | bsz 32.7 | num_updates 281\n",
            "2023-02-06 18:19:45 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2023-02-06 18:19:45 | INFO | train | epoch 013 | loss 3.477 | nll_loss 2.876 | ppl 7.34 | wps 21013.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 281 | lr 5.62e-05 | gnorm 0.459 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 509\n",
            "2023-02-06 18:19:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 014:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:19:45 | INFO | fairseq.trainer | begin training epoch 14\n",
            "2023-02-06 18:19:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 014:  95% 21/22 [00:34<00:01,  1.40s/it, loss=3.504, nll_loss=2.906, ppl=7.5, wps=21389.7, ups=0.59, wpb=36527.5, bsz=369.1, num_updates=300, lr=6e-05, gnorm=0.472, clip=0, loss_scale=4, train_wall=158, gb_free=6.5, wall=542]2023-02-06 18:20:21 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.38it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.29it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.33it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.05it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.34it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.46it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.21it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.03it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:20:22 | INFO | dev_asr_nya | epoch 014 | valid on 'dev_asr_nya' subset | loss 3.364 | nll_loss 2.711 | ppl 6.55 | wps 42697.5 | wpb 3219.1 | bsz 32.7 | num_updates 303\n",
            "2023-02-06 18:20:22 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2023-02-06 18:20:22 | INFO | train | epoch 014 | loss 3.452 | nll_loss 2.846 | ppl 7.19 | wps 21502.2 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 303 | lr 6.06e-05 | gnorm 0.633 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 8.1 | wall 547\n",
            "2023-02-06 18:20:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 015:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:20:22 | INFO | fairseq.trainer | begin training epoch 15\n",
            "2023-02-06 18:20:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 015:  95% 21/22 [00:35<00:01,  1.42s/it]2023-02-06 18:20:59 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.33it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.08it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.67it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.48it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.80it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.54it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.03it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.08it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.02it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.64it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:21:01 | INFO | dev_asr_nya | epoch 015 | valid on 'dev_asr_nya' subset | loss 3.339 | nll_loss 2.667 | ppl 6.35 | wps 39424.4 | wpb 3219.1 | bsz 32.7 | num_updates 325\n",
            "2023-02-06 18:21:01 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
            "2023-02-06 18:21:01 | INFO | train | epoch 015 | loss 3.423 | nll_loss 2.813 | ppl 7.03 | wps 20841.5 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 325 | lr 6.5e-05 | gnorm 0.656 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 7.9 | wall 585\n",
            "2023-02-06 18:21:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 016:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:21:01 | INFO | fairseq.trainer | begin training epoch 16\n",
            "2023-02-06 18:21:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 016:  95% 21/22 [00:34<00:01,  1.45s/it]2023-02-06 18:21:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.95it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.15it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.47it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.82it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.41it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.72it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.92it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.08it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.42it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.76it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:21:38 | INFO | dev_asr_nya | epoch 016 | valid on 'dev_asr_nya' subset | loss 3.294 | nll_loss 2.623 | ppl 6.16 | wps 43671.3 | wpb 3219.1 | bsz 32.7 | num_updates 347\n",
            "2023-02-06 18:21:38 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2023-02-06 18:21:38 | INFO | train | epoch 016 | loss 3.393 | nll_loss 2.778 | ppl 6.86 | wps 21623.3 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 347 | lr 6.94e-05 | gnorm 0.678 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 7.5 | wall 622\n",
            "2023-02-06 18:21:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 017:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:21:38 | INFO | fairseq.trainer | begin training epoch 17\n",
            "2023-02-06 18:21:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 017:  95% 21/22 [00:34<00:01,  1.38s/it]2023-02-06 18:22:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:10,  1.66it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:07,  2.38it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:05,  2.73it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.03it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.61it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.04it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.53it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:02<00:00, 11.80it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 14.34it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.32it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:22:16 | INFO | dev_asr_nya | epoch 017 | valid on 'dev_asr_nya' subset | loss 3.255 | nll_loss 2.582 | ppl 5.99 | wps 34396.9 | wpb 3219.1 | bsz 32.7 | num_updates 369\n",
            "2023-02-06 18:22:16 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2023-02-06 18:22:16 | INFO | train | epoch 017 | loss 3.362 | nll_loss 2.742 | ppl 6.69 | wps 21037.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 369 | lr 7.38e-05 | gnorm 0.816 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.5 | wall 661\n",
            "2023-02-06 18:22:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 018:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:22:16 | INFO | fairseq.trainer | begin training epoch 18\n",
            "2023-02-06 18:22:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 018:  95% 21/22 [00:35<00:01,  1.50s/it]2023-02-06 18:22:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.96it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.33it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.70it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.74it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.11it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.94it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 12.20it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.24it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.53it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 20.01it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:22:54 | INFO | dev_asr_nya | epoch 018 | valid on 'dev_asr_nya' subset | loss 3.216 | nll_loss 2.535 | ppl 5.8 | wps 44542.6 | wpb 3219.1 | bsz 32.7 | num_updates 391\n",
            "2023-02-06 18:22:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2023-02-06 18:22:54 | INFO | train | epoch 018 | loss 3.325 | nll_loss 2.699 | ppl 6.49 | wps 21098.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 391 | lr 7.82e-05 | gnorm 0.544 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 699\n",
            "2023-02-06 18:22:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 019:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:22:54 | INFO | fairseq.trainer | begin training epoch 19\n",
            "2023-02-06 18:22:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 019:  95% 21/22 [00:35<00:01,  1.43s/it, loss=3.37, nll_loss=2.752, ppl=6.73, wps=21054.6, ups=0.58, wpb=36436.7, bsz=367.7, num_updates=400, lr=8e-05, gnorm=0.656, clip=0, loss_scale=4, train_wall=158, gb_free=8, wall=715]2023-02-06 18:23:30 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.43it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  5.22it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.63it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.52it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.36it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.51it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.82it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.49it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 12.09it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 13.79it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 16.30it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:23:32 | INFO | dev_asr_nya | epoch 019 | valid on 'dev_asr_nya' subset | loss 3.184 | nll_loss 2.494 | ppl 5.63 | wps 37462 | wpb 3219.1 | bsz 32.7 | num_updates 413\n",
            "2023-02-06 18:23:32 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2023-02-06 18:23:32 | INFO | train | epoch 019 | loss 3.289 | nll_loss 2.658 | ppl 6.31 | wps 21150 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 413 | lr 8.26e-05 | gnorm 0.557 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 737\n",
            "2023-02-06 18:23:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 020:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:23:32 | INFO | fairseq.trainer | begin training epoch 20\n",
            "2023-02-06 18:23:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 020:  95% 21/22 [00:35<00:01,  1.47s/it]2023-02-06 18:24:09 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.11it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.22it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.19it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.95it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:01,  6.56it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.93it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.01it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.28it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.76it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:24:11 | INFO | dev_asr_nya | epoch 020 | valid on 'dev_asr_nya' subset | loss 3.123 | nll_loss 2.427 | ppl 5.38 | wps 44256.1 | wpb 3219.1 | bsz 32.7 | num_updates 435\n",
            "2023-02-06 18:24:11 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2023-02-06 18:24:11 | INFO | train | epoch 020 | loss 3.252 | nll_loss 2.614 | ppl 6.12 | wps 21014 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 435 | lr 8.7e-05 | gnorm 0.571 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 775\n",
            "2023-02-06 18:24:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 021:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:24:11 | INFO | fairseq.trainer | begin training epoch 21\n",
            "2023-02-06 18:24:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 021:  95% 21/22 [00:35<00:01,  1.44s/it]2023-02-06 18:24:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.79it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.21it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.84it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.43it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.09it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.45it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.51it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.68it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.04it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.61it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:24:48 | INFO | dev_asr_nya | epoch 021 | valid on 'dev_asr_nya' subset | loss 3.079 | nll_loss 2.37 | ppl 5.17 | wps 44622.1 | wpb 3219.1 | bsz 32.7 | num_updates 457\n",
            "2023-02-06 18:24:48 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2023-02-06 18:24:48 | INFO | train | epoch 021 | loss 3.208 | nll_loss 2.562 | ppl 5.91 | wps 21243.3 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 457 | lr 9.14e-05 | gnorm 0.508 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8 | wall 813\n",
            "2023-02-06 18:24:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 022:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:24:48 | INFO | fairseq.trainer | begin training epoch 22\n",
            "2023-02-06 18:24:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 022:  95% 21/22 [00:34<00:01,  1.39s/it]2023-02-06 18:25:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.69it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.41it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.17it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.29it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.85it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  3.86it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.48it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  6.73it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 10.18it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 12.95it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.12it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:25:27 | INFO | dev_asr_nya | epoch 022 | valid on 'dev_asr_nya' subset | loss 3.02 | nll_loss 2.301 | ppl 4.93 | wps 31048.6 | wpb 3219.1 | bsz 32.7 | num_updates 479\n",
            "2023-02-06 18:25:27 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2023-02-06 18:25:27 | INFO | train | epoch 022 | loss 3.162 | nll_loss 2.509 | ppl 5.69 | wps 20937.7 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 479 | lr 9.58e-05 | gnorm 0.441 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 851\n",
            "2023-02-06 18:25:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 023:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:25:27 | INFO | fairseq.trainer | begin training epoch 23\n",
            "2023-02-06 18:25:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 023:  95% 21/22 [00:35<00:01,  1.49s/it, loss=3.2, nll_loss=2.553, ppl=5.87, wps=21310.4, ups=0.58, wpb=36563.9, bsz=367.9, num_updates=500, lr=0.0001, gnorm=0.52, clip=0, loss_scale=4, train_wall=159, gb_free=8, wall=886]2023-02-06 18:26:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.06it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.12it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.12it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.92it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.90it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.76it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  7.95it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.05it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.06it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.61it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:26:05 | INFO | dev_asr_nya | epoch 023 | valid on 'dev_asr_nya' subset | loss 2.969 | nll_loss 2.245 | ppl 4.74 | wps 42570.7 | wpb 3219.1 | bsz 32.7 | num_updates 501\n",
            "2023-02-06 18:26:05 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2023-02-06 18:26:05 | INFO | train | epoch 023 | loss 3.117 | nll_loss 2.456 | ppl 5.49 | wps 21198.9 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 501 | lr 0.0001002 | gnorm 0.498 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.8 | wall 889\n",
            "2023-02-06 18:26:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 024:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:26:05 | INFO | fairseq.trainer | begin training epoch 24\n",
            "2023-02-06 18:26:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 024:  95% 21/22 [00:34<00:01,  1.34s/it]2023-02-06 18:26:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:08,  2.22it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.18it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.57it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.89it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.23it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.40it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.57it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:02,  5.34it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.03it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:02<00:00, 10.58it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.67it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:26:43 | INFO | dev_asr_nya | epoch 024 | valid on 'dev_asr_nya' subset | loss 2.92 | nll_loss 2.182 | ppl 4.54 | wps 30721.9 | wpb 3219.1 | bsz 32.7 | num_updates 523\n",
            "2023-02-06 18:26:43 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2023-02-06 18:26:43 | INFO | train | epoch 024 | loss 3.071 | nll_loss 2.402 | ppl 5.28 | wps 20950.1 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 523 | lr 0.0001046 | gnorm 0.547 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 927\n",
            "2023-02-06 18:26:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 025:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:26:43 | INFO | fairseq.trainer | begin training epoch 25\n",
            "2023-02-06 18:26:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 025:  95% 21/22 [00:35<00:01,  1.45s/it]2023-02-06 18:27:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.64it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.04it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.45it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.01it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.75it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.70it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.71it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.86it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.22it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.87it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:27:22 | INFO | dev_asr_nya | epoch 025 | valid on 'dev_asr_nya' subset | loss 2.88 | nll_loss 2.136 | ppl 4.39 | wps 44316.8 | wpb 3219.1 | bsz 32.7 | num_updates 545\n",
            "2023-02-06 18:27:22 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
            "2023-02-06 18:27:22 | INFO | train | epoch 025 | loss 3.026 | nll_loss 2.35 | ppl 5.1 | wps 20778.6 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 545 | lr 0.000109 | gnorm 0.589 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.6 | wall 966\n",
            "2023-02-06 18:27:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 026:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:27:22 | INFO | fairseq.trainer | begin training epoch 26\n",
            "2023-02-06 18:27:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 026:  95% 21/22 [00:34<00:01,  1.37s/it]2023-02-06 18:27:58 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.97it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.85it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.34it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.76it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.14it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.13it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.97it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.45it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.91it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.86it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:27:59 | INFO | dev_asr_nya | epoch 026 | valid on 'dev_asr_nya' subset | loss 2.819 | nll_loss 2.062 | ppl 4.18 | wps 42798.9 | wpb 3219.1 | bsz 32.7 | num_updates 567\n",
            "2023-02-06 18:27:59 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
            "2023-02-06 18:27:59 | INFO | train | epoch 026 | loss 2.985 | nll_loss 2.302 | ppl 4.93 | wps 21318 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 567 | lr 0.0001134 | gnorm 0.654 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 1004\n",
            "2023-02-06 18:27:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 027:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:27:59 | INFO | fairseq.trainer | begin training epoch 27\n",
            "2023-02-06 18:27:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 027:  95% 21/22 [00:35<00:01,  1.44s/it]2023-02-06 18:28:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.96it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.57it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.41it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.40it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.61it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.95it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.30it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.45it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.43it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:28:38 | INFO | dev_asr_nya | epoch 027 | valid on 'dev_asr_nya' subset | loss 2.793 | nll_loss 2.016 | ppl 4.05 | wps 43302.5 | wpb 3219.1 | bsz 32.7 | num_updates 589\n",
            "2023-02-06 18:28:38 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
            "2023-02-06 18:28:38 | INFO | train | epoch 027 | loss 2.948 | nll_loss 2.259 | ppl 4.79 | wps 20810.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 589 | lr 0.0001178 | gnorm 0.738 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.5 | wall 1042\n",
            "2023-02-06 18:28:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 028:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:28:38 | INFO | fairseq.trainer | begin training epoch 28\n",
            "2023-02-06 18:28:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 028:  95% 21/22 [00:34<00:01,  1.43s/it, loss=2.997, nll_loss=2.317, ppl=4.98, wps=20880.2, ups=0.57, wpb=36595.6, bsz=370.9, num_updates=600, lr=0.00012, gnorm=0.619, clip=0, loss_scale=4, train_wall=159, gb_free=7.7, wall=1062]2023-02-06 18:29:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:03,  5.64it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.50it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.75it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.47it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.14it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.60it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.67it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.83it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.67it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.18it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:29:16 | INFO | dev_asr_nya | epoch 028 | valid on 'dev_asr_nya' subset | loss 2.745 | nll_loss 1.968 | ppl 3.91 | wps 38679.8 | wpb 3219.1 | bsz 32.7 | num_updates 611\n",
            "2023-02-06 18:29:16 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
            "2023-02-06 18:29:16 | INFO | train | epoch 028 | loss 2.902 | nll_loss 2.206 | ppl 4.61 | wps 21276.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 611 | lr 0.0001222 | gnorm 0.503 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 1080\n",
            "2023-02-06 18:29:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 029:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:29:16 | INFO | fairseq.trainer | begin training epoch 29\n",
            "2023-02-06 18:29:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 029:  95% 21/22 [00:35<00:01,  1.42s/it]2023-02-06 18:29:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.36it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.17it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:05,  2.89it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.24it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.77it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.58it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  7.21it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00,  9.53it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 12.70it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 14.30it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:29:54 | INFO | dev_asr_nya | epoch 029 | valid on 'dev_asr_nya' subset | loss 2.71 | nll_loss 1.926 | ppl 3.8 | wps 32480.7 | wpb 3219.1 | bsz 32.7 | num_updates 633\n",
            "2023-02-06 18:29:54 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
            "2023-02-06 18:29:54 | INFO | train | epoch 029 | loss 2.865 | nll_loss 2.162 | ppl 4.48 | wps 20914.6 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 633 | lr 0.0001266 | gnorm 0.577 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 1118\n",
            "2023-02-06 18:29:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 030:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:29:54 | INFO | fairseq.trainer | begin training epoch 30\n",
            "2023-02-06 18:29:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 030:  95% 21/22 [00:35<00:01,  1.52s/it]2023-02-06 18:30:30 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.07it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.94it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.52it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.02it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.39it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.30it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.93it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.39it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.91it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:30:32 | INFO | dev_asr_nya | epoch 030 | valid on 'dev_asr_nya' subset | loss 2.668 | nll_loss 1.872 | ppl 3.66 | wps 43644.2 | wpb 3219.1 | bsz 32.7 | num_updates 655\n",
            "2023-02-06 18:30:32 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
            "2023-02-06 18:30:32 | INFO | train | epoch 030 | loss 2.83 | nll_loss 2.121 | ppl 4.35 | wps 21113.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 655 | lr 0.000131 | gnorm 0.609 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 1156\n",
            "2023-02-06 18:30:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 031:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:30:32 | INFO | fairseq.trainer | begin training epoch 31\n",
            "2023-02-06 18:30:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 031:  95% 21/22 [00:34<00:01,  1.38s/it]2023-02-06 18:31:08 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.33it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.08it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.48it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.80it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.91it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.46it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.30it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.01it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.64it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 14.41it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.44it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:31:10 | INFO | dev_asr_nya | epoch 031 | valid on 'dev_asr_nya' subset | loss 2.659 | nll_loss 1.861 | ppl 3.63 | wps 32899.7 | wpb 3219.1 | bsz 32.7 | num_updates 677\n",
            "2023-02-06 18:31:10 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
            "2023-02-06 18:31:10 | INFO | train | epoch 031 | loss 2.799 | nll_loss 2.085 | ppl 4.24 | wps 21142.5 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 677 | lr 0.0001354 | gnorm 0.648 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 1194\n",
            "2023-02-06 18:31:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 032:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:31:10 | INFO | fairseq.trainer | begin training epoch 32\n",
            "2023-02-06 18:31:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 032:  95% 21/22 [00:35<00:01,  1.48s/it]2023-02-06 18:31:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.83it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.65it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.93it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.57it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  8.20it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 12.50it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.53it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.79it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.99it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:31:49 | INFO | dev_asr_nya | epoch 032 | valid on 'dev_asr_nya' subset | loss 2.604 | nll_loss 1.795 | ppl 3.47 | wps 44331.6 | wpb 3219.1 | bsz 32.7 | num_updates 699\n",
            "2023-02-06 18:31:49 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
            "2023-02-06 18:31:49 | INFO | train | epoch 032 | loss 2.766 | nll_loss 2.047 | ppl 4.13 | wps 20936.4 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 699 | lr 0.0001398 | gnorm 0.594 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 1233\n",
            "2023-02-06 18:31:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 033:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:31:49 | INFO | fairseq.trainer | begin training epoch 33\n",
            "2023-02-06 18:31:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 033:  95% 21/22 [00:34<00:01,  1.41s/it, loss=2.822, nll_loss=2.112, ppl=4.32, wps=20949.9, ups=0.57, wpb=36458.8, bsz=367.5, num_updates=700, lr=0.00014, gnorm=0.591, clip=0, loss_scale=4, train_wall=158, gb_free=7, wall=1236]2023-02-06 18:32:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.09it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.65it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.06it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.54it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.68it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.12it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.76it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.48it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:32:26 | INFO | dev_asr_nya | epoch 033 | valid on 'dev_asr_nya' subset | loss 2.567 | nll_loss 1.756 | ppl 3.38 | wps 41894.4 | wpb 3219.1 | bsz 32.7 | num_updates 721\n",
            "2023-02-06 18:32:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
            "2023-02-06 18:32:26 | INFO | train | epoch 033 | loss 2.731 | nll_loss 2.006 | ppl 4.02 | wps 21423.4 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 721 | lr 0.0001442 | gnorm 0.486 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 1270\n",
            "2023-02-06 18:32:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 034:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:32:26 | INFO | fairseq.trainer | begin training epoch 34\n",
            "2023-02-06 18:32:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 034:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 18:33:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.25it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.42it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.85it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.99it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.57it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.21it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.15it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.88it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 10.33it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 13.40it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 16.08it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:33:04 | INFO | dev_asr_nya | epoch 034 | valid on 'dev_asr_nya' subset | loss 2.558 | nll_loss 1.74 | ppl 3.34 | wps 34088.2 | wpb 3219.1 | bsz 32.7 | num_updates 743\n",
            "2023-02-06 18:33:04 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
            "2023-02-06 18:33:04 | INFO | train | epoch 034 | loss 2.709 | nll_loss 1.98 | ppl 3.94 | wps 21012.6 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 743 | lr 0.0001486 | gnorm 0.674 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 1309\n",
            "2023-02-06 18:33:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 035:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:33:04 | INFO | fairseq.trainer | begin training epoch 35\n",
            "2023-02-06 18:33:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 035:  95% 21/22 [00:34<00:01,  1.50s/it]2023-02-06 18:33:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.50it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.19it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.99it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.97it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.24it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.01it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.83it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.34it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.88it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.88it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:33:42 | INFO | dev_asr_nya | epoch 035 | valid on 'dev_asr_nya' subset | loss 2.533 | nll_loss 1.71 | ppl 3.27 | wps 42982.6 | wpb 3219.1 | bsz 32.7 | num_updates 765\n",
            "2023-02-06 18:33:42 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
            "2023-02-06 18:33:42 | INFO | train | epoch 035 | loss 2.681 | nll_loss 1.947 | ppl 3.86 | wps 21305.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 765 | lr 0.000153 | gnorm 0.572 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8 | wall 1346\n",
            "2023-02-06 18:33:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 036:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:33:42 | INFO | fairseq.trainer | begin training epoch 36\n",
            "2023-02-06 18:33:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 036:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:34:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.59it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.08it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.75it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.82it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.02it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.18it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.82it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  5.59it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.38it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:02<00:00, 10.95it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 14.04it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.31it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:34:20 | INFO | dev_asr_nya | epoch 036 | valid on 'dev_asr_nya' subset | loss 2.498 | nll_loss 1.677 | ppl 3.2 | wps 30349.4 | wpb 3219.1 | bsz 32.7 | num_updates 787\n",
            "2023-02-06 18:34:20 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)\n",
            "2023-02-06 18:34:20 | INFO | train | epoch 036 | loss 2.654 | nll_loss 1.916 | ppl 3.77 | wps 20913.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 787 | lr 0.0001574 | gnorm 0.568 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8.3 | wall 1385\n",
            "2023-02-06 18:34:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 037:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:34:20 | INFO | fairseq.trainer | begin training epoch 37\n",
            "2023-02-06 18:34:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 037:  95% 21/22 [00:35<00:01,  1.51s/it, loss=2.687, nll_loss=1.954, ppl=3.87, wps=21173.6, ups=0.58, wpb=36434, bsz=366.3, num_updates=800, lr=0.00016, gnorm=0.569, clip=0, loss_scale=4, train_wall=159, gb_free=7.4, wall=1408]2023-02-06 18:34:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.97it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.34it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.61it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.26it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.48it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.97it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.98it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.18it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 16.06it/s]\u001b[A\n",
            "epoch 037 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.51it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:34:59 | INFO | dev_asr_nya | epoch 037 | valid on 'dev_asr_nya' subset | loss 2.48 | nll_loss 1.649 | ppl 3.14 | wps 43575 | wpb 3219.1 | bsz 32.7 | num_updates 809\n",
            "2023-02-06 18:34:59 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)\n",
            "2023-02-06 18:34:59 | INFO | train | epoch 037 | loss 2.627 | nll_loss 1.884 | ppl 3.69 | wps 21060.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 809 | lr 0.0001618 | gnorm 0.525 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.2 | wall 1423\n",
            "2023-02-06 18:34:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 038:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:34:59 | INFO | fairseq.trainer | begin training epoch 38\n",
            "2023-02-06 18:34:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 038:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:35:34 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.90it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.53it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.32it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.21it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.61it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.23it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.13it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.16it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.84it/s]\u001b[A\n",
            "epoch 038 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.14it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:35:36 | INFO | dev_asr_nya | epoch 038 | valid on 'dev_asr_nya' subset | loss 2.446 | nll_loss 1.611 | ppl 3.06 | wps 44731 | wpb 3219.1 | bsz 32.7 | num_updates 831\n",
            "2023-02-06 18:35:36 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)\n",
            "2023-02-06 18:35:36 | INFO | train | epoch 038 | loss 2.605 | nll_loss 1.859 | ppl 3.63 | wps 21447.7 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 831 | lr 0.0001662 | gnorm 0.545 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8 | wall 1460\n",
            "2023-02-06 18:35:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 039:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:35:36 | INFO | fairseq.trainer | begin training epoch 39\n",
            "2023-02-06 18:35:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 039:  95% 21/22 [00:35<00:01,  1.42s/it]2023-02-06 18:36:13 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.40it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.42it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.73it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.99it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.53it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.39it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.08it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.02it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.03it/s]\u001b[A\n",
            "epoch 039 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.64it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:36:15 | INFO | dev_asr_nya | epoch 039 | valid on 'dev_asr_nya' subset | loss 2.441 | nll_loss 1.595 | ppl 3.02 | wps 38818.5 | wpb 3219.1 | bsz 32.7 | num_updates 853\n",
            "2023-02-06 18:36:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)\n",
            "2023-02-06 18:36:15 | INFO | train | epoch 039 | loss 2.581 | nll_loss 1.831 | ppl 3.56 | wps 20824.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 853 | lr 0.0001706 | gnorm 0.533 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.9 | wall 1499\n",
            "2023-02-06 18:36:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 040:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:36:15 | INFO | fairseq.trainer | begin training epoch 40\n",
            "2023-02-06 18:36:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 040:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 18:36:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.18it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.43it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.99it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.10it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.23it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.57it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.56it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.70it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.10it/s]\u001b[A\n",
            "epoch 040 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.43it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:36:52 | INFO | dev_asr_nya | epoch 040 | valid on 'dev_asr_nya' subset | loss 2.409 | nll_loss 1.56 | ppl 2.95 | wps 43893.6 | wpb 3219.1 | bsz 32.7 | num_updates 875\n",
            "2023-02-06 18:36:52 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)\n",
            "2023-02-06 18:36:52 | INFO | train | epoch 040 | loss 2.557 | nll_loss 1.803 | ppl 3.49 | wps 21514.8 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 875 | lr 0.000175 | gnorm 0.527 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 7 | wall 1536\n",
            "2023-02-06 18:36:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 041:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:36:52 | INFO | fairseq.trainer | begin training epoch 41\n",
            "2023-02-06 18:36:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 041:  95% 21/22 [00:34<00:01,  1.38s/it]2023-02-06 18:37:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:09,  1.95it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:06,  2.63it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:05,  3.04it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.98it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.89it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.49it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.25it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.97it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:02<00:00, 11.62it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 13.43it/s]\u001b[A\n",
            "epoch 041 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 15.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:37:30 | INFO | dev_asr_nya | epoch 041 | valid on 'dev_asr_nya' subset | loss 2.406 | nll_loss 1.556 | ppl 2.94 | wps 32790.8 | wpb 3219.1 | bsz 32.7 | num_updates 897\n",
            "2023-02-06 18:37:30 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)\n",
            "2023-02-06 18:37:30 | INFO | train | epoch 041 | loss 2.535 | nll_loss 1.778 | ppl 3.43 | wps 21035.7 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 897 | lr 0.0001794 | gnorm 0.528 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 1574\n",
            "2023-02-06 18:37:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 042:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:37:30 | INFO | fairseq.trainer | begin training epoch 42\n",
            "2023-02-06 18:37:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 042:  95% 21/22 [00:35<00:01,  1.46s/it, loss=2.573, nll_loss=1.821, ppl=3.53, wps=21079.1, ups=0.58, wpb=36535, bsz=368.6, num_updates=900, lr=0.00018, gnorm=0.533, clip=0, loss_scale=4, train_wall=158, gb_free=6.5, wall=1581]2023-02-06 18:38:07 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.43it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  5.17it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.20it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.08it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.02it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.20it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.91it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.46it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.89it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.35it/s]\u001b[A\n",
            "epoch 042 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.62it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:38:09 | INFO | dev_asr_nya | epoch 042 | valid on 'dev_asr_nya' subset | loss 2.396 | nll_loss 1.546 | ppl 2.92 | wps 42322.7 | wpb 3219.1 | bsz 32.7 | num_updates 919\n",
            "2023-02-06 18:38:09 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)\n",
            "2023-02-06 18:38:09 | INFO | train | epoch 042 | loss 2.513 | nll_loss 1.751 | ppl 3.37 | wps 20924.5 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 919 | lr 0.0001838 | gnorm 0.549 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.8 | wall 1613\n",
            "2023-02-06 18:38:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 043:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:38:09 | INFO | fairseq.trainer | begin training epoch 43\n",
            "2023-02-06 18:38:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 043:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:38:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.18it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.04it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.16it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.25it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.57it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.93it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.84it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.10it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 10.62it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 13.84it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 15.06it/s]\u001b[A\n",
            "epoch 043 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:02<00:00, 17.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:38:47 | INFO | dev_asr_nya | epoch 043 | valid on 'dev_asr_nya' subset | loss 2.367 | nll_loss 1.507 | ppl 2.84 | wps 34174.7 | wpb 3219.1 | bsz 32.7 | num_updates 941\n",
            "2023-02-06 18:38:47 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)\n",
            "2023-02-06 18:38:47 | INFO | train | epoch 043 | loss 2.508 | nll_loss 1.745 | ppl 3.35 | wps 21080.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 941 | lr 0.0001882 | gnorm 0.724 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 1651\n",
            "2023-02-06 18:38:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 044:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:38:47 | INFO | fairseq.trainer | begin training epoch 44\n",
            "2023-02-06 18:38:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 044:  95% 21/22 [00:35<00:01,  1.50s/it]2023-02-06 18:39:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  3.71it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.36it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.51it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.55it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.96it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.73it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 10.89it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.47it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.06it/s]\u001b[A\n",
            "epoch 044 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.27it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:39:25 | INFO | dev_asr_nya | epoch 044 | valid on 'dev_asr_nya' subset | loss 2.341 | nll_loss 1.479 | ppl 2.79 | wps 41498.7 | wpb 3219.1 | bsz 32.7 | num_updates 963\n",
            "2023-02-06 18:39:25 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)\n",
            "2023-02-06 18:39:25 | INFO | train | epoch 044 | loss 2.471 | nll_loss 1.703 | ppl 3.26 | wps 20753.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 963 | lr 0.0001926 | gnorm 0.552 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 7.5 | wall 1690\n",
            "2023-02-06 18:39:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 045:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:39:25 | INFO | fairseq.trainer | begin training epoch 45\n",
            "2023-02-06 18:39:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 045:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 18:40:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.48it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.11it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.97it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.95it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.93it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.32it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.84it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.55it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.95it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.23it/s]\u001b[A\n",
            "epoch 045 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:40:03 | INFO | dev_asr_nya | epoch 045 | valid on 'dev_asr_nya' subset | loss 2.335 | nll_loss 1.473 | ppl 2.78 | wps 42013.1 | wpb 3219.1 | bsz 32.7 | num_updates 985\n",
            "2023-02-06 18:40:03 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)\n",
            "2023-02-06 18:40:03 | INFO | train | epoch 045 | loss 2.456 | nll_loss 1.685 | ppl 3.21 | wps 21299.6 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 985 | lr 0.000197 | gnorm 0.688 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.8 | wall 1727\n",
            "2023-02-06 18:40:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 046:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:40:03 | INFO | fairseq.trainer | begin training epoch 46\n",
            "2023-02-06 18:40:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 046:  95% 21/22 [00:35<00:01,  1.42s/it, loss=2.476, nll_loss=1.708, ppl=3.27, wps=21120.8, ups=0.58, wpb=36541.1, bsz=369.6, num_updates=1000, lr=0.0002, gnorm=0.621, clip=0, loss_scale=4, train_wall=161, gb_free=7.5, wall=1754]2023-02-06 18:40:39 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:08,  2.04it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  2.86it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.28it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.53it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.06it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.67it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.20it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:02<00:00,  9.74it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 13.21it/s]\u001b[A\n",
            "epoch 046 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 16.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:40:42 | INFO | dev_asr_nya | epoch 046 | valid on 'dev_asr_nya' subset | loss 2.309 | nll_loss 1.436 | ppl 2.71 | wps 32055.4 | wpb 3219.1 | bsz 32.7 | num_updates 1007\n",
            "2023-02-06 18:40:42 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)\n",
            "2023-02-06 18:40:42 | INFO | train | epoch 046 | loss 2.426 | nll_loss 1.65 | ppl 3.14 | wps 20718.4 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1007 | lr 0.0002014 | gnorm 0.594 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.5 | wall 1766\n",
            "2023-02-06 18:40:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 047:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:40:42 | INFO | fairseq.trainer | begin training epoch 47\n",
            "2023-02-06 18:40:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 047:  95% 21/22 [00:35<00:01,  1.48s/it]2023-02-06 18:41:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.85it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.86it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.68it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.58it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.07it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.08it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  9.04it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.17it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 16.06it/s]\u001b[A\n",
            "epoch 047 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.52it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:41:20 | INFO | dev_asr_nya | epoch 047 | valid on 'dev_asr_nya' subset | loss 2.294 | nll_loss 1.426 | ppl 2.69 | wps 44151.2 | wpb 3219.1 | bsz 32.7 | num_updates 1029\n",
            "2023-02-06 18:41:20 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)\n",
            "2023-02-06 18:41:20 | INFO | train | epoch 047 | loss 2.403 | nll_loss 1.623 | ppl 3.08 | wps 21112.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1029 | lr 0.0002058 | gnorm 0.599 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5 | wall 1804\n",
            "2023-02-06 18:41:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 048:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:41:20 | INFO | fairseq.trainer | begin training epoch 48\n",
            "2023-02-06 18:41:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 048:  95% 21/22 [00:35<00:01,  1.37s/it]2023-02-06 18:41:56 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:09,  1.92it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  2.84it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:04,  3.26it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.08it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:04,  3.35it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.44it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.78it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00,  9.84it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 12.76it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:02<00:00, 14.19it/s]\u001b[A\n",
            "epoch 048 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.24it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:41:58 | INFO | dev_asr_nya | epoch 048 | valid on 'dev_asr_nya' subset | loss 2.285 | nll_loss 1.413 | ppl 2.66 | wps 32282.3 | wpb 3219.1 | bsz 32.7 | num_updates 1051\n",
            "2023-02-06 18:41:58 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)\n",
            "2023-02-06 18:41:58 | INFO | train | epoch 048 | loss 2.376 | nll_loss 1.591 | ppl 3.01 | wps 20836.4 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1051 | lr 0.0002102 | gnorm 0.653 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8.3 | wall 1843\n",
            "2023-02-06 18:41:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 049:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:41:59 | INFO | fairseq.trainer | begin training epoch 49\n",
            "2023-02-06 18:41:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 049:  95% 21/22 [00:35<00:01,  1.50s/it]2023-02-06 18:42:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.07it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.42it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.54it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.44it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.59it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.25it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.90it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.70it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.63it/s]\u001b[A\n",
            "epoch 049 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:42:37 | INFO | dev_asr_nya | epoch 049 | valid on 'dev_asr_nya' subset | loss 2.251 | nll_loss 1.376 | ppl 2.6 | wps 42827.4 | wpb 3219.1 | bsz 32.7 | num_updates 1073\n",
            "2023-02-06 18:42:37 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)\n",
            "2023-02-06 18:42:37 | INFO | train | epoch 049 | loss 2.354 | nll_loss 1.565 | ppl 2.96 | wps 20909.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1073 | lr 0.0002146 | gnorm 0.657 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 1881\n",
            "2023-02-06 18:42:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 050:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:42:37 | INFO | fairseq.trainer | begin training epoch 50\n",
            "2023-02-06 18:42:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 050:  95% 21/22 [00:34<00:01,  1.39s/it]2023-02-06 18:43:13 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.45it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.20it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.84it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.22it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.67it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.62it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.55it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.24it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.92it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 14.57it/s]\u001b[A\n",
            "epoch 050 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 16.64it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:43:15 | INFO | dev_asr_nya | epoch 050 | valid on 'dev_asr_nya' subset | loss 2.22 | nll_loss 1.332 | ppl 2.52 | wps 36252.6 | wpb 3219.1 | bsz 32.7 | num_updates 1095\n",
            "2023-02-06 18:43:15 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)\n",
            "2023-02-06 18:43:15 | INFO | train | epoch 050 | loss 2.323 | nll_loss 1.528 | ppl 2.88 | wps 21253.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1095 | lr 0.000219 | gnorm 0.61 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 1919\n",
            "2023-02-06 18:43:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 051:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:43:15 | INFO | fairseq.trainer | begin training epoch 51\n",
            "2023-02-06 18:43:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 051:  95% 21/22 [00:35<00:01,  1.49s/it, loss=2.366, nll_loss=1.579, ppl=2.99, wps=20842.3, ups=0.57, wpb=36527.6, bsz=367.2, num_updates=1100, lr=0.00022, gnorm=0.628, clip=0, loss_scale=4, train_wall=159, gb_free=5.1, wall=1929]2023-02-06 18:43:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.63it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.78it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.33it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.11it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.74it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.11it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.15it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.30it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.65it/s]\u001b[A\n",
            "epoch 051 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.34it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:43:53 | INFO | dev_asr_nya | epoch 051 | valid on 'dev_asr_nya' subset | loss 2.209 | nll_loss 1.318 | ppl 2.49 | wps 42648 | wpb 3219.1 | bsz 32.7 | num_updates 1117\n",
            "2023-02-06 18:43:53 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)\n",
            "2023-02-06 18:43:53 | INFO | train | epoch 051 | loss 2.297 | nll_loss 1.497 | ppl 2.82 | wps 20749.4 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1117 | lr 0.0002234 | gnorm 0.68 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 1958\n",
            "2023-02-06 18:43:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 052:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:43:53 | INFO | fairseq.trainer | begin training epoch 52\n",
            "2023-02-06 18:43:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 052:  95% 21/22 [00:34<00:01,  1.44s/it]2023-02-06 18:44:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.58it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.48it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.30it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.27it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.09it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.42it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.40it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.60it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.97it/s]\u001b[A\n",
            "epoch 052 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:44:31 | INFO | dev_asr_nya | epoch 052 | valid on 'dev_asr_nya' subset | loss 2.223 | nll_loss 1.336 | ppl 2.52 | wps 41194.1 | wpb 3219.1 | bsz 32.7 | num_updates 1139\n",
            "2023-02-06 18:44:31 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)\n",
            "2023-02-06 18:44:31 | INFO | train | epoch 052 | loss 2.272 | nll_loss 1.467 | ppl 2.76 | wps 21314.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1139 | lr 0.0002278 | gnorm 0.698 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.8 | wall 1995\n",
            "2023-02-06 18:44:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 053:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:44:31 | INFO | fairseq.trainer | begin training epoch 53\n",
            "2023-02-06 18:44:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 053:  95% 21/22 [00:35<00:01,  1.42s/it]2023-02-06 18:45:07 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.58it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.47it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.08it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.78it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.75it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.10it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.73it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.25it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 10.75it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.42it/s]\u001b[A\n",
            "epoch 053 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.58it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:45:10 | INFO | dev_asr_nya | epoch 053 | valid on 'dev_asr_nya' subset | loss 2.164 | nll_loss 1.273 | ppl 2.42 | wps 31142.8 | wpb 3219.1 | bsz 32.7 | num_updates 1161\n",
            "2023-02-06 18:45:10 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)\n",
            "2023-02-06 18:45:10 | INFO | train | epoch 053 | loss 2.258 | nll_loss 1.453 | ppl 2.74 | wps 20820 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1161 | lr 0.0002322 | gnorm 0.664 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 2034\n",
            "2023-02-06 18:45:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 054:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:45:10 | INFO | fairseq.trainer | begin training epoch 54\n",
            "2023-02-06 18:45:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 054:  95% 21/22 [00:35<00:01,  1.49s/it]2023-02-06 18:45:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.35it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.29it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.19it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.70it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.54it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  8.45it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 12.78it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.83it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.94it/s]\u001b[A\n",
            "epoch 054 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 20.42it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:45:48 | INFO | dev_asr_nya | epoch 054 | valid on 'dev_asr_nya' subset | loss 2.148 | nll_loss 1.254 | ppl 2.38 | wps 46181.3 | wpb 3219.1 | bsz 32.7 | num_updates 1183\n",
            "2023-02-06 18:45:48 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)\n",
            "2023-02-06 18:45:48 | INFO | train | epoch 054 | loss 2.21 | nll_loss 1.395 | ppl 2.63 | wps 21189.9 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1183 | lr 0.0002366 | gnorm 0.55 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.1 | wall 2072\n",
            "2023-02-06 18:45:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 055:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:45:48 | INFO | fairseq.trainer | begin training epoch 55\n",
            "2023-02-06 18:45:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 055:  95% 21/22 [00:35<00:01,  1.41s/it, loss=2.243, nll_loss=1.434, ppl=2.7, wps=21231.1, ups=0.58, wpb=36538.7, bsz=371.2, num_updates=1200, lr=0.00024, gnorm=0.654, clip=0, loss_scale=4, train_wall=159, gb_free=5.8, wall=2101]2023-02-06 18:46:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.92it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.15it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.65it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.74it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.85it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.39it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  6.15it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.27it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 11.47it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.12it/s]\u001b[A\n",
            "epoch 055 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:46:26 | INFO | dev_asr_nya | epoch 055 | valid on 'dev_asr_nya' subset | loss 2.148 | nll_loss 1.239 | ppl 2.36 | wps 30987.4 | wpb 3219.1 | bsz 32.7 | num_updates 1205\n",
            "2023-02-06 18:46:26 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)\n",
            "2023-02-06 18:46:26 | INFO | train | epoch 055 | loss 2.189 | nll_loss 1.37 | ppl 2.58 | wps 20959.6 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1205 | lr 0.000241 | gnorm 0.71 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.8 | wall 2110\n",
            "2023-02-06 18:46:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 056:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:46:26 | INFO | fairseq.trainer | begin training epoch 56\n",
            "2023-02-06 18:46:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 056:  95% 21/22 [00:35<00:01,  1.48s/it]2023-02-06 18:47:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.02it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.80it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.96it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.19it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.06it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.02it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.77it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.24it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.63it/s]\u001b[A\n",
            "epoch 056 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.68it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:47:05 | INFO | dev_asr_nya | epoch 056 | valid on 'dev_asr_nya' subset | loss 2.12 | nll_loss 1.216 | ppl 2.32 | wps 41418.8 | wpb 3219.1 | bsz 32.7 | num_updates 1227\n",
            "2023-02-06 18:47:05 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)\n",
            "2023-02-06 18:47:05 | INFO | train | epoch 056 | loss 2.19 | nll_loss 1.372 | ppl 2.59 | wps 20797.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1227 | lr 0.0002454 | gnorm 0.779 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 8 | wall 2149\n",
            "2023-02-06 18:47:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 057:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:47:05 | INFO | fairseq.trainer | begin training epoch 57\n",
            "2023-02-06 18:47:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 057:  95% 21/22 [00:34<00:01,  1.44s/it]2023-02-06 18:47:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.24it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.92it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.22it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.26it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.37it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.62it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.40it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.06it/s]\u001b[A\n",
            "epoch 057 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.60it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:47:42 | INFO | dev_asr_nya | epoch 057 | valid on 'dev_asr_nya' subset | loss 2.092 | nll_loss 1.178 | ppl 2.26 | wps 43026.7 | wpb 3219.1 | bsz 32.7 | num_updates 1249\n",
            "2023-02-06 18:47:42 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)\n",
            "2023-02-06 18:47:42 | INFO | train | epoch 057 | loss 2.147 | nll_loss 1.321 | ppl 2.5 | wps 21301.8 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1249 | lr 0.0002498 | gnorm 0.664 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.8 | wall 2187\n",
            "2023-02-06 18:47:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 058:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:47:42 | INFO | fairseq.trainer | begin training epoch 58\n",
            "2023-02-06 18:47:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 058:  95% 21/22 [00:35<00:01,  1.44s/it]2023-02-06 18:48:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.86it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.11it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.60it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.62it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.86it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  6.61it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00,  9.05it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 12.70it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:02<00:00, 15.44it/s]\u001b[A\n",
            "epoch 058 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:02<00:00, 18.35it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:48:21 | INFO | dev_asr_nya | epoch 058 | valid on 'dev_asr_nya' subset | loss 2.09 | nll_loss 1.175 | ppl 2.26 | wps 32770.3 | wpb 3219.1 | bsz 32.7 | num_updates 1271\n",
            "2023-02-06 18:48:21 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)\n",
            "2023-02-06 18:48:21 | INFO | train | epoch 058 | loss 2.12 | nll_loss 1.29 | ppl 2.45 | wps 20665.9 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1271 | lr 0.0002542 | gnorm 0.667 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 2225\n",
            "2023-02-06 18:48:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 059:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:48:21 | INFO | fairseq.trainer | begin training epoch 59\n",
            "2023-02-06 18:48:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 059:  95% 21/22 [00:34<00:01,  1.46s/it]2023-02-06 18:48:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.50it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.01it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.06it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.53it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.63it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.29it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  9.32it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.01it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 15.75it/s]\u001b[A\n",
            "epoch 059 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 17.99it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:48:59 | INFO | dev_asr_nya | epoch 059 | valid on 'dev_asr_nya' subset | loss 2.063 | nll_loss 1.132 | ppl 2.19 | wps 44494.2 | wpb 3219.1 | bsz 32.7 | num_updates 1293\n",
            "2023-02-06 18:48:59 | INFO | fairseq_cli.train | end of epoch 59 (average epoch stats below)\n",
            "2023-02-06 18:48:59 | INFO | train | epoch 059 | loss 2.09 | nll_loss 1.254 | ppl 2.39 | wps 21304.8 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1293 | lr 0.0002586 | gnorm 0.731 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.9 | wall 2263\n",
            "2023-02-06 18:48:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 060:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:48:59 | INFO | fairseq.trainer | begin training epoch 60\n",
            "2023-02-06 18:48:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 060:  95% 21/22 [00:34<00:01,  1.37s/it, loss=2.137, nll_loss=1.309, ppl=2.48, wps=20895.1, ups=0.57, wpb=36510.7, bsz=367.7, num_updates=1300, lr=0.00026, gnorm=0.732, clip=0, loss_scale=4, train_wall=159, gb_free=7.9, wall=2276]2023-02-06 18:49:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:08,  2.21it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  2.97it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.41it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.37it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.20it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.66it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.59it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  6.52it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:02<00:00,  8.98it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 12.00it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:02<00:00, 13.61it/s]\u001b[A\n",
            "epoch 060 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:02<00:00, 16.14it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:49:37 | INFO | dev_asr_nya | epoch 060 | valid on 'dev_asr_nya' subset | loss 2.054 | nll_loss 1.135 | ppl 2.2 | wps 30025.4 | wpb 3219.1 | bsz 32.7 | num_updates 1315\n",
            "2023-02-06 18:49:37 | INFO | fairseq_cli.train | end of epoch 60 (average epoch stats below)\n",
            "2023-02-06 18:49:37 | INFO | train | epoch 060 | loss 2.083 | nll_loss 1.246 | ppl 2.37 | wps 21019 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1315 | lr 0.000263 | gnorm 0.743 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 2301\n",
            "2023-02-06 18:49:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 061:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:49:37 | INFO | fairseq.trainer | begin training epoch 61\n",
            "2023-02-06 18:49:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 061:  95% 21/22 [00:35<00:01,  1.50s/it]2023-02-06 18:50:13 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.05it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  5.12it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.83it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.65it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.74it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.01it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.72it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.34it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.77it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.26it/s]\u001b[A\n",
            "epoch 061 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.91it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:50:15 | INFO | dev_asr_nya | epoch 061 | valid on 'dev_asr_nya' subset | loss 2.062 | nll_loss 1.145 | ppl 2.21 | wps 43761.5 | wpb 3219.1 | bsz 32.7 | num_updates 1337\n",
            "2023-02-06 18:50:15 | INFO | fairseq_cli.train | end of epoch 61 (average epoch stats below)\n",
            "2023-02-06 18:50:15 | INFO | train | epoch 061 | loss 2.055 | nll_loss 1.213 | ppl 2.32 | wps 21066.9 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1337 | lr 0.0002674 | gnorm 0.733 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 2339\n",
            "2023-02-06 18:50:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 062:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:50:15 | INFO | fairseq.trainer | begin training epoch 62\n",
            "2023-02-06 18:50:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 062:  95% 21/22 [00:34<00:01,  1.37s/it]2023-02-06 18:50:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.00it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.60it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.32it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.60it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.61it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.76it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.63it/s]\u001b[A\n",
            "epoch 062 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.09it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:50:53 | INFO | dev_asr_nya | epoch 062 | valid on 'dev_asr_nya' subset | loss 2.018 | nll_loss 1.087 | ppl 2.12 | wps 40095.2 | wpb 3219.1 | bsz 32.7 | num_updates 1359\n",
            "2023-02-06 18:50:53 | INFO | fairseq_cli.train | end of epoch 62 (average epoch stats below)\n",
            "2023-02-06 18:50:53 | INFO | train | epoch 062 | loss 2.034 | nll_loss 1.19 | ppl 2.28 | wps 21498.3 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 1359 | lr 0.0002718 | gnorm 0.746 | clip 0 | loss_scale 4 | train_wall 34 | gb_free 5.1 | wall 2377\n",
            "2023-02-06 18:50:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 063:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:50:53 | INFO | fairseq.trainer | begin training epoch 63\n",
            "2023-02-06 18:50:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 063:  95% 21/22 [00:35<00:01,  1.46s/it]2023-02-06 18:51:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.71it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.09it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.30it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.20it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.04it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.83it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.93it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 13.12it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.95it/s]\u001b[A\n",
            "epoch 063 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.29it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:51:31 | INFO | dev_asr_nya | epoch 063 | valid on 'dev_asr_nya' subset | loss 2.002 | nll_loss 1.072 | ppl 2.1 | wps 43646 | wpb 3219.1 | bsz 32.7 | num_updates 1381\n",
            "2023-02-06 18:51:31 | INFO | fairseq_cli.train | end of epoch 63 (average epoch stats below)\n",
            "2023-02-06 18:51:31 | INFO | train | epoch 063 | loss 1.999 | nll_loss 1.149 | ppl 2.22 | wps 20874.8 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1381 | lr 0.0002762 | gnorm 0.709 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 2415\n",
            "2023-02-06 18:51:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 064:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:51:31 | INFO | fairseq.trainer | begin training epoch 64\n",
            "2023-02-06 18:51:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 064:  95% 21/22 [00:34<00:01,  1.44s/it, loss=2.028, nll_loss=1.182, ppl=2.27, wps=21242.9, ups=0.58, wpb=36486.9, bsz=367.2, num_updates=1400, lr=0.00028, gnorm=0.716, clip=0, loss_scale=4, train_wall=159, gb_free=7.1, wall=2448]2023-02-06 18:52:07 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.59it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.72it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.61it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.82it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.25it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.04it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.76it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.23it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.70it/s]\u001b[A\n",
            "epoch 064 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:52:09 | INFO | dev_asr_nya | epoch 064 | valid on 'dev_asr_nya' subset | loss 1.981 | nll_loss 1.048 | ppl 2.07 | wps 44136.7 | wpb 3219.1 | bsz 32.7 | num_updates 1403\n",
            "2023-02-06 18:52:09 | INFO | fairseq_cli.train | end of epoch 64 (average epoch stats below)\n",
            "2023-02-06 18:52:09 | INFO | train | epoch 064 | loss 1.977 | nll_loss 1.122 | ppl 2.18 | wps 21303.5 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1403 | lr 0.0002806 | gnorm 0.713 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.6 | wall 2453\n",
            "2023-02-06 18:52:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 065:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:52:09 | INFO | fairseq.trainer | begin training epoch 65\n",
            "2023-02-06 18:52:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 065:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 18:52:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.38it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  2.93it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.42it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.64it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:04,  3.34it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.22it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  6.63it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.94it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:02<00:00, 12.12it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:02<00:00, 14.53it/s]\u001b[A\n",
            "epoch 065 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:02<00:00, 16.66it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:52:47 | INFO | dev_asr_nya | epoch 065 | valid on 'dev_asr_nya' subset | loss 1.968 | nll_loss 1.044 | ppl 2.06 | wps 31619.2 | wpb 3219.1 | bsz 32.7 | num_updates 1425\n",
            "2023-02-06 18:52:47 | INFO | fairseq_cli.train | end of epoch 65 (average epoch stats below)\n",
            "2023-02-06 18:52:47 | INFO | train | epoch 065 | loss 1.966 | nll_loss 1.11 | ppl 2.16 | wps 20920.4 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1425 | lr 0.000285 | gnorm 0.756 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 2491\n",
            "2023-02-06 18:52:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 066:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:52:47 | INFO | fairseq.trainer | begin training epoch 66\n",
            "2023-02-06 18:52:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 066:  95% 21/22 [00:35<00:01,  1.48s/it]2023-02-06 18:53:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.02it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.27it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.53it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.13it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.35it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.18it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.81it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.94it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.85it/s]\u001b[A\n",
            "epoch 066 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.31it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:53:25 | INFO | dev_asr_nya | epoch 066 | valid on 'dev_asr_nya' subset | loss 1.997 | nll_loss 1.071 | ppl 2.1 | wps 43754.1 | wpb 3219.1 | bsz 32.7 | num_updates 1447\n",
            "2023-02-06 18:53:25 | INFO | fairseq_cli.train | end of epoch 66 (average epoch stats below)\n",
            "2023-02-06 18:53:25 | INFO | train | epoch 066 | loss 1.951 | nll_loss 1.093 | ppl 2.13 | wps 21085.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1447 | lr 0.0002894 | gnorm 0.699 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 2530\n",
            "2023-02-06 18:53:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 067:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:53:25 | INFO | fairseq.trainer | begin training epoch 67\n",
            "2023-02-06 18:53:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 067:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 18:54:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.37it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.81it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.50it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.26it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.49it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.19it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.59it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  6.25it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00,  9.07it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.41it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 13.17it/s]\u001b[A\n",
            "epoch 067 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 15.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:54:03 | INFO | dev_asr_nya | epoch 067 | valid on 'dev_asr_nya' subset | loss 1.971 | nll_loss 1.032 | ppl 2.05 | wps 32833.2 | wpb 3219.1 | bsz 32.7 | num_updates 1469\n",
            "2023-02-06 18:54:03 | INFO | fairseq_cli.train | end of epoch 67 (average epoch stats below)\n",
            "2023-02-06 18:54:03 | INFO | train | epoch 067 | loss 1.975 | nll_loss 1.123 | ppl 2.18 | wps 21231.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1469 | lr 0.0002938 | gnorm 0.794 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.9 | wall 2567\n",
            "2023-02-06 18:54:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 068:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:54:03 | INFO | fairseq.trainer | begin training epoch 68\n",
            "2023-02-06 18:54:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 068:  95% 21/22 [00:35<00:01,  1.47s/it]2023-02-06 18:54:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.98it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.01it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.83it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.13it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.44it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.37it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.03it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.72it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.21it/s]\u001b[A\n",
            "epoch 068 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.37it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:54:42 | INFO | dev_asr_nya | epoch 068 | valid on 'dev_asr_nya' subset | loss 1.942 | nll_loss 1.011 | ppl 2.01 | wps 43428.1 | wpb 3219.1 | bsz 32.7 | num_updates 1491\n",
            "2023-02-06 18:54:42 | INFO | fairseq_cli.train | end of epoch 68 (average epoch stats below)\n",
            "2023-02-06 18:54:42 | INFO | train | epoch 068 | loss 1.912 | nll_loss 1.047 | ppl 2.07 | wps 20888.5 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1491 | lr 0.0002982 | gnorm 0.648 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.9 | wall 2606\n",
            "2023-02-06 18:54:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 069:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:54:42 | INFO | fairseq.trainer | begin training epoch 69\n",
            "2023-02-06 18:54:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 069:  95% 21/22 [00:34<00:01,  1.38s/it, loss=1.946, nll_loss=1.088, ppl=2.13, wps=20973.3, ups=0.57, wpb=36541, bsz=369, num_updates=1500, lr=0.0003, gnorm=0.715, clip=0, loss_scale=4, train_wall=158, gb_free=7.3, wall=2622]2023-02-06 18:55:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.54it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.66it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.60it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.30it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.67it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.86it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.96it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.99it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.34it/s]\u001b[A\n",
            "epoch 069 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:55:19 | INFO | dev_asr_nya | epoch 069 | valid on 'dev_asr_nya' subset | loss 1.955 | nll_loss 1.019 | ppl 2.03 | wps 45642.1 | wpb 3219.1 | bsz 32.7 | num_updates 1513\n",
            "2023-02-06 18:55:19 | INFO | fairseq_cli.train | end of epoch 69 (average epoch stats below)\n",
            "2023-02-06 18:55:19 | INFO | train | epoch 069 | loss 1.892 | nll_loss 1.026 | ppl 2.04 | wps 21411.7 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 1513 | lr 0.0003026 | gnorm 0.687 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.7 | wall 2643\n",
            "2023-02-06 18:55:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 070:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:55:19 | INFO | fairseq.trainer | begin training epoch 70\n",
            "2023-02-06 18:55:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 070:  95% 21/22 [00:34<00:01,  1.38s/it]2023-02-06 18:55:55 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.34it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.43it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.91it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.67it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.61it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.72it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.00it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  5.63it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.12it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 10.59it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.68it/s]\u001b[A\n",
            "epoch 070 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 14.46it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:55:57 | INFO | dev_asr_nya | epoch 070 | valid on 'dev_asr_nya' subset | loss 1.951 | nll_loss 1.018 | ppl 2.02 | wps 31848.7 | wpb 3219.1 | bsz 32.7 | num_updates 1535\n",
            "2023-02-06 18:55:57 | INFO | fairseq_cli.train | end of epoch 70 (average epoch stats below)\n",
            "2023-02-06 18:55:57 | INFO | train | epoch 070 | loss 1.881 | nll_loss 1.01 | ppl 2.01 | wps 20957.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1535 | lr 0.000307 | gnorm 0.776 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 2682\n",
            "2023-02-06 18:55:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 071:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:55:57 | INFO | fairseq.trainer | begin training epoch 71\n",
            "2023-02-06 18:55:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 071:  95% 21/22 [00:34<00:01,  1.48s/it]2023-02-06 18:56:33 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.95it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.79it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.65it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.64it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.04it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:01,  6.94it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.13it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  9.48it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.57it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.42it/s]\u001b[A\n",
            "epoch 071 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.19it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:56:35 | INFO | dev_asr_nya | epoch 071 | valid on 'dev_asr_nya' subset | loss 1.903 | nll_loss 0.958 | ppl 1.94 | wps 43696.9 | wpb 3219.1 | bsz 32.7 | num_updates 1557\n",
            "2023-02-06 18:56:35 | INFO | fairseq_cli.train | end of epoch 71 (average epoch stats below)\n",
            "2023-02-06 18:56:35 | INFO | train | epoch 071 | loss 1.881 | nll_loss 1.015 | ppl 2.02 | wps 21265.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1557 | lr 0.0003114 | gnorm 0.561 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.9 | wall 2719\n",
            "2023-02-06 18:56:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 072:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:56:35 | INFO | fairseq.trainer | begin training epoch 72\n",
            "2023-02-06 18:56:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 072:  95% 21/22 [00:34<00:01,  1.36s/it]2023-02-06 18:57:11 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.81it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.91it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.68it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.96it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.06it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.54it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.22it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.37it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.06it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 12.87it/s]\u001b[A\n",
            "epoch 072 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 15.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:57:13 | INFO | dev_asr_nya | epoch 072 | valid on 'dev_asr_nya' subset | loss 1.895 | nll_loss 0.948 | ppl 1.93 | wps 32286.8 | wpb 3219.1 | bsz 32.7 | num_updates 1579\n",
            "2023-02-06 18:57:13 | INFO | fairseq_cli.train | end of epoch 72 (average epoch stats below)\n",
            "2023-02-06 18:57:13 | INFO | train | epoch 072 | loss 1.845 | nll_loss 0.97 | ppl 1.96 | wps 21090.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1579 | lr 0.0003158 | gnorm 0.643 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 2758\n",
            "2023-02-06 18:57:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 073:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:57:13 | INFO | fairseq.trainer | begin training epoch 73\n",
            "2023-02-06 18:57:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 073:  95% 21/22 [00:35<00:01,  1.48s/it, loss=1.872, nll_loss=1.003, ppl=2, wps=21338.5, ups=0.58, wpb=36517.6, bsz=368.1, num_updates=1600, lr=0.00032, gnorm=0.703, clip=0, loss_scale=4, train_wall=158, gb_free=7, wall=2793]2023-02-06 18:57:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.16it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.77it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.29it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.40it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.10it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  8.00it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 12.22it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.35it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.60it/s]\u001b[A\n",
            "epoch 073 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 20.04it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:57:52 | INFO | dev_asr_nya | epoch 073 | valid on 'dev_asr_nya' subset | loss 1.921 | nll_loss 0.985 | ppl 1.98 | wps 42684.8 | wpb 3219.1 | bsz 32.7 | num_updates 1601\n",
            "2023-02-06 18:57:52 | INFO | fairseq_cli.train | end of epoch 73 (average epoch stats below)\n",
            "2023-02-06 18:57:52 | INFO | train | epoch 073 | loss 1.874 | nll_loss 1.005 | ppl 2.01 | wps 20948 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1601 | lr 0.0003202 | gnorm 0.8 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.8 | wall 2796\n",
            "2023-02-06 18:57:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 074:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:57:52 | INFO | fairseq.trainer | begin training epoch 74\n",
            "2023-02-06 18:57:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 074:  95% 21/22 [00:34<00:01,  1.44s/it]2023-02-06 18:58:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.14it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.11it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.00it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.56it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.39it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.94it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.21it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.30it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.27it/s]\u001b[A\n",
            "epoch 074 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.81it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:58:29 | INFO | dev_asr_nya | epoch 074 | valid on 'dev_asr_nya' subset | loss 1.877 | nll_loss 0.931 | ppl 1.91 | wps 42876.7 | wpb 3219.1 | bsz 32.7 | num_updates 1623\n",
            "2023-02-06 18:58:29 | INFO | fairseq_cli.train | end of epoch 74 (average epoch stats below)\n",
            "2023-02-06 18:58:29 | INFO | train | epoch 074 | loss 1.821 | nll_loss 0.943 | ppl 1.92 | wps 21370 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 1623 | lr 0.0003246 | gnorm 0.487 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.9 | wall 2834\n",
            "2023-02-06 18:58:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 075:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:58:29 | INFO | fairseq.trainer | begin training epoch 75\n",
            "2023-02-06 18:58:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 075:  95% 21/22 [00:35<00:01,  1.37s/it]2023-02-06 18:59:05 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.74it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.14it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.40it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.83it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.66it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.17it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  6.51it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:01,  8.74it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 11.93it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.60it/s]\u001b[A\n",
            "epoch 075 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.87it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:59:08 | INFO | dev_asr_nya | epoch 075 | valid on 'dev_asr_nya' subset | loss 1.903 | nll_loss 0.967 | ppl 1.95 | wps 31363.2 | wpb 3219.1 | bsz 32.7 | num_updates 1645\n",
            "2023-02-06 18:59:08 | INFO | fairseq_cli.train | end of epoch 75 (average epoch stats below)\n",
            "2023-02-06 18:59:08 | INFO | train | epoch 075 | loss 1.818 | nll_loss 0.939 | ppl 1.92 | wps 20873.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1645 | lr 0.000329 | gnorm 0.76 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 6.9 | wall 2872\n",
            "2023-02-06 18:59:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 076:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:59:08 | INFO | fairseq.trainer | begin training epoch 76\n",
            "2023-02-06 18:59:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 076:  95% 21/22 [00:35<00:01,  1.51s/it]2023-02-06 18:59:44 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.83it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.47it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.86it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.50it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.10it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.04it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.74it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 14.16it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.72it/s]\u001b[A\n",
            "epoch 076 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.67it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 18:59:46 | INFO | dev_asr_nya | epoch 076 | valid on 'dev_asr_nya' subset | loss 1.864 | nll_loss 0.913 | ppl 1.88 | wps 43856.3 | wpb 3219.1 | bsz 32.7 | num_updates 1667\n",
            "2023-02-06 18:59:46 | INFO | fairseq_cli.train | end of epoch 76 (average epoch stats below)\n",
            "2023-02-06 18:59:46 | INFO | train | epoch 076 | loss 1.79 | nll_loss 0.908 | ppl 1.88 | wps 20942.7 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1667 | lr 0.0003334 | gnorm 0.665 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 2910\n",
            "2023-02-06 18:59:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 077:   0% 0/22 [00:00<?, ?it/s]2023-02-06 18:59:46 | INFO | fairseq.trainer | begin training epoch 77\n",
            "2023-02-06 18:59:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 077:  95% 21/22 [00:34<00:01,  1.36s/it]2023-02-06 19:00:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.38it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.33it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.03it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.07it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.03it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.02it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.30it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  6.04it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:02<00:00,  8.39it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 11.52it/s]\u001b[A\n",
            "epoch 077 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 14.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:00:25 | INFO | dev_asr_nya | epoch 077 | valid on 'dev_asr_nya' subset | loss 1.867 | nll_loss 0.915 | ppl 1.89 | wps 29689.2 | wpb 3219.1 | bsz 32.7 | num_updates 1689\n",
            "2023-02-06 19:00:25 | INFO | fairseq_cli.train | end of epoch 77 (average epoch stats below)\n",
            "2023-02-06 19:00:25 | INFO | train | epoch 077 | loss 1.774 | nll_loss 0.89 | ppl 1.85 | wps 20861.3 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1689 | lr 0.0003378 | gnorm 0.683 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.1 | wall 2949\n",
            "2023-02-06 19:00:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 078:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:00:25 | INFO | fairseq.trainer | begin training epoch 78\n",
            "2023-02-06 19:00:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 078:  95% 21/22 [00:35<00:01,  1.49s/it, loss=1.797, nll_loss=0.916, ppl=1.89, wps=20783.6, ups=0.57, wpb=36563, bsz=369.5, num_updates=1700, lr=0.00034, gnorm=0.645, clip=0, loss_scale=4, train_wall=160, gb_free=7.4, wall=2969]2023-02-06 19:01:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.22it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.71it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.34it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.28it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.59it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.39it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.53it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.44it/s]\u001b[A\n",
            "epoch 078 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:01:03 | INFO | dev_asr_nya | epoch 078 | valid on 'dev_asr_nya' subset | loss 1.849 | nll_loss 0.896 | ppl 1.86 | wps 40328.2 | wpb 3219.1 | bsz 32.7 | num_updates 1711\n",
            "2023-02-06 19:01:03 | INFO | fairseq_cli.train | end of epoch 78 (average epoch stats below)\n",
            "2023-02-06 19:01:03 | INFO | train | epoch 078 | loss 1.765 | nll_loss 0.879 | ppl 1.84 | wps 20772.1 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1711 | lr 0.0003422 | gnorm 0.633 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 2988\n",
            "2023-02-06 19:01:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 079:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:01:03 | INFO | fairseq.trainer | begin training epoch 79\n",
            "2023-02-06 19:01:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 079:  95% 21/22 [00:34<00:01,  1.39s/it]2023-02-06 19:01:39 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  3.97it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.26it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.66it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  4.89it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.58it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.17it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.60it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.22it/s]\u001b[A\n",
            "epoch 079 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.34it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:01:41 | INFO | dev_asr_nya | epoch 079 | valid on 'dev_asr_nya' subset | loss 1.841 | nll_loss 0.895 | ppl 1.86 | wps 40362.8 | wpb 3219.1 | bsz 32.7 | num_updates 1733\n",
            "2023-02-06 19:01:41 | INFO | fairseq_cli.train | end of epoch 79 (average epoch stats below)\n",
            "2023-02-06 19:01:41 | INFO | train | epoch 079 | loss 1.76 | nll_loss 0.873 | ppl 1.83 | wps 21305.1 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1733 | lr 0.0003466 | gnorm 0.723 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7 | wall 3025\n",
            "2023-02-06 19:01:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 080:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:01:41 | INFO | fairseq.trainer | begin training epoch 80\n",
            "2023-02-06 19:01:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 080:  95% 21/22 [00:36<00:01,  1.47s/it]2023-02-06 19:02:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  4.38it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.43it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.19it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  6.25it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:01,  7.20it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:01,  7.15it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.58it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.87it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 12.88it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 15.73it/s]\u001b[A\n",
            "epoch 080 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 17.99it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:02:20 | INFO | dev_asr_nya | epoch 080 | valid on 'dev_asr_nya' subset | loss 1.988 | nll_loss 1.064 | ppl 2.09 | wps 40938.5 | wpb 3219.1 | bsz 32.7 | num_updates 1755\n",
            "2023-02-06 19:02:20 | INFO | fairseq_cli.train | end of epoch 80 (average epoch stats below)\n",
            "2023-02-06 19:02:20 | INFO | train | epoch 080 | loss 1.747 | nll_loss 0.858 | ppl 1.81 | wps 20663.6 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1755 | lr 0.000351 | gnorm 0.711 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 5.7 | wall 3064\n",
            "2023-02-06 19:02:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 081:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:02:20 | INFO | fairseq.trainer | begin training epoch 81\n",
            "2023-02-06 19:02:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 081:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 19:02:56 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.71it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.02it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.70it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.54it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.66it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.85it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.76it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.77it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.69it/s]\u001b[A\n",
            "epoch 081 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:02:57 | INFO | dev_asr_nya | epoch 081 | valid on 'dev_asr_nya' subset | loss 1.839 | nll_loss 0.896 | ppl 1.86 | wps 43127.7 | wpb 3219.1 | bsz 32.7 | num_updates 1777\n",
            "2023-02-06 19:02:57 | INFO | fairseq_cli.train | end of epoch 81 (average epoch stats below)\n",
            "2023-02-06 19:02:57 | INFO | train | epoch 081 | loss 1.765 | nll_loss 0.882 | ppl 1.84 | wps 21403.4 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 1777 | lr 0.0003554 | gnorm 0.538 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 3102\n",
            "2023-02-06 19:02:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 082:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:02:57 | INFO | fairseq.trainer | begin training epoch 82\n",
            "2023-02-06 19:02:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 082:  95% 21/22 [00:35<00:01,  1.37s/it]2023-02-06 19:03:34 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:09,  1.84it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:06,  2.77it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.44it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.92it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.28it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.73it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  7.00it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00,  9.34it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 12.53it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 14.13it/s]\u001b[A\n",
            "epoch 082 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.22it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:03:36 | INFO | dev_asr_nya | epoch 082 | valid on 'dev_asr_nya' subset | loss 1.817 | nll_loss 0.876 | ppl 1.84 | wps 35316.5 | wpb 3219.1 | bsz 32.7 | num_updates 1799\n",
            "2023-02-06 19:03:36 | INFO | fairseq_cli.train | end of epoch 82 (average epoch stats below)\n",
            "2023-02-06 19:03:36 | INFO | train | epoch 082 | loss 1.707 | nll_loss 0.812 | ppl 1.76 | wps 20885.1 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1799 | lr 0.0003598 | gnorm 0.571 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5 | wall 3140\n",
            "2023-02-06 19:03:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 083:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:03:36 | INFO | fairseq.trainer | begin training epoch 83\n",
            "2023-02-06 19:03:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 083:  95% 21/22 [00:35<00:01,  1.49s/it, loss=1.747, nll_loss=0.859, ppl=1.81, wps=20937.8, ups=0.57, wpb=36439.1, bsz=367.3, num_updates=1800, lr=0.00036, gnorm=0.634, clip=0, loss_scale=4, train_wall=159, gb_free=7.5, wall=3143]2023-02-06 19:04:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.79it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.24it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.20it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.18it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.59it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  8.09it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.05it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.72it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.36it/s]\u001b[A\n",
            "epoch 083 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.42it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:04:14 | INFO | dev_asr_nya | epoch 083 | valid on 'dev_asr_nya' subset | loss 1.829 | nll_loss 0.889 | ppl 1.85 | wps 44854.2 | wpb 3219.1 | bsz 32.7 | num_updates 1821\n",
            "2023-02-06 19:04:14 | INFO | fairseq_cli.train | end of epoch 83 (average epoch stats below)\n",
            "2023-02-06 19:04:14 | INFO | train | epoch 083 | loss 1.71 | nll_loss 0.817 | ppl 1.76 | wps 21165 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1821 | lr 0.0003642 | gnorm 0.735 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.6 | wall 3178\n",
            "2023-02-06 19:04:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 084:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:04:14 | INFO | fairseq.trainer | begin training epoch 84\n",
            "2023-02-06 19:04:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 084:  95% 21/22 [00:34<00:01,  1.41s/it]2023-02-06 19:04:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.51it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.44it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.43it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.67it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.77it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.36it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  5.23it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  8.06it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.81it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 14.50it/s]\u001b[A\n",
            "epoch 084 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 16.71it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:04:52 | INFO | dev_asr_nya | epoch 084 | valid on 'dev_asr_nya' subset | loss 1.848 | nll_loss 0.904 | ppl 1.87 | wps 32733.1 | wpb 3219.1 | bsz 32.7 | num_updates 1843\n",
            "2023-02-06 19:04:52 | INFO | fairseq_cli.train | end of epoch 84 (average epoch stats below)\n",
            "2023-02-06 19:04:52 | INFO | train | epoch 084 | loss 1.689 | nll_loss 0.792 | ppl 1.73 | wps 21007.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1843 | lr 0.0003686 | gnorm 0.63 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 3216\n",
            "2023-02-06 19:04:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 085:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:04:52 | INFO | fairseq.trainer | begin training epoch 85\n",
            "2023-02-06 19:04:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 085:  95% 21/22 [00:35<00:01,  1.51s/it]2023-02-06 19:05:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.33it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.10it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.01it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.56it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  5.70it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.64it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.44it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 10.91it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.23it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.80it/s]\u001b[A\n",
            "epoch 085 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:05:31 | INFO | dev_asr_nya | epoch 085 | valid on 'dev_asr_nya' subset | loss 1.813 | nll_loss 0.866 | ppl 1.82 | wps 40480.3 | wpb 3219.1 | bsz 32.7 | num_updates 1865\n",
            "2023-02-06 19:05:31 | INFO | fairseq_cli.train | end of epoch 85 (average epoch stats below)\n",
            "2023-02-06 19:05:31 | INFO | train | epoch 085 | loss 1.676 | nll_loss 0.779 | ppl 1.72 | wps 20669.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1865 | lr 0.000373 | gnorm 0.588 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 6.9 | wall 3255\n",
            "2023-02-06 19:05:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 086:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:05:31 | INFO | fairseq.trainer | begin training epoch 86\n",
            "2023-02-06 19:05:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 086:  95% 21/22 [00:34<00:01,  1.40s/it]2023-02-06 19:06:07 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.25it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.73it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.92it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.20it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.12it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.23it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.54it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.61it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.55it/s]\u001b[A\n",
            "epoch 086 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.88it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:06:09 | INFO | dev_asr_nya | epoch 086 | valid on 'dev_asr_nya' subset | loss 1.836 | nll_loss 0.884 | ppl 1.85 | wps 43299.4 | wpb 3219.1 | bsz 32.7 | num_updates 1887\n",
            "2023-02-06 19:06:09 | INFO | fairseq_cli.train | end of epoch 86 (average epoch stats below)\n",
            "2023-02-06 19:06:09 | INFO | train | epoch 086 | loss 1.688 | nll_loss 0.793 | ppl 1.73 | wps 21288.7 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1887 | lr 0.0003774 | gnorm 0.747 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.6 | wall 3293\n",
            "2023-02-06 19:06:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 087:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:06:09 | INFO | fairseq.trainer | begin training epoch 87\n",
            "2023-02-06 19:06:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 087:  95% 21/22 [00:35<00:01,  1.44s/it, loss=1.688, nll_loss=0.792, ppl=1.73, wps=21043.1, ups=0.58, wpb=36550.3, bsz=369, num_updates=1900, lr=0.00038, gnorm=0.679, clip=0, loss_scale=4, train_wall=161, gb_free=5.6, wall=3317]2023-02-06 19:06:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:07,  2.41it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.21it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.52it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.67it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.12it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.65it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  7.39it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 11.42it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 14.43it/s]\u001b[A\n",
            "epoch 087 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.12it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:06:48 | INFO | dev_asr_nya | epoch 087 | valid on 'dev_asr_nya' subset | loss 1.813 | nll_loss 0.864 | ppl 1.82 | wps 36186.1 | wpb 3219.1 | bsz 32.7 | num_updates 1909\n",
            "2023-02-06 19:06:48 | INFO | fairseq_cli.train | end of epoch 87 (average epoch stats below)\n",
            "2023-02-06 19:06:48 | INFO | train | epoch 087 | loss 1.667 | nll_loss 0.768 | ppl 1.7 | wps 20662.6 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1909 | lr 0.0003818 | gnorm 0.631 | clip 0 | loss_scale 4 | train_wall 36 | gb_free 7.5 | wall 3332\n",
            "2023-02-06 19:06:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 088:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:06:48 | INFO | fairseq.trainer | begin training epoch 88\n",
            "2023-02-06 19:06:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 088:  95% 21/22 [00:34<00:01,  1.45s/it]2023-02-06 19:07:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.04it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.31it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.44it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  6.36it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.20it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.49it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  6.40it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.11it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 14.37it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 16.94it/s]\u001b[A\n",
            "epoch 088 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.63it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:07:25 | INFO | dev_asr_nya | epoch 088 | valid on 'dev_asr_nya' subset | loss 1.79 | nll_loss 0.844 | ppl 1.8 | wps 42625.1 | wpb 3219.1 | bsz 32.7 | num_updates 1931\n",
            "2023-02-06 19:07:25 | INFO | fairseq_cli.train | end of epoch 88 (average epoch stats below)\n",
            "2023-02-06 19:07:25 | INFO | train | epoch 088 | loss 1.645 | nll_loss 0.744 | ppl 1.67 | wps 21381.4 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 1931 | lr 0.0003862 | gnorm 0.652 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.4 | wall 3369\n",
            "2023-02-06 19:07:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 089:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:07:25 | INFO | fairseq.trainer | begin training epoch 89\n",
            "2023-02-06 19:07:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 089:  95% 21/22 [00:34<00:01,  1.39s/it]2023-02-06 19:08:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:08,  2.07it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:06,  2.73it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:01<00:05,  3.04it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:04,  3.46it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  3.57it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.05it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.46it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:02<00:01,  6.94it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:02<00:00,  9.43it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:02<00:00, 11.65it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:02<00:00, 13.54it/s]\u001b[A\n",
            "epoch 089 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:02<00:00, 15.92it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:08:04 | INFO | dev_asr_nya | epoch 089 | valid on 'dev_asr_nya' subset | loss 1.797 | nll_loss 0.842 | ppl 1.79 | wps 29499.8 | wpb 3219.1 | bsz 32.7 | num_updates 1953\n",
            "2023-02-06 19:08:04 | INFO | fairseq_cli.train | end of epoch 89 (average epoch stats below)\n",
            "2023-02-06 19:08:04 | INFO | train | epoch 089 | loss 1.631 | nll_loss 0.728 | ppl 1.66 | wps 20875 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1953 | lr 0.0003906 | gnorm 0.59 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 3408\n",
            "2023-02-06 19:08:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 090:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:08:04 | INFO | fairseq.trainer | begin training epoch 90\n",
            "2023-02-06 19:08:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 090:  95% 21/22 [00:35<00:01,  1.49s/it]2023-02-06 19:08:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:04,  3.76it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.58it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.95it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.50it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.13it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.84it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.78it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.96it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.85it/s]\u001b[A\n",
            "epoch 090 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.34it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:08:42 | INFO | dev_asr_nya | epoch 090 | valid on 'dev_asr_nya' subset | loss 1.815 | nll_loss 0.877 | ppl 1.84 | wps 40762.6 | wpb 3219.1 | bsz 32.7 | num_updates 1975\n",
            "2023-02-06 19:08:42 | INFO | fairseq_cli.train | end of epoch 90 (average epoch stats below)\n",
            "2023-02-06 19:08:42 | INFO | train | epoch 090 | loss 1.647 | nll_loss 0.746 | ppl 1.68 | wps 20829.5 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 1975 | lr 0.000395 | gnorm 0.712 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.1 | wall 3446\n",
            "2023-02-06 19:08:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 091:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:08:42 | INFO | fairseq.trainer | begin training epoch 91\n",
            "2023-02-06 19:08:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 091:  95% 21/22 [00:35<00:01,  1.39s/it]2023-02-06 19:09:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.94it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.89it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.97it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.13it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.04it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.21it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 11.14it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 13.94it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 14.98it/s]\u001b[A\n",
            "epoch 091 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 17.17it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:09:20 | INFO | dev_asr_nya | epoch 091 | valid on 'dev_asr_nya' subset | loss 1.804 | nll_loss 0.864 | ppl 1.82 | wps 41666.8 | wpb 3219.1 | bsz 32.7 | num_updates 1997\n",
            "2023-02-06 19:09:20 | INFO | fairseq_cli.train | end of epoch 91 (average epoch stats below)\n",
            "2023-02-06 19:09:20 | INFO | train | epoch 091 | loss 1.627 | nll_loss 0.724 | ppl 1.65 | wps 21188.2 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 1997 | lr 0.0003994 | gnorm 0.685 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 3484\n",
            "2023-02-06 19:09:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 092:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:09:20 | INFO | fairseq.trainer | begin training epoch 92\n",
            "2023-02-06 19:09:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 092:  95% 21/22 [00:35<00:01,  1.48s/it, loss=1.639, nll_loss=0.737, ppl=1.67, wps=20864.8, ups=0.57, wpb=36448, bsz=367.5, num_updates=2000, lr=0.0004, gnorm=0.652, clip=0, loss_scale=4, train_wall=158, gb_free=7.4, wall=3492]2023-02-06 19:09:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.87it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.74it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.45it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.13it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.25it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.12it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 11.75it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 14.44it/s]\u001b[A\n",
            "epoch 092 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 17.11it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:09:59 | INFO | dev_asr_nya | epoch 092 | valid on 'dev_asr_nya' subset | loss 1.771 | nll_loss 0.818 | ppl 1.76 | wps 42959.1 | wpb 3219.1 | bsz 32.7 | num_updates 2019\n",
            "2023-02-06 19:09:59 | INFO | fairseq_cli.train | end of epoch 92 (average epoch stats below)\n",
            "2023-02-06 19:09:59 | INFO | train | epoch 092 | loss 1.608 | nll_loss 0.703 | ppl 1.63 | wps 20745.1 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 2019 | lr 0.0004038 | gnorm 0.61 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 7.5 | wall 3523\n",
            "2023-02-06 19:09:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 093:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:09:59 | INFO | fairseq.trainer | begin training epoch 93\n",
            "2023-02-06 19:09:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 093:  95% 21/22 [00:34<00:01,  1.42s/it]2023-02-06 19:10:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.72it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.25it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.55it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.13it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.32it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.68it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.77it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.73it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.66it/s]\u001b[A\n",
            "epoch 093 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:10:37 | INFO | dev_asr_nya | epoch 093 | valid on 'dev_asr_nya' subset | loss 1.85 | nll_loss 0.906 | ppl 1.87 | wps 43061 | wpb 3219.1 | bsz 32.7 | num_updates 2041\n",
            "2023-02-06 19:10:37 | INFO | fairseq_cli.train | end of epoch 93 (average epoch stats below)\n",
            "2023-02-06 19:10:37 | INFO | train | epoch 093 | loss 1.602 | nll_loss 0.695 | ppl 1.62 | wps 21291.9 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 2041 | lr 0.0004082 | gnorm 0.637 | clip 0 | loss_scale 4 | train_wall 35 | gb_free 5.7 | wall 3561\n",
            "2023-02-06 19:10:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 094:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:10:37 | INFO | fairseq.trainer | begin training epoch 94\n",
            "2023-02-06 19:10:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 094:  95% 21/22 [00:35<00:01,  1.44s/it]2023-02-06 19:11:13 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:08,  2.03it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.28it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.75it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  3.96it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.10it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  4.47it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.98it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.69it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 11.22it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 12.97it/s]\u001b[A\n",
            "epoch 094 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 16.14it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:11:15 | INFO | dev_asr_nya | epoch 094 | valid on 'dev_asr_nya' subset | loss 1.781 | nll_loss 0.837 | ppl 1.79 | wps 34332.3 | wpb 3219.1 | bsz 32.7 | num_updates 2063\n",
            "2023-02-06 19:11:15 | INFO | fairseq_cli.train | end of epoch 94 (average epoch stats below)\n",
            "2023-02-06 19:11:15 | INFO | train | epoch 094 | loss 1.59 | nll_loss 0.682 | ppl 1.6 | wps 20788.7 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 2063 | lr 0.0004126 | gnorm 0.567 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 7.3 | wall 3599\n",
            "2023-02-06 19:11:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 095:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:11:15 | INFO | fairseq.trainer | begin training epoch 95\n",
            "2023-02-06 19:11:15 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 095:  95% 21/22 [00:34<00:01,  1.44s/it]2023-02-06 19:11:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:05,  3.27it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.19it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.60it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.61it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.47it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  8.00it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.13it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.68it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.36it/s]\u001b[A\n",
            "epoch 095 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:11:53 | INFO | dev_asr_nya | epoch 095 | valid on 'dev_asr_nya' subset | loss 1.746 | nll_loss 0.805 | ppl 1.75 | wps 43703.1 | wpb 3219.1 | bsz 32.7 | num_updates 2085\n",
            "2023-02-06 19:11:53 | INFO | fairseq_cli.train | end of epoch 95 (average epoch stats below)\n",
            "2023-02-06 19:11:53 | INFO | train | epoch 095 | loss 1.579 | nll_loss 0.67 | ppl 1.59 | wps 21400.1 | ups 0.59 | wpb 36515.5 | bsz 368.4 | num_updates 2085 | lr 0.000417 | gnorm 0.596 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 7.7 | wall 3637\n",
            "2023-02-06 19:11:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 096:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:11:53 | INFO | fairseq.trainer | begin training epoch 96\n",
            "2023-02-06 19:11:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 096:  95% 21/22 [00:34<00:01,  1.37s/it, loss=1.592, nll_loss=0.684, ppl=1.61, wps=21334.5, ups=0.58, wpb=36624.4, bsz=370.9, num_updates=2100, lr=0.00042, gnorm=0.605, clip=0, loss_scale=8, train_wall=159, gb_free=6.6, wall=3663]2023-02-06 19:12:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:09,  1.89it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:05,  3.00it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:04,  3.62it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:01<00:03,  4.18it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:03,  4.26it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:03,  4.27it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:02,  4.76it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  7.05it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:02<00:00, 10.63it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:02<00:00, 12.47it/s]\u001b[A\n",
            "epoch 096 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:02<00:00, 15.04it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:12:31 | INFO | dev_asr_nya | epoch 096 | valid on 'dev_asr_nya' subset | loss 1.787 | nll_loss 0.856 | ppl 1.81 | wps 32883.1 | wpb 3219.1 | bsz 32.7 | num_updates 2107\n",
            "2023-02-06 19:12:31 | INFO | fairseq_cli.train | end of epoch 96 (average epoch stats below)\n",
            "2023-02-06 19:12:31 | INFO | train | epoch 096 | loss 1.58 | nll_loss 0.672 | ppl 1.59 | wps 21101.9 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 2107 | lr 0.0004214 | gnorm 0.625 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 6.9 | wall 3675\n",
            "2023-02-06 19:12:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 097:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:12:31 | INFO | fairseq.trainer | begin training epoch 97\n",
            "2023-02-06 19:12:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 097:  95% 21/22 [00:35<00:01,  1.47s/it]2023-02-06 19:13:08 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.93it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.39it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.18it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:02,  5.64it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.20it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.90it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:01<00:01,  8.71it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:01<00:00, 12.77it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:01<00:00, 15.68it/s]\u001b[A\n",
            "epoch 097 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:01<00:00, 18.11it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:13:09 | INFO | dev_asr_nya | epoch 097 | valid on 'dev_asr_nya' subset | loss 1.756 | nll_loss 0.809 | ppl 1.75 | wps 42791.8 | wpb 3219.1 | bsz 32.7 | num_updates 2129\n",
            "2023-02-06 19:13:09 | INFO | fairseq_cli.train | end of epoch 97 (average epoch stats below)\n",
            "2023-02-06 19:13:09 | INFO | train | epoch 097 | loss 1.579 | nll_loss 0.671 | ppl 1.59 | wps 20785.2 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 2129 | lr 0.0004258 | gnorm 0.638 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 7.2 | wall 3714\n",
            "2023-02-06 19:13:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 098:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:13:09 | INFO | fairseq.trainer | begin training epoch 98\n",
            "2023-02-06 19:13:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 098:  95% 21/22 [00:35<00:01,  1.39s/it]2023-02-06 19:13:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.84it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  4.07it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  5.00it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:02,  6.51it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  6.48it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.20it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:01,  9.85it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.74it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.05it/s]\u001b[A\n",
            "epoch 098 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 17.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:13:47 | INFO | dev_asr_nya | epoch 098 | valid on 'dev_asr_nya' subset | loss 1.769 | nll_loss 0.829 | ppl 1.78 | wps 43604.6 | wpb 3219.1 | bsz 32.7 | num_updates 2151\n",
            "2023-02-06 19:13:47 | INFO | fairseq_cli.train | end of epoch 98 (average epoch stats below)\n",
            "2023-02-06 19:13:47 | INFO | train | epoch 098 | loss 1.551 | nll_loss 0.638 | ppl 1.56 | wps 21257.4 | ups 0.58 | wpb 36515.5 | bsz 368.4 | num_updates 2151 | lr 0.0004302 | gnorm 0.511 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 7.7 | wall 3752\n",
            "2023-02-06 19:13:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 099:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:13:47 | INFO | fairseq.trainer | begin training epoch 99\n",
            "2023-02-06 19:13:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 099:  95% 21/22 [00:35<00:01,  1.48s/it]2023-02-06 19:14:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.79it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:03,  4.26it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:02,  5.54it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.98it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.02it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:01<00:02,  5.62it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:01<00:00, 10.16it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:01<00:00, 13.63it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:01<00:00, 16.26it/s]\u001b[A\n",
            "epoch 099 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:01<00:00, 18.29it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:14:26 | INFO | dev_asr_nya | epoch 099 | valid on 'dev_asr_nya' subset | loss 1.751 | nll_loss 0.806 | ppl 1.75 | wps 43562.8 | wpb 3219.1 | bsz 32.7 | num_updates 2173\n",
            "2023-02-06 19:14:26 | INFO | fairseq_cli.train | end of epoch 99 (average epoch stats below)\n",
            "2023-02-06 19:14:26 | INFO | train | epoch 099 | loss 1.588 | nll_loss 0.683 | ppl 1.61 | wps 20658 | ups 0.57 | wpb 36515.5 | bsz 368.4 | num_updates 2173 | lr 0.0004346 | gnorm 0.664 | clip 0 | loss_scale 8 | train_wall 36 | gb_free 5.7 | wall 3790\n",
            "2023-02-06 19:14:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 100:   0% 0/22 [00:00<?, ?it/s]2023-02-06 19:14:26 | INFO | fairseq.trainer | begin training epoch 100\n",
            "2023-02-06 19:14:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 100:  95% 21/22 [00:34<00:01,  1.41s/it]2023-02-06 19:15:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:06,  2.70it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  11% 2/19 [00:00<00:04,  3.90it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:03,  4.05it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:03,  4.72it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:01<00:02,  5.41it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:01<00:01,  7.98it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:01<00:00, 12.18it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:01<00:00, 15.28it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:01<00:00, 17.58it/s]\u001b[A\n",
            "epoch 100 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:01<00:00, 19.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2023-02-06 19:15:04 | INFO | dev_asr_nya | epoch 100 | valid on 'dev_asr_nya' subset | loss 1.739 | nll_loss 0.791 | ppl 1.73 | wps 44416.7 | wpb 3219.1 | bsz 32.7 | num_updates 2195\n",
            "2023-02-06 19:15:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 100 @ 2195 updates\n",
            "2023-02-06 19:15:04 | INFO | fairseq.trainer | Saving checkpoint to /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint100.pt\n",
            "2023-02-06 19:15:09 | INFO | fairseq.trainer | Finished saving checkpoint to /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint100.pt\n",
            "2023-02-06 19:15:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint100.pt (epoch 100 @ 2195 updates, score 1.739) (writing took 17.897612732000198 seconds)\n",
            "2023-02-06 19:15:22 | INFO | fairseq_cli.train | end of epoch 100 (average epoch stats below)\n",
            "2023-02-06 19:15:22 | INFO | train | epoch 100 | loss 1.539 | nll_loss 0.625 | ppl 1.54 | wps 14449.8 | ups 0.4 | wpb 36515.5 | bsz 368.4 | num_updates 2195 | lr 0.000439 | gnorm 0.513 | clip 0 | loss_scale 8 | train_wall 35 | gb_free 7.1 | wall 3846\n",
            "2023-02-06 19:15:22 | INFO | fairseq_cli.train | done training in 3845.6 seconds\n"
          ]
        }
      ],
      "source": [
        "!fairseq-train /content/zambezi-voice/nyanja/nya \\\n",
        "  --config-yaml config_asr_nya.yaml \\\n",
        "  --train-subset train_asr_nya \\\n",
        "  --valid-subset dev_asr_nya \\\n",
        "  --skip-invalid-size-inputs-valid-test \\\n",
        "  --save-dir /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints \\\n",
        "  --tensorboard-logdir /content/zambezi-voice/nyanja/nya/nya_asr_tensorboard \\\n",
        "  --num-workers 4 \\\n",
        "  --max-tokens 50000 \\\n",
        "  --max-epoch 100 \\\n",
        "  --save-interval 100 \\\n",
        "  --save-interval-updates 5000 \\\n",
        "  --keep-interval-updates 5 \\\n",
        "  --task speech_to_text \\\n",
        "  --criterion label_smoothed_cross_entropy \\\n",
        "  --label-smoothing 0.1 \\\n",
        "  --arch s2t_transformer_m \\\n",
        "  --dropout 0.15 \\\n",
        "  --optimizer adam \\\n",
        "  --lr 3e-4 \\\n",
        "  --fp16 \\\n",
        "  --lr-scheduler inverse_sqrt \\\n",
        "  --warmup-updates 10000 \\\n",
        "  --clip-norm 10.0 \\\n",
        "  --update-freq 8 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0D2qv686eJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9600da9-3762-4bbe-ba7c-a5e82a261949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(checkpoint_upper_bound=None, inputs=['/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints'], num_best_checkpoints=0, num_epoch_checkpoints=5, num_update_checkpoints=None, output='/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/avg_last_5_checkpoint.pt')\n",
            "averaging checkpoints:  ['/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/checkpoint500.pt', '/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/checkpoint400.pt', '/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/checkpoint300.pt', '/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/checkpoint200.pt', '/content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/checkpoint100.pt']\n",
            "Finished writing averaged checkpoint to /content/drive/MyDrive/BIG-C/checkpoints/bem_asr_checkpoints/avg_last_5_checkpoint.pt\n"
          ]
        }
      ],
      "source": [
        "# Find the AVERAGE MODEL OF THE LAST N CHECKPOINTS FROM CHECKPOINT DIR\n",
        "!python /content/fairseq/scripts/average_checkpoints.py \\\n",
        "  --inputs /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints\\\n",
        "  --num-epoch-checkpoints 5 \\\n",
        "  --output /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/avg_last_5_checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2bqCRKS7SBo",
        "outputId": "10032e9e-68f8-4835-e2e0-1a6a2cc3dd0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-06 19:46:16 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test_asr_nya', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='speech_to_text', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, config_yaml='config_asr_nya.yaml', constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/content/zambezi-voice/nyanja/nya', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eos_token=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test_asr_nya', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lenpen=1, lm_path=None, lm_weight=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=6000, max_target_positions=1024, max_tokens=50000, max_tokens_valid=50000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', path='/content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_best.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment=None, print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='wer', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, suppress_crashes=False, task='speech_to_text', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=0, wer_char_level=False, wer_lowercase=True, wer_remove_punct=True, wer_tokenizer='13a', write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': '13a', 'wer_remove_punct': True, 'wer_char_level': False, 'wer_lowercase': True}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2023-02-06 19:46:16 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm_char_asr_nya.txt): 78\n",
            "2023-02-06 19:46:16 | INFO | fairseq_cli.generate | loading model(s) from /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_best.pt\n",
            "2023-02-06 19:46:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2023-02-06 19:46:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "2023-02-06 19:46:18 | INFO | fairseq.data.audio.speech_to_text_dataset | 'test_asr_nya' has 0.00% OOV\n",
            "2023-02-06 19:46:18 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"test_asr_nya\", n_samples=428, prepend_tgt_lang_tag=False, shuffle=False, transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "), n_frames_per_step=1\n",
            "  0% 0/13 [00:00<?, ?it/s]2023-02-06 19:46:22 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2023-02-06 19:46:22 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "T-40\tAnthu amitundu yosiyanasiyana , amuna kapena akazi , ndi zaka amasangalala kwambiri pamene amuna awiri ali mu mpikisano wa masewera a karati , amuna amavala zovala zoyera nthawi zonse pamene wina akuyesa kumenyana ndi nyumba yozungulira , osewera awiri amatsogolera masewerawo ndi mmodzi. atakhala pampando akuomba muluzi pomwe winayo ali pafupi ndi omenyana awiriwa .\n",
            "H-40\t-0.44126302003860474\t▁ A n t h u ▁ a m i t u n d u ▁ y o s i y a n a s i y a n a ▁ p a m w a m b a ▁ p a ▁ m a k a z i ▁ o k h a l a ▁ n d i ▁ m a g a l a s i ▁ o k h a l a ▁ n d i ▁ n y u m b a ▁ y a b u l u u ▁ y e m w e ▁ w a v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ y o m w e ▁ i l i ▁ n d i ▁ m a l a y a ▁ a b u l u u ▁ a k u s e w e r a ▁ n d i ▁ m i y e n d o ▁ y o b i r i w i r a ▁ y o m w e ▁ i n\n",
            "D-40\t-0.44126302003860474\tAnthu amitundu yosiyanasiyana pamwamba pa makazi okhala ndi magalasi okhala ndi nyumba yabuluu yemwe wavala yunifolomu yobiriwira yomwe ili ndi malaya abuluu akusewera ndi miyendo yobiriwira yomwe in\n",
            "P-40\t-0.1185 -1.8677 -0.2649 -0.0637 -0.1310 -0.0695 -0.1166 -0.1556 -0.6195 -0.5615 -0.2513 -0.0950 -0.3340 -0.0406 -0.0895 -0.1996 -0.3231 -1.0382 -0.5112 -0.0790 -0.0225 -0.1364 -0.0608 -0.1187 -0.2060 -0.0910 -0.0106 -0.1288 -0.0738 -0.1018 -0.2350 -0.8719 -0.1260 -0.3670 -0.9374 -0.1028 -0.0660 -0.1845 -0.1015 -0.1390 -0.0918 -0.1371 -0.3621 -1.5530 -0.8072 -1.2556 -0.9485 -0.3729 -0.0965 -0.1945 -1.3041 -0.3556 -0.0584 -0.1027 -0.0732 -0.0958 -0.1434 -0.1162 -0.1316 -0.0953 -0.1077 -1.9136 -0.1154 -1.3675 -0.0762 -0.0769 -0.0994 -0.3399 -0.0869 -0.2431 -1.0852 -2.6579 -0.4589 -0.1052 -0.1095 -0.0914 -0.1353 -0.4542 -0.1079 -0.0989 -0.5611 -0.8608 -0.4612 -0.9063 -0.1324 -0.0377 -0.1081 -0.1855 -0.1423 -0.5477 -1.6023 -0.1766 -0.0607 -0.0991 -0.0471 -0.4288 -0.7710 -2.3808 -0.0407 -0.0969 -0.0672 -0.1005 -0.8907 -0.1365 -0.4609 -0.0928 -0.0989 -0.1132 -0.1132 -3.0310 -0.0473 -0.0794 -0.0597 -0.0517 -0.0853 -0.1576 -0.0546 -0.0215 -0.0565 -0.1573 -0.0158 -0.1734 -2.4487 -0.1622 -0.0877 -0.0968 -0.0492 -0.1085 -0.1199 -0.1167 -0.3145 -1.1946 -0.2358 -0.5362 -0.5193 -0.1147 -0.0944 -0.1614 -0.5522 -0.1091 -0.0971 -0.3666 -0.0851 -0.0935 -0.1010 -1.0760 -0.1416 -3.0824 -0.3415 -0.0332 -0.1228 -0.1235 -1.0773 -0.5522 -0.1104 -0.0639 -0.0991 -0.1059 -0.2858 -1.2233 -1.2651 -0.1443 -1.3698 -0.2537 -0.1040 -0.0584 -0.0596 -0.1100 -0.2192 -1.3180 -0.3489 -0.0920 -0.1538 -1.9592 -0.9238 -0.4427 -0.6643 -0.0770 -0.0987 -0.0686 -0.1105 -0.1929 -0.6441 -0.7669 -0.2076 -0.2005 -0.1249 -0.0388 -0.0885 -0.1776 -0.1240 -0.4574 -1.7125 -0.7404 -1.3178 -0.1260 -0.0750 -0.1408 -0.1503 -0.2709 -10.3409\n",
            "T-41\tOmenyera nkhondo awiri ovala zoyera atayima papulatifomu limodzi ndi mwamuna wina wovala thalauza lakuda ndi batani lamanja lalifupi, yemwe amawona ngati phazi la munthu wina likuloza kumaso kwa mdani wake wotsekereza .\n",
            "H-41\t-0.43552377820014954\t▁ W o m e n y e r a ▁ w o k o n d w a ▁ w o y e r a ▁ w o v a l a ▁ j u z i ▁ l a k e ▁ l a k u m w a ▁ p a f u p i ▁ n d i ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ l a b u l u u ▁ n d i ▁ m a n j a ▁ o v a l a ▁ j e k e t e ▁ l a b u l u u ▁ w o y e r a ▁ n d i ▁ m a w o n e k a ▁ n g a t i ▁ o c h i t i r a ▁ m w a m u n a ▁ w o v a l a ▁ j u z i ▁ l a k e ▁ l o f i i r a ▁ n d i\n",
            "D-41\t-0.43552377820014954\tWomenyera wokondwa woyera wovala juzi lake lakumwa pafupi ndi mwamuna wina wovala jekete labuluu ndi manja ovala jekete labuluu woyera ndi mawoneka ngati ochitira mwamuna wovala juzi lake lofiira ndi\n",
            "P-41\t-0.1216 -0.3814 -0.0638 -0.0675 -0.4632 -0.0756 -0.0431 -0.3711 -0.5619 -0.1032 -0.1527 -0.6550 -1.8921 -0.5268 -0.4128 -0.0428 -0.0301 -0.3733 -0.2353 -0.1932 -0.1433 -0.2164 -2.8410 -0.2143 -0.0757 -0.0831 -0.2643 -0.1626 -0.3714 -0.0647 -0.1098 -0.1006 -0.1042 -0.1231 -0.3343 -0.1094 -1.1945 -0.0920 -0.1248 -1.7056 -0.0814 -1.0835 -0.1510 -0.1223 -0.5164 -0.1231 -2.5691 -0.0924 -0.2575 -2.0573 -0.4314 -0.1603 -0.1169 -0.2181 -0.9016 -0.1157 -0.4182 -0.1084 -0.1540 -0.1225 -0.0635 -0.0820 -0.1029 -0.2772 -0.6209 -0.1293 -0.0963 -0.0733 -0.0475 -0.0882 -0.1367 -0.1222 -0.5319 -0.0589 -0.0910 -0.1304 -0.1231 -0.4015 -0.1067 -0.0847 -0.0947 -0.1023 -0.1229 -0.2256 -0.7318 -0.6340 -0.0625 -0.0126 -0.0532 -0.1188 -0.0551 -0.1175 -1.2382 -0.1107 -0.0740 -0.5365 -0.0459 -0.2246 -0.2708 -0.0835 -0.0952 -0.2027 -0.9394 -0.1278 -1.2466 -0.0062 -0.1035 -0.1248 -2.0297 -0.4370 -0.0895 -0.0827 -0.0917 -0.1282 -0.2933 -0.2731 -0.1559 -0.0814 -0.0150 -0.0450 -0.1426 -0.1856 -0.1458 -2.3560 -0.1067 -0.0875 -0.1817 -0.0572 -0.3860 -2.0029 -0.1232 -1.2138 -0.0666 -0.6106 -0.0817 -0.2969 -1.5068 -0.1534 -0.1150 -0.2208 -0.3125 -0.2075 -0.3497 -1.0231 -0.3069 -0.3956 -0.1462 -0.4034 -0.1620 -2.5360 -0.1650 -0.0984 -0.0169 -0.0526 -0.1359 -1.3159 -1.2730 -0.2420 -0.3128 -0.0064 -1.2734 -0.4555 -0.1054 -0.1711 -0.9419 -1.9957 -0.8203 -0.3360 -0.0747 -0.0722 -0.0810 -0.1985 -0.0527 -0.2021 -2.7311 -0.1390 -0.0714 -0.1017 -0.1257 -1.2545 -0.9170 -0.3409 -0.0662 -0.1444 -0.3661 -0.3150 -0.5980 -0.1966 -0.1973 -0.0847 -0.6226 -1.4002 -0.3039 -0.1259 -0.1368 -0.7610 -0.2984 -0.5068 -0.1144 -0.0680 -9.4148\n",
            "T-313\tBanja lina lachinyamata likukhala pampando, mkaziyo atavala malaya a ntchito ya buluu, maso ake atatsekedwa, pamene mwamunayo akukhala ndi mkono wake mozungulira, akuyang'ana kamera, mu malaya otuwa.\n",
            "H-313\t-0.30489227175712585\t▁ B a n j a ▁ l i n a ▁ l a c h i n y a m a t a ▁ l i k u k h a l a ▁ p a m p a n d o ▁ k a z i ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m a s e w e r a ▁ a ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ y u n i f o l o m u ▁ y a k u d a ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u y a n g ' a n a ▁ .\n",
            "D-313\t-0.30489227175712585\tBanja lina lachinyamata likukhala pampando kazi atavala malaya abuluu ndi masewera a pamene mwamuna wina yemwe wavala yunifolomu yakuda ndi mwamuna wovala malaya abuluu akuyang'ana .\n",
            "P-313\t-0.1427 -1.0824 -0.1311 -0.2159 -0.0354 -0.1004 -0.1370 -0.0988 -0.3929 -0.0358 -0.1047 -0.1868 -0.2768 -0.1284 -0.0698 -0.1228 -0.0933 -0.2346 -0.0461 -0.1070 -0.0611 -0.1100 -0.0454 -0.0900 -0.1505 -0.1010 -0.0956 -0.1154 -0.0775 -0.8505 -0.2522 -0.1053 -0.0477 -0.1127 -0.1290 -0.1193 -0.1175 -0.1788 -0.2781 -0.1686 -0.0733 -0.0216 -0.0510 -0.1870 -1.3822 -0.1247 -0.4073 -0.1142 -0.2615 -2.3110 -0.0933 -0.0960 -0.2152 -0.1105 -0.0735 -0.1167 -0.1121 -0.2770 -0.1223 -0.2924 -0.1130 -0.0335 -0.0809 -0.1235 -0.1683 -2.4989 -0.1021 -0.0632 -0.0964 -0.0435 -0.2352 -1.7014 -0.4243 -0.1443 -0.1160 -0.2344 -0.0898 -0.4054 -1.5444 -0.3479 -0.0718 -0.1822 -0.1418 -0.2091 -0.1073 -0.0942 -2.5018 -0.7069 -0.8087 -0.0705 -0.0636 -0.0623 -0.1473 -0.0926 -0.4480 -0.1195 -0.2077 -0.0537 -0.0787 -0.0915 -0.1539 -0.7056 -3.3833 -0.0725 -0.1039 -0.2428 -1.6768 -0.0316 -0.0552 -0.0632 -0.1132 -0.1433 -0.3075 -0.0984 -0.9702 -0.1060 -0.0724 -0.1098 -0.1292 -2.7159 -0.0407 -0.0517 -0.0632 -0.1439 -0.0452 -0.6377 -0.0510 -0.0205 -0.0542 -0.1572 -0.0677 -0.5173 -0.3986 -0.4399 -0.3051 -0.1331 -0.2546 -0.9561 -0.2403 -0.1121 -0.1246 -0.1529 -0.6376 -0.1920 -0.2660 -0.1001 -0.0632 -0.0781 -0.1305 -0.1915 -1.2629 -0.4438 -0.1248 -0.0562 -0.1347 -0.1125 -0.2204 -0.1164 -0.0776 -0.1112 -0.0397 -0.1084 -0.1067 -0.4470 -1.5175 -0.0626 -0.0696 -0.0992 -0.0697 -0.3135 -0.4969 -0.8653 -0.1071 -0.2193 -0.4409 -0.0404 -0.0413 -0.0906 -0.1032 -0.0455 -0.0991 -0.2367 -1.6349 -0.0859\n",
            "T-341\tGulu la anthu, kuphatikizapo mwamuna ndi mkazi wokhala ndi zopalasa, aimirira pafupi ndi Charging Bull, yomwe nthawi zina imatchedwa Wall Street Bull, chosema chachikulu cha mkuwa chomwe chili ku Bowling Green Park pafupi ndi Wall Street ku Manhattan, New York City.\n",
            "H-341\t-0.3880367875099182\t▁ G u l u ▁ l a ▁ a n t h u ▁ a t a v a l a ▁ t - s h i r t ▁ k o m a n s o ▁ n d i ▁ m k a z i ▁ w o v a l a ▁ z o k h a l a ▁ n d i ▁ z o b i r i w i r a ▁ p a f u p i ▁ n d i ▁ g u l u ▁ l a ▁ o m w e ▁ l i n a l i ▁ n d i ▁ c h i k w a m a ▁ c h a c h i k u l u ▁ c h a c h i k u l u ▁ n d i ▁ m a t a b w a ▁ o l i m b i t s a ▁ t h u p i ▁ k u m b u y o ▁ .\n",
            "D-341\t-0.3880367875099182\tGulu la anthu atavala t-shirt komanso ndi mkazi wovala zokhala ndi zobiriwira pafupi ndi gulu la omwe linali ndi chikwama chachikulu chachikulu ndi matabwa olimbitsa thupi kumbuyo .\n",
            "P-341\t-0.1271 -0.0314 -0.0701 -0.0573 -0.0900 -0.1267 -0.0641 -0.1225 -0.0725 -0.1186 -0.0391 -0.0219 -0.0498 -0.0822 -0.1708 -1.6193 -1.1277 -0.1502 -1.6337 -0.1160 -0.1007 -0.1114 -0.1092 -1.9328 -0.4475 -0.0638 -0.0255 -0.1583 -0.0690 -0.0072 -0.1687 -2.3548 -0.2358 -0.1272 -0.1783 -0.0852 -0.4576 -0.0843 -0.1388 -2.1263 -0.1897 -0.1367 -0.1644 -0.3912 -0.2666 -0.1098 -0.0117 -0.0785 -0.1410 -0.1266 -0.1064 -0.3988 -0.1028 -0.0878 -0.1222 -0.1108 -0.5843 -0.3522 -2.0917 -0.4646 -0.1134 -0.0881 -0.1003 -0.1125 -0.3734 -0.1254 -0.1036 -0.1130 -0.1662 -0.3701 -1.4705 -0.1157 -0.0764 -0.0846 -0.0655 -0.1079 -0.0598 -0.0940 -0.2364 -2.3177 -0.1267 -0.1825 -0.0956 -0.0345 -0.1260 -0.1668 -0.0802 -0.0984 -0.1257 -0.1316 -2.7731 -0.1370 -0.5259 -0.0916 -0.1960 -0.0857 -0.3899 -0.2762 -2.1791 -0.2725 -0.0409 -0.0733 -0.1530 -0.8478 -0.1573 -0.6675 -0.0725 -1.6617 -0.1727 -0.1751 -0.4752 -0.1035 -0.1302 -0.1364 -1.1514 -0.0818 -0.1564 -2.5779 -0.1630 -0.0784 -0.3287 -0.0997 -0.1456 -0.0116 -0.0761 -0.1105 -0.6583 -0.1030 -0.1003 -0.3920 -0.0853 -0.0964 -0.0603 -0.3232 -1.1231 -0.0751 -0.6364 -2.4629 -0.0901 -0.1191 -0.3622 -0.0939 -0.2017 -0.0675 -0.2353 -0.7328 -0.1050 -0.1125 -0.3064 -0.9092 -0.6534 -0.8955 -0.4261 -0.5654 -0.0109 -0.0957 -0.3056 -1.5862 -0.7386 -0.7940 -0.2269 -0.5018 -0.1557 -0.7317 -0.0503 -0.5300 -0.1927 -0.5591 -0.4167 -0.0926 -0.0685 -0.0977 -0.2512 -1.9182 -0.2625 -1.1017 -0.5074 -0.0723 -0.0835 -0.0651 -0.2285 -2.1210 -0.1029\n",
            "T-398\tMagulu awiri othamanga omwe ali ndi osewera anayi ovala mayunifolomu ofiira ndi oyera komanso osewera awiri ovala mayunifolomu obiriwira ndi achikasu amagwira maukonde pamitengo ndikuthamangira m'bwalo kutsogolo kwa mpanda wautali wazitsulo.\n",
            "H-398\t-0.3403371572494507\t▁ M a g u l u ▁ a w i r i ▁ o t h a m a n g a ▁ o t h a m a n g a ▁ o s e w e r a ▁ n d i ▁ w o v a l a ▁ m a y u n i f o l o m u ▁ o y e r a ▁ o f i i r a ▁ n d i ▁ o y e r a ▁ a k u m a n z e r e ▁ o v a l a ▁ m a y u n i f o l o m u ▁ o b i r i w i r a ▁ n d i ▁ a c h i k a s u ▁ n d i ▁ m a l o ▁ o m w e ▁ a m a g w i r a ▁ n t c h i t o ▁ k u t s o g o l o ▁ k w a ▁ m a l o n d a ▁ o g u l u\n",
            "D-398\t-0.3403371572494507\tMagulu awiri othamanga othamanga osewera ndi wovala mayunifolomu oyera ofiira ndi oyera akumanzere ovala mayunifolomu obiriwira ndi achikasu ndi malo omwe amagwira ntchito kutsogolo kwa malonda ogulu\n",
            "P-398\t-0.1241 -0.1042 -0.0940 -0.3885 -0.0616 -0.0519 -0.1121 -0.1259 -0.1449 -0.3002 -0.1548 -0.0754 -0.0960 -0.2261 -0.0367 -0.7660 -0.0979 -0.0761 -0.0855 -0.0743 -0.0561 -0.0302 -0.0861 -0.1543 -0.0929 -0.3122 -0.3767 -0.0893 -0.1233 -0.0927 -0.0838 -0.0314 -0.0873 -0.1811 -0.9804 -1.2831 -0.0459 -0.0967 -0.0578 -0.0576 -0.1026 -0.2270 -0.0556 -0.1502 -0.0802 -0.1779 -0.6320 -0.0591 -0.5327 -0.1053 -0.0921 -0.0991 -0.1306 -0.1082 -0.1150 -0.7661 -0.0696 -0.0425 -0.0748 -0.0345 -0.0737 -0.0514 -0.0450 -0.0562 -0.0537 -0.2023 -0.0342 -0.4422 -0.0810 -0.1184 -0.0980 -0.2549 -1.7263 -0.4832 -0.1132 -0.2977 -0.0439 -0.1098 -0.4198 -0.2610 -0.0898 -0.1042 -0.1392 -0.6466 -0.0464 -0.0676 -0.1650 -0.1092 -0.3529 -0.4056 -0.3800 -0.1156 -0.3867 -0.1869 -1.0120 -0.8112 -0.0761 -0.0469 -0.3312 -0.2233 -0.4205 -1.1130 -0.1111 -0.0972 -0.1116 -0.1260 -0.2374 -0.1154 -1.2708 -0.0809 -0.0357 -0.0779 -0.0520 -0.0608 -0.0810 -0.0536 -0.0339 -0.0899 -0.2286 -0.7701 -0.6448 -0.1217 -0.0955 -0.0895 -0.0237 -0.0948 -0.0942 -0.1198 -0.3227 -0.1978 -0.0563 -0.1290 -0.3270 -2.3109 -0.3832 -0.1092 -0.1009 -0.0819 -0.0906 -0.0164 -0.0772 -0.2526 -1.9158 -0.0632 -0.1193 -0.3397 -0.8666 -0.1924 -1.6047 -0.2466 -0.1459 -0.1157 -1.2121 -0.0771 -0.0715 -0.1126 -0.3589 -1.5017 -0.1793 -1.5317 -0.5261 -0.0862 -0.1308 -0.2027 -0.1571 -0.4421 -1.7267 -0.5448 -0.1582 -0.1040 -0.0105 -0.1455 -0.1453 -1.4180 -0.1745 -1.0836 -0.2730 -0.0411 -0.0311 -0.0708 -0.0630 -0.0575 -0.1462 -0.0804 -0.0435 -0.1294 -0.2625 -0.1206 -0.8637 -0.8387 -0.1316 -0.6554 -0.0135 -0.4328 -0.2232 -0.4944 -2.4662 -1.2484 -0.1297 -0.2121 -8.9285\n",
            "T-99\tAkuluakulu anayi , kuphatikizapo mayi wovala malaya ofiirira , ndi mwana wamng'ono amakhala mozungulira tebulo lokutidwa ndi nsalu ya patebulo yamizeremizere pamene agalu anayi akugona pansi mozungulira tebulo .\n",
            "H-99\t-0.3541162312030792\t▁ A k u l u a k u l u ▁ a n a y i ▁ a t a t u ▁ o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ o k h a l a ▁ n d i ▁ t s a l u ▁ l o y e r a ▁ n d i ▁ z i z i n d i k i r o ▁ z a ▁ m e n e ▁ a n t h u ▁ o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ .\n",
            "D-99\t-0.3541162312030792\tAkuluakulu anayi atatu ovala malaya ofiira ndi mwamuna wovala malaya abuluu okhala ndi tsalu loyera ndi zizindikiro za mene anthu ovala malaya amizeremizere .\n",
            "P-99\t-0.1293 -0.0990 -1.1522 -0.1187 -0.0335 -0.0689 -0.1961 -0.3961 -0.1034 -0.0405 -0.0608 -0.3002 -0.1511 -0.0282 -0.0720 -0.0287 -0.1022 -0.2602 -0.2523 -1.8390 -0.1590 -0.9801 -0.1397 -0.3946 -0.7457 -0.0612 -0.1196 -0.0905 -0.1060 -0.1169 -0.0715 -0.1268 -0.1794 -0.1097 -0.0655 -0.0916 -0.1227 -0.0476 -2.2414 -0.0948 -0.1958 -0.0595 -0.1884 -0.3909 -0.7121 -0.0770 -0.0959 -0.1020 -0.1025 -0.0597 -0.1007 -0.3352 -0.0756 -0.0477 -0.0922 -0.1463 -0.3004 -0.8134 -0.0599 -0.1073 -0.0940 -0.1146 -0.1170 -0.0683 -0.1420 -0.7015 -0.1124 -0.0668 -0.0874 -0.1286 -0.6948 -1.3031 -0.0873 -0.0635 -0.1151 -0.0467 -0.2632 -0.2718 -0.7633 -1.2067 -0.1114 -0.0719 -0.1028 -0.0974 -0.1918 -0.2383 -0.1182 -0.1163 -2.2299 -0.1656 -0.2889 -0.1725 -0.1938 -0.3211 -0.1637 -0.1951 -0.6250 -0.1572 -0.2697 -0.1000 -0.2668 -2.1235 -0.0688 -0.1201 -0.3320 -0.4586 -0.2900 -2.3159 -0.3008 -0.2700 -0.2318 -0.7863 -0.1032 -0.2954 -0.3056 -0.8077 -0.2241 -0.7021 -0.2397 -0.6647 -1.3886 -1.7040 -0.1067 -0.0973 -0.1304 -0.2655 -0.1816 -1.7822 -0.3952 -0.0604 -0.1051 -0.9356 -0.6385 -0.1085 -0.0592 -0.1155 -0.1333 -0.4620 -0.8787 -0.2337 -0.0991 -0.0187 -0.0899 -0.1220 -0.9669 -1.3478 -0.1714 -0.2425 -0.0703 -0.1353 -0.0519 -0.6802 -0.0488 -0.0375 -0.1109 -0.0662 -0.0969 -0.2904 -3.2844 -0.1007\n",
            "T-18\tAnyamata awiri ovala masuti abuluu ndi zipewa zachikasu akugwiritsa ntchito zinthu zooneka ngati masiponji okhala ndi zogwirira kufalitsa zinthu pamalo athyathyathya m'nyengo yozizira .\n",
            "H-18\t-0.32739460468292236\t▁ A n y a m a t a ▁ a w i r i ▁ o v a l a ▁ m a s u t i ▁ a b u l u u ▁ n d i ▁ t h a l a u z a ▁ l a c h i k a s u ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ z i n y e n g o ▁ z a c h i k a s u ▁ n d i p o ▁ w i n a ▁ w o v a l a ▁ z i p e w a ▁ z o b i r i w i r a ▁ a l i ▁ n d i ▁ m i t u n d u ▁ y a c h i k a s u ▁ y a ▁ m w a m b a ▁ .\n",
            "D-18\t-0.32739460468292236\tAnyamata awiri ovala masuti abuluu ndi thalauza lachikasu akugwiritsa ntchito zinyengo zachikasu ndipo wina wovala zipewa zobiriwira ali ndi mitundu yachikasu ya mwamba .\n",
            "P-18\t-0.1362 -0.1095 -0.8453 -0.0714 -0.0797 -0.0661 -0.0997 -0.0496 -0.1072 -0.1171 -0.0969 -0.1701 -0.1231 -0.0647 -0.0926 -0.3668 -0.0458 -0.0961 -0.1123 -0.0712 -0.1103 -0.0978 -0.1134 -0.1102 -0.6165 -0.3015 -0.0533 -0.0843 -0.1402 -1.4197 -0.4698 -0.1005 -0.0466 -0.1222 -0.0473 -0.1788 -0.0711 -0.0928 -0.0931 -0.0992 -2.0163 -1.1017 -0.0739 -0.1503 -0.1121 -0.0566 -0.2512 -0.0837 -0.1499 -1.8249 -0.1283 -0.2996 -0.0790 -0.0934 -0.2932 -0.0877 -0.0322 -0.0685 -0.2752 -0.2406 -0.1980 -0.1005 -1.1589 -0.0759 -0.3607 -0.0844 -0.2813 -0.0511 -0.2623 -0.1045 -0.1189 -0.0618 -0.0973 -0.0341 -0.1017 -0.1010 -0.0206 -0.0687 -0.0994 -0.9475 -0.2575 -0.4480 -1.0300 -0.2794 -0.0851 -0.0951 -0.0803 -0.1686 -0.8925 -1.4107 -0.7131 -0.1125 -0.0981 -0.1788 -0.2402 -0.0668 -0.0700 -0.2648 -0.1429 -0.1050 -0.0907 -0.1077 -0.0542 -0.1436 -1.1037 -0.4637 -0.0893 -0.0903 -0.1958 -0.8861 -1.0037 -0.0964 -0.1104 -0.0705 -0.1023 -0.1227 -0.4139 -0.4085 -0.5333 -0.2682 -0.0430 -0.1859 -0.2453 -0.3675 -0.5286 -0.8419 -0.2126 -0.0891 -0.1096 -0.0436 -0.1002 -0.0725 -0.0939 -0.3380 -1.0851 -1.0803 -0.1074 -0.1640 -0.2528 -0.1621 -0.3597 -0.0998 -1.0374 -1.5090 -0.8268 -0.4998 -0.0924 -0.0688 -0.1545 -0.1516 -0.0127 -0.5729 -2.8650 -0.2349 -0.0773 -0.8121 -0.0680 -0.0316 -0.0585 -0.2266 -0.1857 -1.0201 -0.6961 -0.3403 -2.3505 -0.3948 -0.3781 -0.9779 -0.0966 -0.3781 -1.3729 -0.1071\n",
            "T-94\tMahatchi awiri onyamula katundu, omangidwa m'ngolo yotchinga yooneka ngati yokhoza kunyamula anthu angapo, anaima mwakachetechete pamene mayi wina wachikulire akuyang'ana munthu wachikulire m'ngoloyo.\n",
            "H-94\t-0.3401600420475006\t▁ M a y i ▁ a c h i l i ▁ a w i r i ▁ o n y a m u l a ▁ k a t u n d u ▁ w a m w a n a ▁ y e m w e ▁ w a n g o n a ▁ y e m w e ▁ w a v a l a ▁ j e k e t e ▁ y o k o n g o l a ▁ a k u n y a m u l a ▁ c h i t h u n z i ▁ p a m e n e ▁ m n y a m a t a ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ a k u y a n g ' a n a ▁ m u t u ▁ w a c h i k u l i r e ▁ .\n",
            "D-94\t-0.3401600420475006\tMayi achili awiri onyamula katundu wamwana yemwe wangona yemwe wavala jekete yokongola akunyamula chithunzi pamene mnyamata wina yemwe wavala malaya obiriwira akuyang'ana mutu wachikulire .\n",
            "P-94\t-0.1285 -0.0449 -0.0878 -0.8203 -0.1195 -0.1427 -0.3912 -0.5420 -0.0983 -0.1163 -2.4596 -0.3365 -0.1405 -0.3643 -0.5396 -0.1235 -0.0804 -0.0830 -0.1872 -0.0543 -0.0350 -0.0783 -0.0911 -0.1986 -0.0697 -0.0887 -0.0937 -0.1520 -0.1642 -0.1051 -0.1258 -0.0539 -0.0492 -0.1127 -0.0542 -0.1647 -0.3492 -0.7391 -1.2735 -1.5623 -0.1643 -0.5489 -0.2727 -0.1453 -1.6861 -0.0532 -0.3038 -0.2598 -0.0484 -0.1441 -0.1661 -0.1832 -1.3395 -0.1699 -0.2997 -0.3214 -0.7396 -0.1440 -0.0623 -0.2552 -1.2190 -0.4672 -0.0666 -0.1529 -0.3773 -0.2809 -1.5008 -0.1100 -0.0999 -0.1052 -0.1337 -1.4293 -0.5024 -0.0548 -0.0626 -0.0372 -0.1803 -0.1103 -0.0533 -0.3772 -0.6834 -0.2743 -0.1775 -0.1179 -0.1360 -1.0815 -0.1080 -0.1977 -0.9452 -0.9737 -0.1060 -0.1436 -0.0605 -0.1190 -0.1648 -0.0500 -0.0425 -0.1137 -0.1371 -2.4271 -0.0921 -0.1290 -0.1491 -0.8113 -0.0713 -0.0761 -0.2117 -0.1140 -0.1686 -1.0731 -0.1368 -0.3989 -0.9818 -0.0558 -0.0562 -0.1224 -0.1064 -1.5425 -0.1615 -0.1034 -0.0812 -0.0825 -0.0398 -0.0877 -0.1869 -0.0552 -0.1249 -0.0692 -0.1046 -0.1557 -1.0008 -0.0621 -0.0702 -0.0342 -0.0811 -0.1306 -0.1160 -0.1007 -1.2125 -0.1002 -0.0722 -0.0968 -0.1132 -1.5608 -0.1604 -0.3365 -0.0969 -0.0407 -0.0851 -0.1058 -1.3493 -0.9795 -0.1216 -0.1272 -0.0945 -0.0124 -0.0875 -0.0993 -0.0978 -0.3193 -0.9412 -0.9434 -0.1102 -1.7006 -0.2202 -0.1063 -0.0236 -0.0631 -0.0802 -0.1130 -0.1108 -0.1507 -0.9899 -1.3893 -0.9595 -0.0443 -0.0942 -0.0729 -0.2475 -0.3065 -0.0705 -0.0928 -2.0429 -0.0939 -0.0275 -0.9263 -0.0933 -0.0582 -0.3031 -0.9697 -0.1002\n",
            "  8% 1/13 [00:05<01:08,  5.69s/it, wps=263]T-328\tMayi wina wovala blazer ya beige ndi magalasi adzuwa akuyang'ana mwamuna wina wovala t-sheti yamizeremizere, yemwe akuyang'anitsitsa azimayi awiri omwe akumwetulira ovala zankhondo m'mphepete mwa mzindawo .\n",
            "H-328\t-0.2870415151119232\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ b e i g e ▁ y a ▁ b e i g e ▁ n d i ▁ m a g a l a s i ▁ a d z u w a ▁ a k u y a n g ' a n a ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ y o y e r a ▁ a k u y e n d a ▁ m ' m i z e r e ▁ y o m w e ▁ i l i ▁ n d i ▁ m a l a y a ▁ o b i r i w i r a ▁ a k u m w e t u l i r a ▁ .\n",
            "D-328\t-0.2870415151119232\tMayi wina wovala beige ya beige ndi magalasi adzuwa akuyang'ana mwamuna wina wovala jekete yoyera akuyenda m'mizere yomwe ili ndi malaya obiriwira akumwetulira .\n",
            "P-328\t-0.1374 -0.0533 -0.1336 -0.0737 -0.0991 -0.1299 -0.0772 -0.1228 -0.0964 -0.1025 -0.1117 -0.0848 -0.0662 -0.0628 -0.1088 -0.0952 -0.1033 -0.1028 -1.2009 -1.3151 -0.2469 -0.5983 -0.0631 -0.1225 -0.8960 -0.1540 -0.2773 -0.5391 -0.9810 -0.0879 -1.0247 -0.2053 -0.1544 -1.3479 -0.0675 -0.1005 -0.0950 -0.0892 -0.2381 -0.3289 -0.2906 -0.2564 -0.1115 -0.0639 -0.0688 -0.2558 -0.1238 -0.5098 -0.0206 -0.1275 -0.0768 -0.0988 -0.3970 -0.1036 -0.0506 -0.0852 -0.0728 -0.1016 -0.0761 -0.0258 -0.0477 -0.0996 -0.0578 -0.1019 -0.1513 -0.1121 -1.7075 -0.1259 -0.1563 -0.0860 -0.0646 -0.0890 -0.1470 -0.0788 -0.4180 -0.0728 -0.0899 -0.1294 -0.9235 -0.0807 -0.0385 -0.1040 -0.0820 -0.0986 -0.1095 -0.9083 -0.1274 -0.2735 -0.1161 -0.0328 -0.2011 -0.1091 -0.2463 -2.0068 -0.3099 -0.0616 -0.1244 -0.0899 -0.1880 -1.7479 -0.1865 -0.0807 -0.0777 -0.5661 -0.1686 -0.1568 -0.1537 -0.1199 -0.8756 -0.3021 -0.7291 -0.8764 -0.6278 -0.3451 -0.2171 -0.0564 -0.3219 -0.1130 -0.3968 -0.5394 -0.0393 -0.1115 -0.0992 -0.2696 -2.0419 -0.1094 -0.0912 -0.7106 -0.1202 -0.1023 -0.1061 -0.1157 -0.2059 -1.0285 -0.4119 -0.1184 -0.0967 -0.1336 -0.1192 -0.3449 -0.1249 -0.0707 -0.0903 -0.0269 -0.0981 -0.0703 -0.0931 -0.2817 -1.4520 -0.1891 -0.1034 -0.3820 -0.3572 -0.0572 -0.0300 -0.0470 -0.0429 -0.0785 -0.0816 -0.0949 -0.1519 -2.9285 -0.1209\n",
            "T-350\tBambo ovala malaya oyera ndi akabudula a khaki akupsompsona mwachikondi mwana wawo, yemwe amamuwona atavala malaya ofiira akuda ndi mathalauza a denim, pamutu pamene akukhala chete atakhala pakhomo la galimoto.\n",
            "H-350\t-0.30345967411994934\t▁ B a m b o ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ k a b u d u l a ▁ a t a k h a l a ▁ k u t s o g o l o ▁ k w a ▁ m a d z i ▁ n d i ▁ m w a n a ▁ w a m n g ' o n o ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ a t a v a l a ▁ m a t h a l a u z a ▁ a b u l u u ▁ n d i ▁ m a t h a l a u z a ▁ o m w e ▁ a t a k h a l a ▁ p a m e n e ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u\n",
            "D-350\t-0.30345967411994934\tBambo wovala malaya oyera ndi kabudula atakhala kutsogolo kwa madzi ndi mwana wamng'ono atavala malaya abuluu atavala mathalauza abuluu ndi mathalauza omwe atakhala pamene mwamuna wovala malaya abulu\n",
            "P-350\t-0.1340 -0.1028 -0.1069 -0.0833 -0.0773 -0.1111 -0.1051 -0.0918 -0.3998 -0.1068 -0.1218 -0.0775 -0.1095 -0.0971 -0.0717 -0.1061 -0.0823 -0.1002 -0.0887 -0.0878 -0.0977 -0.0759 -0.0672 -0.0588 -0.1120 -0.0865 -0.1863 -0.1484 -0.1478 -0.1073 -0.1093 -0.2972 -0.1232 -0.0311 -0.0961 -0.0370 -0.0611 -0.0706 -0.0956 -0.1277 -0.1265 -2.6342 -0.1067 -0.0871 -0.0893 -0.0916 -0.0536 -0.0918 -0.1112 -0.3205 -0.1164 -1.2213 -0.0963 -0.1240 -0.0661 -0.1050 -0.2339 -0.1184 -0.1187 -0.2907 -0.2596 -0.1272 -0.1169 -0.2040 -0.1942 -3.4319 -0.1426 -0.1863 -0.2483 -0.7676 -0.0704 -0.1163 -0.8666 -0.0740 -0.0422 -0.1358 -0.3159 -0.0888 -0.1431 -0.0962 -1.2434 -1.5594 -0.1301 -0.4061 -0.0415 -0.1063 -0.0859 -0.0744 -0.1687 -0.2432 -0.6079 -0.1044 -0.1388 -0.1036 -0.0714 -0.1154 -0.1050 -0.0768 -0.1279 -0.0883 -0.1110 -0.0794 -0.0862 -0.0876 -0.3845 -0.7465 -0.0903 -0.0463 -0.2070 -0.0522 -0.2503 -0.6437 -0.5333 -0.1075 -0.6349 -0.1340 -0.0780 -0.1144 -0.0944 -0.5217 -0.1086 -0.5574 -0.4406 -0.1379 -0.0354 -0.1063 -0.0440 -0.0228 -0.0821 -0.1075 -1.0633 -1.4846 -0.0815 -0.0566 -0.2811 -0.0628 -0.2234 -0.7490 -0.1587 -0.1299 -0.0937 -0.0654 -0.3679 -1.0344 -0.6842 -0.1368 -0.0503 -0.0934 -0.0486 -0.1433 -0.0844 -0.1200 -2.0460 -0.6127 -0.0590 -0.1058 -0.0886 -0.1011 -0.6772 -0.0923 -1.3371 -0.0247 -0.1055 -0.0367 -0.1127 -0.1263 -0.4544 -0.1198 -0.3326 -0.7647 -0.0305 -0.0877 -0.0900 -0.3842 -0.6848 -0.0863 -0.0968 -0.0775 -0.0806 -0.0805 -0.1541 -0.0853 -1.7453 -0.4245 -0.0985 -0.0608 -0.0989 -0.1291 -0.5512 -0.1411 -0.2797 -0.0903 -0.0322 -0.0956 -0.1376 -0.2869 -0.6084 -0.0582 -0.0661 -0.0593 -9.2088\n",
            "T-221\tAchinyamata asanu ndi anayi ovala jekeseni ya jeans akuwoneka pamasitepe akutsogolo ndi khonde la nyumba ya 3-level clapboard, monga momwe mwana amawonera ali pakhonde lachiwiri.\n",
            "H-221\t-0.3525475859642029\t▁ A c h i n y a m a t a ▁ a c h i n y a m a t a ▁ n d i ▁ a n a y i ▁ o v a l a ▁ j e k e t e ▁ y a ▁ j e k e t e ▁ y a ▁ b u l u u ▁ a k u w o n e k a ▁ m a g o l o n i ▁ n d i ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y o m w e ▁ i l i ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o m w e ▁ i l i ▁ n d i ▁ m w a m u n a ▁ w o n d e r a .\n",
            "D-221\t-0.3525475859642029\tAchinyamata achinyamata ndi anayi ovala jekete ya jekete ya buluu akuwoneka magoloni ndi kutsogolo kwa nyumba yomwe ili ndi mwamuna wovala yunifolomu yomwe ili ndi mwamuna wondera.\n",
            "P-221\t-0.1144 -0.0488 -2.2586 -0.2259 -0.0926 -0.1020 -0.0208 -0.0911 -0.0443 -0.0890 -0.0458 -0.1005 -0.1370 -0.1402 -0.9814 -0.1453 -0.0894 -1.1392 -0.6875 -0.2924 -0.2019 -0.0980 -0.6278 -0.1104 -0.1959 -0.1186 -0.1169 -0.0941 -0.2743 -2.3636 -0.0635 -0.2207 -0.0651 -0.0635 -0.1937 -0.0509 -0.0470 -0.1215 -0.0727 -0.1162 -0.1120 -0.4850 -0.1059 -0.0268 -0.0527 -0.0474 -0.0992 -0.1406 -0.3470 -0.1123 -0.4733 -1.9277 -0.1481 -0.2147 -0.0596 -0.0423 -0.1325 -0.1445 -0.2169 -0.1296 -0.5442 -0.4204 -0.3847 -0.1489 -0.1376 -0.0630 -0.1744 -0.7850 -0.1803 -0.1045 -0.4542 -0.0533 -0.0820 -0.0822 -0.0520 -0.1171 -0.0994 -1.3995 -0.1238 -1.4389 -0.2232 -0.4208 -0.0482 -0.6464 -1.9831 -0.1913 -0.3236 -0.0781 -0.1294 -0.8632 -0.6734 -0.4029 -0.1065 -1.0472 -0.0606 -0.1208 -0.0606 -0.0716 -0.0733 -0.1270 -1.4868 -0.1813 -0.1515 -0.1407 -0.8528 -1.2228 -0.0554 -0.1634 -0.0285 -0.1254 -0.2886 -0.0825 -0.5028 -1.7961 -0.1484 -0.0940 -0.0990 -0.1892 -0.0340 -0.1116 -0.0914 -0.8980 -0.1201 -0.1116 -0.1298 -1.4444 -0.3371 -0.1263 -0.0567 -0.0849 -0.0801 -0.0872 -0.1235 -0.1837 -0.3634 -0.7625 -0.1063 -0.0721 -0.1044 -0.1186 -3.5169 -0.0499 -0.0447 -0.0920 -0.0620 -0.0260 -0.6801 -0.0396 -0.0368 -0.0496 -0.1459 -0.3679 -0.4164 -1.7305 -0.1244 -0.1259 -0.1198 -0.2291 -0.4779 -0.1000 -0.1172 -0.9173 -0.1349 -0.3027 -0.1073 -0.9600 -1.5367 -0.1536 -0.2013 -0.1376 -0.0444 -0.1259 -0.1646 -0.0899 -0.5419 -0.9473 -1.1850 -0.0672 -0.7803 -0.0930 -2.2890 -0.0973\n",
            "T-134\tAtsikana awiri , yemwe ali kuseriyo wavala zakuda , pamene msungwana wina kutsogoloyo wavala kabudula wa khaki , malaya ofiirira ndi ma sneakers ndikuchita manja ngati akupsompsona .\n",
            "H-134\t-0.34145116806030273\t▁ A t s i k a n a ▁ a w i r i , ▁ y e m w e ▁ a l i ▁ k u s e r i ▁ w o v a l a ▁ z a k u d a ▁ a k u j a m b u l a ▁ p a m e n e ▁ m t s o g o l o ▁ w a ▁ b u l u u ▁ w o v a l a ▁ k a b u d u l a ▁ w a k h a l a ▁ p a f u p i ▁ n d i ▁ m a s o ▁ o f i i r a ▁ n d i ▁ m a t h a l a u z a ▁ a m b i r i ▁ o m w e ▁ a m a s o n k h a n a .\n",
            "D-134\t-0.34145116806030273\tAtsikana awiri, yemwe ali kuseri wovala zakuda akujambula pamene mtsogolo wa buluu wovala kabudula wakhala pafupi ndi maso ofiira ndi mathalauza ambiri omwe amasonkhana.\n",
            "P-134\t-0.1243 -0.0551 -0.2788 -0.0423 -0.1079 -0.0971 -0.1331 -0.0690 -0.1078 -0.1587 -0.1491 -0.4679 -0.1523 -0.0597 -0.1062 -2.5285 -0.1290 -1.5436 -0.0240 -0.0380 -0.1672 -0.0890 -0.1549 -0.1249 -0.0243 -0.1014 -0.1407 -1.0748 -0.0918 -0.6341 -0.0730 -0.1089 -0.0913 -0.2715 -0.4351 -0.9158 -0.0439 -0.1210 -0.0930 -0.1145 -0.1565 -0.2366 -0.1108 -0.0733 -0.0835 -0.2162 -0.1292 -0.4810 -1.3391 -0.1496 -0.1156 -0.8710 -0.0995 -0.1080 -0.1799 -0.1350 -0.0630 -0.0914 -0.2025 -1.3354 -0.1226 -0.2036 -0.2840 -0.0903 -0.0979 -0.1496 -0.1871 -1.5303 -0.0476 -0.5130 -0.1800 -0.1694 -0.0564 -0.0729 -0.1888 -0.0976 -0.4850 -0.4303 -1.3058 -0.6847 -0.0974 -0.1897 -0.0631 -0.4151 -1.0008 -1.2839 -1.4945 -0.1208 -0.0879 -0.1246 -0.1180 -0.9743 -0.1772 -0.3759 -0.0825 -0.0478 -0.0727 -0.0348 -0.1903 -0.1973 -0.0842 -0.1833 -1.2063 -0.2812 -0.1070 -0.0488 -0.1158 -0.1348 -2.3157 -0.2733 -0.4710 -0.2407 -0.0571 -0.1283 -0.1717 -0.0455 -0.0666 -0.1088 -0.0843 -0.0934 -0.1343 -0.4126 -0.3637 -0.1284 -1.0793 -0.1200 -0.1221 -0.1914 -0.0694 -0.3585 -0.5471 -0.5032 -0.0846 -0.1192 -0.1407 -0.0763 -0.1416 -2.8679 -0.9376 -0.0881 -0.9167 -0.1088 -0.0512 -0.1180 -0.1042 -0.2372 -1.0302 -0.6899 -0.1555 -0.4741 -0.0521 -0.0842 -0.4896 -1.7079 -0.2901 -0.2286 -0.1275 -0.1706 -0.2131 -0.8357 -0.1765 -0.3315 -0.2587 -0.3699 -0.7628 -0.0827 -0.0837 -0.2952 -0.0589 -1.6130 -0.1005\n",
            "T-77\tOphunzira ochuluka omwe amawoneka ngati aku Asia asonkhana mozungulira matebulo osiyanasiyana, ndi tebulo lomwe linali ndi chikwangwani cholembedwa kuti New York City pakati pake.\n",
            "H-77\t-0.344732403755188\t▁ W o p h u n z i r a ▁ w o k h a l a ▁ w o k h a l a ▁ n d i ▁ k a m e r a ▁ y a k u ▁ A s i a ▁ a k u k h a l a ▁ m o z u n g u l i r a ▁ m o z u n g u l i r a ▁ m a s i t e p e ▁ a n t h u ▁ o m w e ▁ i n a s i y a n a ▁ n d i ▁ c h i k w a n g w a n i ▁ c h o k o n g o l e t s e d w a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-77\t-0.344732403755188\tWophunzira wokhala wokhala ndi kamera yaku Asia akukhala mozungulira mozungulira masitepe anthu omwe inasiyana ndi chikwangwani chokongoletsedwa ndi chipale chofewa .\n",
            "P-77\t-0.1355 -0.6608 -0.0939 -0.6230 -0.0717 -0.0663 -0.0429 -0.0660 -0.1209 -0.0317 -0.0874 -0.1390 -0.1824 -0.2586 -0.4814 -0.1205 -0.1129 -0.0910 -0.0933 -0.1020 -2.9139 -0.0935 -0.8677 -0.0447 -0.1006 -0.1252 -0.0903 -0.1277 -0.0994 -0.5100 -0.0973 -0.2287 -1.4039 -0.1025 -0.3353 -0.7439 -0.1064 -0.0829 -0.2114 -0.7131 -0.1130 -0.5864 -0.1361 -0.0993 -0.6168 -0.0542 -0.0698 -0.1163 -0.2316 -0.1667 -0.5544 -0.1259 -0.4494 -0.1308 -0.1021 -0.1278 -0.1009 -0.1358 -1.3812 -0.1402 -0.9427 -0.4131 -0.0343 -0.0144 -0.0525 -0.1181 -0.1075 -0.0777 -0.1082 -0.1914 -0.8786 -1.6946 -1.4475 -0.0475 -0.0373 -0.0151 -0.0559 -0.0844 -0.1162 -0.0829 -0.1086 -0.1661 -1.1623 -0.2749 -1.1424 -0.3271 -0.3214 -0.0435 -0.4979 -0.2538 -0.1961 -0.4150 -2.2035 -0.5802 -0.0428 -0.0726 -0.0989 -0.7531 -0.3717 -0.1506 -0.0836 -0.1027 -2.0048 -0.7071 -0.0970 -1.0240 -0.1004 -0.8886 -0.1880 -0.0690 -0.0776 -0.5043 -0.2033 -0.0846 -0.1097 -0.1353 -1.2748 -0.1160 -0.1691 -1.2076 -0.0261 -0.0848 -0.2893 -0.0314 -0.0224 -0.1059 -0.1175 -0.1022 -0.1387 -0.0767 -0.0945 -0.3950 -0.9968 -1.5156 -0.0965 -0.6396 -0.2477 -0.0863 -0.0407 -0.2842 -0.0870 -0.3186 -0.3696 -0.0468 -0.0742 -0.2163 -0.3367 -0.1128 -0.1209 -0.2521 -2.4993 -0.1249 -0.6298 -0.3310 -0.5341 -0.1636 -0.0511 -0.1372 -0.0994 -0.1038 -0.0773 -0.2749 -0.0598 -0.0257 -0.1003 -0.4198 -1.9922 -0.0961\n",
            "T-257\tMwamuna wokhala ndi chipewa ndi malaya abulauni atayima pamtunda waudzu pafupi ndi mulu wa udzu kapena udzu pamtundu wina wa matabwa womangidwa pa kavalo wokhala ndi maunyolo.\n",
            "H-257\t-0.2955968379974365\t▁ M w a m u n a ▁ w o k h a l a ▁ n d i ▁ c h i p e w a ▁ n d i ▁ m a l a y a ▁ a b u l a u n i ▁ a t a i m a ▁ p a m t u n d a ▁ w a u z u ▁ p a f u p i ▁ n d i ▁ m u n t h u ▁ w a u k u l u ▁ w a ▁ m t u n d a ▁ w i n a ▁ w o v a l a ▁ m a t h a l a u z a ▁ o m a n g i d w a ▁ n d i ▁ k a b u d u l a ▁ w o k h a l a ▁ n d i ▁ m a w u ▁ o k h a l a ▁ n d i ▁ m a l o ▁ o b i r i w i r a .\n",
            "D-257\t-0.2955968379974365\tMwamuna wokhala ndi chipewa ndi malaya abulauni ataima pamtunda wauzu pafupi ndi munthu waukulu wa mtunda wina wovala mathalauza omangidwa ndi kabudula wokhala ndi mawu okhala ndi malo obiriwira.\n",
            "P-257\t-0.1312 -0.0745 -0.0787 -0.1033 -0.1291 -0.0741 -0.0740 -0.0957 -0.1185 -0.1102 -0.0590 -0.3711 -0.0117 -0.1042 -0.0518 -0.0959 -0.1040 -0.0500 -0.1133 -0.1049 -0.0960 -0.2518 -0.0850 -0.0991 -0.0242 -0.3891 -0.1782 -0.1413 -0.2128 -1.8515 -0.1286 -0.0845 -0.0952 -0.0476 -0.1488 -0.8203 -0.1058 -0.0402 -0.0936 -0.1526 -0.1142 -1.4941 -0.1047 -0.0789 -0.4292 -0.0477 -0.0726 -0.0964 -0.1735 -0.8967 -0.2766 -0.0959 -0.3922 -0.0684 -0.1131 -0.1163 -0.1933 -0.1337 -0.4539 -0.6080 -0.2360 -0.0667 -0.0288 -0.0721 -0.1584 -0.0514 -0.1145 -0.4306 -0.5898 -0.0701 -0.2126 -0.1860 -0.1335 -0.0268 -0.0946 -0.0478 -0.1149 -0.1378 -0.0575 -0.1737 -0.1208 -0.1121 -0.6744 -1.5735 -0.3590 -0.9099 -0.0776 -0.0660 -0.1424 -0.0355 -0.4857 -0.5751 -0.2416 -0.1563 -0.2438 -0.0567 -0.2037 -0.2222 -0.2493 -0.7177 -0.3297 -2.0865 -1.2552 -0.1452 -0.0282 -0.1475 -0.1793 -0.0322 -0.1738 -0.0448 -0.0975 -0.1428 -0.0593 -1.7160 -1.4396 -0.1002 -0.0891 -0.1046 -0.1279 -0.3042 -0.1079 -0.1378 -0.2561 -0.1156 -0.0662 -0.1145 -0.0387 -0.0301 -0.1111 -0.1269 -0.3017 -1.0533 -2.2972 -0.0309 -0.1131 -0.0581 -0.2094 -0.0362 -0.0985 -0.1590 -0.5457 -0.0962 -0.0903 -0.1935 -1.8226 -0.2136 -1.2901 -0.0830 -0.6126 -0.0933 -0.0331 -0.5481 -0.2346 -0.0321 -0.1508 -0.5177 -0.0294 -0.1151 -0.0584 -0.1114 -0.1206 -0.1064 -0.1043 -0.1065 -0.1321 -0.1180 -0.3477 -0.5060 -0.1946 -0.2978 -0.8125 -1.6996 -0.1309 -0.1111 -0.0575 -0.1076 -0.1474 -0.2211 -0.0883 -0.0924 -0.1789 -0.1153 -0.3871 -1.3936 -0.4831 -0.1372 -0.3206 -2.7664 -0.1684 -0.1387 -0.0558 -0.0299 -0.0637 -0.1493 -0.1289 -1.8413 -0.1471\n",
            "T-397\tWosewera wa lacrosse wovala yunifolomu yofiira yokhala ndi nambala 33 kumbuyo amayang'ana kumwamba pomwe wosewera wovala yunifolomu yobiriwira yokhala ndi chikasu chachikasu amawonekera kumbuyo.\n",
            "H-397\t-0.2916198968887329\t▁ W o s e w e r a ▁ w a ▁ h o c k e y ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o f i y i r a ▁ y o k h a l a ▁ n d i ▁ n a m b a l a ▁ y o k h a l a ▁ n d i ▁ k u m b u y o ▁ a m a y a n g ' a n a ▁ k u m b u y o ▁ k w a ▁ m w a m u n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o m w e ▁ i l i ▁ n d i ▁ c h i p a l e ▁ c h a c h i k a s u ▁ a m a w o n e k e r a ▁ k u m b u y o .\n",
            "D-397\t-0.2916198968887329\tWosewera wa hockey wovala yunifolomu yofiyira yokhala ndi nambala yokhala ndi kumbuyo amayang'ana kumbuyo kwa mwamuna wovala yunifolomu yomwe ili ndi chipale chachikasu amawonekera kumbuyo.\n",
            "P-397\t-0.1242 -0.1895 -0.0676 -0.2239 -0.0670 -0.0628 -0.0621 -0.0693 -0.1695 -0.1474 -0.2419 -0.1683 -0.2527 -2.9789 -0.7520 -1.1807 -0.0629 -0.2929 -0.4326 -0.1733 -0.1233 -0.2587 -1.1152 -0.1220 -0.0912 -0.1098 -0.1352 -0.1695 -0.0346 -0.0349 -0.0468 -0.0430 -0.0892 -0.0594 -0.0510 -0.0308 -0.0559 -0.1281 -0.0076 -0.1403 -0.3382 -0.1722 -0.9023 -0.0843 -0.1316 -0.1022 -0.3284 -0.1474 -0.0898 -0.0308 -0.0486 -0.1115 -0.0716 -0.0989 -0.1488 -0.0757 -0.1162 -0.1050 -0.1003 -0.3004 -0.6462 -0.2219 -0.0564 -0.1028 -0.0410 -0.1029 -0.1201 -1.1090 -0.9460 -0.3966 -0.0420 -0.0941 -0.1325 -0.0874 -0.1073 -0.1644 -0.1988 -0.1329 -0.1270 -4.2722 -0.2398 -0.5515 -0.0322 -0.1513 -0.0622 -0.0744 -0.2084 -1.0986 -0.3423 -0.1004 -0.4334 -0.2521 -0.0516 -0.0251 -0.0680 -0.0849 -0.0793 -0.0944 -0.1409 -0.4337 -0.1630 -0.9366 -0.0951 -0.2433 -0.0459 -0.0693 -0.1745 -0.2703 -0.2928 -0.1340 -0.3522 -0.4581 -1.4958 -0.1108 -0.0633 -1.1553 -0.0826 -0.0880 -0.1362 -0.0981 -0.0999 -0.7920 -0.0980 -0.0723 -0.1060 -0.1106 -0.8552 -0.0520 -0.0483 -0.0759 -0.0620 -0.0481 -0.1948 -0.0410 -0.0210 -0.1414 -0.1678 -0.0091 -0.0839 -0.6443 -0.1624 -0.1206 -0.1180 -0.2257 -0.5204 -0.0943 -0.0915 -0.7337 -0.1372 -0.1179 -0.1074 -1.6815 -0.0631 -0.1371 -0.9831 -0.9545 -0.1746 -0.2201 -0.1002 -0.0705 -0.0761 -0.7088 -1.2241 -0.0723 -0.0927 -0.1052 -0.1186 -0.0413 -0.0579 -0.2155 -1.0912 -0.3501 -0.2645 -0.4224 -0.4880 -0.0836 -0.0730 -0.2538 -0.7395 -0.3227 -0.1319 -0.2339 -1.3288 -0.2283 -0.0852 -0.0300 -0.0629 -0.0362 -0.0413 -1.8938 -0.1265\n",
            "T-148\tPanthawi ya masewera olimbitsa thupi , katswiri wa masewera olimbitsa thupi ovala yunifolomu ya buluu ndi golide adzakhala akugwiritsa ntchito ma hoops awo kuti azichita .\n",
            "H-148\t-0.30896225571632385\t▁ A n t h u ▁ a w i r i ▁ a m a s e w e r a ▁ o l i m b i t s a ▁ t h u p i ▁ a m a s e w e r a ▁ o l i m b i t s a ▁ t h u p i ▁ y o b i r i w i r a ▁ y a b u l u u ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ l i k u g w i r i t s a ▁ n t c h i t o ▁ k u g w i r i t s a ▁ n t c h i t o ▁ k u t i ▁ a w o .\n",
            "D-148\t-0.30896225571632385\tAnthu awiri amasewera olimbitsa thupi amasewera olimbitsa thupi yobiriwira yabuluu ndi gulu la anthu likugwiritsa ntchito kugwiritsa ntchito kuti awo.\n",
            "P-148\t-0.1225 -0.2229 -0.0339 -0.0433 -0.0397 -0.0965 -0.1232 -0.1314 -0.5199 -0.1312 -0.0827 -0.1021 -0.2577 -0.1666 -0.1527 -0.1205 -0.0481 -0.0387 -0.0706 -0.0657 -0.0874 -0.1229 -0.1825 -0.4076 -0.6697 -0.0884 -0.0575 -0.0295 -0.0716 -0.0825 -0.0458 -0.0987 -0.1317 -0.1268 -0.0865 -0.0617 -0.1741 -0.0573 -0.2518 -2.1527 -1.5177 -0.7080 -0.0734 -0.1047 -0.0631 -0.0593 -0.1210 -0.1357 -0.1889 -0.1566 -0.6865 -0.1541 -0.0708 -0.0295 -0.0686 -0.0469 -0.0506 -0.1665 -0.1350 -0.4091 -0.0891 -0.0635 -0.1690 -0.0646 -0.2492 -2.0998 -0.1231 -0.7600 -0.2169 -0.5977 -0.0916 -0.0688 -0.1032 -0.1189 -0.0857 -0.2117 -1.0160 -1.7235 -1.0881 -0.1335 -0.0615 -0.1074 -0.0523 -0.4269 -0.4373 -0.2148 -0.1279 -0.3777 -0.8892 -0.1339 -0.0894 -0.0743 -0.1619 -0.0456 -0.6759 -0.0766 -0.1212 -0.6397 -0.2564 -0.2512 -0.0730 -0.1176 -0.5156 -0.1909 -1.9220 -0.0786 -0.3931 -1.4797 -0.2776 -0.0851 -0.6108 -0.0254 -0.0910 -0.1035 -0.1058 -0.3223 -0.1037 -0.0282 -0.0931 -0.1354 -0.0116 -0.0352 -0.1065 -1.4042 -0.0639 -0.7869 -0.1010 -0.0815 -0.0467 -1.1634 -0.0323 -0.1855 -0.1004 -0.1116 -0.2752 -0.0516 -0.0697 -0.0895 -0.1248 -0.0152 -0.0268 -0.1366 -2.2506 -0.1096 -1.0492 -0.4825 -0.2264 -0.5094 -1.6918 -0.0862 -1.8724 -0.1141\n",
            "T-228\tMwamuna wamutu wofiira atavala kilt akuvina ndi mkazi wamutu wofiira atavala siketi yobiriwira poyang'ana siteji yakuda.\n",
            "H-228\t-0.27309873700141907\t▁ M w a m u n a ▁ w a ▁ m u t u ▁ w o f i i r a ▁ a t a v a l a ▁ t - s h i r t ▁ y a k u d a ▁ n d i ▁ m k a z i ▁ w a m u t u ▁ w o f i i r a ▁ a t a v a l a ▁ j e k e t e ▁ y o b i r i w i r a ▁ y o y e r a ▁ n d i ▁ d z a n j a ▁ l a k e ▁ l o b i r i w i r a ▁ .\n",
            "D-228\t-0.27309873700141907\tMwamuna wa mutu wofiira atavala t-shirt yakuda ndi mkazi wamutu wofiira atavala jekete yobiriwira yoyera ndi dzanja lake lobiriwira .\n",
            "P-228\t-0.1229 -0.0868 -0.1073 -0.0861 -0.0795 -0.0937 -0.0935 -0.0986 -0.1466 -0.1084 -0.4852 -1.4770 -0.4174 -0.8586 -0.1585 -0.1439 -0.0981 -0.0942 -0.2692 -0.2433 -0.1030 -0.2078 -0.0916 -0.2870 -0.2504 -0.0864 -0.0443 -0.1011 -0.0208 -0.1133 -0.0862 -0.1127 -0.1037 -0.8982 -0.5404 -0.1115 -0.0261 -0.6807 -0.0161 -0.0080 -0.1015 -1.2534 -0.3594 -0.2980 -0.0980 -0.1475 -0.0810 -0.1772 -0.0507 -0.0754 -0.1142 -0.0989 -0.0901 -0.0570 -0.0973 -0.0136 -0.0895 -0.1294 -0.0865 -0.4313 -0.7224 -0.5345 -0.1523 -0.0396 -0.1391 -0.1588 -0.2221 -0.8150 -0.1109 -0.3304 -0.0745 -0.2123 -0.2280 -0.1593 -0.0401 -0.0961 -0.2579 -0.1040 -0.0827 -0.1170 -0.0899 -1.4265 -0.1149 -0.0552 -0.0751 -0.0147 -0.0936 -0.0940 -0.2827 -0.0671 -1.0234 -0.2958 -0.1350 -0.0802 -0.0312 -0.0978 -0.1358 -0.0934 -0.2229 -2.4402 -0.2113 -0.4287 -0.3124 -0.3502 -0.1006 -0.2718 -0.4699 -0.1769 -0.0925 -0.2598 -2.3514 -0.5179 -0.2118 -0.0257 -0.1737 -0.4588 -0.1701 -0.0583 -0.2812 -0.1293 -0.0854 -0.1855 -0.2951 -0.9805 -1.2712 -0.0894 -0.2221 -0.1130 -0.0231 -0.1075 -0.2185 -0.0890 -0.6178 -0.9412 -0.1024\n",
            "T-196\tBambo akugwira ntchito yonola m'mphepete mwa mpeni, patebulo m'khitchini yowotchedwa ndi dzuwa.\n",
            "H-196\t-0.3671998083591461\t▁ B a m b o ▁ a k u g w i r a ▁ n t c h i t o ▁ y o y e r a ▁ y o m w e ▁ i l i ▁ p a t e b u l o ▁ l a ▁ t e b u l o ▁ n d i ▁ c h i z i n d i k i r o ▁ .\n",
            "D-196\t-0.3671998083591461\tBambo akugwira ntchito yoyera yomwe ili patebulo la tebulo ndi chizindikiro .\n",
            "P-196\t-0.1325 -0.0841 -0.1041 -0.1028 -0.1266 -0.0651 -0.1111 -1.5898 -0.1317 -0.0836 -0.0943 -0.1384 -0.0927 -0.0542 -0.0995 -0.1035 -0.0393 -0.0319 -0.0116 -0.1052 -0.0975 -0.0385 -0.0404 -0.0720 -0.1996 -0.3035 -1.9214 -0.2777 -0.0760 -0.1083 -0.1421 -1.6634 -2.3571 -0.4141 -0.3208 -0.0746 -0.1068 -0.4772 -0.5019 -0.1178 -0.0951 -0.1344 -0.1437 -0.9779 -0.0369 -0.1051 -0.0606 -0.0782 -0.0398 -0.1100 -1.1886 -0.3622 -0.5499 -0.8317 -0.6408 -1.0166 -0.0742 -0.1017 -0.0555 -0.1661 -1.3712 -0.1151 -0.1435 -0.0974 -0.7940 -0.0911 -0.1199 -3.2549 -0.1513 -0.3588 -0.5169 -0.0890 -0.0290 -1.5083 -0.1456 -0.0273 -0.1410 -0.5386 -0.1342\n",
            "T-181\tWosewera mpira wa tennis amayang'ana kwambiri mpirawo pamene akukonzekera kuwumenya , pamene wojambula zithunzi amaima kumbuyo pafupi ndi chizindikiro cha malonda a La Quinta .\n",
            "H-181\t-0.3222188353538513\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ t e n i s ▁ a m a y a n g ' a n a ▁ k w a m b i r i ▁ w o v a l a ▁ m a l a y a ▁ o k o n z e k e r a ▁ k u m e n y a ▁ p a m e n e ▁ m n y a m a t a ▁ w o j a m b u l a ▁ z i t h u n z i ▁ n d i ▁ m a n j a ▁ a k e ▁ k u m b u y o ▁ k w a k e ▁ n d i ▁ m a l o ▁ o m w e ▁ a k u y a n g ' a n a ▁ .\n",
            "D-181\t-0.3222188353538513\tWosewera mpira wa tenis amayang'ana kwambiri wovala malaya okonzekera kumenya pamene mnyamata wojambula zithunzi ndi manja ake kumbuyo kwake ndi malo omwe akuyang'ana .\n",
            "P-181\t-0.1190 -0.1177 -0.0909 -0.1187 -0.0522 -0.0857 -0.0529 -0.0596 -0.4624 -0.1633 -0.0693 -0.0117 -0.0905 -0.0739 -0.1248 -0.1986 -0.0924 -0.1624 -0.1746 -0.1488 -0.0789 -0.1322 -0.5746 -0.0541 -0.6207 -1.7338 -0.1491 -0.1687 -0.6587 -0.1093 -0.1162 -0.0170 -0.1919 -0.0868 -0.0653 -0.0973 -0.1088 -2.2013 -0.5285 -0.1257 -0.1506 -0.0422 -0.0854 -0.0441 -0.0811 -0.2099 -0.6096 -0.1945 -2.0544 -0.1028 -0.0803 -0.1016 -0.1188 -0.3781 -0.2251 -0.2309 -0.1216 -0.0602 -0.0828 -0.1270 -0.4659 -0.8226 -0.0400 -0.0607 -0.1368 -0.0546 -0.0732 -0.0561 -0.1402 -0.1206 -0.1761 -0.6813 -0.1175 -0.6841 -0.2979 -0.0798 -0.1429 -0.1249 -0.1933 -1.5322 -0.1773 -0.3739 -0.2196 -0.0535 -0.1600 -0.1397 -2.1039 -0.5932 -0.0506 -0.1035 -0.0592 -0.0653 -0.0327 -0.0812 -0.1538 -0.0217 -1.6169 -1.7622 -0.1176 -0.2263 -0.0580 -0.1043 -0.0995 -0.0999 -0.2396 -0.3553 -0.0842 -0.2583 -0.3344 -0.0789 -0.0666 -0.0400 -0.0762 -0.1829 -1.8277 -0.1282 -0.1181 -0.2292 -0.6966 -0.0998 -2.9428 -0.2979 -0.0964 -0.1044 -0.2499 -0.4302 -0.8283 -0.2147 -1.2611 -0.1039 -0.2521 -0.0528 -0.0933 -0.0442 -0.0531 -0.1187 -0.8506 -0.0570 -0.1153 -0.3216 -0.1172 -0.3585 -0.9686 -0.1155 -0.0828 -0.0927 -1.1261 -0.8545 -0.2099 -0.2693 -0.1434 -0.9484 -1.0468 -0.1154 -0.0898 -0.1476 -0.1172 -1.8018 -0.1444 -0.5561 -0.6622 -0.0742 -0.0826 -0.0791 -0.0936 -0.0873 -0.1230 -0.4699 -0.5439 -0.0882\n",
            "T-330\tMwamuna wina wovala chipewa choweta ng'ombe akuyendetsa ngolo ya ayisikilimu yokhala ndi mawu akuti ' Sorvete e Gelados Nicolau .\n",
            "H-330\t-0.33366402983665466\t▁ M w a m u n a ▁ w i n a ▁ w o v a l a ▁ c h i p e w a ▁ c h o w e t a ▁ n g ' o m b e ▁ y a k u d a ▁ n d i ▁ y a f u l o n g o ▁ y o k h a l a ▁ n d i ▁ n s i k e ▁ y o k h a l a ▁ n d i ▁ m i t e n g o ▁ y o k h a l a ▁ n d i ▁ g a l u ▁ w a b u l a u n i ▁ .\n",
            "D-330\t-0.33366402983665466\tMwamuna wina wovala chipewa choweta ng'ombe yakuda ndi yafulongo yokhala ndi nsike yokhala ndi mitengo yokhala ndi galu wabulauni .\n",
            "P-330\t-0.1244 -0.0575 -0.0511 -0.1053 -0.2700 -0.0824 -0.0978 -0.0993 -0.1391 -0.0815 -0.1117 -0.0774 -0.0989 -0.1264 -0.0900 -0.1098 -0.0371 -0.1122 -0.0812 -0.1156 -0.1030 -0.1039 -0.1009 -0.0807 -0.0404 -0.0734 -0.0697 -0.0919 -0.1374 -0.0407 -0.1177 -0.0747 -0.1439 -0.2033 -0.1804 -0.0838 -0.1448 -0.0736 -0.0171 -0.2216 -0.0863 -0.0475 -0.0232 -0.1389 -0.1538 -0.2077 -0.1258 -0.4510 -0.0947 -1.0889 -0.2628 -0.2927 -0.4349 -0.3398 -0.1474 -0.0863 -1.2330 -0.3982 -2.6399 -0.2400 -0.2120 -0.0442 -1.1652 -1.1652 -0.0357 -0.3447 -0.1833 -1.4717 -0.2371 -0.0427 -0.1344 -0.0736 -0.1057 -0.1099 -0.2349 -0.1662 -0.1180 -0.0778 -1.2083 -1.0904 -0.1913 -1.0307 -0.3580 -0.8864 -0.0650 -0.1848 -0.1048 -0.0475 -0.1344 -0.0665 -0.1099 -0.0983 -0.1753 -0.2284 -0.1078 -0.0829 -0.3922 -2.3190 -0.1154 -1.8471 -0.2774 -0.0203 -0.0603 -0.1006 -0.2715 -0.5467 -1.2164 -0.2658 -0.4454 -0.0614 -0.0868 -0.1104 -0.3857 -0.5460 -0.1741 -0.0739 -2.8818 -0.1044 -0.0790 -1.3766 -0.1060 -0.2096 -0.4311 -2.0211 -0.0930 -0.0618 -1.0692 -0.0367 -0.0406 -0.0671 -0.3045 -1.3174 -0.1039\n",
            "T-166\tAchinyamata awiri akukwera pa makwerero , mtsikanayo ali pakati pa mtengo wokutidwa ndi masamba ndipo mnzake wovala malaya abuluu akumwetulira kumbuyo .\n",
            "H-166\t-0.33656758069992065\t▁ A c h i n y a m a t a ▁ a w i r i ▁ a k u k w e r a ▁ p a ▁ m a k w e r e r o ▁ n d i p o ▁ a t a y i m a ▁ p a k a t i ▁ p a ▁ m t e n g o ▁ w o k u t i d w a ▁ n d i ▁ m a s a m b a ▁ o v a l a ▁ s h a t i ▁ n d i p o ▁ m a l a y a ▁ a b u l u u ▁ a m a t u l i r a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-166\t-0.33656758069992065\tAchinyamata awiri akukwera pa makwerero ndipo atayima pakati pa mtengo wokutidwa ndi masamba ovala shati ndipo malaya abuluu amatulira kumbuyo kwake .\n",
            "P-166\t-0.1168 -0.0537 -0.9967 -0.2690 -0.0926 -0.1345 -0.0465 -0.1037 -0.0468 -0.0984 -0.0261 -0.0955 -0.1464 -0.0940 -0.0234 -0.1050 -0.0533 -0.0875 -0.1876 -0.2583 -0.3825 -0.1250 -0.1311 -0.1128 -0.0422 -0.0951 -0.1662 -0.1489 -0.0634 -0.1402 -1.2092 -0.1831 -0.0599 -2.3951 -0.0512 -0.0568 -0.1485 -1.5377 -0.1523 -0.0652 -0.2258 -0.1077 -1.4040 -0.1065 -2.4451 -0.0851 -0.1180 -1.2235 -1.7355 -0.1384 -0.3952 -0.0668 -1.2501 -0.0860 -0.1624 -0.0409 -0.1514 -0.3513 -0.1924 -0.0120 -0.0750 -0.1491 -0.0283 -0.1492 -0.1250 -0.3550 -2.2238 -0.0879 -0.0541 -0.0264 -0.0638 -0.1649 -0.4020 -0.3857 -1.1964 -0.5251 -0.0126 -0.0613 -0.0100 -0.0455 -0.0951 -0.1247 -0.1240 -0.1058 -0.1109 -0.1235 -0.0734 -0.1198 -0.1801 -0.1705 -0.0192 -0.0237 -0.1072 -0.1249 -1.6846 -2.2979 -0.0998 -0.0625 -0.1016 -0.0993 -0.6624 -1.2587 -0.1473 -0.0623 -0.0583 -0.1173 -1.7669 -0.0403 -0.1063 -0.6777 -0.0779 -0.0934 -0.3808 -0.9293 -0.6376 -0.1748 -0.0508 -0.1105 -0.1068 -0.1428 -0.3020 -0.1166 -0.0420 -0.0827 -0.0457 -0.1633 -0.3788 -1.8474 -0.1333 -1.1966 -0.2952 -1.0037 -0.5324 -0.2788 -0.0898 -0.3523 -0.5456 -0.2282 -0.4146 -0.0251 -0.0477 -0.0326 -0.0429 -0.1850 -0.3100 -0.1590 -0.1168 -0.6594 -0.0759 -0.9542 -0.2058 -0.1028\n",
            "T-96\tAnthu awiri omwe ali ndi ma jekete alalanje ndi oyera ofanana ndi zipewa zoyera atakhala panjinga yamoto panjira yonyowa njerwa yotuwa; Masitepe a njerwa imvi akukwera kumbuyo kwawo .\n",
            "H-96\t-0.26438722014427185\t▁ A n t h u ▁ a w i r i ▁ o m w e ▁ a l i ▁ n d i ▁ m a j a k e t i ▁ a l a l a n j e ▁ n d i p o ▁ w i n a ▁ w o v a l a ▁ n d i ▁ z i p e w a ▁ z o y e r a ▁ a t a k h a l a ▁ p a n j i n g a ▁ y a m o t o ▁ y o k h a l a ▁ n d i ▁ n j e r w a ▁ y o t u w a ▁ m a s i t e p e ▁ o t u w a ▁ n d i ▁ m a s i t e p e ▁ o y e r a ▁ k u m b u y o ▁ k w a w o .\n",
            "D-96\t-0.26438722014427185\tAnthu awiri omwe ali ndi majaketi alalanje ndipo wina wovala ndi zipewa zoyera atakhala panjinga yamoto yokhala ndi njerwa yotuwa masitepe otuwa ndi masitepe oyera kumbuyo kwawo.\n",
            "P-96\t-0.1273 -0.0320 -0.1511 -0.0648 -0.1310 -0.0934 -0.1143 -0.1233 -0.2417 -0.1443 -0.0681 -0.0867 -0.2528 -0.1031 -0.5102 -0.1858 -0.0926 -0.1264 -0.0958 -0.0268 -0.0823 -0.1211 -0.0349 -0.1053 -0.1037 -0.0943 -0.1002 -0.0977 -1.2862 -0.0933 -0.2726 -0.2464 -0.1898 -0.1692 -0.1343 -0.1404 -2.3363 -0.2959 -0.0499 -0.1006 -0.0369 -0.0290 -0.0421 -0.2814 -0.4290 -0.0905 -0.0972 -0.5938 -0.0614 -0.0952 -1.4447 -0.4210 -0.1319 -0.0883 -0.1795 -0.2325 -0.1735 -0.6741 -0.1099 -0.1124 -0.1038 -0.1256 -1.1035 -1.0249 -0.1306 -0.4187 -0.0991 -0.1305 -0.3757 -0.0906 -0.0902 -0.1026 -0.2165 -0.0379 -0.1174 -0.0293 -0.0793 -0.0991 -0.0998 -0.3090 -0.1096 -0.4491 -0.1130 -0.1369 -0.0522 -0.0972 -0.0511 -0.1079 -0.1527 -0.0553 -0.1361 -0.2676 -0.0375 -0.0891 -0.0736 -0.0332 -0.0677 -0.1922 -0.0173 -1.2788 -0.3476 -0.0279 -0.1432 -0.0761 -0.2320 -0.0759 -0.2464 -2.3091 -0.2748 -0.1065 -0.0584 -0.0856 -0.1381 -0.5277 -0.5651 -0.1012 -0.1030 -1.6026 -0.2635 -0.8776 -0.3466 -0.0475 -0.0791 -0.2267 -0.0358 -0.2102 -0.9757 -0.2844 -0.0126 -0.0987 -0.3476 -0.9350 -1.0988 -0.0763 -0.1878 -0.1235 -0.0590 -0.2140 -0.0885 -0.1463 -0.4582 -0.3870 -0.1268 -0.0641 -0.1069 -0.2976 -0.7499 -0.3323 -0.1183 -0.3521 -0.2358 -0.0663 -0.1452 -0.2310 -0.1300 -0.0545 -0.1918 -0.0817 -0.1505 -0.7746 -0.7776 -0.1644 -0.1577 -0.0749 -0.3169 -0.6968 -0.1436 -0.8027 -0.0247 -0.0737 -0.0614 -0.0749 -0.2574 -0.3385 -0.1005 -0.1101 -0.2478 -0.1382 -1.6654 -0.0988\n",
            "T-52\tKamtsikana kakang'ono m'bafa ndikumwetulira kwakukulu ndipo tsitsi lake lonyowa likulunjika ngati tsitsi la Alfalfa mu pulogalamu yakale yapa TV The Little Rascals .\n",
            "H-52\t-0.3760451376438141\t▁ K a m t s i k a n a ▁ k a k a n g ' o n o ▁ k a ▁ b a s k e t b a l l ▁ w a i m i r i r a ▁ k u t s o g o l o ▁ k w a k e ▁ n d i ▁ s i k e t i ▁ y a ▁ b u l u u ▁ n d i ▁ j e a n s ▁ y a b u l u u ▁ p a f u p i ▁ n d i ▁ m u t u ▁ w o v a l a ▁ m o t o ▁ .\n",
            "D-52\t-0.3760451376438141\tKamtsikana kakang'ono ka basketball waimirira kutsogolo kwake ndi siketi ya buluu ndi jeans yabuluu pafupi ndi mutu wovala moto .\n",
            "P-52\t-0.1349 -0.2056 -0.1277 -0.0646 -0.0179 -0.0620 -0.1043 -0.1049 -0.1146 -0.1181 -0.1191 -0.1546 -0.0321 -0.1078 -0.2196 -0.1194 -0.0879 -0.0421 -0.0626 -0.0672 -0.0528 -0.0790 -0.1071 -0.2695 -0.2725 -0.9240 -2.0767 -0.3097 -0.5597 -1.5021 -0.1472 -0.0265 -0.1337 -0.0853 -0.0259 -0.4659 -0.2899 -1.2728 -0.2558 -0.8455 -0.1146 -0.7745 -0.1541 -0.1052 -0.0598 -0.1496 -0.1308 -0.4829 -0.0752 -1.3093 -1.3773 -0.1075 -0.0539 -0.0681 -0.0592 -0.0829 -0.1323 -0.4827 -0.2206 -0.1243 -1.6984 -0.0439 -0.2207 -0.2335 -0.0735 -0.1281 -0.2243 -0.9260 -0.2455 -1.0150 -0.0232 -0.1859 -0.0508 -0.1502 -0.3969 -0.3076 -1.0185 -0.7873 -0.2307 -0.0645 -0.1014 -0.0596 -0.1715 -1.3836 -0.1341 -0.1425 -0.1661 -3.4962 -0.7413 -0.4944 -0.1572 -0.3634 -0.1425 -0.2315 -0.1456 -1.4292 -0.0731 -0.0470 -0.0865 -0.0322 -0.1887 -1.3211 -0.1289 -1.8107 -0.0753 -0.0776 -0.0897 -0.1460 -0.1195 -0.1733 -0.1350 -0.0968 -1.3016 -1.0730 -0.9205 -0.0877 -0.1040 -0.1974 -1.0304 -0.3580 -0.1045 -0.0809 -0.1125 -0.1627 -0.7349 -0.6318 -0.9646 -0.0618 -0.4115 -0.9940 -0.1105\n",
            "T-2\tBambo wakuda yemwe akuoneka kuti alibe pokhala ndi nsapato zosagwirizana , mathalauza awiri ndi jekete lolemera amayesa kutenthetsa manja ake atakhala pakhomo.\n",
            "H-2\t-0.3700198531150818\t▁ B a m b o ▁ a k u j a m b u l a ▁ w o n e k a ▁ n g a t i ▁ a l i ▁ k u t i ▁ a k h a l a ▁ p a ▁ n s a p a t o ▁ z o f i i r i r a ▁ m a t h a l a u z a ▁ o v a l a ▁ j e k e t e ▁ l o l e m e r a ▁ n d i p o ▁ a m a y e s a ▁ k u m a n j a ▁ k w a k e ▁ .\n",
            "D-2\t-0.3700198531150818\tBambo akujambula woneka ngati ali kuti akhala pa nsapato zofiirira mathalauza ovala jekete lolemera ndipo amayesa kumanja kwake .\n",
            "P-2\t-0.1165 -0.4156 -0.1047 -0.0659 -0.1142 -0.1013 -0.1138 -1.2711 -0.0978 -0.0859 -0.6273 -1.1905 -0.3304 -0.3849 -0.1010 -0.0775 -0.6310 -0.1358 -0.8386 -1.3503 -0.1951 -0.6407 -0.1745 -0.0942 -0.1049 -0.4343 -0.1725 -0.0730 -0.5682 -0.1176 -0.0975 -0.6968 -0.1764 -0.1343 -0.1068 -1.2452 -0.3083 -0.2205 -0.7439 -0.1328 -0.6167 -0.6864 -0.0796 -0.1078 -0.0504 -0.1274 -0.1069 -0.2806 -0.1149 -1.8281 -1.2966 -0.4476 -0.1237 -0.2784 -0.1069 -0.0334 -0.0359 -0.0961 -0.0084 -0.6447 -0.7846 -0.1196 -0.2732 -0.0780 -0.4344 -0.1458 -0.1153 -0.2344 -2.5420 -0.3943 -0.5555 -0.1300 -0.0878 -0.3265 -0.0940 -0.0812 -0.0830 -0.1044 -0.0959 -0.6823 -2.0863 -1.2853 -0.1142 -0.1060 -0.1026 -0.9965 -0.0772 -0.0244 -0.0722 -0.0136 -0.0824 -0.1002 -0.1478 -0.3454 -0.8702 -0.2264 -0.1904 -0.4476 -0.1288 -0.1041 -0.1586 -0.8694 -0.1281 -0.1158 -0.7950 -0.0648 -0.0901 -0.9389 -0.3096 -0.1101 -0.1156 -0.1278 -0.7347 -0.1106 -0.1195 -0.2839 -0.0858 -1.5921 -0.5616 -0.1278 -0.0131 -0.0962 -0.1200 -0.9648 -0.4276 -0.1333 -1.2720 -0.0408 -0.2477 -1.0612 -0.1100\n",
            " 15% 2/13 [00:07<00:39,  3.60s/it, wps=515]T-283\tMtsikana wina wosewera mpira wa basketball yemwe wavala yunifolomu yofiira wanyamula mpira wa basketball akuyang'ana m'mwamba kwinaku dzanja likufuna kumutsekereza .\n",
            "H-283\t-0.28959712386131287\t▁ A t s i k a n a ▁ a w i r i ▁ o s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ p o y e r a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o y e r a ▁ w a g w i r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ m ' m b a l i ▁ m w a ▁ m s e w u ▁ n d i ▁ m z i n d a ▁ a k u f u n a ▁ .\n",
            "D-283\t-0.28959712386131287\tAtsikana awiri osewera mpira wa basketball poyera wovala yunifolomu yoyera wagwira mpira wa basketball m'mbali mwa msewu ndi mzinda akufuna .\n",
            "P-283\t-0.1320 -0.2909 -0.5412 -0.1092 -0.0885 -0.0723 -0.1135 -0.0886 -0.1023 -0.1553 -0.1028 -0.0824 -0.1190 -0.1306 -0.0858 -0.5922 -0.7899 -0.0923 -0.0372 -0.1093 -0.0792 -0.0629 -0.0996 -0.2014 -0.0329 -0.2037 -0.0888 -0.1942 -0.1123 -0.2423 -0.1451 -0.1977 -0.3976 -0.4239 -0.0816 -0.0368 -0.1112 -0.0876 -0.0221 -0.1797 -0.0706 -0.0319 -0.2931 -0.3329 -0.7351 -0.4567 -0.3542 -0.1214 -0.8144 -0.0628 -0.2096 -2.5045 -0.1787 -0.2294 -0.1114 -0.0905 -0.1120 -0.1191 -0.3314 -0.0472 -0.0450 -0.0480 -0.0106 -0.0889 -0.1007 -0.0562 -0.0285 -0.0498 -0.1522 -0.0385 -0.2080 -1.3251 -0.1609 -0.1667 -0.0904 -0.2099 -1.4603 -0.1247 -0.6116 -0.2396 -0.1884 -0.0983 -0.1145 -0.1589 -0.2582 -0.3671 -0.8188 -0.1005 -0.1194 -0.1908 -0.2307 -0.2345 -0.8934 -0.0542 -0.0959 -0.0940 -0.2867 -0.1086 -0.0522 -0.0270 -0.0841 -0.0741 -0.6317 -0.4863 -0.6113 -0.2315 -0.2532 -0.4226 -0.1054 -0.0262 -0.0836 -0.1807 -0.2122 -0.1831 -0.1019 -0.1681 -0.6550 -1.4198 -0.0418 -0.0475 -0.0853 -0.2251 -1.3376 -0.2212 -0.1303 -0.2794 -1.1048 -1.9773 -0.3263 -0.0953 -0.0278 -0.1006 -0.1794 -0.9871 -0.1406 -0.0957 -1.6476 -0.0216 -0.3096 -0.5502 -0.5301 -1.1495 -0.1193\n",
            "T-65\tAchinyamata atatu amawoloka msewu pa nyali yofiyira, m'modzi wavala kapu ya baseball yoyera ndi ya bulauni, m'modzi wavala kapu yakuda ya baseball ndipo wina wapakati wavala kapu ya sitoko.\n",
            "H-65\t-0.3585290014743805\t▁ A c h i n y a m a t a ▁ a t a t u ▁ o m w e ▁ w o v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ n d i ▁ o f i i r a ▁ m ' m o d z i ▁ w a v a l a ▁ k a b u d u l a ▁ w o y e r a ▁ n d i p o ▁ w i n a ▁ w a v a l a ▁ j u z i ▁ l a k u d a ▁ l a b u l u u ▁ w o y e r a ▁ n d i p o ▁ w i n a ▁ w a v a l a ▁ j e k e t e ▁ l a b u l u u ▁ w o k h a l a ▁ n d i ▁ m a s i t o l o ▁ o f i i r a .\n",
            "D-65\t-0.3585290014743805\tAchinyamata atatu omwe wovala malaya obiriwira ndi ofiira m'modzi wavala kabudula woyera ndipo wina wavala juzi lakuda labuluu woyera ndipo wina wavala jekete labuluu wokhala ndi masitolo ofiira.\n",
            "P-65\t-0.1328 -0.0591 -0.6572 -0.1632 -0.1066 -0.0584 -0.0285 -0.0977 -0.0587 -0.1060 -0.0441 -0.0920 -0.1279 -0.1295 -0.0314 -0.0856 -0.0670 -0.0559 -0.1811 -0.2780 -0.3835 -0.0950 -0.0879 -0.1076 -1.9931 -0.6806 -0.1579 -0.0971 -0.1199 -0.1028 -0.1160 -0.2314 -0.1922 -1.2939 -0.1069 -0.0429 -0.0940 -0.1209 -1.4783 -0.6035 -0.4005 -0.0531 -0.0718 -0.0305 -0.1243 -0.0746 -0.0957 -0.2808 -1.4827 -0.2415 -0.0984 -0.1535 -0.8734 -1.3361 -0.1191 -0.4499 -0.0658 -0.2607 -0.4781 -0.6529 -1.0215 -0.5336 -0.0566 -0.0475 -0.0287 -0.1125 -0.1970 -0.0935 -0.3831 -1.6663 -0.0861 -0.1010 -0.1092 -0.1158 -0.6674 -0.1615 -0.2041 -0.0905 -0.5455 -0.1135 -0.0731 -0.1231 -0.1874 -0.8295 -0.6276 -0.0650 -0.0630 -0.1052 -0.0981 -0.2811 -0.1107 -0.1322 -0.1380 -2.4040 -0.0759 -0.1247 -0.8490 -0.3135 -0.0611 -0.0741 -0.2734 -0.1858 -0.2204 -1.4957 -0.0802 -0.1005 -0.1018 -0.1117 -0.9175 -0.1477 -0.0379 -0.1027 -0.1318 -0.8219 -0.3136 -0.1525 -0.0856 -0.0801 -0.0821 -0.1606 -1.4301 -0.2901 -0.9544 -0.0684 -0.0796 -0.4298 -0.0378 -0.2659 -0.8385 -1.3246 -1.6079 -0.0738 -0.3423 -0.0931 -0.2276 -0.7178 -0.1005 -0.1045 -1.4922 -0.0696 -0.1062 -0.1699 -0.1310 -0.0531 -0.0942 -0.1742 -0.1973 -0.1920 -0.7522 -0.1012 -0.0803 -0.1024 -0.1133 -0.6736 -1.5773 -0.9090 -0.0797 -0.0497 -0.1813 -0.1348 -0.4776 -0.6952 -1.4621 -0.0551 -0.0863 -0.1344 -0.0656 -0.2733 -0.4160 -1.0354 -1.5952 -0.2696 -0.1155 -0.0669 -0.1000 -0.1604 -0.2297 -0.4378 -0.1255 -0.1679 -2.3614 -0.1140 -1.2704 -0.1615 -0.1479 -0.0968 -1.5215 -0.0464 -0.5967 -0.8466 -1.0541 -0.1186 -0.1288 -0.1244 -0.1646 -0.6821 -0.1192\n",
            "T-211\tMunthu wovekedwa mikanjo yakuda, amadziunjikira potsegula mlatho, ndi zakumwa zoziziritsa kukhosi pamapazi obisika.\n",
            "H-211\t-0.4050193130970001\t▁ M u n t h u ▁ w o v a l a ▁ m i k a n j o ▁ y a k u d a ▁ a m a i m a ▁ p a m a d z i ▁ o t c h e d w a ▁ n d i ▁ z i t o l o ▁ z o z u n g u l i r i d w a ▁ n d i ▁ z i n g w e ▁ z o s i y i k a .\n",
            "D-211\t-0.4050193130970001\tMunthu wovala mikanjo yakuda amaima pamadzi otchedwa ndi zitolo zozunguliridwa ndi zingwe zosiyika.\n",
            "P-211\t-0.1214 -0.0819 -0.3934 -0.0657 -0.0636 -0.0919 -0.0694 -0.1600 -0.0837 -0.0507 -0.1105 -0.3169 -0.0772 -0.1964 -0.1186 -0.6567 -0.0996 -2.5886 -0.1464 -0.0574 -0.1415 -0.0417 -0.1703 -0.0691 -0.1365 -0.1797 -0.0870 -0.0372 -0.1084 -0.1772 -0.1101 -0.1343 -0.1117 -2.6495 -0.2745 -0.1671 -0.0773 -0.3599 -0.1477 -1.0785 -0.1467 -1.1450 -0.7945 -0.1070 -0.1453 -0.1618 -0.1590 -2.1702 -0.0825 -0.0801 -0.9188 -0.0329 -0.1284 -0.2098 -1.5369 -0.2353 -0.1079 -0.4309 -0.9498 -0.2565 -1.7724 -0.2904 -0.3418 -0.3434 -0.2049 -0.0525 -0.6634 -1.0876 -1.8642 -0.1016 -0.0587 -0.0605 -0.1502 -0.0823 -0.1617 -0.5651 -0.3386 -0.2466 -0.0920 -0.1246 -0.6430 -0.2513 -0.1180 -0.1019 -0.0158 -0.0736 -1.6277 -0.3680 -0.1103 -0.1493 -0.1910 -0.0582 -0.6220 -0.0883 -0.0608 -0.0411 -1.5542 -0.5790 -0.1076 -3.8141 -0.1208\n",
            "T-317\tMayi wina wachikulire wovala diresi lamitundumitundu , jekete lachikopa komanso chipewa chakuda amakhala pabenchi moyang'anizana ndi khoma lakale kwambiri.\n",
            "H-317\t-0.33313173055648804\t▁ A n a ▁ a w i r i , ▁ w a c h i k u l i r e ▁ w o v a l a ▁ d i r e s i ▁ a m i t u n d u m i t u n d u ▁ y a ▁ j e k e t e ▁ y a c h i k o p a ▁ k u m a n z e r e ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ c h a ▁ m a g a l a s i ▁ n d i ▁ k o m a n g a ▁ a n t h u ▁ o m w e ▁ a l i ▁ n d i ▁ k w a m b i r i .\n",
            "D-317\t-0.33313173055648804\tAna awiri, wachikulire wovala diresi amitundumitundu ya jekete yachikopa kumanzere akujambula chithunzi cha magalasi ndi komanga anthu omwe ali ndi kwambiri.\n",
            "P-317\t-0.1253 -0.1096 -1.1114 -0.1311 -0.1828 -0.1545 -0.3108 -0.1054 -0.1514 -0.1010 -2.8407 -0.1413 -0.1642 -0.2204 -0.0394 -0.1130 -0.0947 -0.0623 -0.0819 -0.0718 -0.0778 -0.0606 -0.0786 -0.3517 -0.0803 -0.1243 -0.0583 -0.1156 -0.1048 -0.1170 -0.1183 -2.0225 -0.1147 -0.0096 -0.0651 -0.0298 -0.0884 -0.2662 -0.7306 -0.5618 -0.2087 -0.0312 -0.0662 -0.0950 -0.0300 -0.0702 -0.1389 -0.1021 -0.1063 -0.0718 -0.0607 -0.0481 -0.1009 -0.3065 -1.5663 -0.1194 -1.3343 -1.1660 -0.1702 -0.2066 -0.1040 -0.0447 -0.0852 -0.1755 -0.2265 -0.1086 -0.0974 -0.0547 -0.1366 -0.0398 -0.9120 -1.6435 -0.1757 -0.3771 -0.0680 -0.2752 -0.1602 -0.0694 -0.2942 -0.2167 -0.1375 -0.1270 -0.1945 -0.3042 -0.6140 -0.2307 -0.1190 -1.4261 -0.1014 -0.1380 -0.1279 -0.0850 -0.0546 -0.1110 -0.1880 -0.3652 -0.0749 -0.1444 -0.5337 -0.6635 -0.1785 -0.0596 -0.0311 -0.1281 -0.1925 -0.8839 -0.1342 -0.1341 -0.1527 -1.6885 -0.3137 -1.3235 -0.3444 -0.0603 -0.2754 -0.5319 -0.0726 -0.2715 -1.3895 -0.0528 -0.1273 -0.5201 -0.8070 -0.8665 -0.2710 -0.1397 -0.1444 -1.6513 -0.1674 -0.1719 -0.3696 -1.1514 -1.7928 -0.1948 -0.0619 -0.1575 -0.4798 -0.3635 -0.8050 -0.0866 -0.1419 -0.1347 -0.3519 -0.0827 -0.1496 -0.1900 -0.0959 -0.1041 -0.1679 -0.7062 -1.8021 -0.1249 -0.0933 -0.0298 -0.0622 -0.0742 -0.0717 -1.4430 -0.0997\n",
            "T-324\tOyimba violin atatu, wamkazi, wina wamwamuna, m'modzi wobisika, ndi woyimba cell waamuna atakhala posewera ndikuvala zakuda.\n",
            "H-324\t-0.35149744153022766\t▁ O y i m b a ▁ a t a v a l a ▁ t h u k u t a ▁ l o m w e ▁ l i n a l i ▁ m w a m u n a ▁ w a m n g ' o n o ▁ m ' m o d z i ▁ w o b i r i w i r a ▁ n d i ▁ t s i t s i ▁ l a k a n g ' o n o ▁ n d i p o ▁ w a ▁ m u n a ▁ a t a v a l a ▁ z a k u d a ▁ n d i ▁ g a l a s i ▁ l a k u d a .\n",
            "D-324\t-0.35149744153022766\tOyimba atavala thukuta lomwe linali mwamuna wamng'ono m'modzi wobiriwira ndi tsitsi lakang'ono ndipo wa muna atavala zakuda ndi galasi lakuda.\n",
            "P-324\t-0.1180 -0.4733 -0.9075 -0.8127 -0.1791 -0.0513 -0.1151 -0.1434 -0.7435 -0.3805 -0.1082 -0.0757 -0.1166 -0.0754 -0.1192 -0.1226 -1.4213 -0.5588 -0.0567 -0.0955 -0.1414 -0.0877 -0.0816 -0.1593 -0.0916 -2.3588 -0.2510 -0.0248 -0.1048 -0.1220 -0.3407 -0.1859 -0.6662 -0.1104 -0.6435 -0.4322 -0.1468 -0.3444 -0.5331 -0.0890 -0.1383 -0.0932 -0.1134 -0.0882 -0.2103 -0.8603 -0.1148 -0.5301 -0.2344 -0.0482 -0.0373 -0.0801 -0.0810 -0.0719 -0.2379 -0.3061 -0.8658 -0.1498 -0.2035 -0.0417 -0.0363 -0.0724 -0.2647 -0.3009 -0.4614 -1.2829 -0.0950 -0.5347 -0.1083 -0.1043 -0.1048 -0.3099 -0.0978 -0.3063 -0.3979 -0.0766 -0.0962 -0.1445 -1.4877 -0.1113 -0.8452 -0.1129 -0.0527 -0.1364 -0.1264 -0.0469 -0.9135 -0.9987 -0.6209 -0.5694 -0.3288 -0.0725 -0.0702 -0.0807 -0.0670 -0.1453 -1.4921 -0.0731 -0.1156 -0.6647 -0.0626 -0.1121 -0.2644 -0.1422 -1.7135 -0.1650 -0.2969 -0.0762 -1.0460 -0.1141 -0.3663 -0.8360 -0.0934 -1.1310 -0.1063 -0.0775 -0.1190 -0.1634 -0.8712 -0.3408 -0.5463 -0.0850 -0.1181 -0.1291 -0.4130 -0.9742 -0.1277 -0.0994 -0.1547 -3.0106 -0.2451 -0.0605 -0.4474 -0.2524 -0.0415 -0.3166 -1.3705 -0.0976 -0.2694 -0.0936 -0.0983 -0.1677 -1.2788 -0.0978\n",
            "T-95\tAnthu awiri ovala zipewa zofiira za njinga yamoto akukwera limodzi panjinga yamoto yofiyira m'mphepete mwa msewu kudutsa zikwangwani zonena za Chikomyunizimu.\n",
            "H-95\t-0.28182393312454224\t▁ A n t h u ▁ a w i r i ▁ o v a l a ▁ z i p e w a ▁ z o f i i r a ▁ n d i ▁ n j i n g a ▁ y a m o t o ▁ a k u k w e r a ▁ n j i n g a ▁ y a m o t o ▁ y a m o t o ▁ y o f i i r a ▁ k u t i ▁ m w a m u n a ▁ w o v a l a ▁ z i p e w a ▁ z a c h i k w a n g w a n i ▁ z a ▁ m i t u n d u m i t u n d u ▁ .\n",
            "D-95\t-0.28182393312454224\tAnthu awiri ovala zipewa zofiira ndi njinga yamoto akukwera njinga yamoto yamoto yofiira kuti mwamuna wovala zipewa zachikwangwani za mitundumitundu .\n",
            "P-95\t-0.1247 -0.0224 -0.0919 -0.0348 -0.1066 -0.0855 -0.1293 -0.1411 -0.2177 -0.1083 -0.0890 -0.0762 -0.2571 -0.1104 -0.0731 -0.1210 -0.0848 -0.1228 -0.1005 -0.0245 -0.1125 -0.0177 -0.1123 -0.0519 -0.1074 -0.1593 -0.0106 -0.3855 -0.0888 -0.1184 -0.4888 -0.0829 -0.1827 -0.2845 -0.6459 -1.0354 -0.1022 -0.1140 -0.1907 -0.6372 -0.0937 -0.1053 -0.0346 -0.0873 -0.1697 -0.1351 -0.1022 -0.3033 -0.0304 -0.0462 -0.0849 -0.1410 -0.1378 -0.0869 -0.1068 -0.2941 -0.0816 -0.0589 -0.1179 -0.1074 -0.1377 -0.6551 -0.0787 -0.0953 -0.0875 -0.0250 -0.1053 -0.2185 -0.0496 -0.1223 -0.1340 -0.0140 -0.0638 -0.0792 -0.1801 -0.0864 -0.7169 -0.9812 -0.0979 -0.2570 -0.1243 -0.2048 -0.5241 -0.4377 -0.0396 -0.1182 -1.1618 -0.0729 -0.1285 -0.3512 -0.2767 -0.1733 -0.3059 -1.3032 -0.1335 -0.6927 -0.3355 -0.1147 -0.3601 -0.2147 -0.1191 -0.0743 -0.1401 -0.6293 -1.9332 -1.1282 -0.1078 -0.0930 -0.1041 -0.1120 -0.4533 -0.3020 -2.0202 -0.0884 -0.1114 -0.0960 -0.1918 -0.0370 -0.1370 -3.3654 -0.1002 -0.1187 -0.5589 -0.2734 -0.1005 -0.3141 -0.4713 -0.0681 -0.0955 -0.1035 -0.0567 -0.1465 -0.8527 -0.3173 -0.5316 -1.4675 -0.5675 -0.5388 -0.6590 -0.1447 -0.0745 -0.0610 -0.6371 -0.0363 -0.4870 -0.1871 -0.1092 -0.1150 -0.1090 -0.3695 -1.1710 -0.1162\n",
            "T-292\tBambo wina wovala jekete la buluu atakwera galu akuwolokera pa chigwa chokutidwa ndi chipale chofewa .\n",
            "H-292\t-0.27529510855674744\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ b u l u u ▁ a t a k h a l a ▁ p a ▁ b u l u u ▁ w o k h a l a ▁ p a ▁ c h i n g w a n g w a ▁ c h o t c h i n g i d w a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-292\t-0.27529510855674744\tBambo wina wovala jekete la buluu atakhala pa buluu wokhala pa chingwangwa chotchingidwa ndi chipale chofewa .\n",
            "P-292\t-0.1328 -0.5684 -0.1018 -0.0683 -0.0726 -0.1088 -0.1476 -0.0554 -0.1227 -0.1050 -0.1054 -0.1106 -0.0755 -0.0935 -0.0515 -0.1122 -0.0978 -0.1155 -0.0983 -1.6371 -0.1507 -0.0698 -0.0752 -0.0333 -0.1764 -0.0986 -0.4549 -0.0720 -0.7347 -0.0457 -0.2101 -0.0677 -0.0843 -0.0393 -0.1243 -0.2481 -0.1189 -0.1121 -0.4477 -0.0828 -0.1040 -0.0441 -0.0935 -0.1048 -0.9948 -0.4079 -1.5374 -0.6289 -0.5270 -0.0785 -0.1071 -0.0736 -0.1049 -0.3608 -0.3770 -0.5181 -0.5321 -0.4226 -0.1233 -0.0926 -0.0906 -0.5494 -0.1117 -0.3215 -0.1722 -0.0893 -0.1016 -0.1257 -0.1004 -0.0569 -0.4960 -1.1267 -1.0709 -0.0986 -0.0870 -0.1299 -0.0763 -0.0843 -0.1552 -0.1528 -1.5270 -0.0770 -0.0945 -0.7263 -0.0894 -0.2961 -0.3948 -0.0417 -0.1157 -0.1395 -0.9409 -0.1316 -0.1235 -0.0960 -0.2443 -0.0829 -3.4517 -0.3439 -0.1134 -0.1060 -0.0771 -0.0904 -0.0441 -0.0970 -0.0627 -0.0141 -0.0743 -0.0541 -0.1189 -0.2854 -0.8071 -0.1143\n",
            "T-42\tbambo akuyesera kuti atsike pamasewera a baseball pomwe woponya mpira akuponyera mpirawo kuti amuponyere kunja .\n",
            "H-42\t-0.28552374243736267\t▁ B a m b o ▁ a k u y e s e r a ▁ k u t i ▁ a k u t i ▁ a t a t s e k e r a ▁ m a s e w e r a ▁ a ▁ b a s e b a l l ▁ p o m w e ▁ o n y a m u l a ▁ m p i r a ▁ a k u p o n y a ▁ m p i r a ▁ w o y e r a ▁ .\n",
            "D-42\t-0.28552374243736267\tBambo akuyesera kuti akuti atatsekera masewera a baseball pomwe onyamula mpira akuponya mpira woyera .\n",
            "P-42\t-0.1291 -0.0514 -0.1142 -0.0714 -0.0762 -0.0770 -0.1056 -0.4179 -0.1248 -0.0749 -1.3540 -0.0743 -0.0429 -0.0546 -0.0383 -0.1149 -0.1007 -0.0667 -0.0825 -0.4436 -0.1288 -0.0857 -0.1725 -0.4045 -0.1347 -0.3665 -0.6568 -0.2199 -0.3015 -0.1611 -0.3189 -0.7451 -0.5034 -0.0424 -0.7974 -0.3169 -0.2531 -0.1278 -0.1175 -2.3426 -0.1346 -0.1506 -0.3316 -0.1625 -0.0507 -0.1005 -0.1212 -0.1221 -0.2369 -0.0457 -0.0339 -1.1915 -0.0514 -0.2039 -0.0279 -0.1457 -0.0354 -0.2375 -0.6671 -0.0940 -0.1932 -0.4892 -0.1608 -0.1115 -0.0927 -2.3505 -0.8283 -0.0347 -0.1106 -0.0535 -0.0590 -0.0682 -0.1143 -0.1044 -0.5200 -0.0992 -0.0583 -0.0948 -0.1106 -0.2341 -1.4870 -0.1501 -0.0964 -0.5378 -0.0845 -0.1131 -0.0087 -0.1734 -0.1263 -0.1134 -0.2087 -0.1053 -0.1369 -0.1116 -0.3410 -0.5532 -0.3254 -1.0898 -0.0718 -0.0984 -0.1213 -0.3107 -1.3671 -0.1178\n",
            "T-225\tMunthu atanyamula Baibulo lokhala ndi chikwangwani cholembedwa kuti ' Lapani . Yesu Khristu adzaweruza dziko lapansi .\n",
            "H-225\t-0.3599558472633362\t▁ M u n t h u ▁ a t a n y a m u l a ▁ b u l u u ▁ n d i ▁ k h a l a ▁ n d i ▁ c h i k w a n g w a n i ▁ c h o l e m b e d w a ▁ k u t i ▁ a k u y e n d e t s a ▁ p a n j i n g a ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ p a ▁ u d z u ▁ .\n",
            "D-225\t-0.3599558472633362\tMunthu atanyamula buluu ndi khala ndi chikwangwani cholembedwa kuti akuyendetsa panjinga akugwiritsa ntchito pa udzu .\n",
            "P-225\t-0.1304 -0.2677 -0.2638 -0.0827 -0.0470 -0.1101 -0.0591 -0.1612 -0.0942 -0.0948 -0.0912 -0.0324 -0.0187 -0.0899 -0.0898 -0.0764 -0.0836 -0.1103 -0.1881 -0.3120 -1.9926 -0.0946 -0.3674 -0.1151 -0.1622 -1.0226 -0.0937 -0.1148 -0.0909 -1.6628 -2.3429 -0.1304 -0.0997 -0.1024 -0.1748 -0.9468 -0.0703 -0.1111 -0.0997 -1.1944 -0.1490 -0.1039 -1.7871 -0.0519 -0.1041 -0.2295 -0.0084 -0.0719 -0.0920 -0.0659 -0.0890 -0.1300 -0.1100 -0.1085 -0.0528 -0.1817 -0.0808 -0.1024 -0.7206 -0.0319 -0.0202 -0.0369 -0.1028 -0.2721 -0.5250 -0.1680 -0.7130 -0.2076 -0.1288 -1.6267 -1.1085 -0.2283 -1.1986 -0.0457 -1.7575 -0.0449 -0.0867 -0.0761 -0.0353 -0.2457 -0.1169 -0.3349 -0.1918 -1.4267 -1.1146 -0.1810 -0.4703 -0.0867 -0.0897 -0.1899 -2.1611 -0.4138 -0.1422 -0.9030 -0.0444 -0.8693 -0.2296 -0.5824 -0.0755 -0.0939 -0.0973 -0.1242 -0.2050 -0.2188 -0.1544 -0.1279 -0.1244 -0.0203 -0.0841 -0.1171 -1.9725 -0.1366 -0.7118 -1.1197 -0.7352 -0.0159 -0.0566 -0.3123 -0.7291 -0.1214\n",
            "T-293\tanthu ambiri akhala pamatebulo amatabwa moyang'anizana ndi mapiri okutidwa ndi chipale chofewa .\n",
            "H-293\t-0.39031562209129333\t▁ A m u n a ▁ a n t h u ▁ a m b i r i ▁ a t a k h a l a ▁ p a m a t a b w a ▁ a t a n y a m u l a ▁ n y u m b a ▁ i n a ▁ y a ▁ b u l u u ▁ n d i ▁ z i p a l e ▁ z o f e w a ▁ .\n",
            "D-293\t-0.39031562209129333\tAmuna anthu ambiri atakhala pamatabwa atanyamula nyumba ina ya buluu ndi zipale zofewa .\n",
            "P-293\t-0.1428 -1.9869 -0.3430 -0.5177 -0.1162 -0.4804 -0.1463 -0.3075 -0.1995 -0.6317 -0.1848 -0.0545 -0.1285 -0.1792 -2.7598 -0.2068 -0.0897 -0.0515 -0.0954 -0.1517 -0.2176 -0.5975 -0.1117 -0.0548 -0.0774 -0.0944 -0.0430 -0.1034 -0.1003 -0.0779 -0.1270 -0.3663 -0.4116 -0.0353 -0.6915 -0.0361 -0.2561 -0.0862 -0.1834 -0.8875 -1.3796 -0.1020 -0.5788 -0.0874 -0.0941 -0.0872 -0.1144 -0.0674 -0.0909 -0.1132 -0.4089 -0.3107 -0.1494 -0.2326 -0.0563 -0.1139 -0.1275 -3.2409 -0.4935 -0.0970 -0.1372 -0.6236 -0.5392 -0.6976 -1.9209 -0.3100 -0.2599 -0.1259 -0.0712 -0.2534 -1.7541 -0.2209 -0.1026 -0.0695 -1.5312 -0.5362 -0.8444 -0.1326 -1.2632 -0.1003 -0.1184 -0.1665 -0.2225 -0.2887 -0.0722 -0.1475 -0.0858 -0.6476 -0.5015 -0.1050\n",
            "T-405\tGulu la anyamata achichepere mkati mwamasewera a lacrosse, mamembala awiri a timu imodzi akuthamangira kumbuyo kwa osewera awiri a timu ina.\n",
            "H-405\t-0.37669283151626587\t▁ G u l u ▁ l a ▁ a n y a m a t a ▁ a c h i c h e p e r e ▁ m ' k a t i ▁ m w a ▁ m w a m u n a ▁ a t a v a l a ▁ m a l a y a ▁ o s e m b e r a ▁ a ▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ a k u t h a m a n g i r a ▁ k w a ▁ c h i n g w e ▁ .\n",
            "D-405\t-0.37669283151626587\tGulu la anyamata achichepere m'kati mwa mwamuna atavala malaya osembera a munthu wovala malaya ofiira akuthamangira kwa chingwe .\n",
            "P-405\t-0.1197 -0.1032 -0.0816 -0.0797 -0.0851 -0.1047 -0.1140 -0.1204 -0.0514 -0.0993 -0.0629 -0.1475 -0.0759 -0.0588 -0.1012 -0.0933 -0.1002 -0.1194 -1.7164 -0.0621 -0.0969 -0.1140 -0.1596 -0.0890 -0.0450 -0.1731 -0.0432 -0.0927 -0.0640 -0.1639 -0.3533 -0.5155 -1.4689 -0.1613 -0.4649 -0.0938 -0.1590 -0.0941 -0.0340 -0.0939 -0.1999 -0.4125 -3.1323 -0.1095 -0.2423 -0.2043 -0.1201 -0.0751 -0.1648 -0.2880 -1.1601 -0.1115 -0.8392 -0.1260 -0.0743 -0.1235 -0.0977 -0.1522 -0.1192 -0.5232 -0.1003 -0.0517 -0.0654 -0.1069 -1.9015 -0.2904 -0.0715 -0.4489 -0.8754 -0.1347 -0.3829 -0.1129 -0.2119 -0.4369 -0.6760 -0.6889 -2.7701 -0.1462 -0.0705 -0.0435 -0.1026 -0.1311 -0.7088 -0.1726 -1.2867 -0.1228 -0.0870 -0.1032 -0.0945 -1.6984 -0.1350 -1.2884 -0.1119 -0.0472 -0.0882 -0.0906 -0.3830 -1.4935 -0.0987 -0.1838 -0.0762 -0.1453 -0.2357 -0.7963 -0.5853 -0.1017 -1.1728 -1.7869 -0.8611 -0.2313 -0.0809 -0.0573 -0.0473 -0.4168 -0.2469 -0.1054 -0.1359 -0.8040 -0.7971 -0.1054 -0.3427 -2.5147 -0.1066 -0.1019 -1.5714 -1.0835 -0.0200 -0.0537 -0.2812 -0.1225 -0.0923\n",
            "T-27\tOsewera mpira wa basketball otsutsa amadumphira pansi kuti awongolere mpirawo pomwe wosewera mpira amawomba mluzu wake.\n",
            "H-27\t-0.3576779067516327\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ t s i t s i ▁ l a k u d a ▁ a m a t h a m a n g i r a ▁ p a n s i ▁ k u t s o g o l o ▁ k w a ▁ w o m b e r a ▁ y e m w e ▁ w a v a l a ▁ m p i r a ▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ m ' b w a l o ▁ l a ▁ m o z u n g u l i r a .\n",
            "D-27\t-0.3576779067516327\tWosewera mpira wa tsitsi lakuda amathamangira pansi kutsogolo kwa wombera yemwe wavala mpira wosewera mpira wa m'bwalo la mozungulira.\n",
            "P-27\t-0.1277 -1.0032 -0.0794 -0.0584 -0.0636 -0.0744 -0.0931 -0.0681 -0.1093 -0.1345 -0.2281 -0.1270 -0.1093 -0.0660 -0.1083 -0.1603 -0.1049 -0.1276 -0.1859 -1.1456 -1.6516 -0.2051 -0.2604 -0.4390 -0.1045 -0.1004 -0.1080 -0.5528 -1.7937 -0.1736 -0.7258 -0.2045 -0.2265 -0.2930 -0.1328 -0.1128 -0.1720 -0.8050 -0.2119 -0.2726 -0.0821 -0.1882 -0.2468 -0.8928 -0.2100 -0.1117 -0.1132 -0.3245 -0.1478 -0.1507 -1.1737 -0.0756 -0.1719 -1.6282 -0.0733 -0.1568 -0.7991 -0.1931 -0.0941 -0.0681 -0.1048 -0.2219 -0.1426 -1.0087 -0.1388 -0.2024 -0.2697 -0.3775 -0.0285 -1.3318 -0.8559 -0.1129 -0.2164 -0.1137 -0.2168 -0.9757 -0.4229 -0.5738 -0.3276 -0.0762 -0.1029 -0.3823 -0.2550 -1.5711 -0.1116 -0.0938 -0.1204 -0.1120 -1.0324 -0.1450 -0.1749 -0.0453 -0.1153 -0.1877 -0.0999 -0.2671 -1.1381 -0.0580 -0.0631 -0.1533 -0.0744 -0.1188 -0.2274 -0.4814 -0.9164 -0.0831 -0.0906 -0.0970 -0.2453 -0.1697 -0.1916 -0.2866 -0.2951 -1.4771 -0.2835 -1.1509 -0.0807 -0.3723 -0.0868 -0.3109 -0.1489 -0.3316 -0.6774 -0.6959 -2.2448 -1.2832 -0.3316 -0.0379 -0.0355 -0.0311 -0.2480 -0.1071 -0.1233 -0.1091 -1.5112 -0.1179\n",
            "T-59\tMnyamata wina wakhala pamsika akuyang'ana kutsogolo mosayang'ana pakati pa nsalu zokongola komanso zosindikizidwa kumbuyo kwake ndipo patsogolo pake pali mulu wa tirigu .\n",
            "H-59\t-0.2820650339126587\t▁ M n y a m a t a ▁ w i n a ▁ w a k h a l a ▁ w o y a n g ' a n a ▁ k u s a n g a l a l a ▁ p a k a t i ▁ p a ▁ z o k o n g o l a ▁ z o k o n g o l a ▁ z o z u n g u l i r i d w a ▁ n d i p o ▁ k u m b u y o ▁ k w a k e ▁ n d i p o ▁ k u t s o g o l o ▁ k w a k e ▁ .\n",
            "D-59\t-0.2820650339126587\tMnyamata wina wakhala woyang'ana kusangalala pakati pa zokongola zokongola zozunguliridwa ndipo kumbuyo kwake ndipo kutsogolo kwake .\n",
            "P-59\t-0.1395 -0.0872 -0.0780 -0.0698 -0.1069 -0.0857 -0.1169 -0.0372 -0.1144 -0.1231 -0.0566 -0.1313 -0.0828 -0.1128 -0.1084 -0.0607 -0.2894 -0.8055 -0.0146 -0.1309 -0.0589 -0.1112 -0.1156 -0.7250 -0.6198 -0.3124 -0.1315 -0.4815 -0.1750 -0.3146 -0.1082 -0.0770 -0.2047 -0.1168 -0.2600 -0.2499 -1.5083 -0.8636 -0.2097 -0.0415 -0.0830 -0.0694 -0.1207 -0.1548 -0.1004 -0.1595 -1.0837 -0.1445 -1.2433 -0.1077 -0.1466 -0.1175 -0.2362 -0.2540 -0.1643 -0.1305 -0.8125 -0.0555 -0.0901 -0.4799 -0.0688 -0.0182 -0.0633 -0.0594 -0.1096 -0.2298 -0.5881 -0.1672 -0.5708 -0.4273 -0.0975 -0.1222 -0.0467 -0.0813 -0.1065 -0.2105 -1.0847 -0.6164 -1.4264 -1.2672 -0.0652 -0.0812 -0.1620 -0.1116 -0.1199 -0.2018 -0.6797 -0.0684 -0.0582 -0.0992 -0.1553 -0.1407 -0.0900 -0.1242 -1.1102 -0.0530 -0.1044 -1.6537 -0.0729 -0.3139 -0.0322 -0.0835 -0.0617 -0.0980 -0.1182 -0.1554 -0.1167 -0.1197 -0.1487 -0.0428 -0.2365 -1.0507 -0.1427 -0.1073 -0.2101 -0.0676 -0.0954 -1.8872 -0.1106 -0.1622 -1.9087 -0.0514 -0.0097 -0.0904 -0.0571 -0.0861 -0.1106 -0.0814 -0.0580 -0.1517 -1.5035 -0.0378 -0.4497 -0.3054 -0.1121\n",
            "T-370\tbambo wina wovala malaya apinki ndi achikasu komanso chomangira chabuluu kumutu ali ndi mpikisano wamasewera a tenisi ali chilili chotsegula kukamwa .\n",
            "H-370\t-0.2666652202606201\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ n d i ▁ m k a z i ▁ a t a v a l a ▁ c h o v a l a ▁ c h a b u l u u ▁ c h a ▁ b u l u u ▁ n d i ▁ m p i k i s a n o ▁ w a k e ▁ p a m a s e w e r a ▁ a ▁ m a s e w e r a ▁ a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-370\t-0.2666652202606201\tBambo wina wovala malaya apinki ndi mkazi atavala chovala chabuluu cha buluu ndi mpikisano wake pamasewera a masewera a chipale chofewa .\n",
            "P-370\t-0.1306 -0.0452 -0.1099 -0.0974 -0.0850 -0.0840 -0.1209 -0.1003 -0.1484 -0.0794 -0.1007 -0.1236 -0.1101 -0.0971 -0.0563 -0.1287 -0.0919 -0.1299 -0.1092 -0.0699 -0.1172 -0.0552 -0.1062 -0.1314 -0.1009 -0.0990 -0.1593 -0.4086 -0.1352 -0.0331 -0.0360 -0.0784 -0.1767 -0.3104 -0.1151 -0.1174 -0.1081 -1.6710 -0.3516 -0.1058 -0.0640 -0.0984 -0.1243 -0.3540 -1.2732 -0.1599 -0.3255 -0.1139 -0.1017 -0.1019 -0.1074 -0.5441 -0.0816 -0.9876 -0.1578 -0.1099 -0.1217 -0.0913 -0.1234 -0.0782 -0.1156 -0.4235 -1.4050 -0.0962 -0.0598 -0.1053 -0.0495 -0.1400 -1.4859 -0.1128 -1.0166 -0.6847 -0.1665 -0.1548 -0.0746 -0.1189 -0.0753 -0.1569 -0.1565 -0.1361 -0.1237 -0.1163 -0.5163 -0.3482 -0.1425 -1.2130 -0.0455 -0.1239 -0.1145 -0.1556 -0.0946 -0.1039 -0.5211 -0.3459 -0.9509 -0.0842 -0.1868 -1.1304 -0.1485 -0.1807 -0.1952 -0.0800 -0.2378 -0.0492 -0.0998 -0.0875 -0.1000 -0.1381 -0.5443 -0.0801 -0.9720 -0.2654 -1.0088 -0.0974 -0.0706 -0.0954 -0.1138 -0.1232 -0.1508 -1.1755 -0.1993 -0.5046 -0.5481 -0.1875 -2.2333 -0.2465 -0.0542 -0.0951 -0.0967 -0.0128 -0.1159 -0.0466 -0.9201 -0.1016 -0.0488 -0.1170 -0.4327 -0.3759 -0.1094\n",
            "T-114\tAgalu awiri akuda pa nthaka yokutidwa ndi chipale chofewa, pansi pakuwoneka buluu kumbuyo, galu mmodzi akudumpha ndi mapazi pansi.\n",
            "H-114\t-0.3114827275276184\t▁ A g a l u ▁ a w i r i ▁ a k u d a ▁ a t a k h a l a ▁ p a ▁ n y u m b a ▁ y o k u t i d w a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ p a m e n e ▁ g a l u ▁ w a b u l u u ▁ k u m b u y o ▁ k w a ▁ z i n g w e ▁ .\n",
            "D-114\t-0.3114827275276184\tAgalu awiri akuda atakhala pa nyumba yokutidwa ndi chipale chofewa pamene galu wabuluu kumbuyo kwa zingwe .\n",
            "P-114\t-0.1223 -0.0474 -0.3169 -0.0968 -0.0526 -0.0863 -0.1421 -0.1133 -0.0569 -0.1194 -0.0683 -0.0965 -0.2559 -0.1149 -0.0682 -0.1175 -0.0411 -0.1042 -0.2846 -0.4610 -0.6702 -0.1301 -0.1371 -0.0960 -0.1019 -0.0473 -0.0961 -0.1193 -0.3983 -0.1194 -0.6265 -0.1882 -1.3808 -0.1346 -0.3781 -0.0920 -0.0899 -0.1296 -0.5972 -0.1497 -2.7499 -0.4989 -0.9048 -0.1658 -0.0271 -0.0473 -0.0925 -0.1381 -0.2065 -0.1335 -0.1368 -0.2527 -0.6081 -0.0988 -0.4076 -0.0374 -0.1340 -0.0810 -0.0985 -0.1184 -0.7501 -0.1244 -0.0773 -0.0628 -0.0771 -0.0543 -0.1136 -0.2679 -0.3679 -0.1384 -0.7544 -0.0853 -0.0828 -0.1209 -0.1108 -0.2164 -0.7442 -0.0628 -0.0910 -0.1195 -0.3133 -0.7221 -1.4352 -0.0729 -0.0593 -0.1300 -0.0741 -0.2286 -0.8209 -0.6384 -0.2217 -0.7066 -0.1150 -0.0338 -0.0517 -0.1392 -0.5082 -0.1206 -0.1153 -1.5875 -1.0812 -0.1009 -1.9856 -0.6698 -0.0799 -0.1247 -0.2416 -1.6634 -0.1029\n",
            "T-124\tMwamuna wina wovala malaya obiriwira ndi bandana yofiira ataphimba theka lakumtunda la nkhope yake, wagona muudzu pamene njiwa ikuyenda pambali pake.\n",
            "H-124\t-0.29734498262405396\t▁ M w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ n d i ▁ b a n d a n a ▁ a t a v a l a ▁ j e k e t e ▁ l a k u d a ▁ a k u m w e t u l i r a ▁ n k h o p e ▁ y a k e ▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ p a m e n e ▁ m w a m b a ▁ p a k e ▁ .\n",
            "D-124\t-0.29734498262405396\tMwamuna wina wovala malaya obiriwira ndi bandana atavala jekete lakuda akumwetulira nkhope yake munthu wovala malaya amizeremizere pamene mwamba pake .\n",
            "P-124\t-0.1151 -0.0863 -0.0422 -0.1001 -0.0696 -0.1024 -0.1025 -0.1060 -0.1405 -0.0807 -0.1072 -0.1173 -0.1011 -0.1266 -0.0712 -0.0879 -0.0727 -0.1208 -0.0869 -0.1176 -0.1088 -0.0690 -0.1166 -0.0510 -0.1099 -0.1037 -0.1029 -0.1045 -0.2192 -0.2181 -0.0660 -0.0915 -0.0843 -0.0267 -0.1168 -0.0876 -0.0936 -0.2012 -0.1060 -0.1123 -0.0933 -0.1900 -1.0738 -0.0993 -0.1041 -0.1196 -0.0608 -0.0480 -0.2096 -0.1121 -0.5885 -0.0784 -0.1020 -2.9825 -0.2095 -0.0625 -0.0982 -0.0960 -0.9418 -0.0890 -0.1323 -0.0937 -0.0354 -0.0567 -0.1005 -0.3758 -0.0912 -0.8386 -0.2899 -1.2635 -0.0796 -0.1745 -0.4023 -0.2360 -0.1129 -1.3529 -2.1643 -0.1026 -0.1326 -0.0766 -0.0750 -0.2049 -0.2169 -0.0926 -0.1184 -1.8598 -1.2703 -0.0776 -0.1489 -0.7607 -0.0468 -0.1089 -0.0316 -0.1195 -0.0993 -0.0381 -0.2126 -1.8222 -0.8028 -0.9455 -0.0830 -0.0251 -0.0727 -0.0840 -0.2697 -0.1028 -1.5751 -0.1131 -0.0718 -0.1136 -0.1057 -0.1236 -0.1291 -0.1238 -0.1074 -0.0949 -0.1045 -0.0899 -0.6773 -0.9553 -0.3447 -0.5742 -0.0615 -0.3606 -0.0743 -0.3174 -0.0580 -0.2577 -0.0651 -0.2505 -0.1118 -0.2214 -0.5799 -0.1470 -0.1505 -0.6056 -0.0433 -0.1124 -0.1196 -0.7521 -1.2951 -0.1337 -0.3810 -0.6732 -0.0825 -0.1995 -1.7286 -0.1470 -0.8161 -0.0831 -0.7553 -0.1946 -0.1061\n",
            "T-108\tMayi wina wachikulire wagwira mwamphamvu galu wamkulu woyera atakhala pampando waukulu wofiira kutsogolo kwa zipangizo zina zamagetsi .\n",
            "H-108\t-0.2693333029747009\t▁ M a y i ▁ w i n a ▁ w a c h i k u l i r e ▁ w a ▁ k u ▁ A m e r i c a ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ a t a k h a l a ▁ p a m p a n d o ▁ w a u k u l u ▁ w o f i i r a ▁ k u t s o g o l o ▁ k w a ▁ z i n a ▁ n d i ▁ z o f i i r a ▁ .\n",
            "D-108\t-0.2693333029747009\tMayi wina wachikulire wa ku America wavala malaya abuluu atakhala pampando waukulu wofiira kutsogolo kwa zina ndi zofiira .\n",
            "P-108\t-0.1326 -0.0503 -0.0967 -0.0498 -0.1020 -0.1196 -0.0486 -0.1221 -0.1094 -0.1028 -0.1268 -0.0837 -0.1007 -0.1209 -0.1046 -0.0940 -0.0814 -0.0909 -0.2451 -0.0883 -0.0534 -0.0544 -0.1735 -0.0401 -0.1609 -0.5913 -0.8629 -0.2948 -0.2370 -0.6293 -0.4005 -1.2343 -0.0204 -0.1314 -0.3685 -0.0552 -0.1612 -1.7269 -0.1682 -1.1987 -0.1223 -0.1006 -0.1113 -0.1071 -0.6096 -1.6746 -0.3089 -0.1830 -0.0694 -0.0869 -0.1124 -0.1481 -0.6354 -0.1163 -0.0765 -0.1008 -0.0438 -0.1872 -0.5497 -0.4165 -0.1314 -0.3236 -0.0482 -0.1120 -0.0483 -0.1292 -0.1004 -0.0199 -0.1303 -0.2279 -0.0166 -0.1797 -0.0627 -0.0535 -0.0578 -0.0926 -0.0683 -0.4598 -0.6238 -1.0691 -0.0655 -0.0627 -0.0682 -0.1334 -0.2135 -0.5959 -0.1252 -0.1174 -0.3817 -0.0902 -0.1473 -0.2411 -0.8739 -0.1096 -0.3084 -0.1093 -0.0482 -0.0510 -0.0896 -0.0590 -0.0629 -0.0864 -0.3008 -0.0450 -0.1242 -0.1211 -0.7792 -0.3399 -0.3577 -0.4993 -0.2661 -0.4033 -0.1087 -0.1379 -0.1127 -0.1886 -0.1121 -1.4963 -0.5196 -0.1711 -0.1061 -0.3911 -0.4780 -2.1218 -0.0972\n",
            "T-267\tSitima yapamadzi yaikulu imadutsa m'mphepete mwa nyanja kumene owotchera dzuwa amakhala pansi pa maambulera achikasu .\n",
            "H-267\t-0.3121621608734131\t▁ M t s i k a n a ▁ y e m w e ▁ w a v a l a ▁ j e a n s ▁ y a ▁ b u l u u ▁ a m a d u t s a ▁ m ' m p h e p e t e ▁ m w a ▁ n y a n j a ▁ w o t c h e r a ▁ z o w a l a ▁ a m a k h a l a ▁ p a n s i ▁ p a ▁ m b a l e ▁ y a c h i k a s u ▁ .\n",
            "D-267\t-0.3121621608734131\tMtsikana yemwe wavala jeans ya buluu amadutsa m'mphepete mwa nyanja wotchera zowala amakhala pansi pa mbale yachikasu .\n",
            "P-267\t-0.1197 -0.2806 -0.3057 -0.2679 -0.1160 -0.1442 -0.0911 -0.1440 -0.1084 -0.5066 -0.0963 -0.2274 -0.1062 -0.1166 -0.1089 -0.0940 -1.2048 -0.1045 -0.1639 -0.1162 -0.0643 -0.0950 -0.1175 -1.2124 -0.4222 -1.0649 -0.1006 -0.0606 -0.1320 -0.2944 -0.0780 -0.9055 -0.8131 -0.0677 -0.0714 -0.0754 -0.0291 -0.1410 -2.6911 -0.1855 -0.4494 -0.8799 -0.3711 -0.5094 -0.1247 -0.0920 -0.1265 -0.3312 -0.4268 -0.1254 -0.1061 -0.0193 -0.0587 -0.0418 -0.0632 -0.0177 -0.0968 -0.0987 -0.1365 -0.1010 -0.1343 -0.1126 -0.2409 -0.0305 -0.1103 -0.0701 -0.0485 -0.1099 -0.1470 -0.9854 -0.1152 -1.1087 -0.0213 -0.0709 -1.4580 -0.4799 -0.2335 -0.1794 -1.2941 -0.8120 -0.8212 -0.1297 -0.4859 -0.0813 -0.2216 -0.3630 -0.2875 -0.1539 -0.1397 -1.0813 -0.1010 -0.0616 -0.1038 -0.1010 -0.1013 -0.1135 -0.7035 -0.0841 -0.0760 -0.1352 -0.3917 -0.1145 -0.9006 -0.1868 -0.8866 -0.0927 -0.0593 -1.4450 -0.1600 -1.2340 -0.1304 -0.2368 -0.0868 -0.0879 -0.0651 -0.0899 -0.0353 -0.0468 -0.3438 -0.7306 -0.1175\n",
            "T-87\tGulu la azimayi azaka zapakati limayima pamalo okwerera basi; awiri mwa amayiwa akukonzekera kukwera basi .\n",
            "H-87\t-0.3334782123565674\t▁ G u l u ▁ l a ▁ a z i m a y i ▁ a t a v a l a ▁ z a k a ▁ z a p a k a t i ▁ n d i ▁ m a l o ▁ o k w e r e r a ▁ p a m a s i t e p e ▁ a w i r i ▁ a ▁ m a y i ▁ w i n a ▁ a k u k o n z e k e r a ▁ k u k w e r a ▁ k w a ▁ b a s k e t b a l l ▁ .\n",
            "D-87\t-0.3334782123565674\tGulu la azimayi atavala zaka zapakati ndi malo okwerera pamasitepe awiri a mayi wina akukonzekera kukwera kwa basketball .\n",
            "P-87\t-0.1164 -0.0590 -0.0559 -0.0580 -0.0806 -0.1163 -0.0780 -0.1359 -0.1438 -0.1599 -0.1283 -0.1159 -0.2044 -0.0966 -0.0442 -0.1700 -0.1267 -1.2485 -0.8550 -0.2207 -1.9688 -0.1333 -0.0847 -0.1239 -0.1030 -1.1230 -0.1232 -1.6094 -0.1152 -1.9335 -0.2206 -0.1133 -0.4859 -0.1503 -0.0459 -0.1113 -0.0073 -0.0987 -0.1686 -0.6326 -0.3578 -0.1078 -0.2498 -0.0825 -0.1513 -1.9996 -0.3277 -0.0855 -0.2970 -1.4535 -0.0767 -0.0591 -0.0698 -0.8141 -0.2270 -0.1041 -0.2319 -0.1240 -0.1451 -0.5709 -0.0939 -0.2271 -0.0919 -0.4845 -0.2637 -0.2981 -0.0597 -0.1766 -0.1175 -1.2578 -0.1214 -0.1072 -0.1329 -0.2862 -0.3085 -0.6876 -0.6358 -0.2425 -1.1781 -0.0736 -0.1713 -0.3133 -0.1234 -0.1428 -0.0906 -0.1828 -0.0865 -0.5057 -0.1438 -0.1954 -0.9240 -0.1157 -0.0108 -0.0471 -0.0127 -0.0502 -0.1941 -0.1063 -0.1154 -0.3065 -0.2683 -0.8236 -0.8466 -0.1230 -0.1734 -0.0881 -0.1707 -1.5774 -0.7452 -0.1225 -0.1128 -0.5067 -0.5630 -0.0886 -0.6243 -0.1479 -0.0323 -0.1480 -0.1051 -0.0458 -0.2267 -1.0537 -0.8471 -0.1256\n",
            "T-117\tMayi wina wovala mathalauza abuluu komanso pamwamba pabuluu akuyang'ana pansi pa dzanja lake ataima pafupi ndi galimoto yakuda yotuwa ndipo atazunguliridwa ndi dothi .\n",
            "H-117\t-0.2691704332828522\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ m a t h a l a u z a ▁ a b u l u u ▁ k o m a n s o ▁ p a b w a l o ▁ l a ▁ b u l u u ▁ a k u y a n g ' a n a ▁ p a n s i ▁ p a ▁ j a n j i ▁ a t a y i m a ▁ p a f u p i ▁ n d i ▁ g a l i m o t o ▁ y a k u d a ▁ n d i ▁ g a l i m o t o ▁ y o t u w a ▁ .\n",
            "D-117\t-0.2691704332828522\tMayi wina wovala mathalauza abuluu komanso pabwalo la buluu akuyang'ana pansi pa janji atayima pafupi ndi galimoto yakuda ndi galimoto yotuwa .\n",
            "P-117\t-0.1438 -0.0520 -0.1022 -0.0713 -0.0964 -0.1359 -0.1156 -0.1175 -0.1022 -0.1097 -0.1240 -0.1739 -0.0835 -0.0662 -0.1171 -0.0838 -0.1102 -0.0987 -0.0971 -0.1084 -0.2211 -0.0090 -0.1000 -0.0342 -0.1101 -0.0230 -0.0164 -0.0878 -0.1197 -0.3082 -0.2568 -0.0791 -0.0391 -0.0856 -0.0491 -0.1745 -0.2906 -0.3121 -0.0418 -0.1372 -0.1800 -0.0514 -0.0737 -0.0968 -1.3142 -0.1175 -1.2700 -0.1724 -0.0782 -0.1373 -0.0963 -0.1260 -0.6290 -0.1309 -1.2608 -0.6922 -0.2917 -0.1286 -0.1481 -0.0395 -0.1996 -0.3995 -0.2307 -0.0953 -0.0911 -0.1554 -0.0912 -0.2427 -0.1014 -0.1134 -0.0867 -0.1584 -0.1133 -0.6274 -0.2104 -0.0428 -0.6098 -0.1002 -0.2313 -0.3729 -0.1485 -0.4964 -2.0260 -0.3716 -0.2871 -0.4964 -0.1201 -0.1706 -1.2399 -0.3157 -0.1117 -1.2808 -0.1346 -0.0992 -0.1066 -0.0894 -0.0240 -0.1376 -0.0100 -0.0859 -0.0313 -0.1284 -0.1150 -0.0699 -0.0948 -0.1339 -0.0846 -0.8444 -0.1066 -0.0409 -0.0685 -0.0465 -0.0375 -0.0386 -0.0319 -0.1075 -0.0246 -0.3335 -0.5125 -0.1840 -0.0919 -0.0881 -0.2008 -0.2962 -0.0763 -0.1152 -0.1279 -2.1850 -1.0316 -0.0556 -0.1387 -0.0564 -0.0420 -0.0403 -0.0298 -0.1828 -1.5838 -0.9459 -1.2235 -0.8108 -0.0517 -0.1567 -0.2471 -2.4412 -0.1098\n",
            "T-321\tMayi wina wokhwima mwauzimu amanyamula mavwende awiri, imodzi pa dzanja lililonse, pamene akuyenda kudutsa galimoto yoyera.\n",
            "H-321\t-0.3462051749229431\t▁ M a y i ▁ w i n a ▁ w a ▁ k u ▁ A s i a ▁ w a n y a m u l a ▁ m w a n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ p a n s i ▁ p a m e n e ▁ a k u d u t s a ▁ g a l i m o t o ▁ y o y e r a ▁ .\n",
            "D-321\t-0.3462051749229431\tMayi wina wa ku Asia wanyamula mwana wovala malaya amizeremizere pansi pamene akudutsa galimoto yoyera .\n",
            "P-321\t-0.1296 -0.0906 -0.1236 -0.0645 -0.0867 -0.1169 -0.0619 -0.1052 -0.0783 -0.1076 -0.1153 -0.1593 -0.5170 -0.6366 -0.0787 -0.0884 -0.1587 -0.8545 -1.1205 -0.0759 -0.0933 -0.1641 -1.9765 -0.2846 -1.1618 -0.1179 -0.0888 -0.0973 -0.0762 -0.0404 -0.1149 -0.1089 -0.3843 -3.4066 -0.1306 -0.6000 -0.0900 -0.1462 -0.1723 -1.1497 -0.0373 -0.1180 -0.0863 -0.1094 -0.1214 -1.3246 -0.4346 -0.6872 -0.1084 -0.0839 -0.0932 -0.1260 -1.4674 -1.8949 -0.1144 -0.2390 -0.0484 -0.0659 -0.0653 -0.3863 -0.0510 -0.0610 -0.0463 -0.0974 -0.0835 -0.1562 -0.7702 -0.1358 -0.2456 -0.3895 -0.0883 -0.1307 -0.1000 -0.1338 -2.1915 -0.2971 -0.0689 -0.0690 -0.0918 -2.7638 -1.0657 -0.0911 -0.4675 -0.0996 -0.3053 -0.1130 -0.0852 -0.1339 -0.2245 -0.1413 -0.0468 -0.0754 -0.0294 -0.0460 -0.0804 -0.0423 -0.3029 -0.2152 -0.0677 -0.6906 -0.1279 -0.4770 -0.0912 -0.7284 -0.1031 -0.0890\n",
            "T-351\tKamwana kakang'ono ka jekete yofiira akuwonetsa zoseweretsa zake pomwe mwamuna wamkulu wovala malaya oyera akuwoneka akuyendetsa galimotoyo .\n",
            "H-351\t-0.23731712996959686\t▁ K a m w a n a ▁ k a k a n g ' o n o ▁ k a ▁ j e k e t e ▁ y o f i i r a ▁ a k u w o n e t s a ▁ z o w e t s e r e k a ▁ z a k e ▁ p o m w e ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u w o n e k a ▁ k u w o n e k a ▁ k u t i ▁ a g a l i m o t o ▁ .\n",
            "D-351\t-0.23731712996959686\tKamwana kakang'ono ka jekete yofiira akuwonetsa zowetsereka zake pomwe mwamuna wovala malaya oyera akuwoneka kuwoneka kuti agalimoto .\n",
            "P-351\t-0.1265 -0.0515 -0.1604 -0.0649 -0.1803 -0.1605 -0.1041 -0.1102 -0.1389 -0.0922 -0.1176 -0.5939 -0.1065 -0.0867 -0.0552 -0.0754 -0.0601 -0.0826 -0.0713 -0.1146 -0.0842 -0.2265 -0.3677 -0.4434 -0.2441 -0.1352 -0.0904 -0.0351 -0.1969 -0.1170 -1.6256 -0.1698 -0.1283 -0.1202 -0.6469 -0.0836 -0.1121 -0.2297 -0.1543 -0.0964 -0.0851 -0.2506 -0.1879 -0.0706 -0.2108 -0.0749 -0.0318 -0.1754 -0.0853 -0.0347 -0.3284 -1.0775 -0.8220 -0.1742 -0.0416 -0.6045 -0.1776 -0.2471 -0.1180 -0.4163 -0.1814 -0.8733 -0.1304 -0.8310 -0.1766 -0.1752 -0.0927 -0.7179 -0.0435 -0.0828 -0.1454 -0.1228 -0.3324 -0.1165 -0.1062 -0.0616 -0.0567 -0.1020 -0.0914 -0.1748 -0.0639 -0.7279 -0.0884 -0.1018 -0.0781 -0.1208 -0.1170 -0.1040 -0.1277 -0.0838 -0.1153 -0.0291 -0.1122 -0.1014 -0.5065 -0.0307 -0.0664 -0.1007 -0.1110 -0.1774 -0.1047 -0.1383 -0.0939 -0.3154 -0.2909 -0.0999 -0.0514 -0.0241 -0.0982 -0.1187 -0.3366 -0.0943 -2.1794 -0.1180 -0.0528 -0.0717 -0.0945 -0.0981 -0.1346 -0.5117 -0.1457 -0.7308 -0.2376 -0.1169 -0.1830 -1.4286 -1.9329 -0.0789 -0.0951 -0.3008 -0.0493 -0.0344 -0.0646 -0.5955 -0.4995 -0.1006\n",
            "T-152\tMnyamata watsitsi labulauni, atavala zovala zosewerera akuthamanga mwachangu ngati mpira wawung'ono wabuluu, woyera, ndi wofiira uli paudzu kumbuyo kwake.\n",
            "H-152\t-0.2521952986717224\t▁ M n y a m a t a ▁ w a t s i t s i ▁ l a b u l a u n i ▁ a t a v a l a ▁ z o v a l a ▁ z o s e w e r a ▁ a k u t h a m a n g a ▁ m ' m w a m b a ▁ n g a t i ▁ m p i r a ▁ w a ▁ b u l u u ▁ n d i ▁ w o y e r a ▁ w a i m a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-152\t-0.2521952986717224\tMnyamata watsitsi labulauni atavala zovala zosewera akuthamanga m'mwamba ngati mpira wa buluu ndi woyera waima kumbuyo kwake .\n",
            "P-152\t-0.1287 -0.0350 -0.0450 -0.0511 -0.0990 -0.0804 -0.1084 -0.0438 -0.0969 -0.1120 -0.0773 -0.1348 -0.4574 -0.1923 -0.0872 -0.0400 -0.0382 -0.0838 -0.0778 -0.0991 -0.1703 -0.8384 -0.1214 -0.0656 -0.1064 -0.0487 -0.0532 -0.0590 -0.1945 -0.8865 -0.0879 -0.1001 -0.0210 -0.1005 -0.0729 -0.1078 -0.1016 -0.0902 -0.0470 -0.4635 -0.1052 -0.0883 -0.1122 -0.1220 -0.0146 -0.0876 -0.2645 -0.5969 -0.0812 -0.1004 -0.0709 -0.1153 -0.2013 -0.0844 -0.1963 -0.0985 -0.0932 -0.0861 -0.1101 -0.0870 -0.1012 -0.0941 -0.0337 -0.0999 -0.1729 -0.1074 -0.5710 -2.3812 -0.5454 -0.1042 -0.0576 -0.0606 -0.1069 -0.1415 -1.3538 -1.0483 -0.3425 -0.0677 -0.0842 -0.1270 -0.6140 -1.0420 -0.4378 -0.0898 -0.1250 -0.2053 -0.0783 -0.1339 -0.5614 -0.8893 -0.2865 -0.0651 -0.1837 -0.0945 -0.1645 -1.5216 -0.1078 -0.0996 -0.2334 -0.4987 -0.1790 -0.1534 -0.0678 -0.1330 -0.0847 -0.2152 -0.1739 -0.2037 -0.5885 -0.1049 -0.1348 -0.0894 -1.3491 -0.0814 -0.3973 -0.1648 -0.0872 -0.0804 -0.0690 -0.1326 -0.8358 -0.1146 -0.1160 -0.5274 -0.1521 -0.2875 -2.0669 -0.1174\n",
            "T-311\tMtsikana wina yemwe ali ndi chipewa chakuda ndi jekete yofiira ndi yakuda , akukwera pa mpira wofiira-lalanje womwe umagwirizanitsidwa ndi chingwe cha buluu.\n",
            "H-311\t-0.27313926815986633\t▁ M t s i k a n a ▁ w i n a ▁ y e m w e ▁ a l i ▁ n d i ▁ c h i p e w a ▁ c h a k u d y a ▁ n d i ▁ j e k e t e ▁ y a k u d a ▁ a k u k w e r a ▁ p a f u p i ▁ n d i ▁ l a l a n j e ▁ w o m w e ▁ u m a y i ▁ w i n a ▁ n d i ▁ c h i t s a n t i ▁ c h a ▁ b u l u u ▁ .\n",
            "D-311\t-0.27313926815986633\tMtsikana wina yemwe ali ndi chipewa chakudya ndi jekete yakuda akukwera pafupi ndi lalanje womwe umayi wina ndi chitsanti cha buluu .\n",
            "P-311\t-0.1217 -0.0739 -0.1759 -0.0708 -0.1207 -0.1555 -0.1085 -0.0961 -0.1051 -0.1517 -0.8172 -0.0986 -0.1664 -0.1023 -0.2440 -0.4769 -0.0369 -0.0430 -0.1794 -0.0973 -0.1129 -0.1168 -0.0438 -0.0911 -0.1028 -0.0556 -0.0826 -0.1275 -0.1621 -0.6090 -0.0928 -0.1087 -0.1468 -1.8097 -0.3026 -0.1069 -0.1328 -0.0388 -0.0637 -0.2377 -0.4744 -0.0719 -0.0541 -0.3606 -0.2215 -0.2036 -0.1698 -0.0801 -0.1215 -0.1112 -0.6557 -0.2083 -0.0503 -0.0484 -0.0303 -0.1479 -0.1269 -0.0279 -0.3741 -0.1821 -0.0738 -0.0512 -0.1084 -0.2145 -0.0855 -0.0715 -0.0887 -0.1031 -0.0781 -0.1161 -0.0941 -0.1116 -0.1373 -0.1013 -0.1507 -1.0865 -0.1585 -0.1340 -0.1354 -0.1127 -0.4042 -0.1184 -0.1201 -0.1096 -1.5990 -0.3740 -0.0531 -0.2763 -0.0440 -0.0125 -0.0722 -0.1702 -1.4034 -0.1846 -0.5284 -0.0395 -0.1098 -0.1226 -0.5160 -0.4190 -0.1349 -1.2697 -0.0729 -0.3006 -1.8964 -0.2495 -0.1046 -0.1289 -0.1584 -0.5326 -0.1147 -0.1165 -0.1233 -1.7783 -0.1285 -0.1038 -1.0862 -0.1896 -0.2375 -0.2377 -0.9713 -0.4474 -0.2568 -0.0720 -0.0989 -0.1123 -0.3814 -2.1964 -0.7633 -0.0761 -0.1113 -0.1114 -0.3078 -0.3008 -0.1050\n",
            " 23% 3/13 [00:10<00:32,  3.26s/it, wps=673]T-133\tAna anayi avala ngati zidole ndi ovina pa siteji pamene ana ena awiri ovala ngati anthu ochita zisudzo amaimitsidwa zingwe.\n",
            "H-133\t-0.3583974242210388\t▁ A n a ▁ a n a y i ▁ o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ n d i p o ▁ p a ▁ s i t e j i ▁ p a m e n e ▁ a n a ▁ e n a ▁ a w i r i ▁ o v a l a ▁ m a g a l a s i ▁ a d z u w a ▁ a m a y i m i t s i d w a ▁ p a m a d z i ▁ .\n",
            "D-133\t-0.3583974242210388\tAna anayi ovala malaya amizeremizere ndipo pa siteji pamene ana ena awiri ovala magalasi adzuwa amayimitsidwa pamadzi .\n",
            "P-133\t-0.1358 -0.0555 -0.0712 -0.2267 -0.1492 -0.1375 -0.0527 -0.1719 -0.0348 -0.0689 -0.1793 -0.4140 -0.3073 -0.1120 -0.0770 -0.1179 -0.1167 -0.3004 -0.4076 -1.4813 -0.1163 -0.0613 -0.0961 -0.1289 -0.4368 -0.2749 -0.7740 -0.5841 -0.2342 -0.1070 -0.2418 -0.1828 -0.1020 -0.1166 -0.0634 -0.1617 -0.2009 -0.1790 -1.2797 -0.1312 -0.0874 -1.8900 -0.1204 -0.1374 -1.1539 -0.1460 -0.8334 -0.1615 -0.4544 -0.1076 -0.0793 -0.1196 -0.0784 -0.3468 -2.5019 -0.1528 -0.0850 -0.0336 -0.0524 -0.0621 -0.1203 -0.6754 -0.5682 -0.2879 -0.3526 -0.4817 -0.0576 -0.0754 -0.1286 -0.0826 -0.6442 -0.1334 -0.0384 -0.0826 -0.1954 -0.1866 -0.3022 -0.1041 -0.0965 -0.1098 -0.1114 -2.4218 -0.4044 -0.2897 -0.0872 -0.1836 -0.1172 -0.1474 -0.1064 -0.1985 -0.6909 -1.4049 -0.0357 -0.6833 -0.0645 -0.2297 -0.2553 -0.3685 -0.3052 -0.5788 -0.7303 -0.4567 -1.7066 -0.0947 -0.9038 -0.6047 -0.0759 -0.3293 -0.0553 -0.0859 -0.1786 -1.0099 -0.1255 -0.1819 -0.2171 -1.8984 -0.0137 -0.0894 -0.6495 -1.7390 -0.1174\n",
            "T-223\tGulu la anthu anayi likuyang'ana pamene mwamuna wina wovala malaya otuwa akugwira chingwe cha trapeze chomwe chili panthambi yamtengo .\n",
            "H-223\t-0.23817859590053558\t▁ G a l u ▁ a n t h u ▁ a n a y i ▁ a l i ▁ n d i ▁ k u y a n g ' a n a ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u g w i r a ▁ c h i t h u n z i ▁ c h o m w e ▁ c h i l i ▁ p a m w a m b a ▁ p a ▁ m i t e n g o ▁ .\n",
            "D-223\t-0.23817859590053558\tGalu anthu anayi ali ndi kuyang'ana pamene mwamuna wina wovala malaya abuluu akugwira chithunzi chomwe chili pamwamba pa mitengo .\n",
            "P-223\t-0.1214 -0.3421 -0.1107 -0.0729 -0.1131 -0.1204 -0.5994 -0.3170 -0.3313 -0.1204 -0.0692 -0.1124 -0.1134 -0.2583 -0.7109 -0.0790 -0.0730 -0.1276 -0.5636 -0.4431 -0.0903 -0.1104 -0.2912 -0.1115 -0.0911 -0.1513 -0.3691 -0.6118 -0.0420 -0.1283 -0.1277 -0.1084 -0.0687 -0.0949 -0.0835 -0.0999 -0.1029 -0.1776 -0.1208 -0.3592 -0.1907 -0.0932 -0.0807 -0.1305 -0.1367 -0.2836 -0.0934 -0.1299 -0.0814 -0.0699 -0.0895 -0.1493 -0.0390 -0.1125 -0.0982 -0.1179 -0.1463 -0.0945 -0.2267 -0.0403 -0.1098 -0.0903 -0.1174 -0.1081 -0.0698 -0.1196 -0.0920 -0.1195 -0.0510 -0.1037 -0.1148 -0.5111 -2.1618 -0.0906 -0.0794 -0.2013 -0.0578 -0.1599 -0.1152 -0.0829 -0.1038 -1.8847 -0.2569 -0.2385 -0.0456 -0.1951 -0.0969 -0.1168 -0.0932 -0.1350 -0.9924 -1.2445 -0.1138 -0.0353 -0.0757 -0.0914 -0.1360 -0.0817 -0.0740 -0.1732 -0.2109 -0.0819 -0.0983 -0.1148 -0.5846 -0.1007 -0.1399 -0.1256 -0.0800 -0.1019 -0.0702 -0.1309 -0.7355 -1.1061 -0.1251 -0.1229 -0.0843 -1.4660 -0.1677 -0.1895 -0.1328 -0.4555 -1.5949 -0.8392 -0.0234 -0.1230 -0.0932 -0.0201 -0.0404 -0.2579 -0.6389 -0.0993\n",
            "T-15\tMwamuna wa magalasi akuda , jekete lakuda , ndi malaya amizere yopingasa yoyera ndi yofiira akuloza chinachake ataima m'mbali mwa msewu .\n",
            "H-15\t-0.3158525228500366\t▁ M w a m u n a ▁ w o v a l a ▁ m a g a l a s i ▁ a k u j a m b u l a ▁ c h a k u d a ▁ n d i ▁ m a l a y a ▁ a m i z e r e ▁ y o p a n g a ▁ y o y e r a ▁ y o f i i r a ▁ n d i ▁ y o y e r a ▁ a k u l o z a ▁ c h i n a c h a k e ▁ m ' m b a l i ▁ m w a ▁ m s e w u ▁ .\n",
            "D-15\t-0.3158525228500366\tMwamuna wovala magalasi akujambula chakuda ndi malaya amizere yopanga yoyera yofiira ndi yoyera akuloza chinachake m'mbali mwa msewu .\n",
            "P-15\t-0.1289 -0.1059 -0.0598 -0.0853 -0.0882 -0.0912 -0.1147 -0.0987 -0.1341 -0.0871 -3.2102 -0.1266 -0.1117 -0.0899 -0.1021 -0.1033 -0.2051 -0.1050 -2.0316 -0.1560 -0.0720 -0.1109 -0.0775 -0.0707 -0.1434 -0.0821 -0.1886 -0.1167 -1.7577 -0.1172 -1.2612 -0.3587 -0.0527 -0.2283 -0.1595 -0.1289 -0.5087 -0.1031 -0.5790 -0.1110 -0.1712 -0.2532 -1.0845 -0.1798 -0.2551 -0.0925 -0.1085 -0.2258 -1.1856 -0.3979 -0.1697 -0.1247 -0.1388 -0.1003 -0.1235 -0.1627 -0.1846 -0.0394 -0.0482 -0.0793 -0.0293 -0.0810 -0.7893 -0.0864 -0.5377 -0.8996 -0.1305 -0.2438 -0.0549 -0.0981 -0.2016 -1.4754 -0.4730 -0.3927 -0.1180 -0.0879 -0.0880 -0.2594 -1.3481 -0.4519 -0.5184 -0.1117 -0.5407 -0.0678 -0.1409 -0.3426 -0.6036 -0.1471 -0.1125 -0.1298 -0.2247 -0.1109 -0.2927 -0.0775 -0.0951 -0.0917 -0.2084 -0.2496 -0.0801 -0.0967 -1.3601 -0.5886 -1.9422 -0.9670 -0.1034 -0.0143 -0.0819 -0.1277 -0.1648 -0.1108 -0.1857 -0.1125 -0.1220 -0.0358 -0.0670 -0.1697 -0.3333 -0.4356 -0.2361 -1.3324 -0.0958 -0.0285 -0.1185 -0.1633 -0.1504 -0.0167 -0.0906 -0.1660 -2.0897 -0.2799 -0.0326 -0.0263 -0.0423 -0.3340 -0.0430 -0.1095\n",
            "T-110\tMwana wamng'ono wanyamula mtanga wa mazira a Isitala amitundu yowala bwino ndipo akutola lapinki paudzu .\n",
            "H-110\t-0.3371303379535675\t▁ M w a n a ▁ w a m n g ' o n o ▁ w a m n y a m a t a ▁ w a m n g ' o n o ▁ w a m a d z i ▁ a t a v a l a ▁ j u z i ▁ l a ▁ m i t u n d u ▁ y o b i r i w i r a ▁ n d i p o ▁ w a p i n k i ▁ .\n",
            "D-110\t-0.3371303379535675\tMwana wamng'ono wamnyamata wamng'ono wamadzi atavala juzi la mitundu yobiriwira ndipo wapinki .\n",
            "P-110\t-0.1177 -0.0612 -0.0750 -0.1202 -0.1180 -0.0945 -0.1664 -0.0994 -0.1226 -0.0615 -0.0972 -0.0624 -0.0333 -0.0794 -0.0524 -0.0600 -0.1705 -0.0757 -0.8299 -0.7795 -0.3158 -0.4532 -0.1032 -0.0571 -0.1844 -0.0650 -0.1120 -0.1430 -0.3115 -0.3272 -0.6789 -0.5113 -0.0287 -0.3285 -0.2400 -0.0338 -0.1129 -0.1586 -0.7250 -0.1473 -0.5902 -0.1563 -1.0024 -0.0156 -0.0926 -0.2242 -0.0903 -0.3060 -0.1051 -0.4513 -0.1252 -0.0818 -0.1271 -0.0970 -3.3463 -0.1943 -0.2227 -0.0824 -0.1467 -0.2381 -0.1184 -1.0398 -1.0788 -0.0541 -0.7097 -0.3909 -0.0843 -0.0155 -0.1203 -0.1912 -0.2818 -0.0981 -3.1328 -0.1010 -0.0921 -0.1007 -0.1116 -0.1074 -0.1001 -0.0959 -0.2161 -0.5868 -0.0962 -0.0908 -0.4565 -0.0812 -0.1126 -1.4730 -0.1389 -2.0379 -0.2568 -0.0709 -0.3677 -0.0862 -0.6342 -1.8560 -0.1050\n",
            "T-255\tBambo wina wazaka zapakati akukhala m'malo ogwirira ntchito m'mafakitale akuwerenga nyuzipepala .\n",
            "H-255\t-0.2817842960357666\t▁ B a m b o ▁ w i n a ▁ w a z a k e ▁ z a p a k a t i ▁ a k u k h a l a ▁ m ' m a l o ▁ o g w i r a ▁ n t c h i t o ▁ m ' m a f u n d e ▁ a k u g w e d e z a ▁ p a f u p i ▁ n d i ▁ g a l u ▁ l a ▁ a n t h u ▁ .\n",
            "D-255\t-0.2817842960357666\tBambo wina wazake zapakati akukhala m'malo ogwira ntchito m'mafunde akugwedeza pafupi ndi galu la anthu .\n",
            "P-255\t-0.1264 -0.2782 -0.1197 -0.0773 -0.1071 -0.0760 -0.1233 -0.0510 -0.1171 -0.0903 -0.1067 -0.1220 -0.0918 -0.3044 -0.4130 -0.1252 -0.1022 -0.5620 -0.1238 -0.0677 -0.1046 -0.3727 -0.1272 -0.0108 -0.1167 -0.0263 -0.1028 -0.1210 -0.1907 -0.2385 -0.2396 -0.1653 -1.5611 -0.1189 -0.0899 -0.1081 -0.1007 -0.2232 -0.4625 -0.6285 -0.1133 -0.3584 -0.0952 -0.0714 -0.0307 -1.1980 -0.9552 -0.0933 -0.0600 -0.3518 -0.1785 -0.0419 -0.0445 -0.0102 -0.1031 -0.1456 -0.0273 -0.0382 -0.0921 -0.0640 -1.1126 -0.1141 -0.1449 -0.0688 -2.2544 -1.4551 -0.4078 -0.0567 -0.1116 -0.1104 -0.5492 -0.1697 -0.0319 -0.1011 -0.1709 -0.1276 -0.0934 -0.3107 -0.1975 -0.1428 -1.1505 -0.2027 -1.2215 -0.0672 -0.1821 -0.1588 -0.1160 -0.1824 -0.4865 -0.1575 -0.1072 -0.7231 -0.6540 -0.0406 -0.2450 -0.1349 -1.1003 -0.0997 -0.4290 -0.1570 -0.3985 -0.6724 -0.1652 -0.0835 -0.1145 -0.9092 -0.0932\n",
            "T-366\tAmuna awiri ovala ma jekete achikasu amtundu wa neon akwera pamahatchi awiri abulauni mumsewu pafupi ndi bedi la maluwa achikasu owala.\n",
            "H-366\t-0.30749282240867615\t▁ A m u n a ▁ a w i r i ▁ o v a l a ▁ m a ▁ j e k e t e ▁ a c h i k a s u ▁ n d i ▁ w a n t h u ▁ a k u y e n d a ▁ p a m a l a y a ▁ a c h i k a s u ▁ n d i ▁ a b u l u u ▁ p a f u p i ▁ n d i ▁ m a s i t e p e ▁ a c h i k a s u ▁ .\n",
            "D-366\t-0.30749282240867615\tAmuna awiri ovala ma jekete achikasu ndi wanthu akuyenda pamalaya achikasu ndi abuluu pafupi ndi masitepe achikasu .\n",
            "P-366\t-0.1243 -0.0742 -0.0749 -0.0783 -0.0804 -0.1259 -0.1387 -0.1380 -0.2456 -0.1258 -0.0694 -0.1162 -0.3037 -0.0370 -0.0790 -0.1128 -0.0771 -0.1113 -0.1041 -0.1292 -0.1132 -1.7606 -0.0123 -0.1719 -0.0775 -0.0830 -0.0449 -0.0911 -0.1107 -0.5789 -0.3139 -0.1170 -0.0978 -0.2585 -0.1178 -0.0506 -0.4538 -0.1734 -1.0740 -0.1442 -0.2220 -0.1815 -0.5166 -0.3139 -0.3544 -1.5886 -0.0934 -0.0843 -0.1017 -0.2962 -0.9691 -0.1219 -0.4068 -0.1280 -0.2275 -0.0405 -0.2248 -0.1358 -0.1750 -0.1393 -0.4703 -0.1462 -0.4871 -1.6106 -0.3296 -0.0987 -0.0969 -0.8954 -1.1481 -0.0876 -0.1064 -0.1865 -0.1831 -0.4005 -0.2243 -0.1881 -0.6512 -0.0933 -0.1167 -0.2720 -1.5622 -0.1500 -0.1045 -0.0499 -0.2541 -0.0549 -0.2228 -0.7290 -0.1351 -0.2281 -0.0784 -0.1282 -0.1584 -0.1049 -0.0709 -0.0799 -0.2476 -0.0780 -0.1430 -0.1104 -1.6056 -0.8694 -0.2372 -0.2404 -0.7200 -0.0803 -0.1506 -0.2665 -1.9413 -0.1336 -0.1127 -0.0179 -0.1551 -0.0321 -0.0456 -0.2764 -2.3084 -0.0950\n",
            "T-259\tMzimayi wovala malaya otuwa ndipo ali ndi kachikwama kofiira atakhala pa benchi ya paki yobiriwira akuwerenga nyuzipepala .\n",
            "H-259\t-0.236102893948555\t▁ M z i m a y i ▁ w o v a l a ▁ m a l a y a ▁ o t u w a ▁ n d i p o ▁ w a l i ▁ n d i ▁ k a c h i k w a m a ▁ k o f i i r a ▁ a t a k h a l a ▁ p a ▁ b e n c h i ▁ y o b i r i w i r a ▁ a k u w e r e n g a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-259\t-0.236102893948555\tMzimayi wovala malaya otuwa ndipo wali ndi kachikwama kofiira atakhala pa benchi yobiriwira akuwerenga kumbuyo kwake .\n",
            "P-259\t-0.1302 -0.0886 -0.1104 -0.1494 -0.1519 -0.1175 -0.0457 -0.0964 -0.1042 -0.0690 -0.0890 -0.0613 -0.1322 -0.0701 -0.1240 -0.1137 -0.0689 -0.1344 -0.0500 -0.1092 -0.0467 -0.0933 -0.1161 -0.0929 -0.0326 -0.0541 -0.0135 -0.0879 -0.1923 -0.1384 -0.0835 -0.1154 -0.2341 -0.1122 -0.0814 -0.1074 -0.1065 -1.9393 -0.7090 -0.1190 -0.1643 -0.0807 -0.1177 -0.8555 -0.2151 -0.4957 -0.7892 -0.0776 -0.1266 -0.0571 -0.4468 -0.0919 -0.1117 -0.0969 -0.1211 -0.8432 -0.1377 -1.4208 -0.0975 -0.3699 -0.0498 -0.3714 -0.2878 -0.1053 -0.0497 -0.1186 -0.1832 -0.0760 -0.1063 -0.0442 -0.1138 -0.1041 -0.0109 -0.1327 -0.4654 -0.1718 -0.0236 -0.0779 -0.0316 -0.1015 -0.1074 -0.1046 -0.0074 -1.1257 -0.1377 -0.0904 -0.0551 -0.0728 -0.0506 -0.1065 -0.0669 -0.0946 -0.1702 -0.1509 -0.4053 -0.1083 -0.9954 -0.0968 -0.3825 -0.7745 -0.0783 -0.0651 -0.0861 -0.1590 -2.1639 -0.4178 -0.9073 -1.0597 -0.1234 -0.0529 -0.0821 -0.1453 -0.4545 -0.0416 -0.1678 -0.4609 -0.0791 -0.3226 -0.4158 -0.1117\n",
            "T-315\tMtsikana wa ku Asia wovala nsonga ya pinki ndi yakuda ya mizere yakuda akuyenda pafupi ndi mtsikanayo pamutu wotuwa.\n",
            "H-315\t-0.29729291796684265\t▁ M t s i k a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a ▁ p i n k i ▁ n d i ▁ j e a n s ▁ y a k u d a ▁ a k u j a m b u l i r a ▁ p a f u p i ▁ n d i ▁ g a l i m o t o ▁ y a ▁ m u t u ▁ w a ▁ m u t u ▁ w a ▁ m u t u ▁ w a ▁ m o t u w a ▁ .\n",
            "D-315\t-0.29729291796684265\tMtsikana wovala yunifolomu ya pinki ndi jeans yakuda akujambulira pafupi ndi galimoto ya mutu wa mutu wa mutu wa motuwa .\n",
            "P-315\t-0.1224 -0.0801 -0.0279 -0.0792 -0.1029 -0.0592 -0.1178 -0.1024 -0.1146 -0.1272 -0.6619 -2.1694 -0.3388 -0.1114 -0.0789 -0.1015 -0.1050 -1.3378 -0.0777 -0.0468 -0.0954 -0.2258 -0.1406 -0.0583 -0.1209 -0.1030 -0.0535 -0.1119 -0.0190 -0.1203 -0.3981 -0.3659 -0.1807 -0.0324 -0.0665 -0.0616 -0.1730 -0.2951 -0.0623 -0.1090 -0.0910 -1.3501 -0.5327 -0.4839 -0.1796 -0.0904 -0.1825 -0.0590 -0.1185 -0.7750 -0.1044 -0.1207 -0.1829 -0.2170 -0.2381 -0.0688 -0.1040 -0.5521 -0.1127 -0.0814 -0.1078 -0.0848 -0.0517 -1.6140 -0.5650 -0.0731 -0.1244 -1.1317 -0.1275 -0.0274 -0.0879 -0.1141 -0.1507 -0.1086 -0.0586 -0.0694 -0.1168 -0.0821 -2.5485 -0.1929 -0.0361 -1.5932 -0.0210 -0.0625 -0.1291 -0.0801 -0.1512 -0.0816 -0.1296 -1.1216 -2.3278 -0.5200 -0.5310 -0.0585 -0.0880 -0.0295 -0.1257 -0.4509 -0.2137 -0.1713 -0.1296 -0.0528 -0.0974 -0.0516 -0.1585 -0.5736 -0.1869 -0.6848 -0.0655 -0.0468 -0.1092 -0.0393 -0.2289 -0.9575 -0.3620 -1.5859 -0.0625 -0.3393 -0.1004 -0.0976 -0.5306 -0.2191 -0.1268\n",
            "T-387\tMwamuna wovala malaya oyera ndi magalasi adzuwa ndi mwamuna wovala malaya akuda ndi magalasi adzuwa amakhala patebulo ndi mabotolo anayi amowa .\n",
            "H-387\t-0.20545868575572968\t▁ M w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ m a g a l a s i ▁ a d z u w a ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ n d i ▁ m a k a z i ▁ a t a k h a l a ▁ p a m p h e p o ▁ n d i ▁ m a l o ▁ o t u w a ▁ a n a y i ▁ .\n",
            "D-387\t-0.20545868575572968\tMwamuna wovala malaya oyera ndi magalasi adzuwa ndi mwamuna wovala malaya achikasu ndi makazi atakhala pamphepo ndi malo otuwa anayi .\n",
            "P-387\t-0.1300 -0.1170 -0.0385 -0.0973 -0.0876 -0.0969 -0.1259 -0.1030 -0.1629 -0.1483 -0.0836 -0.0530 -0.1347 -0.0775 -0.1258 -0.1137 -0.0563 -0.1081 -0.0568 -0.1092 -0.0752 -0.1022 -0.1201 -0.0626 -0.0815 -0.0557 -0.0893 -0.1035 -0.1954 -0.0596 -0.0913 -0.0884 -0.1032 -0.0600 -0.1094 -0.0344 -0.1232 -0.0928 -0.1228 -0.0461 -0.0645 -0.1918 -0.1332 -0.0613 -0.0994 -0.0651 -0.0359 -0.0930 -0.3118 -0.3500 -0.0525 -0.0977 -0.1329 -0.0797 -0.1289 -0.1189 -0.2642 -0.0651 -0.0601 -0.0930 -0.1901 -0.2663 -0.0804 -0.0328 -0.1160 -0.0794 -0.1192 -0.1120 -0.0641 -0.1323 -0.0731 -0.1126 -0.0430 -0.1024 -0.0990 -0.1163 -1.9323 -0.1750 -0.0959 -0.1281 -0.1069 -0.0540 -0.0942 -0.1630 -0.8941 -0.1136 -0.1097 -0.2143 -0.1529 -0.1233 -0.6141 -0.3475 -0.1066 -0.1517 -0.1221 -0.4919 -1.7255 -0.0764 -0.3099 -0.0352 -0.1099 -0.0639 -0.1041 -0.0872 -0.0473 -0.1723 -0.7565 -0.5291 -1.0890 -0.0538 -0.1536 -0.5218 -0.1471 -0.1961 -0.1220 -0.1188 -0.2014 -0.0875 -0.1094 -1.4596 -0.0893 -0.0889 -1.7151 -0.2156 -0.3258 -0.0804 -0.1112 -0.3711 -0.4256 -0.5279 -0.1968 -0.1240 -0.0664 -0.3020 -0.6444 -0.1085\n",
            "T-244\tBrunette wamkazi atavala malaya ofiira, akugwiritsa ntchito zodzoladzola kwa mwamuna wa brunette ndi maso ake otsekedwa, komanso mu malaya ofiira.\n",
            "H-244\t-0.27999448776245117\t▁ M n y a m a t a ▁ w a m k a z i ▁ a t a v a l a ▁ m a l a y a ▁ o f i i r a ▁ a k u g w i r a ▁ n t c h i t o ▁ z o g w i r a ▁ z o l a m o ▁ k w a ▁ m w a m u n a ▁ w a ▁ b u l a u n i ▁ n d i ▁ m a s o ▁ o s e k e d w a ▁ k u m a s o ▁ k w a k e ▁ .\n",
            "D-244\t-0.27999448776245117\tMnyamata wamkazi atavala malaya ofiira akugwira ntchito zogwira zolamo kwa mwamuna wa bulauni ndi maso osekedwa kumaso kwake .\n",
            "P-244\t-0.1254 -0.0735 -0.2874 -0.1060 -0.1866 -0.0657 -0.1136 -0.2127 -0.1021 -0.1157 -0.6440 -0.1374 -0.1011 -0.0638 -0.2301 -0.0188 -0.1877 -0.1454 -0.1082 -0.0769 -0.1049 -0.1498 -0.1076 -0.0792 -0.1218 -0.0976 -0.0840 -0.0991 -0.0330 -0.1116 -0.0676 -0.0995 -0.1093 -0.0619 -0.6328 -0.1058 -0.1785 -0.0697 -0.1776 -0.2519 -0.1174 -0.1094 -0.0865 -0.0019 -0.0668 -0.0939 -0.0803 -0.5517 -0.1487 -0.2099 -0.1028 -0.0259 -0.1363 -0.1007 -0.0273 -0.0655 -0.0863 -0.0628 -0.1671 -1.9188 -1.1527 -0.0956 -0.1737 -0.2267 -0.2205 -0.7017 -0.1514 -1.3773 -0.2033 -1.1473 -0.9323 -0.2614 -0.6894 -0.1930 -0.1177 -0.8662 -0.1172 -0.3763 -0.0997 -0.1619 -0.1039 -0.0621 -0.0937 -0.1559 -0.2502 -0.2568 -0.5183 -0.3164 -1.5924 -0.0681 -0.5701 -0.1171 -0.1165 -0.0875 -0.1557 -0.2566 -0.0951 -0.1478 -0.4075 -0.5490 -0.3965 -0.6077 -0.3851 -0.0752 -0.5618 -0.3020 -0.0615 -0.1132 -0.0347 -1.1249 -0.0169 -0.1210 -0.3325 -1.1737 -0.2242 -0.1599 -0.4788 -0.7012 -0.0731 -0.1071 -1.2454 -0.6914 -0.1326 -0.5942 -0.0427 -0.3882 -0.3856 -0.1171\n",
            "T-141\tAnthu awiri akuuluka akuuluka kuchokera pachoulukira chofiira, choyera ndi chakuda chokhala ndi thambo lamtambo wabuluu kumbuyo kwawo.\n",
            "H-141\t-0.29779118299484253\t▁ A n t h u ▁ a w i r i ▁ a k u l u a k u l u ▁ a k u c h o k e r a ▁ k u c h o k e r a ▁ p a ▁ c h o f i y i r a ▁ c h o f i i r a ▁ n d i ▁ c h a k u d y a ▁ c h a k u d y a ▁ c h o k h a l a ▁ n d i ▁ t h a m b o ▁ l o m w e ▁ l i m a t a b w a ▁ k u m b u y o ▁ .\n",
            "D-141\t-0.29779118299484253\tAnthu awiri akuluakulu akuchokera kuchokera pa chofiyira chofiira ndi chakudya chakudya chokhala ndi thambo lomwe limatabwa kumbuyo .\n",
            "P-141\t-0.1159 -0.0298 -0.0631 -0.0349 -0.0787 -0.0823 -0.1209 -0.1428 -0.0849 -0.1210 -0.0798 -0.1000 -0.3178 -1.1604 -0.1366 -0.1696 -2.0556 -0.1609 -0.5635 -0.0243 -0.2489 -0.0432 -0.0689 -0.1606 -0.1292 -0.0910 -0.1108 -1.0939 -0.1052 -0.0829 -0.0095 -0.0356 -0.0849 -0.0969 -0.1141 -0.5565 -0.0590 -0.3469 -0.0697 -0.0790 -0.0082 -0.0442 -0.0645 -0.1021 -0.1474 -2.1150 -0.1651 -0.9309 -0.1122 -0.0692 -0.1519 -0.2894 -0.1412 -1.0025 -0.1128 -0.0950 -0.1124 -0.2359 -0.2500 -0.0767 -0.3396 -0.2369 -0.1621 -1.0606 -0.0702 -0.1376 -0.2548 -0.1782 -0.1144 -0.1363 -0.1319 -0.3537 -0.0776 -0.2020 -0.2988 -0.0739 -0.3095 -0.0371 -0.1465 -0.1717 -0.2479 -0.0929 -0.3898 -2.1061 -0.1179 -0.1965 -0.3310 -0.1267 -0.1695 -1.4491 -0.1081 -1.0684 -0.2058 -0.0420 -0.1101 -0.0586 -0.1044 -0.0933 -0.1865 -0.1678 -0.1190 -0.0997 -2.1070 -0.8811 -0.0762 -0.2879 -0.0768 -0.0472 -0.1478 -0.1066 -0.5070 -2.2549 -0.3020 -0.1424 -0.1108 -0.1723 -0.2965 -1.2421 -0.2343 -0.0466 -0.5011 -0.1116 -0.0354 -0.0675 -0.2783 -0.8617 -0.1446 -0.5988 -0.0615 -0.0598 -0.0798 -0.0671 -0.2808 -0.3697 -0.1045\n",
            "T-29\tWosewera mpira wovala yunifolomu yobiriwira akuyesa kugwira mpira, pomwe mdani wake atavala yunifomu yabuluu akuyesa kumuletsa.\n",
            "H-29\t-0.25990667939186096\t▁ W o s e w e r a ▁ m p i r a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a ▁ m p i r a ▁ a k u y e s a ▁ k u m b u y o ▁ n d i ▁ a n t h u ▁ a m b i r i ▁ a t a v a l a ▁ y u n i f o l o m u ▁ y a b u l u u ▁ y a ▁ b u l u u ▁ .\n",
            "D-29\t-0.25990667939186096\tWosewera mpira wovala yunifolomu ya mpira akuyesa kumbuyo ndi anthu ambiri atavala yunifolomu yabuluu ya buluu .\n",
            "P-29\t-0.1152 -0.1591 -0.1958 -0.0304 -0.2646 -0.0583 -0.0621 -0.1022 -0.1231 -0.1442 -0.0900 -0.0889 -0.0831 -0.0881 -0.1107 -0.2033 -0.1148 -0.1364 -0.1082 -0.1159 -0.0817 -0.1115 -0.1118 -0.0202 -0.0258 -0.0351 -0.0428 -0.0155 -0.1094 -0.0451 -0.0590 -0.0259 -0.0892 -0.1155 -0.0176 -0.1784 -1.0775 -0.3415 -1.7833 -0.0774 -0.0969 -0.0997 -0.1739 -0.1582 -0.0480 -0.1103 -0.5853 -0.1630 -0.2463 -0.1298 -0.0920 -0.0282 -0.1165 -1.2211 -0.1093 -0.1659 -0.0391 -0.1214 -0.1686 -1.0117 -0.2277 -0.1216 -0.3851 -1.9594 -0.9873 -0.2225 -0.0981 -0.0612 -0.1066 -0.5650 -0.9717 -0.1351 -0.0899 -0.0402 -0.0840 -0.2073 -0.7249 -0.2951 -0.0949 -0.8182 -0.1189 -0.0845 -0.1244 -0.0934 -0.8222 -0.0629 -0.0472 -0.0358 -0.0202 -0.0500 -0.2252 -0.1410 -0.0222 -0.0458 -0.1324 -0.0158 -0.1873 -0.9966 -0.1068 -0.0684 -0.0874 -0.0505 -0.1764 -0.4091 -1.3075 -0.9435 -0.5736 -0.2190 -0.0691 -0.0824 -0.0747 -0.2051 -2.0812 -0.1094\n",
            "T-284\tAzimayi awiri ovala malaya akuda amakhala pamadesiki amatabwa m'chipinda choyera chokhala ndi denga lotchingidwa komanso kuwala kochepa.\n",
            "H-284\t-0.2971906065940857\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u t h a m a n g a ▁ p a m a s i t e p e ▁ a ▁ m u n t h u ▁ w a ▁ m ' c h i p i n d a ▁ c h o y e r a ▁ n d i ▁ c h o k h a l a ▁ n d i ▁ n d e n g a ▁ k u m b u y o ▁ k w a k e ▁ k u n t c h i t o ▁ k w a k e ▁ .\n",
            "D-284\t-0.2971906065940857\tMayi wina wovala malaya akuda akuthamanga pamasitepe a munthu wa m'chipinda choyera ndi chokhala ndi ndenga kumbuyo kwake kuntchito kwake .\n",
            "P-284\t-0.1248 -0.0685 -0.0963 -0.0953 -0.1032 -0.1235 -0.6394 -0.1908 -0.3099 -0.1033 -0.1165 -0.0999 -0.1186 -0.0995 -0.1208 -0.0905 -0.1193 -0.1042 -0.0542 -0.1128 -0.0829 -0.1147 -0.0700 -0.0883 -0.1208 -0.3351 -0.2804 -0.0758 -0.2995 -0.0887 -0.1336 -0.5693 -0.2042 -0.1189 -2.0856 -0.0368 -0.0949 -0.1094 -0.0858 -0.0936 -0.0647 -0.0810 -0.0887 -0.0380 -0.1340 -0.2436 -0.1744 -3.1974 -0.1426 -1.0148 -0.0287 -0.2178 -0.0460 -0.1337 -0.1170 -0.3185 -0.2107 -0.5036 -0.2063 -0.0379 -0.1038 -0.0749 -0.1119 -0.3965 -0.1789 -1.6290 -0.1909 -1.8222 -0.3388 -0.0960 -0.1478 -0.0897 -0.0794 -0.0297 -0.0817 -0.1019 -0.1556 -0.0209 -0.0892 -0.0696 -0.3807 -0.0941 -0.1385 -0.0923 -0.2034 -0.8306 -0.1177 -0.1185 -0.1185 -1.3536 -0.0995 -0.1447 -0.0983 -0.2736 -0.0972 -0.0552 -0.0976 -0.0913 -0.4345 -0.0770 -0.1889 -0.0879 -1.7231 -1.2284 -0.2839 -0.3837 -0.0929 -0.6142 -0.1424 -0.5599 -0.2284 -0.1509 -0.1537 -0.1389 -0.0471 -0.1019 -0.1116 -0.1757 -0.2000 -0.1814 -0.4964 -0.1206 -0.1830 -0.9503 -0.2786 -1.7465 -0.1360 -0.3641 -0.0535 -0.1184 -0.1933 -0.1653 -0.0658 -1.6088 -0.1568 -0.1398 -1.2556 -0.1682 -0.2332 -0.8554 -0.1152\n",
            "T-213\tMkazi watsitsi lopaka utoto wabulauni ndi wabulauni wanyamula mkono wake pa mwamuna amene wanyamula kapu .\n",
            "H-213\t-0.29025864601135254\t▁ M k a z i ▁ w a t s i t s i ▁ l o p a k a t i d w a ▁ w a ▁ b u l a u n i ▁ n d i ▁ w a b u l a u n i ▁ w a n y a m u l a ▁ m k o n o ▁ w a k e ▁ p a m e n e ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ .\n",
            "D-213\t-0.29025864601135254\tMkazi watsitsi lopakatidwa wa bulauni ndi wabulauni wanyamula mkono wake pamene mwamuna wovala malaya oyera .\n",
            "P-213\t-0.1184 -0.1472 -0.0720 -0.1176 -0.0250 -0.0838 -0.1886 -0.0297 -0.1712 -2.3069 -0.5090 -0.1364 -0.0629 -0.1111 -0.1196 -0.1118 -0.0375 -0.1451 -0.1321 -0.1433 -0.4099 -0.1218 -3.3791 -0.1578 -0.1365 -0.5187 -0.1306 -0.1685 -0.4802 -0.1370 -0.9028 -0.2167 -0.3103 -0.1591 -0.1441 -0.0429 -0.0540 -0.0601 -0.1460 -0.6119 -0.0462 -0.0879 -0.2770 -0.0522 -0.4722 -0.2761 -0.0841 -0.0879 -0.0801 -0.0527 -0.0514 -0.0560 -0.1675 -0.4392 -0.1594 -1.6890 -0.3798 -0.0887 -0.1102 -0.0520 -0.0617 -0.1228 -0.1236 -0.7814 -0.4330 -0.1759 -0.1052 -0.0980 -0.1799 -0.1433 -0.5963 -0.1517 -0.0418 -0.1620 -0.2569 -0.3942 -0.1466 -0.1434 -0.0602 -0.0651 -0.0997 -0.7619 -0.4206 -0.0869 -0.0525 -0.0421 -0.0620 -0.0867 -0.1454 -0.0808 -0.5957 -1.5498 -0.0972 -0.0975 -0.1059 -0.1323 -0.3537 -0.9777 -0.2637 -0.1560 -0.0860 -0.1026 -0.1526 -0.4252 -1.2794 -0.0716 -0.1451 -0.0952 -0.7969 -0.7792 -0.1071\n",
            "T-28\tWosewera mpira wa basketball wovala yunifolomu yoyera yobiriwira ndi yachikasu, wangopanga basiketi pamasewera.\n",
            "H-28\t-0.2952146530151367\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o y e r a ▁ n d i ▁ w a c h i k a s u ▁ w a k h a l a ▁ p a n j i n g a ▁ p a ▁ s k a t e b o a r d ▁ w a ▁ m a s e w e r a ▁ .\n",
            "D-28\t-0.2952146530151367\tWosewera mpira wa basketball wovala yunifolomu yoyera ndi wachikasu wakhala panjinga pa skateboard wa masewera .\n",
            "P-28\t-0.1232 -3.1747 -0.2070 -0.1135 -0.0573 -0.0638 -0.0766 -0.0675 -0.1149 -0.1267 -0.1072 -0.4448 -0.1268 -0.0471 -0.1003 -0.1595 -0.1322 -0.3998 -0.5388 -1.1053 -0.0772 -0.0204 -0.1137 -0.1134 -0.0457 -0.0429 -0.0722 -0.0305 -0.1897 -0.2548 -0.3967 -0.5549 -0.0947 -0.0875 -0.1035 -0.0864 -0.1302 -0.0619 -0.0444 -0.0782 -0.0562 -0.1270 -0.1617 -0.1453 -0.0642 -0.0311 -0.1259 -0.1854 -0.0562 -0.0795 -0.1004 -0.1064 -0.0866 -0.0880 -0.2003 -0.3433 -0.1883 -0.1384 -0.1066 -0.6956 -0.6761 -0.0827 -0.0669 -0.0967 -0.0203 -0.1106 -0.1000 -0.0537 -0.2025 -0.4630 -0.3116 -0.5188 -1.0045 -0.1550 -0.1060 -0.0848 -0.1099 -0.1470 -0.1174 -1.3562 -0.7965 -0.1514 -0.4861 -0.0356 -0.0943 -0.1467 -2.0069 -0.1438 -0.4673 -1.6197 -0.6698 -0.2121 -0.0257 -0.1159 -0.1077 -0.0415 -0.0950 -0.0582 -0.0769 -0.2166 -1.8947 -0.5592 -0.6567 -0.3143 -1.2511 -0.0633 -0.4477 -0.0370 -0.0849 -0.1016 -0.1026 -0.4521 -1.2522 -0.1129\n",
            "T-383\tBambo wina akuwoloka msewu pakati pa galimoto yowala kwambiri ndi taxi yachikasu yokhala ndi basiketi yomangidwa ndi zingwe zonyamulira katundu wake.\n",
            "H-383\t-0.3162291944026947\t▁ B a m b o ▁ w i n a ▁ a k u w o l o k a ▁ m s e w u ▁ p a k a t i ▁ p a ▁ n g a l i m o t o ▁ y o w a l a ▁ k w a m b i r i ▁ n d i ▁ k a z i ▁ y a c h i k a s u ▁ y o k h a l a ▁ n d i ▁ t h e k e ▁ y a m a s o ▁ n d i ▁ z i n t h u ▁ z o n y a m u l i r a ▁ .\n",
            "D-383\t-0.3162291944026947\tBambo wina akuwoloka msewu pakati pa ngalimoto yowala kwambiri ndi kazi yachikasu yokhala ndi theke yamaso ndi zinthu zonyamulira .\n",
            "P-383\t-0.1317 -0.0504 -0.1026 -0.0962 -0.0978 -0.1015 -0.1238 -0.0756 -0.1327 -0.0835 -0.1046 -0.1101 -1.2094 -0.1408 -0.1140 -0.7262 -0.7095 -1.1369 -0.0913 -0.0492 -0.0995 -0.1243 -0.1384 -0.9134 -0.0763 -0.1101 -0.0551 -0.1349 -1.0439 -0.1397 -0.8981 -0.1064 -0.4561 -0.0902 -0.1149 -0.3969 -0.1294 -0.0517 -1.1185 -0.1867 -0.1977 -1.5275 -0.2520 -0.8524 -0.0520 -0.3177 -0.0489 -0.0965 -0.0164 -0.1136 -0.5576 -0.0841 -0.0734 -0.0971 -0.1685 -0.1662 -0.0460 -0.1038 -0.1051 -0.0290 -0.1118 -0.0551 -0.1227 -0.2674 -0.3322 -0.1521 -0.1261 -0.1165 -0.5672 -0.1212 -1.9649 -0.1595 -0.1552 -0.2513 -0.4434 -1.2968 -0.0964 -0.1125 -0.0606 -0.1286 -0.0471 -0.0974 -0.1533 -0.9227 -0.1575 -0.1347 -0.0424 -0.1037 -0.0578 -0.0987 -0.1058 -0.0536 -0.1217 -0.1248 -0.1038 -1.6837 -1.0735 -0.3923 -1.6731 -0.3399 -0.1670 -0.2560 -0.1777 -0.7400 -0.1357 -1.2806 -1.9826 -0.2070 -0.3140 -0.0955 -0.1430 -0.6011 -0.2424 -0.3937 -0.4502 -0.3371 -0.0253 -0.0682 -0.1484 -0.0601 -0.0860 -0.3389 -0.0923 -0.1530 -0.1324 -0.3477 -0.0419 -0.9065 -0.0914 -0.0953 -0.2948 -0.7519 -0.0941\n",
            "T-67\tMwamuna wamfupi wotuwa wokhala ndi mikwingwirima yakuda pafupi ndi pamwamba pa lamba akunyamula zolemera .\n",
            "H-67\t-0.3393622934818268\t▁ M w a m u n a ▁ w a m p i r a ▁ w o t h a m a n g a ▁ w o k h a l a ▁ n d i ▁ m a p i r i ▁ a k u j a m b u l a ▁ p a f u p i ▁ n d i ▁ k h a m u ▁ l a ▁ a n t h u ▁ a k u m e n y a ▁ m p i r a ▁ .\n",
            "D-67\t-0.3393622934818268\tMwamuna wampira wothamanga wokhala ndi mapiri akujambula pafupi ndi khamu la anthu akumenya mpira .\n",
            "P-67\t-0.1273 -0.0822 -0.1138 -0.1065 -0.2024 -0.0736 -0.0911 -0.1108 -0.1489 -0.2016 -2.6895 -0.4455 -1.3139 -0.2108 -0.2053 -0.6970 -0.1590 -0.3068 -0.4324 -0.7330 -0.1813 -0.7756 -0.6429 -0.0873 -0.0810 -0.0460 -0.1492 -0.1450 -0.3735 -0.1683 -0.1563 -0.0167 -0.1038 -0.0650 -0.0918 -0.0975 -0.0781 -0.1467 -0.1097 -0.0903 -0.2096 -0.7311 -1.3538 -0.0545 -0.0290 -0.1231 -0.1883 -0.7230 -0.1700 -0.1376 -1.4483 -0.0878 -0.3537 -0.0705 -0.1032 -0.0487 -0.5578 -0.2064 -1.1835 -0.1284 -0.1859 -0.1238 -0.0652 -0.1351 -0.1212 -0.0786 -0.0685 -0.1164 -0.1685 -1.2095 -1.4862 -0.2052 -0.1184 -0.0866 -0.0742 -0.1005 -0.1791 -0.0939 -0.1621 -0.4613 -0.6636 -0.0841 -0.0660 -0.0773 -1.0048 -0.5582 -0.1107 -0.5298 -1.0762 -0.1067 -0.1108 -0.1388 -0.3106 -0.6599 -1.1201 -0.5569 -0.0981 -0.1153 -0.4987 -1.0724 -0.1104\n",
            "T-276\tWapolisi wamkazi akumwetulira atanyamula nkhwangwa yabuluu ndikuvala St. Patrick's Day memorabilis akuyenda pamaso pa anthu osonkhana.\n",
            "H-276\t-0.2684042155742645\t▁ W a p o l i s i ▁ w a m k a z i ▁ a k u m w e t u l i r a ▁ a t a n y a m u l a ▁ n k h o n d o ▁ y a b u l u u ▁ n d i ▁ k u v a l a ▁ j e k e t e ▁ l a c h i k a s u ▁ n d i ▁ m w a m u n a ▁ a k u y e n d a ▁ p a m a s o ▁ p a ▁ a n t h u ▁ o s o n k h a n a .\n",
            "D-276\t-0.2684042155742645\tWapolisi wamkazi akumwetulira atanyamula nkhondo yabuluu ndi kuvala jekete lachikasu ndi mwamuna akuyenda pamaso pa anthu osonkhana.\n",
            "P-276\t-0.1034 -0.3738 -0.3023 -0.1252 -0.0539 -0.0747 -0.1052 -0.0377 -0.0986 -0.1311 -0.0582 -0.8915 -0.2830 -0.0363 -0.2128 -0.0159 -0.1186 -0.1384 -0.0870 -0.2478 -0.0953 -1.4795 -0.2057 -0.0821 -0.0148 -0.0428 -0.0872 -0.0895 -0.0976 -0.1093 -0.1342 -0.0889 -0.0288 -0.0931 -0.0826 -0.0370 -0.1083 -0.0668 -0.0577 -0.0754 -0.0934 -0.1334 -1.6408 -0.2003 -0.0810 -0.9031 -0.1526 -0.9183 -0.0984 -0.1525 -0.0273 -0.1181 -0.5140 -0.1571 -0.0718 -0.0799 -0.0447 -0.2066 -0.1825 -0.0662 -0.1060 -0.3886 -0.2382 -0.4501 -1.3443 -0.1218 -0.0612 -0.1088 -0.0817 -1.9777 -0.2465 -0.0912 -0.0445 -0.0163 -0.0804 -0.1141 -0.1440 -0.2063 -0.3416 -0.0954 -0.1038 -1.5953 -0.1967 -0.0966 -0.1099 -0.1864 -1.7701 -0.0896 -0.1081 -0.0927 -0.1313 -0.4529 -0.1112 -0.1565 -0.1069 -0.0748 -0.0856 -0.0910 -1.1990 -0.3282 -0.0907 -0.4913 -0.1782 -0.1941 -0.0344 -0.1098 -0.1312 -0.0241 -0.1425 -0.5399 -0.0924 -0.0475 -0.0935 -0.0761 -0.5428 -0.2780 -0.1657 -2.6241 -0.3139 -0.0087 -0.1485 -0.0607 -0.1515 -0.2605 -0.2007 -0.1643 -0.1607 -0.3683 -0.2212 -0.1257 -0.0368 -0.1830 -1.8450 -0.1012\n",
            "T-193\tAmuna awiri omwe ali muofesi yomasuka ndipo onse akuyang'ana makompyuta awo ndipo wina wakweza mapazi awo pa desiki .\n",
            "H-193\t-0.30977874994277954\t▁ A m u n a ▁ a w i r i ▁ o m w e ▁ a l i ▁ m ' m o d z i ▁ a m a s u k a ▁ n d i p o ▁ w i n a ▁ a k u m e n y a ▁ m a k o m p y u t a ▁ a w i r i ▁ n d i p o ▁ w i n a ▁ a k u y a n g ' a n a ▁ p a ▁ k a z i ▁ .\n",
            "D-193\t-0.30977874994277954\tAmuna awiri omwe ali m'modzi amasuka ndipo wina akumenya makompyuta awiri ndipo wina akuyang'ana pa kazi .\n",
            "P-193\t-0.1098 -0.0428 -0.0783 -0.0728 -0.0935 -0.0903 -0.1411 -0.1568 -0.2344 -0.1545 -0.0632 -0.1062 -0.2610 -0.0813 -0.3745 -0.1647 -0.0900 -0.1455 -0.1392 -0.0535 -0.1130 -0.1291 -0.1949 -0.9730 -0.3070 -0.5527 -0.0982 -0.0698 -0.0981 -0.1498 -0.2831 -0.2323 -0.5669 -0.4851 -1.1193 -0.0759 -0.0707 -0.1565 -0.3240 -0.0463 -0.1246 -0.5513 -0.0650 -0.1021 -2.7126 -0.8401 -0.0912 -0.0966 -0.1655 -0.3492 -0.0944 -0.1081 -0.1337 -0.0587 -0.0666 -0.0853 -0.1068 -0.3896 -0.0806 -0.3633 -2.7175 -0.0725 -0.4351 -0.0579 -0.1880 -0.0674 -0.0070 -0.0803 -0.1699 -0.4632 -0.3546 -0.2043 -0.0970 -0.1052 -0.2896 -0.6310 -0.0764 -0.1016 -0.1273 -0.0729 -0.0897 -0.7201 -0.2611 -0.0918 -0.1003 -0.1949 -0.2805 -0.2871 -0.0915 -1.1024 -1.5243 -0.1374 -0.2039 -0.0676 -0.0957 -0.1026 -0.1328 -0.1226 -1.7651 -0.1529 -0.9056 -1.3593 -0.4765 -0.3207 -0.1508 -0.4864 -0.5310 -0.0988\n",
            "T-236\tGalu woyera , watsitsi lopiringizika wavala chomangira n'kumaonera m'madzi galu wina wakuda ndi wabulauni .\n",
            "H-236\t-0.3243892788887024\t▁ G a l u ▁ w o y e r a ▁ w a t s i t s i ▁ l o p i n d i k a ▁ w a v a l a ▁ c h o v a l a ▁ c h o m a n g i r i r a ▁ k u m a n j a ▁ m w a m u n a ▁ w i n a ▁ w a k u d a ▁ n d i ▁ w o y i m b a ▁ w a m k u l u ▁ w a b u l a u n i ▁ .\n",
            "D-236\t-0.3243892788887024\tGalu woyera watsitsi lopindika wavala chovala chomangirira kumanja mwamuna wina wakuda ndi woyimba wamkulu wabulauni .\n",
            "P-236\t-0.1290 -0.1233 -0.1007 -0.0662 -0.1743 -0.1514 -0.0466 -0.0560 -0.0327 -0.0641 -0.0856 -0.1078 -0.1754 -0.0809 -0.1602 -2.3292 -0.0651 -0.0841 -0.1046 -0.1062 -0.0974 -0.0911 -0.2980 -0.1074 -0.7385 -0.1068 -1.0217 -0.6153 -0.2199 -0.1010 -0.1278 -0.1660 -0.0771 -0.2331 -0.0841 -0.1111 -0.0982 -0.1170 -0.0968 -0.1086 -0.1230 -0.1813 -0.1253 -0.1242 -0.0720 -0.1129 -0.1165 -0.0203 -0.1032 -1.1885 -0.2269 -0.1866 -0.0594 -0.2002 -0.0511 -0.7294 -0.7055 -1.3855 -0.1518 -0.1511 -0.4064 -0.2645 -0.2745 -0.2129 -2.2205 -0.1276 -0.1186 -0.1408 -0.9275 -1.0346 -0.1592 -0.8318 -0.0603 -0.0998 -0.1066 -0.1457 -0.1909 -0.2254 -0.1019 -0.0886 -0.1263 -0.5433 -0.1756 -1.6776 -0.1085 -0.1717 -0.1016 -0.1797 -0.9478 -0.2040 -0.1260 -0.0975 -0.2227 -0.3510 -0.5569 -0.4975 -0.1538 -0.5409 -0.7441 -0.1846 -2.0491 -0.2188 -1.1828 -0.6596 -0.0661 -0.4774 -0.0678 -0.2877 -0.8469 -0.2224 -1.2344 -0.0840 -0.0613 -0.1471 -0.0636 -0.0661 -0.0757 -0.5121 -0.1758 -0.1040\n",
            "T-280\tBambo wina wovala malaya ofiira amizeremizere akutsamira pampando wa galimoto yake n'kumaseweretsa malaya a jekete .\n",
            "H-280\t-0.3011136054992676\t▁ M n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ a m i z e r e m i z e r e ▁ a k u t s a m i r a ▁ p a m k a n d o ▁ w a k e ▁ n d i ▁ k u m a s e w e r a ▁ k u m a s e w e r a ▁ a ▁ k u m a n j a ▁ a k e ▁ .\n",
            "D-280\t-0.3011136054992676\tMnyamata wovala malaya ofiira amizeremizere akutsamira pamkando wake ndi kumasewera kumasewera a kumanja ake .\n",
            "P-280\t-0.1137 -0.8407 -2.0021 -0.2945 -0.0978 -0.1261 -0.0997 -0.2426 -0.1144 -0.1403 -0.0698 -0.1863 -0.1579 -0.1091 -0.0666 -0.1156 -0.1112 -0.0589 -0.0983 -0.1423 -0.1103 -0.0718 -0.0921 -0.1057 -0.1063 -0.0535 -0.1162 -0.1360 -0.0779 -0.2080 -0.1922 -0.1400 -0.1037 -0.1032 -0.0227 -0.0637 -0.0199 -0.0736 -0.2755 -0.0529 -0.0195 -0.0692 -0.0357 -0.0831 -0.1148 -0.4950 -0.0995 -0.0834 -1.2635 -0.0812 -0.1117 -0.1750 -0.1363 -0.0431 -0.0884 -0.1144 -0.1292 -0.1402 -0.2855 -1.9602 -0.1042 -0.6869 -0.1694 -0.1089 -0.1072 -0.0604 -0.3849 -1.6020 -0.0474 -0.1544 -0.7968 -0.1870 -0.1026 -1.2636 -0.7838 -1.0917 -0.0987 -0.3329 -0.1494 -0.0996 -0.3736 -0.0947 -0.0905 -0.3430 -0.1335 -0.7944 -0.4935 -0.2045 -0.0856 -0.0933 -0.0964 -0.1145 -0.0731 -0.0768 -0.5330 -0.1219 -0.8996 -0.2683 -2.7067 -0.2455 -1.0399 -0.1600 -1.4143 -0.0937 -0.0907 -0.0865 -0.4021 -0.4665 -0.0446 -0.2360 -0.5724 -0.1017\n",
            "T-281\tmunthu wovala chovala chonyezimira amachotsa m'mphepete mwa msewu pogwiritsa ntchito chowuzira .\n",
            "H-281\t-0.2450961023569107\t▁ M u n t h u ▁ w o v a l a ▁ c h o v a l a ▁ c h a m i z e r e m i z e r e ▁ a m a t h a m a n g a ▁ m ' c h i p o l e ▁ c h o f e w a ▁ .\n",
            "D-281\t-0.2450961023569107\tMunthu wovala chovala chamizeremizere amathamanga m'chipole chofewa .\n",
            "P-281\t-0.1229 -0.1758 -0.0466 -0.0802 -0.0502 -0.0707 -0.0735 -0.1554 -0.0555 -0.0807 -0.0666 -0.1248 -0.0790 -0.1046 -0.0968 -0.0559 -0.0887 -0.6709 -0.0589 -0.1005 -0.0731 -0.1039 -0.0838 -0.0396 -0.0932 -0.3147 -1.5280 -0.0724 -0.5139 -0.2401 -0.0865 -0.2349 -0.1381 -0.0651 -0.4081 -0.2099 -0.1874 -0.2287 -0.1443 -0.6695 -0.1349 -0.1209 -0.6963 -0.1812 -0.1403 -0.0699 -0.1049 -0.1538 -0.0204 -0.1484 -0.0937 -0.1028 -0.7103 -1.1383 -0.0941 -0.1271 -0.4240 -1.3112 -0.6447 -0.2172 -0.3831 -0.0533 -0.0801 -0.1301 -1.3214 -0.1192 -0.1141 -0.1520 -0.2211 -0.2914 -0.1079\n",
            "T-16\tBambo akugwira gitala ndikugwira ntchito pa betbook ya Asus, pomwe bambo wina amagwiritsa ntchito Apple netbook pambali pake.\n",
            "H-16\t-0.42171913385391235\t▁ B a m b o ▁ a k u m e t a ▁ c h i t h u n z i ▁ n d i ▁ n y a l i ▁ y a ▁ b a s e b a l l ▁ y a k e ▁ p o m w e ▁ o m w e ▁ a n t h u ▁ e n a ▁ a m a g w i r i t s a ▁ n t c h i t o ▁ p a f u p i ▁ n d i ▁ k a m b i r i ▁ .\n",
            "D-16\t-0.42171913385391235\tBambo akumeta chithunzi ndi nyali ya baseball yake pomwe omwe anthu ena amagwiritsa ntchito pafupi ndi kambiri .\n",
            "P-16\t-0.1322 -0.0291 -0.0939 -0.1115 -0.0782 -0.1015 -0.1049 -0.2728 -0.0584 -0.0800 -1.2858 -0.3421 -0.5688 -0.1003 -0.2127 -0.2608 -0.1706 -0.1104 -0.0902 -0.2561 -0.1646 -0.1059 -0.0668 -0.1025 -0.2119 -0.9527 -0.0526 -0.1038 -0.3294 -2.4568 -0.1383 -0.7419 -0.4477 -0.2370 -0.1387 -0.8442 -0.8354 -0.8110 -0.5553 -0.8049 -0.2013 -0.0498 -0.0824 -0.0529 -0.0336 -0.7638 -0.2146 -0.5076 -0.4219 -2.5669 -0.3377 -0.1056 -0.2088 -1.2931 -0.0691 -0.1177 -0.1215 -0.0753 -1.4704 -1.6538 -0.2391 -0.0921 -0.0898 -0.7394 -0.5716 -0.0550 -0.5580 -0.0614 -0.1161 -2.7497 -0.0941 -0.0681 -0.0977 -1.2757 -0.3175 -0.1107 -2.6543 -0.1211 -0.0799 -0.1543 -0.3705 -0.2052 -0.1243 -0.1008 -0.0960 -0.1376 -0.0161 -0.0574 -0.1079 -0.1129 -0.0157 -0.0376 -0.0760 -1.2446 -0.1773 -3.2149 -0.0590 -0.0295 -0.0780 -0.2083 -0.2823 -0.3550 -0.0885 -0.2165 -0.6225 -0.3232 -1.6063 -0.5507 -0.4571 -0.2406 -0.0730 -0.4021 -1.1268 -0.1062\n",
            "T-22\tWosewera mpira wachimuna wamwamuna wovala yunifolomu yakuda akuyesa kuletsa wosewera mpira wachimuna atavala yunifolomu yoyera .\n",
            "H-22\t-0.2418050915002823\t▁ W o s e w e r a ▁ m p i r a ▁ w a c h i m u n a ▁ w a n y a m u l a ▁ m w a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a k u d a ▁ a k u y e s a ▁ k u g w i r a ▁ c h i n g w e ▁ c h a ▁ m p i r a ▁ w a c h i m u n a ▁ a t a v a l a ▁ c h o y e r a ▁ .\n",
            "D-22\t-0.2418050915002823\tWosewera mpira wachimuna wanyamula mwana wovala yunifolomu yakuda akuyesa kugwira chingwe cha mpira wachimuna atavala choyera .\n",
            "P-22\t-0.1113 -0.6392 -0.0591 -0.0875 -0.0653 -0.0743 -0.0640 -0.0835 -0.1254 -0.1346 -0.0593 -0.0141 -0.0928 -0.0651 -0.1153 -0.1702 -0.0334 -0.1066 -0.0963 -0.1881 -0.1014 -0.7654 -0.0385 -0.0976 -0.2162 -0.1778 -0.0367 -0.1344 -0.7138 -0.1645 -0.0929 -0.0841 -0.1057 -0.0627 -0.0880 -0.1370 -0.4039 -0.3058 -0.1058 -0.6524 -0.0662 -0.2028 -0.0647 -0.0859 -0.0343 -0.1084 -0.0754 -0.1090 -0.1157 -0.0887 -0.0552 -0.0404 -0.0507 -0.0105 -0.0698 -0.0418 -0.0488 -0.0270 -0.0753 -0.1292 -0.0094 -0.1327 -0.5107 -0.1355 -0.0969 -0.1184 -0.1454 -0.3537 -0.0494 -0.1107 -0.2737 -0.0700 -0.1617 -0.1339 -0.0894 -0.0396 -0.0897 -2.9038 -0.2953 -0.5482 -0.0488 -0.5217 -0.1107 -1.9351 -0.1608 -0.3899 -1.1487 -0.9784 -0.1117 -0.0960 -0.1337 -0.3612 -0.1117 -0.2345 -0.2781 -0.3411 -0.1006 -0.0846 -0.1484 -0.1225 -0.1716 -0.0842 -0.1447 -0.7452 -0.0943 -0.1041 -1.3687 -0.3210 -0.1031 -0.3100 -0.2364 -0.8350 -0.0154 -0.0924 -0.0552 -0.1089 -0.0682 -0.1092 -0.1271 -1.7518 -0.0833 -0.8530 -0.1254 -0.2855 -0.1604 -0.0900 -0.4273 -0.1590 -0.1066\n",
            " 31% 4/13 [00:13<00:26,  2.89s/it, wps=772]T-129\tGulu la anthu likuimirira ndi kumvetsera mmodzi wa gululo m'dera la miyala lozunguliridwa ndi nyumba ndi mitengo .\n",
            "H-129\t-0.3082006275653839\t▁ G u l u ▁ l a ▁ a n t h u ▁ l i k u i m i r a ▁ n d i k u m w e t s e r a ▁ m o d z i ▁ w a b u l u u ▁ a m i y a l a ▁ m ' n y e n g o ▁ y o z u n g u l i r i d w a ▁ n d i ▁ n y u m b a ▁ .\n",
            "D-129\t-0.3082006275653839\tGulu la anthu likuimira ndikumwetsera modzi wabuluu amiyala m'nyengo yozunguliridwa ndi nyumba .\n",
            "P-129\t-0.1145 -0.0269 -0.0668 -0.0565 -0.0696 -0.1084 -0.0514 -0.1124 -0.1005 -0.1005 -0.0601 -0.0651 -0.0769 -0.0796 -0.1091 -0.4463 -0.1234 -0.9719 -0.0974 -1.2179 -0.0781 -0.1566 -0.2177 -1.0371 -0.1246 -0.4466 -0.1789 -0.1196 -0.7330 -0.1043 -0.2458 -0.7571 -0.1075 -0.0352 -0.4081 -0.1088 -0.1072 -0.2657 -0.1485 -0.2966 -1.1687 -0.7652 -0.0250 -0.1047 -0.2251 -0.5014 -0.1270 -1.5204 -0.0836 -0.0611 -0.1216 -0.0763 -0.2138 -1.2404 -1.2818 -0.1470 -0.0553 -0.2719 -0.0486 -0.1267 -0.1921 -0.6871 -0.4835 -0.5325 -0.0562 -1.7153 -0.0664 -0.0990 -0.0643 -0.1204 -1.3398 -0.2354 -0.4345 -0.0535 -0.1123 -0.0191 -0.0675 -0.0717 -0.0846 -0.1439 -0.1657 -0.0429 -0.0812 -0.0912 -0.1249 -0.0578 -0.0989 -0.1402 -0.0938 -1.3651 -0.5542 -0.0685 -0.1196 -0.0986 -0.0951 -0.2766 -2.1473 -0.1046\n",
            "T-82\tOsewera mpira achikazi anayi akuyesera kumenya mpira pogwiritsa ntchito mitu yawo nthawi imodzi pamasewera ovuta.\n",
            "H-82\t-0.29703783988952637\t▁ O s e w e r a ▁ m p i r a ▁ a c h i k a z i ▁ a n a y i ▁ a k u y e s e r a ▁ k u m e n y a ▁ m p i r a ▁ w o g w i r i t s a ▁ n t c h i t o ▁ m i t u n d u ▁ y o m w e ▁ i l i ▁ p a n s i ▁ p a ▁ m a s e w e r a ▁ o l i m b a ▁ .\n",
            "D-82\t-0.29703783988952637\tOsewera mpira achikazi anayi akuyesera kumenya mpira wogwiritsa ntchito mitundu yomwe ili pansi pa masewera olimba .\n",
            "P-82\t-0.1284 -0.7902 -0.0992 -0.0448 -0.0832 -0.0669 -0.0980 -0.1112 -0.1360 -0.1226 -0.1900 -0.1039 -0.0751 -0.1101 -0.2095 -1.3104 -0.0798 -0.1788 -0.1051 -0.1887 -0.1420 -0.0251 -0.0860 -0.1543 -0.1447 -0.3596 -0.1261 -0.0410 -0.0618 -0.1639 -0.1152 -0.0853 -0.0806 -1.1416 -0.2557 -0.2374 -0.0465 -0.0312 -0.1045 -0.1338 -0.1100 -0.0893 -0.1198 -1.1270 -0.1744 -0.1052 -0.1094 -0.4034 -0.1357 -0.1874 -0.0816 -0.1055 -0.1469 -0.2001 -1.7168 -0.8491 -0.5840 -0.0331 -0.1343 -0.1152 -0.1065 -0.3617 -0.1204 -0.0915 -0.1231 -0.0242 -0.3198 -0.0256 -0.1164 -0.1379 -0.0133 -0.0550 -0.0998 -0.9904 -0.7615 -1.4164 -0.1808 -0.2202 -0.0928 -0.1043 -0.1348 -0.2967 -0.8755 -0.2136 -1.4961 -0.0990 -0.1203 -0.1801 -0.5027 -0.1032 -0.1702 -0.0956 -0.1508 -0.8925 -0.4142 -0.0751 -0.2991 -1.2810 -0.2142 -0.7618 -0.4398 -0.3746 -0.5196 -0.2018 -0.0753 -0.1571 -0.1209 -0.1309 -0.5689 -0.3605 -1.2573 -0.5656 -0.0280 -0.2427 -0.4939 -0.9284 -0.4469 -0.1038\n",
            "T-38\tAzimayi atatu achikulire ali m'chipinda chochezera, chokongoletsedwa pa Khirisimasi, kope la VAIO ndilofunika kwambiri.\n",
            "H-38\t-0.3304474949836731\t▁ A z i m a y i ▁ a t a t u ▁ a c h i k u l i r e ▁ a l i ▁ m ' c h i p a n d e z e r a ▁ c h o k o n g o l e t s e r a ▁ k u n g o l e t s e r e k a ▁ p a ▁ k o m a n s o ▁ k u m b u y o ▁ k w a w o ▁ k w a m b i r i ▁ .\n",
            "D-38\t-0.3304474949836731\tAzimayi atatu achikulire ali m'chipandezera chokongoletsera kungoletsereka pa komanso kumbuyo kwawo kwambiri .\n",
            "P-38\t-0.1266 -0.2670 -0.0425 -0.0966 -0.1361 -0.1048 -0.0242 -0.0948 -0.1116 -0.1447 -0.0722 -0.0980 -0.0684 -0.0560 -0.1790 -0.1378 -0.9623 -0.0636 -0.0868 -1.1323 -0.0812 -0.3072 -0.0748 -0.0845 -0.0481 -0.1843 -0.1091 -0.3671 -0.0926 -0.1212 -0.7430 -0.0308 -0.1013 -0.0916 -0.1049 -0.0379 -0.0997 -0.9094 -0.1278 -0.5276 -0.8490 -0.0940 -0.5885 -0.6999 -0.2157 -0.0785 -0.1331 -0.1260 -0.4834 -0.1976 -0.1372 -0.0464 -0.0577 -0.0698 -0.0409 -0.0601 -0.0702 -0.0600 -0.1011 -0.0945 -0.1811 -0.2921 -0.2860 -0.5006 -1.7316 -0.0633 -0.0631 -0.4836 -0.1049 -0.1084 -0.0648 -0.1546 -1.7270 -0.2733 -0.5650 -0.1418 -0.0467 -0.1953 -0.4595 -1.2245 -0.6822 -0.9533 -0.0910 -1.0112 -0.0501 -0.2352 -0.0852 -0.9134 -1.5087 -0.7565 -0.4497 -0.2148 -0.0359 -0.0670 -0.1491 -0.1838 -0.0660 -0.1235 -0.9036 -0.2101 -0.2127 -1.6572 -1.2798 -0.1371 -1.3894 -0.3484 -0.0950 -0.0712 -0.1183 -0.4250 -1.3497 -0.1162\n",
            "T-127\tMtsikana yemwe wavala kansalu kansalu kabuluu akuvala mahula pa siteji yokhala ndi zibaluni kumbuyo kwake .\n",
            "H-127\t-0.3346158564090729\t▁ M t s i k a n a ▁ y e m w e ▁ w a v a l a ▁ k a b u d u l a ▁ w o k h a l a ▁ n d i ▁ m a k a l a ▁ a k u l u a k u l u ▁ o k h a l a ▁ n j i n g a ▁ y o k h a l a ▁ n d i ▁ z i p a l e ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-127\t-0.3346158564090729\tMtsikana yemwe wavala kabudula wokhala ndi makala akuluakulu okhala njinga yokhala ndi zipale kumbuyo kwake .\n",
            "P-127\t-0.1255 -0.1665 -0.1218 -0.0681 -0.1219 -0.0861 -0.0952 -0.0921 -0.1051 -0.8416 -0.0816 -0.0267 -0.0513 -0.0653 -0.1148 -0.0998 -0.0312 -0.1240 -0.0684 -0.1233 -0.0744 -0.1249 -0.1001 -0.6169 -0.1377 -1.4737 -0.1165 -0.3608 -0.1035 -0.1542 -0.4072 -0.1425 -0.3776 -1.2547 -0.1201 -0.3496 -0.1055 -0.0587 -0.1071 -0.1047 -0.2919 -0.7142 -0.3034 -0.1159 -0.2499 -0.1427 -1.1275 -1.0723 -0.6218 -0.1122 -0.5673 -0.3845 -0.6444 -0.1080 -1.3786 -0.1007 -0.5732 -0.5038 -0.0748 -0.0258 -0.0802 -0.1494 -2.0063 -1.4744 -0.2253 -0.1160 -0.0748 -0.1139 -0.0936 -0.1610 -1.6314 -0.1885 -0.1340 -0.3279 -0.1199 -0.1183 -0.2177 -1.0153 -0.9342 -0.0362 -0.1155 -0.0911 -0.1120 -0.0944 -0.2174 -0.0984 -0.1081 -0.1000 -1.2011 -0.0664 -2.9683 -0.2122 -1.3622 -0.4784 -0.1210 -0.2656 -0.3475 -0.0787 -0.0199 -0.0730 -0.0575 -0.0748 -0.1703 -0.1252 -0.0705 -0.1207 -0.0583 -0.0729 -0.7895 -0.1306 -0.1092\n",
            "T-35\tBambo wina ataimirira yekha pansi pa mtengo pa kapinga , n'kupukuta m'maso poganizira za chitukuko cha nyumbayo.\n",
            "H-35\t-0.3625754117965698\t▁ B a m b o ▁ w i n a ▁ a t a v a l a ▁ y u n i f o l o m u ▁ y a ▁ n j e r w a ▁ a t a k h a l a ▁ p a f u p i ▁ n d i ▁ m a s o ▁ o k h a l a ▁ n d i ▁ c h i t h u n z i ▁ c h a ▁ n y u m b a y o ▁ .\n",
            "D-35\t-0.3625754117965698\tBambo wina atavala yunifolomu ya njerwa atakhala pafupi ndi maso okhala ndi chithunzi cha nyumbayo .\n",
            "P-35\t-0.1340 -0.1474 -0.1021 -0.0722 -0.1124 -0.0948 -0.1350 -0.0686 -0.0954 -0.1301 -0.0904 -0.1142 -0.0991 -0.0628 -0.1173 -2.7673 -0.1838 -0.0845 -0.1182 -0.1186 -1.2745 -0.1167 -0.0768 -0.0710 -0.3285 -0.4679 -0.1663 -0.2726 -0.1088 -0.1359 -0.1143 -0.3376 -0.8951 -0.9250 -0.7922 -0.2266 -0.2262 -0.8297 -0.3302 -0.0589 -0.1429 -1.4926 -1.0099 -0.1139 -0.1167 -0.0467 -0.1034 -0.0430 -0.0979 -0.0891 -0.2833 -0.1265 -2.4647 -0.0814 -0.1030 -0.1276 -0.0921 -0.1520 -0.3069 -0.1348 -0.0923 -1.4141 -0.1499 -0.9883 -0.1265 -0.1190 -0.7234 -0.6022 -0.1765 -0.0956 -0.1829 -0.0834 -0.0932 -0.4088 -0.4303 -0.1218 -0.1030 -2.5516 -0.1201 -0.1100 -0.3196 -0.6599 -0.0628 -0.1203 -0.0892 -0.1024 -0.1961 -0.1627 -0.1095 -0.2227 -0.3668 -2.9459 -0.6056 -0.2824 -0.1097 -0.0561 -0.1056 -1.1549 -0.0926 -0.2318 -0.4498 -0.1117\n",
            "T-230\tKamnyamata kakang'ono kamene kali pa sileyi yobiriwira amadutsa paphiri la chipale chofewa dzuwa likamalowa .\n",
            "H-230\t-0.2980586886405945\t▁ K a m n y a m a t a ▁ k a k a n g ' o n o ▁ k a m e n e ▁ k a l i ▁ p a ▁ s i l e r i ▁ y o b i r i w i r a ▁ a m a j a m b u l a ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ c h i k w a n g w a n i ▁ c h a ▁ m a l o w a .\n",
            "D-230\t-0.2980586886405945\tKamnyamata kakang'ono kamene kali pa sileri yobiriwira amajambula chipale chofewa ndi chikwangwani cha malowa.\n",
            "P-230\t-0.1269 -0.0502 -0.1159 -0.0995 -0.1582 -0.2248 -0.0979 -0.0484 -0.0945 -0.0880 -0.0953 -0.1106 -0.0638 -0.1049 -0.3257 -0.3482 -0.0925 -0.0326 -0.1101 -0.0589 -0.0651 -0.0834 -0.1030 -0.1507 -0.1213 -0.8388 -0.0303 -0.0640 -0.0786 -0.1159 -0.0971 -0.1236 -0.0497 -0.0882 -0.1131 -0.0844 -0.1338 -0.3246 -1.4770 -0.4257 -0.2396 -1.0688 -2.0429 -0.1730 -0.5116 -0.1913 -0.0862 -0.0998 -0.1143 -0.0725 -0.0949 -0.0346 -0.1101 -0.0948 -0.1566 -0.2437 -0.1591 -0.1432 -0.1248 -2.5551 -0.1125 -0.1925 -0.1866 -0.1724 -0.0657 -0.1944 -0.1776 -0.2725 -0.0651 -0.1381 -0.4226 -0.1347 -0.1339 -0.0625 -0.1018 -0.0133 -0.0767 -0.0581 -0.0383 -0.0725 -0.0568 -0.1031 -0.2101 -2.3642 -0.0809 -0.1154 -0.1930 -1.9641 -0.0737 -0.2564 -0.9344 -1.0561 -0.1004 -0.7219 -0.1192 -0.0492 -0.0942 -0.1306 -0.0868 -0.2062 -1.0743 -0.1366 -0.7184 -0.4109 -0.1282 -0.2596 -1.9215 -0.2076 -0.1325 -0.4555 -0.8908 -0.1065\n",
            "T-395\tMunthu wovala malaya achikasu, akugwira ntchito pa chinthu chokhala ndi mawaya ofiira ndi akuda omwe amatuluka pachivundikiro choyera.\n",
            "H-395\t-0.2789273262023926\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ a k u n g u l a ▁ c h i d o l e ▁ c h o k h a l a ▁ n d i ▁ m a w o n e r a ▁ o f i i r a ▁ n d i ▁ a n t h u ▁ o m w e ▁ a m a w u l u k a ▁ m ' k a t i ▁ m w a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-395\t-0.2789273262023926\tMunthu wovala malaya achikasu akungula chidole chokhala ndi mawonera ofiira ndi anthu omwe amawuluka m'kati mwa chipale chofewa .\n",
            "P-395\t-0.1257 -0.0712 -0.0614 -0.0835 -0.0961 -0.0969 -0.0751 -0.1269 -0.0614 -0.0832 -0.0516 -0.1403 -0.0659 -0.1190 -0.1019 -0.0715 -0.1349 -0.0793 -0.1169 -0.0728 -0.0996 -0.0963 -0.1542 -0.0343 -0.0858 -0.0860 -0.0952 -0.0937 -0.2274 -0.0501 -0.1245 -0.3471 -0.0854 -0.0970 -2.0224 -0.1700 -0.8659 -0.1512 -0.1275 -0.1035 -0.0717 -0.1033 -0.1471 -0.1741 -0.1150 -1.4410 -0.0512 -0.1350 -0.2038 -0.1154 -0.1101 -0.0399 -0.0323 -0.1093 -0.0602 -0.1094 -0.1168 -0.0426 -0.1023 -0.1021 -0.0802 -0.0845 -0.0868 -0.5869 -0.4536 -0.9759 -0.8735 -0.3575 -0.1624 -0.1340 -0.4718 -0.1597 -0.1426 -0.2948 -0.0668 -0.1228 -0.2709 -0.2115 -0.0986 -0.1221 -0.0802 -0.1701 -0.8434 -0.1062 -0.0710 -0.0763 -0.1150 -1.8126 -0.0906 -0.0635 -0.1481 -0.1112 -0.1046 -0.5717 -0.1029 -1.4809 -1.0748 -0.3689 -0.0564 -0.0191 -0.0927 -0.1261 -0.9929 -0.9422 -2.1045 -0.3430 -0.3090 -0.0965 -0.1070 -0.5018 -0.0377 -0.1852 -0.2850 -1.4210 -0.0815 -0.2427 -2.3842 -0.3752 -0.2578 -0.0729 -0.1150 -0.0400 -0.0854 -0.0389 -0.8450 -0.0978 -0.0453 -0.1201 -0.4344 -0.0904 -0.1080\n",
            "T-250\tAmuna aku Asia amakhala osalowerera ndale ngati akuyembekezera chinachake, bambo wina akulankhula pa foni yake.\n",
            "H-250\t-0.37107977271080017\t▁ A m u n a ▁ a k u ▁ A s i a ▁ a m a k h a l a ▁ o s a m b i r a ▁ l o s a n g a l a t i r a ▁ m ' n y e n g o ▁ a k u i m b i r a ▁ c h i n a c h a k e ▁ c h a ▁ m w a m u n a ▁ w i n a ▁ w a k u d a ▁ a k u y a n g ' a n a ▁ .\n",
            "D-250\t-0.37107977271080017\tAmuna aku Asia amakhala osambira losangalatira m'nyengo akuimbira chinachake cha mwamuna wina wakuda akuyang'ana .\n",
            "P-250\t-0.1246 -0.0948 -0.0829 -0.0795 -0.0953 -0.0874 -0.1259 -0.1361 -1.2425 -0.1203 -1.1884 -0.9745 -0.1445 -0.1036 -0.1176 -0.2267 -0.4176 -0.1531 -0.1331 -0.0384 -0.0704 -0.1021 -0.0677 -0.1058 -0.1170 -0.5128 -0.1178 -0.0662 -2.0931 -0.0571 -0.1121 -0.0699 -0.0952 -0.2190 -1.7685 -0.2856 -1.3266 -0.0796 -1.6338 -0.1789 -0.0829 -0.1227 -0.0972 -0.4259 -0.2450 -0.3556 -0.1123 -0.4219 -0.3781 -0.1101 -0.8115 -0.6038 -0.3316 -0.0786 -0.4528 -0.5199 -0.1308 -1.4208 -0.1709 -0.1075 -0.4676 -0.0576 -0.0517 -0.1867 -1.0550 -0.1224 -0.1542 -0.2904 -0.0854 -0.1348 -0.1072 -0.2026 -0.1806 -0.0734 -0.1149 -0.0142 -0.0674 -0.2577 -1.6979 -0.1028 -0.3067 -0.6676 -0.9676 -1.8166 -0.1431 -0.4717 -0.7449 -0.1210 -0.0908 -0.1070 -0.2620 -0.2321 -0.0643 -0.0970 -0.1244 -0.5011 -0.2093 -0.4003 -0.5559 -0.8083 -0.1085 -0.2671 -2.3946 -0.3421 -0.0765 -1.5833 -0.1188 -0.3868 -0.2562 -0.1196 -0.0849 -0.0546 -0.1092 -0.2083 -0.9775 -0.0950\n",
            "T-251\tGalu watsitsi lalitali akuthamanga pa udzu kulowera ku kamera , lilime lake likulendewera pakamwa potsegula .\n",
            "H-251\t-0.35764920711517334\t▁ G a l u ▁ w a ▁ t s i t s i ▁ l a l i t a l i ▁ a k u t h a m a n g a ▁ p a ▁ u l u ▁ l e n e r a ▁ l a ▁ m e n e ▁ l a k e ▁ l i m e n e ▁ l a k u g w e d e z e k a ▁ p a m w a m b a ▁ p a ▁ k a m w a ▁ .\n",
            "D-251\t-0.35764920711517334\tGalu wa tsitsi lalitali akuthamanga pa ulu lenera la mene lake limene lakugwedezeka pamwamba pa kamwa .\n",
            "P-251\t-0.1103 -0.0603 -0.1082 -0.0576 -0.0808 -0.1132 -0.0358 -0.1697 -0.7684 -1.0026 -0.0755 -0.1147 -0.0551 -0.0490 -0.1048 -0.0897 -0.0997 -0.1379 -0.0487 -0.1015 -0.0269 -0.1019 -0.0446 -0.0843 -0.2069 -0.1818 -0.0790 -0.1178 -1.4551 -0.1054 -0.0882 -0.0712 -0.1032 -0.1086 -0.0682 -0.0887 -0.1162 -0.4573 -0.2268 -0.9373 -1.2495 -0.3216 -0.7361 -0.2470 -1.5612 -0.3836 -2.2469 -0.6549 -0.2584 -0.1001 -0.1846 -0.2074 -0.1960 -0.1558 -0.2471 -1.0235 -0.2461 -0.2849 -0.1482 -0.4121 -0.5655 -1.0706 -0.3801 -0.1644 -0.3196 -0.2763 -0.6266 -0.0518 -0.0767 -0.1033 -0.0914 -1.0837 -0.7690 -0.2919 -0.2298 -1.3224 -0.0411 -0.1591 -0.2790 -0.0517 -1.2825 -0.0552 -1.0870 -0.0651 -0.1187 -0.3264 -0.1231 -1.6769 -0.4557 -0.0887 -0.4102 -0.0446 -0.1254 -0.1955 -0.6970 -0.1494 -0.1040 -1.0162 -1.1766 -0.2386 -0.5137 -0.0872 -0.1773 -0.3575 -0.1093\n",
            "T-137\tMunthu m'ngalawa yobiriwira amapalasa m'mabwinja atanyamula nkhafi ndipo atavala pamwamba pa lalanje ndi wakuda.\n",
            "H-137\t-0.3219278156757355\t▁ M u n t h u ▁ m ' n k h a l a n g o ▁ y o b i r i w i r a ▁ a m a s a m b i r a ▁ a t a v a l a ▁ m a g w i r a ▁ n j i n g a ▁ a t a n y a m u l a ▁ c h i k w a m a ▁ n d i p o ▁ m w a m u n a ▁ w a v a l a ▁ j e k e t e ▁ l a b u l u u ▁ .\n",
            "D-137\t-0.3219278156757355\tMunthu m'nkhalango yobiriwira amasambira atavala magwira njinga atanyamula chikwama ndipo mwamuna wavala jekete labuluu .\n",
            "P-137\t-0.1185 -0.1168 -0.0466 -0.1052 -0.0947 -0.0784 -0.0900 -0.1271 -0.9756 -0.3440 -2.1159 -0.7221 -0.2485 -0.1092 -0.0692 -0.1236 -0.3305 -0.0700 -0.1730 -0.1853 -0.2770 -0.1075 -1.5227 -0.0902 -0.0460 -0.0771 -0.0323 -0.1218 -0.0748 -0.0969 -0.2047 -0.3329 -0.3075 -0.1333 -0.7526 -0.5944 -0.1401 -0.0407 -0.1273 -0.0768 -0.1176 -0.1262 -2.6679 -0.6066 -0.1780 -0.3280 -0.1041 -0.0736 -0.1173 -0.1018 -0.1440 -0.3989 -0.3598 -1.0820 -0.1178 -0.4618 -0.2087 -0.1389 -1.0452 -1.2811 -0.1482 -0.0329 -0.0417 -0.0840 -0.1583 -0.5379 -0.1222 -0.1136 -0.0734 -0.0115 -0.1193 -0.0625 -0.1807 -0.0453 -0.1191 -0.1067 -1.1932 -0.1537 -0.0973 -1.2847 -0.0714 -0.1278 -0.4017 -0.1117 -0.1190 -1.5613 -0.1827 -0.1157 -1.2055 -0.1001 -0.0894 -0.2840 -0.3380 -0.1003 -0.2900 -1.0214 -0.2538 -0.0865 -0.1183 -0.2945 -0.2330 -0.4761 -0.1084 -0.0693 -0.1283 -0.0928 -0.1092 -0.1082 -0.6133 -0.2047 -0.0221 -0.1515 -0.1135 -0.0329 -0.1958 -2.2791 -0.0775 -0.0711 -0.1989 -0.0440 -0.2443 -1.2944 -0.1093\n",
            "T-161\tKatswiri wankhondo yemwe ali kutsogolo akuponya ntchafu ya mdani wakeyo , pamene khamu la anthu ndi oweruza akuonera chapatali .\n",
            "H-161\t-0.36209940910339355\t▁ G a l i m o t o ▁ y o k o n d w a ▁ y e m w e ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ b u l u u ▁ a k u j a m b u l i r a ▁ m ' n k h a l a n g o ▁ y o k h a l a ▁ p a m e n e ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u y e n d a ▁ p a t a l i ▁ .\n",
            "D-161\t-0.36209940910339355\tGalimoto yokondwa yemwe ali kutsogolo kwa buluu akujambulira m'nkhalango yokhala pamene mwamuna wovala malaya abuluu akuyenda patali .\n",
            "P-161\t-0.1092 -3.0804 -0.1097 -0.1403 -0.5718 -0.2593 -0.1150 -0.2409 -0.0569 -0.1222 -0.1086 -0.5406 -0.8440 -0.1795 -0.0359 -0.0644 -0.2276 -1.3012 -0.1628 -0.5187 -0.0752 -0.0403 -0.0619 -0.0953 -0.1163 -0.1779 -0.0725 -0.0901 -0.0902 -0.1804 -0.1004 -0.0726 -0.1292 -0.0539 -0.0299 -0.0564 -0.0813 -0.0380 -0.0915 -0.7876 -0.3395 -0.1198 -0.1663 -1.9572 -1.1866 -0.1227 -0.1346 -0.0506 -0.1282 -1.6521 -0.2927 -0.0973 -1.8817 -0.1023 -0.1001 -0.1834 -0.0801 -0.0733 -1.1212 -0.5184 -0.0937 -0.1660 -0.3168 -1.1261 -1.9665 -1.1981 -0.0559 -0.4568 -0.1143 -0.2772 -0.0360 -0.2648 -0.0696 -0.1696 -1.0847 -0.2010 -1.3881 -0.1504 -0.1051 -0.1563 -0.1043 -0.1289 -0.2183 -0.1243 -0.0670 -0.1028 -0.0411 -0.0623 -0.0911 -0.3836 -0.9980 -0.0866 -0.0629 -0.0569 -0.0800 -0.0772 -0.1097 -1.7135 -1.2113 -0.2345 -0.1026 -0.1055 -0.1031 -0.1045 -0.6671 -0.1095 -0.5850 -0.0911 -0.0535 -0.0911 -0.0935 -1.0081 -0.2191 -0.0628 -0.0621 -0.0622 -0.0354 -0.1260 -0.6558 -0.2986 -0.0844 -0.8808 -0.2362 -0.3932 -0.0791 -0.1021 -0.1896 -0.9219 -0.1497 -2.5226 -0.5597 -0.0406 -0.0747 -0.4151 -0.9789 -0.0915\n",
            "T-390\tAnyamata awiri , m'modzi wovala malaya abuluu ndi m'modzi wa malaya akuda akuvina pamaso pa gulu loimba komanso achikulire angapo.\n",
            "H-390\t-0.22820207476615906\t▁ A n y a m a t a ▁ a w i r i ▁ m ' m o d z i ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m o d z i ▁ w a m a l a y a ▁ a k u d a ▁ a k u v i n a ▁ p a m a s o ▁ p a ▁ b u l u u ▁ w o v a l a ▁ m a l a y a ▁ a c h i k u l i r e ▁ a k u m a n g a ▁ .\n",
            "D-390\t-0.22820207476615906\tAnyamata awiri m'modzi wovala malaya abuluu ndi modzi wamalaya akuda akuvina pamaso pa buluu wovala malaya achikulire akumanga .\n",
            "P-390\t-0.1289 -0.0659 -0.0636 -0.0650 -0.0947 -0.0982 -0.1062 -0.0585 -0.1052 -0.1253 -0.1217 -0.1320 -0.1053 -0.0755 -0.0965 -0.5280 -1.1764 -0.4721 -0.1256 -0.0382 -0.0928 -0.0347 -0.0957 -0.1576 -0.1031 -0.0874 -0.0905 -0.1149 -0.0906 -0.1312 -0.1270 -0.0942 -0.1228 -0.0868 -0.1283 -0.0915 -0.1043 -0.1384 -0.1444 -0.0801 -0.0902 -0.0618 -0.1044 -0.0524 -0.2215 -0.1130 -0.0887 -0.1251 -0.1018 -0.2240 -1.1058 -0.2626 -0.0819 -0.0954 -0.1926 -0.0540 -0.2395 -0.8544 -0.3642 -0.1563 -0.1294 -0.0470 -0.1023 -0.1537 -0.0948 -0.2140 -0.1111 -0.1635 -0.1430 -0.3321 -0.1547 -0.1227 -0.1055 -0.6522 -0.1133 -0.0482 -0.1072 -0.1189 -0.1139 -0.1219 -0.1661 -0.2010 -0.1597 -0.0698 -0.1066 -0.2921 -0.1220 -0.2182 -0.8167 -0.2208 -0.0665 -0.1111 -0.0916 -0.2552 -0.9093 -0.4354 -0.6836 -0.1102 -0.0917 -0.1101 -0.1076 -0.3056 -0.1279 -0.4546 -0.0965 -0.0490 -0.0863 -0.1134 -1.2195 -0.3075 -0.1389 -0.1059 -0.0385 -1.8605 -0.2653 -0.1888 -0.1236 -0.0817 -0.2452 -0.2341 -0.8125 -0.1429 -0.2526 -0.4495 -0.1070 -0.6202 -0.0913 -0.2354 -1.8189 -0.1098\n",
            "T-319\tMwamuna wovala jekete lamasewera wokhala ndi tsitsi lalitali lofiirira ndi magalasi akutenga chidwi ndi ojambula angapo .\n",
            "H-319\t-0.2651495933532715\t▁ M w a m u n a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ m a s e w e r a ▁ o k h a l a ▁ n d i ▁ t s i t s i ▁ l a l i t a l i ▁ l o f i i r i r a ▁ n d i ▁ m a g a l a s i ▁ a k u t i ▁ n d i ▁ b w a t o ▁ l a c h i k a s u ▁ .\n",
            "D-319\t-0.2651495933532715\tMwamuna wovala jekete la masewera okhala ndi tsitsi lalitali lofiirira ndi magalasi akuti ndi bwato lachikasu .\n",
            "P-319\t-0.1265 -0.1544 -0.0536 -0.0884 -0.1439 -0.1337 -0.0840 -0.0940 -0.1452 -0.0941 -0.0944 -0.0347 -0.1234 -0.0752 -0.1058 -0.1091 -0.0414 -0.1210 -0.0690 -0.0736 -0.0294 -0.1683 -0.1018 -0.1629 -0.1192 -0.3622 -0.1967 -0.1021 -0.0843 -0.0974 -0.0676 -0.0943 -0.1250 -0.1077 -0.1464 -0.2058 -0.2310 -0.2624 -0.1035 -0.0575 -0.0977 -0.1023 -0.0478 -0.1034 -0.1056 -0.0888 -1.0272 -0.1660 -0.1047 -0.0793 -0.0468 -0.1035 -0.0937 -0.0413 -1.0833 -0.0642 -0.1011 -0.0637 -0.0737 -0.0314 -0.1195 -0.2752 -0.9514 -0.0528 -0.2649 -0.1038 -0.1943 -0.0728 -0.3701 -0.0789 -0.1131 -0.2448 -0.4896 -0.1575 -0.1017 -0.1152 -0.1932 -0.1127 -0.3829 -0.2061 -0.2327 -0.1107 -0.0266 -0.0843 -0.2005 -0.1758 -0.4612 -0.1256 -1.6312 -1.1015 -0.6538 -0.9992 -0.0879 -0.1025 -0.4516 -1.6388 -0.9036 -0.1070 -0.3307 -0.4872 -0.1213 -0.0645 -0.1572 -1.1863 -0.1168 -0.0827 -1.3635 -0.2036 -0.4253 -0.1011 -0.1889 -2.9178 -0.1029\n",
            "T-282\tAchinyamata asanu ndi mmodzi akujambula chithunzi m'sitima yapansi panthaka .\n",
            "H-282\t-0.2731296122074127\t▁ A n y a m a t a ▁ a t a t u ▁ a s a n u ▁ n d i ▁ m m o d z i ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ y a k e ▁ p a n s i ▁ .\n",
            "D-282\t-0.2731296122074127\tAnyamata atatu asanu ndi mmodzi akujambula chithunzi yake pansi .\n",
            "P-282\t-0.1215 -0.1424 -0.0893 -0.0360 -0.0746 -0.0975 -0.0899 -0.0606 -0.0952 -0.1015 -0.1271 -0.4142 -0.1160 -0.4857 -0.8393 -0.1098 -0.3702 -0.6642 -0.0830 -0.1216 -0.1042 -0.1399 -0.2600 -0.0550 -0.0898 -0.0794 -0.2236 -1.2847 -0.1191 -0.1880 -0.1820 -0.0968 -0.1126 -0.1625 -0.0646 -0.0755 -0.2181 -0.0769 -0.1046 -0.0713 -0.0433 -0.0518 -0.0941 -0.1287 -0.2659 -0.0907 -0.0996 -0.1780 -0.0996 -0.0540 -0.0596 -0.0236 -0.0845 -0.1581 -2.2133 -0.1603 -2.0736 -0.0678 -0.1295 -1.4452 -0.1465 -0.1093 -0.0851 -0.0732 -0.2244 -2.0648 -0.1271\n",
            "T-348\tMunthu akusuzumira pazipangizo zake zowonera zinthu akuyang'ana chinachake m'chizimezime .\n",
            "H-348\t-0.35636115074157715\t▁ M u n t h u ▁ a k u t u l u z u n g u l i r a ▁ p a ▁ z i z i r o ▁ z a ▁ t e n i s i ▁ n d i ▁ z o y e r a ▁ a k u y a n g ' a n a ▁ c h i n a c h a k e ▁ c h a ▁ c h i m e n e ▁ .\n",
            "D-348\t-0.35636115074157715\tMunthu akutuluzungulira pa ziziro za tenisi ndi zoyera akuyang'ana chinachake cha chimene .\n",
            "P-348\t-0.1340 -0.1051 -0.0487 -0.0906 -0.0994 -0.0757 -0.0781 -0.1397 -0.1614 -0.1202 -0.1083 -1.3299 -0.6962 -0.3894 -0.1639 -0.1953 -1.4401 -0.3903 -0.2195 -0.0958 -0.0914 -0.1501 -0.0310 -0.0885 -0.1296 -0.0848 -0.1529 -1.3266 -0.3049 -0.1565 -1.2566 -0.3811 -1.0345 -0.7713 -0.2260 -0.0608 -0.1818 -0.2038 -2.2011 -0.0865 -0.1739 -0.5057 -1.1866 -0.1390 -0.1779 -0.9463 -0.4552 -0.1049 -0.2210 -1.4218 -0.1586 -1.4199 -0.5274 -0.0920 -0.1025 -0.2403 -0.7646 -0.1984 -0.0967 -0.1322 -0.1132 -0.0954 -0.0993 -0.1286 -0.0952 -0.0928 -0.1196 -0.1094 -0.0317 -0.0976 -0.0963 -0.2754 -0.2226 -0.1443 -0.0745 -0.1123 -0.0375 -0.0955 -0.1552 -0.3130 -0.1016 -0.5478 -0.3045 -2.6888 -0.1453 -0.0874 -0.7487 -0.1261 -0.0664 -0.1509 -0.1809 -1.3010 -0.1165\n",
            "T-391\tBambo wina wovala thukuta la buluu komanso mwana wovala sweti yofinya akuyenda molunjika mumzinda womwe munadzaza anthu .\n",
            "H-391\t-0.2297312468290329\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ t h u k u t a ▁ l a b u l u u ▁ k o m a n s o ▁ m w a n a ▁ w o v a l a ▁ s w e t i ▁ y o f i y i r a ▁ a k u y e n d a ▁ m u m z i n d a ▁ w o m w e ▁ u n a l i ▁ m o y a n g ' a n a ▁ .\n",
            "D-391\t-0.2297312468290329\tBambo wina wovala thukuta labuluu komanso mwana wovala sweti yofiyira akuyenda mumzinda womwe unali moyang'ana .\n",
            "P-391\t-0.1370 -0.0321 -0.1069 -0.0805 -0.0898 -0.0819 -0.1168 -0.0559 -0.1075 -0.0777 -0.1072 -0.1305 -0.1073 -0.0966 -0.0547 -0.1104 -0.0841 -0.1209 -0.1064 -0.0598 -0.1078 -0.0540 -0.0311 -0.0461 -0.0146 -0.0997 -0.1340 -0.1167 -0.0978 -1.1679 -0.1291 -0.0497 -0.1067 -0.0559 -0.1574 -1.1860 -0.1428 -0.0505 -0.1125 -0.0813 -0.0290 -0.0735 -0.0811 -0.5477 -0.0912 -0.1394 -0.2807 -0.0938 -0.1309 -0.0564 -0.0966 -0.0685 -0.1063 -0.0978 -0.1149 -0.1193 -0.0869 -0.2162 -0.0962 -0.1228 -0.0678 -0.1152 -0.0527 -0.5352 -0.0822 -0.0944 -1.7292 -0.0745 -0.1310 -0.1389 -0.1929 -0.0850 -0.0633 -0.1277 -0.8782 -0.0920 -0.1034 -0.0618 -0.1070 -0.1038 -0.0699 -0.2614 -0.7258 -0.8486 -0.0978 -0.0482 -0.0449 -0.1195 -0.2042 -0.2941 -0.1984 -1.8883 -0.0681 -0.1325 -0.1325 -0.5392 -0.6487 -0.0957 -0.5515 -0.1925 -0.0986 -0.2391 -0.7555 -1.4901 -0.8341 -0.1016 -0.9707 -0.0889 -0.0917 -0.0783 -0.3470 -0.1865 -0.3460 -0.1083\n",
            "T-289\tBanja lina likuyang'ana anyamata awiri aang'ono akuwasonyeza chinthu kunja kwa barani pamene atsikana aang'ono awiri aima cham'mbali .\n",
            "H-289\t-0.3738009035587311\t▁ G a l u ▁ w i n a ▁ a k u y a n g ' a n a ▁ m n y a m a t a ▁ w i n a ▁ a k u m w a ▁ m o n o ▁ a k u w a s o n y e z a ▁ c h i n t h u ▁ c h a k u d a ▁ p a m e n e ▁ m i y a l a ▁ y a ▁ m i t u n d u ▁ y o m w e ▁ i l i ▁ p a m w a m b a ▁ p a ▁ c h a m b i r i ▁ .\n",
            "D-289\t-0.3738009035587311\tGalu wina akuyang'ana mnyamata wina akumwa mono akuwasonyeza chinthu chakuda pamene miyala ya mitundu yomwe ili pamwamba pa chambiri .\n",
            "P-289\t-0.1150 -1.9437 -0.1073 -0.0673 -1.5844 -0.1160 -0.5326 -0.5531 -0.0694 -0.1076 -0.1165 -1.4772 -0.1476 -0.0779 -0.0558 -0.1119 -0.0637 -0.1472 -0.0850 -0.1037 -0.0709 -0.1103 -0.1376 -0.6518 -0.7132 -0.0665 -0.1158 -0.0372 -0.0905 -0.0434 -0.1092 -0.1580 -0.2766 -0.1999 -0.6665 -0.1157 -0.1316 -0.5151 -0.2566 -0.0782 -0.9836 -1.0502 -0.9382 -0.2050 -0.2019 -0.5915 -1.2717 -0.8020 -0.1436 -0.2885 -0.1741 -0.2030 -0.2242 -0.3543 -1.3529 -0.1976 -0.1898 -0.1160 -0.0558 -0.0201 -0.1078 -0.1259 -0.0577 -0.1146 -0.1179 -0.0601 -0.0176 -0.0836 -0.0808 -0.1217 -0.6977 -0.1275 -0.4888 -0.4915 -0.4630 -0.4197 -0.7512 -0.1642 -0.3108 -0.1560 -0.1146 -0.8804 -0.0703 -0.0992 -0.0929 -0.4981 -0.1245 -0.9619 -0.1083 -0.0827 -0.0956 -0.1416 -0.4882 -0.3101 -1.5990 -0.2653 -0.1932 -2.5862 -0.6186 -0.1955 -0.0388 -0.0971 -0.1498 -0.1702 -1.0180 -1.9117 -0.0799 -0.0612 -0.1062 -0.2007 -0.8219 -0.0878 -0.0969 -1.1768 -0.1201 -0.9946 -0.9625 -0.0933 -0.1886 -0.0508 -0.0892 -0.2666 -0.5394 -0.1373 -0.1297 -1.3679 -0.0493 -0.6348 -1.4846 -0.2578 -0.1834 -0.0566 -0.1182 -0.9414 -0.0750 -0.1031\n",
            "T-100\tAzimayi awiri, wina atavala mpango ndipo wina atavala chipewa chachikulu, akugunda chakudya chomwe chili patebulo lachikale lokhala ndi malaya amatabwa.\n",
            "H-100\t-0.2600301206111908\t▁ A z i m a y i ▁ a w i r i ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i p o ▁ w i n a ▁ a t a v a l a ▁ c h i p e w a ▁ c h a k u d a ▁ a k u g u n d a ▁ c h a k u d a ▁ p a ▁ c h o m w e ▁ c h i l i ▁ p a k a t i ▁ p a ▁ m a l o ▁ o k h a l a ▁ n d i ▁ m a t a b w a .\n",
            "D-100\t-0.2600301206111908\tAzimayi awiri atavala malaya abuluu ndipo wina atavala chipewa chakuda akugunda chakuda pa chomwe chili pakati pa malo okhala ndi matabwa.\n",
            "P-100\t-0.1268 -0.0307 -0.2667 -0.0907 -0.0921 -0.1231 -0.0241 -0.0794 -0.0980 -0.1558 -0.0281 -0.1233 -0.0805 -0.0975 -0.3494 -0.4057 -0.1935 -0.1118 -1.2802 -0.1398 -0.0786 -0.1111 -0.0917 -0.1374 -0.9095 -0.0866 -0.1078 -0.1296 -0.0935 -0.1000 -0.1972 -2.1322 -0.1085 -0.0840 -0.1761 -0.0344 -0.1652 -0.0994 -0.0689 -0.0966 -0.0831 -0.0833 -0.0865 -0.0807 -0.0867 -0.0814 -0.0954 -0.1296 -0.1592 -0.0749 -0.1024 -0.0281 -0.1064 -0.0826 -0.1011 -0.0939 -0.3534 -0.0840 -0.1169 -0.7415 -0.1446 -0.0623 -0.0794 -0.1718 -0.2309 -0.0959 -0.0923 -0.4233 -0.1215 -0.5589 -0.1220 -0.2031 -0.0957 -0.0622 -0.1196 -0.8513 -0.9669 -0.5154 -0.0674 -0.1190 -0.1304 -0.1001 -0.0794 -1.4059 -0.5225 -0.0866 -0.2633 -0.1692 -0.1532 -0.9913 -0.1373 -1.6187 -0.0472 -0.0636 -0.6840 -0.3232 -0.2354 -0.0773 -0.0787 -0.1807 -0.0861 -0.0991 -0.1590 -0.1131 -0.0908 -0.0319 -0.1480 -1.0855 -0.6720 -0.0678 -0.0737 -0.1466 -0.3615 -0.6399 -0.0862 -1.5729 -0.0805 -1.5199 -0.4316 -0.0910 -0.3240 -0.1289 -0.1366 -0.1182 -0.0447 -0.1070 -0.1367 -0.0446 -0.1398 -0.0996 -0.0940 -0.0688 -0.1188 -0.0810 -0.1893 -1.2963 -0.0369 -0.1120 -1.3253 -0.1161\n",
            "T-197\tmunthu wovala chovala chabulauni ndi chipewa chachikulu chooneka ngati koloko atakhala pamasitepe okhala ndi mbale za zinthu zofiira .\n",
            "H-197\t-0.2479758858680725\t▁ M u n t h u ▁ w o v a l a ▁ c h o v a l a ▁ c h a b u l a u n i ▁ n d i ▁ c h i p e w a ▁ c h a c h i k u l u ▁ c h o o n e k a ▁ n g a t i ▁ w o l o k o n g o l o ▁ a t a k h a l a ▁ p a ▁ m s e w u ▁ w o k h a l a ▁ n d i ▁ z o f i i r a ▁ .\n",
            "D-197\t-0.2479758858680725\tMunthu wovala chovala chabulauni ndi chipewa chachikulu chooneka ngati wolokongolo atakhala pa msewu wokhala ndi zofiira .\n",
            "P-197\t-0.1355 -0.1608 -0.1079 -0.0890 -0.0824 -0.1531 -0.0869 -0.1503 -0.0722 -0.0566 -0.0477 -0.1332 -0.0799 -0.1142 -0.1065 -0.0305 -0.0756 -0.6799 -0.0283 -0.1174 -0.0802 -0.1099 -0.0950 -0.0167 -0.0882 -0.1638 -1.1695 -0.1017 -0.0868 -0.2525 -0.0560 -0.0817 -0.0779 -0.1295 -0.2403 -0.1069 -0.1377 -0.1443 -0.5721 -0.0824 -0.1004 -0.0550 -0.0684 -0.0553 -0.1141 -0.1197 -0.0201 -0.0961 -0.1479 -0.2949 -0.1131 -0.0730 -0.0618 -0.0750 -0.0539 -0.1657 -0.1222 -0.2597 -0.1127 -0.0673 -0.9855 -0.4883 -1.1208 -0.0327 -0.1077 -0.1162 -0.2088 -0.0513 -0.1196 -0.0257 -0.1521 -0.1091 -2.5746 -0.1941 -0.5341 -0.3296 -0.4508 -0.5899 -1.4876 -0.3368 -0.0557 -0.0735 -0.8340 -0.1821 -0.5699 -0.3659 -0.1263 -0.0692 -0.2258 -0.1246 -0.0546 -0.1121 -0.0932 -0.0187 -0.1400 -2.0744 -0.4357 -0.5500 -0.4068 -0.1160 -0.0633 -0.1379 -0.3646 -0.1247 -0.0591 -0.1241 -0.1010 -0.0568 -0.1130 -0.0896 -0.0729 -0.1202 -0.0987 -0.0725 -0.3497 -0.1908 -0.7458 -0.0895 -0.2116 -0.0669 -0.5300 -0.6710 -1.0625 -0.1111\n",
            "T-43\tBambo yemwe wavala juzi , jinzi , ndi bereti yobiriwira amagonera pogwiritsira ntchito makina opangira makina .\n",
            "H-43\t-0.34581226110458374\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ j u z i ▁ n d i ▁ j e a n s ▁ y a y i k u l u ▁ y o b i r i w i r a ▁ a m a k w e r a ▁ k w a ▁ n y u m b a ▁ y o f i i r a ▁ n d i ▁ n j i n g a ▁ y o m a n g a ▁ .\n",
            "D-43\t-0.34581226110458374\tBambo wina wovala juzi ndi jeans yayikulu yobiriwira amakwera kwa nyumba yofiira ndi njinga yomanga .\n",
            "P-43\t-0.1158 -0.1222 -0.0889 -0.0543 -0.0661 -0.0917 -0.2498 -0.3106 -0.1266 -0.0899 -0.1157 -0.1243 -0.2751 -0.3079 -0.1191 -0.1074 -0.0959 -0.0953 -0.1007 -0.2609 -0.6990 -0.1060 -0.0880 -0.1005 -0.5462 -0.1031 -0.1107 -0.1043 -0.3918 -0.8735 -0.3102 -0.0905 -0.0377 -0.1278 -0.0980 -0.2541 -0.8660 -0.3972 -1.5614 -0.1068 -0.0927 -0.1171 -0.1449 -0.2874 -0.1184 -0.6986 -0.0879 -0.0468 -0.0822 -0.0405 -0.1162 -0.1102 -0.0904 -0.1402 -0.4776 -0.1150 -0.1268 -1.7817 -1.0563 -0.1684 -0.1937 -0.1904 -0.1203 -1.3393 -1.1624 -0.1080 -1.0807 -0.2329 -0.0415 -0.2482 -0.4922 -0.0724 -0.1520 -0.1230 -0.1358 -0.6253 -1.3105 -0.1020 -0.6213 -0.0612 -0.1856 -0.1831 -1.1272 -0.3369 -0.1102 -0.3336 -0.9390 -1.0346 -0.1441 -0.3608 -0.0521 -0.0834 -0.1066 -1.3420 -1.3447 -0.1452 -0.5138 -0.2324 -0.1616 -0.4215 -0.1496 -1.9876 -0.1205\n",
            "T-357\tAmuna awiri omwe akuthamanga ndi zizindikiro zokhala ndi manambala pamalaya awo akuyesa kulumpha chipika chomwe chili panjira yawo .\n",
            "H-357\t-0.2782592475414276\t▁ A m u n a ▁ a w i r i ▁ o m w e ▁ a k u t h a m a n g a ▁ n d i ▁ z i n g w e ▁ z o k h a l a ▁ n d i ▁ n y a m a ▁ n d i ▁ m b a l a m e ▁ a k u y e s a ▁ m a l a y a ▁ o y e r a ▁ k u l u m p h a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-357\t-0.2782592475414276\tAmuna awiri omwe akuthamanga ndi zingwe zokhala ndi nyama ndi mbalame akuyesa malaya oyera kulumpha chipale chofewa .\n",
            "P-357\t-0.1178 -0.0319 -0.1161 -0.0830 -0.0946 -0.1001 -0.1398 -0.1219 -0.0910 -0.1423 -0.0626 -0.1120 -0.2110 -0.0872 -0.3572 -0.0866 -0.0890 -0.1447 -0.0768 -0.2663 -0.0795 -0.0685 -0.1137 -0.0855 -0.1057 -0.0998 -0.0704 -0.1056 -0.1020 -0.1313 -0.3596 -0.0815 -0.1040 -0.1374 -0.0538 -0.0835 -1.0493 -0.8159 -0.2093 -0.0806 -0.1765 -0.0290 -0.1088 -0.0303 -0.3258 -0.1217 -0.0544 -0.1162 -0.1496 -0.0663 -0.1343 -0.0907 -0.1166 -0.6515 -0.3675 -0.1402 -0.8159 -0.1112 -0.1122 -1.7474 -0.1490 -0.1162 -0.1336 -0.3422 -0.6528 -0.1042 -0.0897 -0.1136 -0.2853 -0.6486 -0.1543 -1.0922 -0.2096 -0.1030 -0.5884 -0.3269 -0.1641 -0.1033 -0.1352 -1.8827 -0.2835 -0.0629 -0.3960 -0.0241 -0.1090 -0.0955 -1.4147 -0.1566 -0.1280 -0.3984 -0.1161 -0.1471 -0.4342 -0.0802 -1.9541 -0.3147 -0.3056 -0.0216 -0.0727 -1.1170 -0.2046 -0.2330 -0.0923 -0.5866 -1.1526 -0.1480 -0.9073 -0.0640 -0.0940 -0.0419 -0.0926 -0.0843 -1.1305 -0.0837 -0.0259 -0.0995 -0.3340 -0.6725 -0.1035\n",
            "T-80\tOsewera mpira akusewera masewero ausiku ndipo mpira uli mmwamba pomwe matimu awiriwa akumenyera nkhondo.\n",
            "H-80\t-0.35388875007629395\t▁ O s e w e r a ▁ m p i r a ▁ a k u s e w e r a ▁ m a s e w e r a ▁ o p a n g i d w a ▁ n d i p o ▁ m p i r a ▁ w i n a ▁ w a m n g ' o n o ▁ a k u m u l u ▁ a w i r i ▁ o m w e ▁ a k u m e n y a ▁ m p i r a .\n",
            "D-80\t-0.35388875007629395\tOsewera mpira akusewera masewera opangidwa ndipo mpira wina wamng'ono akumulu awiri omwe akumenya mpira.\n",
            "P-80\t-0.1275 -0.6191 -0.1323 -0.0415 -0.0700 -0.0807 -0.0987 -0.1193 -0.1496 -1.1903 -0.0313 -0.0920 -0.0798 -0.1082 -0.1573 -0.0947 -0.1559 -0.0784 -0.0874 -0.0513 -0.1366 -0.0778 -0.0769 -0.1125 -0.1438 -0.1617 -0.1256 -0.0477 -0.0471 -0.0445 -0.0628 -0.1086 -0.1370 -0.1460 -0.1591 -1.0184 -0.1410 -1.1948 -0.7765 -0.9727 -0.4527 -0.0805 -0.0597 -0.1201 -0.4104 -0.0368 -0.1134 -0.8791 -0.0635 -0.0824 -0.5445 -1.1256 -0.0972 -0.0805 -0.0993 -0.2931 -0.2762 -0.7982 -0.1068 -0.0927 -0.1367 -1.3856 -0.6382 -1.4622 -0.5729 -0.2696 -0.0400 -0.0810 -0.1718 -0.0454 -0.1571 -0.6989 -1.0985 -0.1854 -0.2258 -0.8229 -0.6890 -1.1638 -1.5166 -1.0422 -0.2511 -0.3081 -0.0999 -0.1020 -0.1819 -1.5749 -0.6401 -1.0393 -0.1071 -0.1338 -0.1466 -0.2248 -0.1279 -0.3394 -0.3460 -0.4193 -0.0575 -0.1526 -0.5984 -1.2668 -0.2725 -0.1240 -0.1318 -0.0833 -1.2240 -0.0861\n",
            "T-202\tMtsikana wina wamng'ono atavala pinki akuyang'ana wina, yemwenso atavala pinki, adalumpha pa trampoline.\n",
            "H-202\t-0.31245511770248413\t▁ M t s i k a n a ▁ w i n a ▁ w a m n g ' o n o ▁ w o v a l a ▁ k a p i n k i ▁ a k u n g o y a n g ' a n a ▁ a n g a p o ▁ e n a ▁ a w i r i ▁ a t a n y a m u l a ▁ k a p i n k i ▁ a t a v a l a ▁ b u l u u ▁ .\n",
            "D-202\t-0.31245511770248413\tMtsikana wina wamng'ono wovala kapinki akungoyang'ana angapo ena awiri atanyamula kapinki atavala buluu .\n",
            "P-202\t-0.1167 -0.1524 -0.0807 -0.0812 -0.1159 -0.0670 -0.1233 -0.1268 -0.1164 -0.1392 -0.0840 -0.1120 -0.1185 -0.1141 -0.1442 -0.1305 -0.3794 -0.1316 -0.0446 -0.4786 -0.1020 -0.1205 -0.0520 -0.1102 -0.1205 -0.7146 -0.6193 -1.2287 -0.1223 -0.1029 -0.1230 -0.1158 -1.9763 -0.3360 -0.2547 -0.3105 -0.1073 -0.2694 -0.1112 -0.1464 -0.1925 -0.0284 -0.1037 -1.0731 -1.2207 -0.2876 -0.0508 -0.0930 -0.0974 -0.0573 -0.0451 -0.1201 -0.0809 -0.1123 -0.1225 -0.6639 -1.7073 -0.1676 -0.3174 -0.4079 -0.0669 -0.1674 -0.6003 -0.0512 -0.0781 -0.1038 -0.1754 -0.1130 -0.0965 -0.2142 -0.1160 -0.2510 -1.3082 -0.0447 -0.1002 -0.8564 -0.0324 -0.2563 -0.0718 -0.0870 -0.0625 -0.1249 -0.0936 -3.4901 -0.3467 -0.7068 -0.8951 -0.0532 -0.2941 -0.0530 -0.1973 -1.0868 -0.1200 -0.0814 -0.3446 -0.0925 -0.0848 -0.1262 -0.0924 -1.3320 -0.2881 -0.1171 -0.0924 -0.0905 -0.2142 -1.1975 -0.1140\n",
            "T-121\tBambo wina atavala suti ya njinga yamoto yophimbidwa, akukhala panjinga yamoto akukweza dzanja lake .\n",
            "H-121\t-0.25799986720085144\t▁ B a m b o ▁ w i n a ▁ a t a v a l a ▁ s u t i ▁ y a ▁ n j i n g a ▁ y a m o t o ▁ y a ▁ p i n k i ▁ a k u g w a ▁ p a n j i n g a ▁ y a k u d a ▁ a k u k w e z a ▁ n j a n j i ▁ .\n",
            "D-121\t-0.25799986720085144\tBambo wina atavala suti ya njinga yamoto ya pinki akugwa panjinga yakuda akukweza njanji .\n",
            "P-121\t-0.1251 -0.0656 -0.1109 -0.1035 -0.0818 -0.0863 -0.1295 -0.0499 -0.1077 -0.0848 -0.1090 -0.1521 -0.1335 -0.1243 -0.0910 -0.0585 -0.1053 -0.1108 -0.1158 -0.1032 -0.0672 -0.0413 -0.0419 -0.0575 -0.1081 -0.0480 -0.1007 -0.5171 -0.1181 -0.0914 -0.8346 -0.0353 -0.0766 -0.0888 -0.1330 -0.0200 -0.1391 -0.2077 -0.0210 -0.0453 -0.0402 -0.1439 -0.0300 -0.1758 -1.3371 -1.3941 -0.1791 -0.1110 -0.1947 -0.1163 -0.2489 -1.0473 -0.1006 -0.0975 -1.1942 -0.6338 -0.7067 -0.3738 -0.4194 -0.1950 -0.2826 -0.0411 -0.1217 -0.0469 -0.0806 -0.0990 -0.1422 -0.1633 -0.1402 -0.7871 -0.1647 -0.1803 -0.1159 -0.1586 -1.4940 -0.2725 -0.0850 -1.2832 -0.0986 -0.0594 -0.0179 -0.1252 -0.1074 -0.9272 -0.0607 -0.3125 -0.1859 -0.1099 -0.1175 -0.1577 -2.1055 -0.1108\n",
            "T-70\tWoimba wina wamkazi atavala diresi lakuda akukokera maikolofoni pamene oimba atatu akuimba zoimbira za zingwe.\n",
            "H-70\t-0.281605064868927\t▁ W o y i m b a ▁ w i n a ▁ w o v a l a ▁ m a g a l a s i ▁ a t a v a l a ▁ j e a n s ▁ y a k u d a ▁ a k u k o n z e k e r a ▁ m a i k o l o f o n i ▁ p a m e n e ▁ m n y a m a t a ▁ w i n a ▁ a k u l i m b a ▁ z i n g w e ▁ .\n",
            "D-70\t-0.281605064868927\tWoyimba wina wovala magalasi atavala jeans yakuda akukonzekera maikolofoni pamene mnyamata wina akulimba zingwe .\n",
            "P-70\t-0.1212 -0.3698 -0.1244 -0.1878 -0.4196 -0.1445 -0.0749 -0.1119 -0.1174 -0.2096 -0.1414 -0.0869 -0.0945 -0.1086 -1.6547 -0.7345 -0.9190 -0.1108 -0.1138 -0.1135 -0.1113 -0.0695 -0.4131 -1.4731 -0.1274 -0.1133 -0.1095 -0.1195 -0.0861 -0.1307 -0.2559 -0.7891 -0.1158 -0.0914 -0.1119 -0.0678 -0.1111 -0.1194 -0.0620 -0.0704 -1.0107 -0.0919 -0.0794 -0.1121 -0.7620 -0.1013 -0.1906 -0.0887 -0.5260 -0.0779 -0.1614 -0.0992 -0.0784 -0.1081 -0.1343 -0.1612 -0.2734 -0.8362 -0.6195 -0.1171 -0.0736 -0.0519 -0.1039 -0.1249 -1.1192 -1.5433 -1.4513 -0.7622 -0.0337 -0.0766 -0.0443 -0.0839 -0.0465 -0.0590 -0.0584 -0.1331 -0.0365 -0.1365 -0.2059 -0.1852 -0.0739 -0.1082 -0.1123 -1.2433 -1.6865 -0.0537 -0.1000 -0.0471 -0.1522 -0.0324 -0.1168 -0.1335 -0.2330 -0.4145 -0.0862 -0.1021 -0.1058 -0.3709 -0.2139 -0.0993 -0.7547 -0.0694 -0.5095 -0.0564 -0.1841 -0.1608 -0.1052 -0.1483 -0.6290 -0.2774 -0.0772 -0.0977 -0.6938 -0.5753 -0.0940\n",
            "T-186\tMayi wina akuliza piyano yopakidwa malo pafupi ndi bambo wina amene waimirira n'kumaimba chojambulira chamatabwa .\n",
            "H-186\t-0.2620953321456909\t▁ M a y i ▁ w i n a ▁ a k u l i z a ▁ p i y a n g ' a n o ▁ y o p a n g i d w a ▁ n d i p o ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w i n a ▁ y e m w e ▁ w a i m i r i r a ▁ k u m b a l i ▁ c h o j a m b u l i r a ▁ c h a m a t a b w a ▁ .\n",
            "D-186\t-0.2620953321456909\tMayi wina akuliza piyang'ano yopangidwa ndipo pafupi ndi bambo wina yemwe waimirira kumbali chojambulira chamatabwa .\n",
            "P-186\t-0.1349 -0.0526 -0.0978 -0.0550 -0.0956 -0.1413 -0.0491 -0.1222 -0.0929 -0.1078 -0.1133 -0.1000 -0.1597 -0.1049 -0.2284 -0.0949 -0.0339 -0.1021 -0.1385 -0.3108 -0.3498 -1.8253 -0.1484 -0.0664 -1.9041 -0.0230 -0.6034 -0.0453 -0.2336 -0.0901 -0.1428 -0.1663 -1.0565 -0.2542 -0.0259 -1.4633 -0.0934 -0.0086 -0.0449 -0.0869 -0.1216 -0.8954 -0.0773 -0.0934 -0.7348 -0.0786 -0.1029 -0.8568 -0.1125 -0.3045 -0.0937 -0.0271 -0.1094 -0.1185 -0.0946 -0.1085 -0.1006 -0.1083 -1.6588 -0.1923 -0.1607 -0.0451 -0.0489 -0.0985 -0.0508 -0.1330 -0.1174 -0.0873 -0.1648 -0.2879 -0.0457 -0.0585 -0.1837 -0.1022 -0.1239 -0.0306 -0.1103 -0.3143 -0.0313 -0.5356 -0.1495 -0.0727 -0.1222 -0.1306 -0.1505 -0.1083 -0.1212 -0.0965 -0.1750 -0.4635 -0.5341 -0.0797 -0.1713 -1.7187 -0.0740 -0.2195 -1.4811 -0.1101 -0.0361 -0.0459 -0.0994 -0.0725 -0.1189 -0.3796 -0.0815 -0.1863 -0.4325 -0.0764 -0.4498 -0.9844 -0.3109 -0.1076 -0.1730 -0.1714 -0.0515 -0.0871 -0.7486 -0.7971 -0.1122\n",
            "T-111\tWosewera wa Dodgers adangomenya tag yachitatu-baseman, mumasewera oyandikira kwambiri.\n",
            "H-111\t-0.32875028252601624\t▁ W o s e w e r a ▁ w a ▁ j e r s e y ▁ a t a n y a m u l a ▁ m i y a l a ▁ y a c h i t a l e ▁ y a c h i t a t u ▁ m ' m a s e w e r a ▁ o y e r a ▁ n d i ▁ m a s e w e r a ▁ o f i i r a ▁ k w a m b i r i .\n",
            "D-111\t-0.32875028252601624\tWosewera wa jersey atanyamula miyala yachitale yachitatu m'masewera oyera ndi masewera ofiira kwambiri.\n",
            "P-111\t-0.1100 -0.1093 -0.0974 -0.0869 -0.0591 -0.1310 -0.0767 -0.0747 -0.2014 -0.1381 -0.8806 -0.2537 -0.4969 -0.3082 -0.1128 -0.6606 -1.2364 -0.6830 -0.2148 -0.1013 -0.0884 -0.2180 -0.1286 -0.1568 -0.0543 -0.1043 -0.0719 -0.0690 -0.0715 -0.1479 -0.1058 -1.4181 -1.4416 -0.2308 -0.5624 -0.0791 -0.0824 -0.1471 -0.0441 -0.1081 -1.2892 -0.0791 -0.1056 -0.1218 -0.1212 -1.7511 -1.0840 -0.1704 -0.2423 -0.1402 -0.5893 -0.0892 -0.1048 -0.3135 -0.7215 -0.4012 -0.0547 -0.1797 -1.8849 -0.1272 -0.1237 -0.2666 -0.1105 -0.1223 -0.0992 -0.1716 -0.1341 -0.1065 -0.1343 -0.0359 -0.3367 -0.2383 -0.1102 -0.0831 -0.1522 -0.2510 -0.0585 -0.1111 -0.0985 -2.4664 -0.8351 -0.1023 -0.1549 -0.0578 -0.1159 -0.1254 -0.0931 -0.1891 -0.3340 -3.1558 -0.1263 -0.1862 -0.0600 -0.1506 -0.5764 -0.5861 -0.1050 -0.1014 -0.1120 -0.0332 -0.1213 -0.0926 -0.1676 -0.6852 -0.1066\n",
            "T-32\tMnyamata wovala epuloni yoyera ali ndi manja m'chipinda chochezeramo komanso m'chipinda chamivi pomwe mnyamata wabuluu akuyang'ana .\n",
            "H-32\t-0.28985247015953064\t▁ M n y a m a t a ▁ w o v a l a ▁ t u w e ▁ y o y e r a ▁ a l i ▁ n d i ▁ m a n j a ▁ a l i ▁ m ' c h i p i n d a ▁ c h o t s e t s e r e k a ▁ k u m a n j a ▁ n d i p o ▁ m t s i k a n a ▁ w a m n g ' o n o ▁ .\n",
            "D-32\t-0.28985247015953064\tMnyamata wovala tuwe yoyera ali ndi manja ali m'chipinda chotsetsereka kumanja ndipo mtsikana wamng'ono .\n",
            "P-32\t-0.1319 -0.0550 -0.0624 -0.0624 -0.1011 -0.0794 -0.1167 -0.0427 -0.1217 -0.1366 -0.1122 -0.1661 -0.0863 -0.1224 -0.0824 -0.1224 -0.1058 -1.2087 -0.5739 -0.4860 -0.5730 -1.0113 -0.5729 -0.5234 -0.1821 -0.0864 -0.0771 -0.0974 -0.1648 -0.3308 -0.0468 -0.1059 -0.1185 -0.2176 -0.1064 -0.1011 -0.0802 -0.0751 -0.0995 -1.4678 -0.0165 -0.1135 -0.0973 -0.3087 -0.8288 -0.1967 -0.0878 -2.2497 -0.1721 -0.0836 -0.0838 -0.1509 -0.0816 -0.3225 -0.0391 -0.0164 -0.1245 -0.1652 -0.0321 -0.1204 -0.0599 -0.7358 -0.0710 -0.0343 -0.2322 -0.0188 -0.0551 -0.0913 -1.5712 -0.0989 -0.2539 -0.1935 -1.6325 -0.1773 -0.3231 -0.2957 -0.2280 -0.1896 -0.1005 -0.1382 -1.2533 -0.5402 -0.0989 -0.0848 -0.0535 -0.1047 -0.2182 -1.1662 -0.1013 -0.0926 -0.4489 -0.0790 -0.0976 -0.0701 -0.1496 -0.0238 -0.5137 -1.2011 -0.1067 -0.0322 -0.2894 -0.1411 -0.0557 -0.0723 -0.1205 -1.9890 -0.1036\n",
            "T-126\tGulu la ana ang'onoang'ono amaliseche akusamba pafupi ndi zitsulo zazikulu ndi ndowa zachikasu.\n",
            "H-126\t-0.27317145466804504\t▁ G u l u ▁ l a ▁ a n a ▁ a n g ' o n o a n g ' o n o ▁ a t a v a l a ▁ m a l a y a ▁ a c h i s a n u ▁ k u t s a m b a ▁ p a f u p i ▁ n d i ▁ z i t s u l o ▁ z a c h i k a s u ▁ n d i ▁ n d o d o ▁ z a c h i k a s u ▁ .\n",
            "D-126\t-0.27317145466804504\tGulu la ana ang'onoang'ono atavala malaya achisanu kutsamba pafupi ndi zitsulo zachikasu ndi ndodo zachikasu .\n",
            "P-126\t-0.1223 -0.2962 -0.0560 -0.0734 -0.0640 -0.1155 -0.0875 -0.1146 -0.1383 -0.1261 -0.0636 -0.1144 -0.1576 -0.2527 -1.8218 -0.0412 -0.1320 -0.0548 -0.0605 -0.0788 -0.6520 -0.0741 -0.0256 -0.0708 -0.0708 -0.0604 -0.0788 -0.1333 -0.2586 -1.5171 -0.1124 -0.8547 -0.0995 -0.0939 -0.1171 -0.0941 -0.1246 -0.1179 -0.5126 -0.1333 -0.0802 -0.0755 -0.1219 -0.6619 -0.6484 -0.1032 -0.1428 -1.0855 -0.0987 -0.2508 -0.1703 -0.1623 -1.3343 -0.5681 -1.3654 -0.0996 -0.3746 -0.2224 -0.1257 -0.1027 -0.1335 -0.2801 -0.1303 -0.7599 -0.0907 -0.0271 -0.1634 -0.1049 -0.0470 -0.0746 -0.1421 -0.0934 -0.2994 -0.0748 -0.6345 -0.3419 -0.0910 -0.0799 -0.0643 -0.0958 -0.1823 -0.4571 -0.2848 -0.1091 -0.1086 -0.3642 -0.3884 -0.5481 -0.0635 -0.1929 -0.1891 -0.0575 -0.0873 -0.1287 -0.6767 -1.1709 -0.0646 -1.3755 -0.0501 -0.1578 -1.0020 -0.1816 -0.2359 -0.0880 -0.1077 -0.2584 -0.1057 -0.0800 -0.0691 -0.9302 -0.0890 -0.0944\n",
            "T-275\tmwamuna wovala zovala zakuda ndi magalasi adzuwa akukwera njinga yamapiri kudutsa m'nkhalango pafupi ndi mtsinje.\n",
            "H-275\t-0.22136074304580688\t▁ M w a m u n a ▁ w o v a l a ▁ z o v a l a ▁ z o v a l a ▁ z a k u d a ▁ n d i ▁ m a t h a l a u z a ▁ a k u k w e r a ▁ n j i n g a ▁ y a m a k w e r a ▁ n j i n g a ▁ y a m o t o ▁ p a f u p i ▁ n d i ▁ m t e n g o ▁ .\n",
            "D-275\t-0.22136074304580688\tMwamuna wovala zovala zovala zakuda ndi mathalauza akukwera njinga yamakwera njinga yamoto pafupi ndi mtengo .\n",
            "P-275\t-0.1173 -0.1317 -0.0623 -0.0974 -0.0837 -0.0917 -0.0740 -0.1012 -0.1668 -0.0728 -0.0620 -0.0374 -0.1326 -0.0952 -0.1159 -0.1089 -0.2183 -0.0867 -0.0672 -0.1012 -0.0899 -0.1082 -0.1052 -0.1506 -0.5335 -0.3394 -0.0992 -0.0979 -0.0986 -0.1093 -0.0746 -0.0904 -0.2181 -0.0665 -0.0504 -0.0963 -0.1411 -0.2616 -0.0794 -0.0963 -0.0737 -0.0745 -0.1212 -0.6161 -0.9083 -0.1090 -0.0434 -0.1126 -0.0421 -0.0922 -0.0926 -0.0979 -0.1349 -0.3163 -0.0541 -0.1264 -0.3516 -0.0699 -0.0909 -0.1069 -0.0894 -0.6400 -0.0436 -0.1608 -0.0315 -0.0190 -0.1042 -0.1145 -0.0245 -0.1424 -0.1877 -0.1688 -1.5973 -0.3561 -0.0455 -0.0739 -0.1098 -0.1138 -0.7924 -1.9458 -0.0980 -0.0467 -0.0161 -0.0928 -0.1085 -0.1369 -0.1837 -0.2387 -1.2249 -0.0526 -0.1789 -0.1500 -1.3823 -0.1039 -0.2607 -0.0655 -0.0236 -0.1073 -0.1315 -0.0450 -0.1712 -0.1191 -0.0806 -1.3089 -0.1703 -0.5006 -0.0554 -0.1164 -0.0597 -0.2076 -1.9271 -0.1019\n",
            "T-149\tMnyamata wina wovala malaya amizeremizere yabuluu akugona pa udzu kutsogolo kwa tebulo lofiira ndipo akuwerenga buku .\n",
            "H-149\t-0.2158661037683487\t▁ M n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a ▁ b u l u u ▁ a k u g o n a ▁ p a ▁ u d z u ▁ k u t s o g o l o ▁ k w a ▁ t e b u l o ▁ l o f i i r a ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ .\n",
            "D-149\t-0.2158661037683487\tMnyamata wina wovala malaya amizeremizere ya buluu akugona pa udzu kutsogolo kwa tebulo lofiira ndi gulu la anthu .\n",
            "P-149\t-0.1252 -0.0710 -0.0339 -0.0637 -0.1016 -0.1311 -0.1179 -0.0499 -0.1146 -0.1287 -0.1161 -0.1053 -0.1044 -0.1110 -0.1201 -0.1137 -0.1043 -0.0730 -0.1217 -0.0843 -0.1191 -0.1013 -0.0540 -0.1252 -0.0480 -0.1036 -0.0761 -0.0982 -0.0983 -0.1472 -0.8336 -0.0658 -0.0423 -0.0556 -0.0361 -0.0653 -0.0946 -0.0514 -0.0223 -0.0669 -0.0541 -0.0801 -0.1739 -0.1607 -0.1523 -0.6436 -0.0393 -0.0796 -0.0939 -0.0835 -0.0630 -0.1199 -0.5875 -0.0600 -0.0964 -0.0390 -2.4133 -0.5984 -0.1198 -0.0988 -0.0375 -0.1383 -1.0186 -0.4993 -0.5770 -0.0256 -0.1068 -0.1738 -0.5107 -0.1724 -0.1496 -0.1175 -0.0809 -0.0455 -0.1092 -0.0903 -0.0770 -0.0927 -0.0421 -0.0918 -0.1307 -0.4554 -0.1024 -0.0345 -0.0269 -0.0785 -0.0895 -0.0710 -0.0974 -0.1549 -0.2819 -0.1395 -0.1262 -0.2140 -0.0927 -0.2031 -0.2030 -0.1631 -0.1113 -0.1209 -1.2509 -2.3252 -0.1606 -0.1963 -0.0475 -0.1287 -0.0746 -0.1206 -0.2873 -0.2460 -0.1370 -1.4962 -0.0994 -0.0668 -0.1379 -1.2754 -0.0995\n",
            "T-81\tBambo wina wachikulire yemwe anavala malaya abuluu komanso mathalauza obiriwira atakhala patebulo ndi makina ojambulira kumbuyo kwake .\n",
            "H-81\t-0.20847435295581818\t▁ B a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ y e m w e ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ k o m a n s o ▁ m a t h a l a u z a ▁ o b i r i w i r a ▁ a t a k h a l a ▁ p a ▁ t e b u l o ▁ l o k h a l a ▁ n d i ▁ m a t h a l a u z a ▁ a b u l u u ▁ .\n",
            "D-81\t-0.20847435295581818\tBambo wina wachikulire yemwe wavala malaya abuluu komanso mathalauza obiriwira atakhala pa tebulo lokhala ndi mathalauza abuluu .\n",
            "P-81\t-0.1276 -0.0362 -0.1039 -0.0863 -0.1095 -0.0938 -0.1148 -0.0619 -0.1242 -0.0875 -0.0996 -0.1232 -0.0580 -0.1683 -0.0406 -0.0936 -0.0946 -0.0885 -0.0771 -0.0624 -0.0720 -0.0640 -0.0608 -0.1736 -1.2017 -0.0411 -0.0793 -0.0622 -0.0794 -0.1209 -0.9399 -0.1086 -0.1969 -0.1011 -0.0919 -0.1101 -0.1158 -0.3168 -0.1255 -0.1031 -0.1147 -0.0814 -0.0980 -0.1209 -0.1774 -0.0331 -0.0801 -0.0548 -0.0808 -0.0481 -0.1359 -0.1493 -0.1171 -0.0533 -0.1072 -0.0879 -0.0531 -0.0679 -0.0873 -0.0881 -0.1334 -0.8353 -0.0494 -0.0869 -0.4396 -0.1013 -0.0705 -0.0187 -0.1184 -0.1112 -0.1247 -0.4717 -0.0730 -0.1028 -0.0715 -0.1006 -0.0911 -0.1294 -0.1037 -0.1914 -0.1270 -0.1844 -0.1086 -0.5212 -0.0331 -0.1140 -0.0507 -0.1132 -0.0962 -0.2826 -0.1446 -1.1078 -1.1233 -0.0796 -0.4151 -0.0873 -0.0717 -0.1225 -0.0978 -1.2912 -0.6951 -0.6536 -0.0422 -0.1091 -0.0475 -0.0976 -0.1100 -0.0411 -0.1017 -0.1011 -0.0705 -0.1176 -0.1133 -1.7071 -1.0129 -0.1029 -0.6831 -0.1048 -0.0513 -0.1435 -0.1075 -0.1697 -0.5700 -1.2539 -0.2019 -0.0651 -0.1684 -0.0554 -0.2311 -0.8084 -0.1239\n",
            " 38% 5/13 [00:14<00:20,  2.52s/it, wps=919]T-347\tGulu la achichepere aimirira mumsewu kutsogolo kwa khoma la njerwa lokhala ndi chipata chachitali chamatabwa .\n",
            "H-347\t-0.3114929497241974\t▁ G u l u ▁ l a ▁ a t a t u ▁ a c h i c h e p e r e ▁ a i m i r i r a ▁ k u t s o g o l o ▁ k w a ▁ k h o m a ▁ l a ▁ n j e r w a ▁ o k h a l a ▁ n d i ▁ c h i t a t u ▁ c h a ▁ m a t a l i ▁ .\n",
            "D-347\t-0.3114929497241974\tGulu la atatu achichepere aimirira kutsogolo kwa khoma la njerwa okhala ndi chitatu cha matali .\n",
            "P-347\t-0.1185 -0.0236 -0.0715 -0.0669 -0.0935 -0.1096 -0.0684 -0.1788 -0.2293 -0.1529 -2.5667 -0.1603 -1.1276 -0.4538 -0.1763 -1.2523 -0.1356 -0.1121 -0.1365 -0.3570 -0.1128 -0.0784 -0.0548 -0.0819 -0.0766 -0.0724 -0.1238 -0.2597 -1.4053 -0.0334 -0.0901 -0.2287 -0.1463 -0.0916 -0.1252 -0.0990 -2.1619 -0.0443 -0.2108 -0.0490 -0.1408 -0.0289 -0.1344 -0.0566 -0.0836 -0.1064 -0.1959 -0.1517 -0.1123 -0.1554 -0.7301 -0.4501 -0.1814 -0.0572 -0.0592 -0.1259 -0.1224 -0.1399 -0.3616 -0.5934 -0.0174 -0.0615 -0.0257 -0.0366 -0.0887 -0.1510 -2.8964 -0.0455 -0.0571 -0.1035 -0.0490 -0.1000 -0.0842 -0.0392 -0.1082 -0.1456 -0.0883 -0.5592 -0.0930 -0.0965 -0.3293 -1.4293 -0.4909 -0.0653 -0.1229 -0.1539 -0.0943 -0.1608 -0.3278 -0.5489 -0.1123 -1.6606 -0.0933 -0.5969 -0.0569 -0.4188 -1.7963 -0.0972\n",
            "T-411\tAzimayi awiri anayimirira atagwirana manja pamalo pomwe pali anthu ambiri, mayi wina akudutsa ndipo mwamuna akuima chapatali .\n",
            "H-411\t-0.32534050941467285\t▁ A z i m a y i ▁ a w i r i ▁ a n a y i ▁ a n a y i ▁ a t a v a l a ▁ m a l a y a ▁ a p i n k i ▁ a m a n j a ▁ o m w e ▁ a l i ▁ p a m e n e ▁ b a m b o ▁ w i n a ▁ y e m w e ▁ a k u d u t s a ▁ c h a k u m w a ▁ c h a k e ▁ .\n",
            "D-411\t-0.32534050941467285\tAzimayi awiri anayi anayi atavala malaya apinki amanja omwe ali pamene bambo wina yemwe akudutsa chakumwa chake .\n",
            "P-411\t-0.1330 -0.0448 -0.0456 -0.1050 -0.1260 -0.1207 -0.0301 -0.0930 -0.1081 -0.1614 -0.0634 -0.1328 -0.0782 -0.1122 -0.2291 -0.1464 -1.5310 -0.1001 -0.0695 -0.0753 -0.2796 -0.1287 -0.2444 -0.1377 -0.1332 -0.0735 -0.2709 -0.1225 -0.3710 -0.1125 -1.3915 -0.1270 -0.0680 -0.1136 -0.1142 -1.4682 -0.2569 -0.5811 -0.1066 -0.1339 -0.0859 -0.1237 -0.1580 -1.6455 -0.1286 -0.7325 -0.1357 -0.0721 -0.1584 -0.4255 -1.0878 -0.1343 -0.1522 -0.0537 -0.1252 -0.1230 -1.1204 -0.1583 -0.0995 -0.0862 -0.1051 -0.2250 -0.1542 -0.0857 -0.1177 -0.3912 -0.1366 -0.3470 -0.4160 -0.0474 -0.0861 -0.1227 -0.7943 -0.1437 -1.9922 -0.0553 -1.0386 -0.1313 -0.2464 -0.1027 -0.0926 -0.0972 -0.2126 -0.7667 -0.0599 -0.1023 -0.0560 -0.1169 -0.1061 -0.4003 -0.1240 -0.1164 -0.5798 -0.0960 -1.2509 -0.0588 -0.1035 -0.1129 -1.0640 -0.1147 -1.5308 -0.3309 -0.0539 -0.8796 -0.1919 -0.1451 -0.1381 -1.5837 -0.1341 -0.9578 -0.4982 -1.0016 -0.2294 -0.6955 -0.1258\n",
            "T-24\tMtsikana wovala yunifolomu yobiriwira ndi msungwana wovala yunifolomu yoyera atanyamula timitengo ta lacrosse .\n",
            "H-24\t-0.19881030917167664\t▁ M t s i k a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ n d i ▁ m t s i k a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o y e r a ▁ a t a n y a m u l a ▁ m p h a t e ▁ .\n",
            "D-24\t-0.19881030917167664\tMtsikana wovala yunifolomu yobiriwira ndi mtsikana wovala yunifolomu yoyera atanyamula mphate .\n",
            "P-24\t-0.1338 -0.0659 -0.0523 -0.0711 -0.1135 -0.0634 -0.1009 -0.0878 -0.1103 -0.1377 -0.0846 -0.1018 -0.5594 -0.1431 -0.0755 -0.1209 -0.1416 -0.1926 -0.0408 -0.0386 -0.0465 -0.0124 -0.0793 -0.0894 -0.0471 -0.0435 -0.0862 -0.1266 -0.2826 -0.1135 -0.1191 -0.1228 -0.0812 -0.1173 -0.0309 -0.1383 -0.1043 -0.0892 -0.2091 -0.3245 -0.0584 -0.1169 -0.0981 -0.0671 -0.2787 -0.0569 -0.0964 -0.1260 -0.2913 -0.0819 -0.0875 -0.1890 -0.0619 -0.1220 -0.3702 -0.1159 -0.0807 -0.1174 -0.1188 -0.1583 -0.0403 -0.0538 -0.0619 -0.0288 -0.0938 -0.1137 -0.0458 -0.0232 -0.0691 -0.1567 -0.2931 -1.1363 -0.0922 -0.0879 -0.1903 -0.0894 -0.1926 -0.0658 -0.0752 -0.0937 -0.1086 -0.0576 -0.0872 -0.0998 -0.1019 -0.0762 -0.0935 -0.1144 -1.8361 -1.1395 -0.3676 -0.1593 -1.7477 -0.8996 -0.1460 -1.7460 -0.1072\n",
            "T-297\tMwana amatsamira pachionetsero chopangidwa ndi pulasitiki wabuluu ndi wachikasu, pamene wamkulu akuyang'ana .\n",
            "H-297\t-0.3812834322452545\t▁ A n y a m a t a ▁ a s a m i r a ▁ p a ▁ c h i y e n d e t s e r o ▁ c h o p a n g a ▁ c h o p a n d a ▁ n d i ▁ b u l u u ▁ w a ▁ b u l u u ▁ w a c h i k a s u ▁ p a m e n e ▁ w a c h i k a s u ▁ a k u y a n g ' a n a ▁ k u m b u y o ▁ .\n",
            "D-297\t-0.3812834322452545\tAnyamata asamira pa chiyendetsero chopanga chopanda ndi buluu wa buluu wachikasu pamene wachikasu akuyang'ana kumbuyo .\n",
            "P-297\t-0.1245 -0.2034 -0.0352 -0.5034 -0.1042 -0.0861 -0.0989 -0.1755 -0.1586 -0.1326 -0.1416 -1.3996 -0.1082 -1.2205 -0.5593 -0.2109 -0.2196 -0.1359 -0.0737 -0.1308 -0.5633 -0.3467 -0.0918 -0.1214 -1.7557 -0.1304 -0.2018 -0.1771 -0.8309 -0.0750 -0.0477 -0.1258 -0.0425 -0.1324 -0.1578 -0.0731 -0.1213 -0.1875 -0.8517 -0.1462 -0.1420 -0.7966 -1.0775 -0.1904 -0.6557 -0.1027 -0.3097 -0.8444 -0.1840 -0.1226 -1.0321 -0.2560 -0.1610 -0.4613 -0.2259 -0.1225 -1.0167 -2.1817 -0.1267 -0.1306 -0.3474 -0.1267 -0.1690 -0.2579 -0.1235 -1.7474 -1.8141 -0.0718 -0.0984 -0.1267 -0.0630 -0.1612 -2.3457 -0.1757 -0.5457 -0.0604 -0.1238 -0.5356 -0.1007 -0.0280 -0.0597 -0.1572 -0.8887 -0.3446 -0.0936 -1.5416 -0.0584 -0.0624 -0.1043 -1.3911 -0.6441 -0.2629 -0.0621 -0.1044 -0.3661 -0.2669 -0.0491 -0.0711 -0.1098 -0.9223 -0.9012 -0.1039 -0.2458 -0.1063 -0.0709 -0.2433 -0.0588 -0.0873 -0.0498 -0.1093 -0.1747 -1.3921 -0.2155 -1.2846 -0.0500 -0.2579 -0.0671 -0.0721 -0.3935 -1.4112 -0.1141\n",
            "T-165\tBambo wina wovala kabudula woyera komanso pamwamba pa wetsuit wakwera pabwalo losambira lachikasu lowala kwambiri .\n",
            "H-165\t-0.3106956481933594\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ k a b u d u l a ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ m a w u ▁ a k u t s u k a ▁ p a b w a l o ▁ l a ▁ m u n t h u ▁ w a n y a m u l a ▁ c h i t s u l o ▁ c h a c h i k a s u ▁ k w a m b i r i ▁ .\n",
            "D-165\t-0.3106956481933594\tBambo wina wovala kabudula woyera wokhala ndi mawu akutsuka pabwalo la munthu wanyamula chitsulo chachikasu kwambiri .\n",
            "P-165\t-0.1242 -0.5983 -0.8006 -0.1808 -0.1114 -0.0822 -0.1265 -0.0403 -0.1478 -0.0623 -0.1032 -0.1006 -0.0382 -0.0973 -0.0809 -0.1095 -0.0943 -0.1107 -0.0958 -1.0709 -0.1398 -0.4467 -0.0896 -0.0487 -0.0553 -0.0622 -0.0979 -0.1209 -0.0371 -0.0634 -0.0666 -0.0631 -0.0907 -0.0882 -0.1587 -0.6153 -0.3416 -0.0825 -0.1713 -0.0974 -0.0731 -0.0798 -0.1089 -1.1066 -0.4188 -0.1147 -0.1041 -0.6643 -0.1114 -2.1467 -0.2900 -0.0898 -0.4668 -0.4507 -0.1258 -0.7690 -0.4366 -0.1282 -1.0011 -0.0878 -0.1212 -0.2845 -0.1552 -0.9544 -0.1317 -0.1075 -0.0608 -0.0402 -0.0958 -0.0406 -0.5607 -0.6130 -0.4845 -1.7131 -0.0602 -0.0567 -0.0739 -0.0662 -0.1059 -0.0651 -0.2045 -2.7949 -0.2472 -0.1610 -0.2646 -0.0623 -0.0445 -0.1402 -0.0944 -0.4721 -0.0642 -0.1189 -2.2007 -0.1041 -0.3799 -0.0399 -0.0410 -0.0981 -0.7578 -0.0872 -0.7341 -0.7719 -0.1444 -0.0941 -0.2670 -0.2053 -0.0551 -0.0384 -0.1160 -1.5403 -0.9245 -0.1271 -0.9478 -0.0378 -0.0799 -0.1158 -0.0910 -0.3543 -0.4772 -0.1056\n",
            "T-157\tMayi wina atakwera njinga akuimitsidwa pafupi ndi bambo wina amene wakhala pampando atanyamula taipi pachifuwa chake .\n",
            "H-157\t-0.21822772920131683\t▁ M a y i ▁ w i n a ▁ a t a k w e r a ▁ n j i n g a ▁ k u n j i d w a ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w i n a ▁ w a k h a l a ▁ p a m p a n d o ▁ a t a n y a m u l a ▁ c h i k w a n g w a n i ▁ c h a k e ▁ .\n",
            "D-157\t-0.21822772920131683\tMayi wina atakwera njinga kunjidwa pafupi ndi bambo wina wakhala pampando atanyamula chikwangwani chake .\n",
            "P-157\t-0.1296 -0.0554 -0.1257 -0.0485 -0.0991 -0.1311 -0.0336 -0.1145 -0.0877 -0.1086 -0.1152 -0.0495 -0.1265 -0.1055 -0.2370 -0.1868 -0.1064 -0.1507 -0.0945 -0.1316 -0.0889 -0.0256 -0.0992 -0.0529 -0.0461 -0.0965 -0.1216 -1.0339 -0.0973 -1.9023 -1.4097 -0.0999 -0.5741 -0.0894 -0.1001 -0.1746 -0.1439 -0.1391 -0.0574 -0.0795 -0.0209 -0.1325 -0.1090 -0.0746 -0.0578 -0.1142 -0.1216 -0.4324 -0.1448 -0.1021 -0.0322 -0.0646 -0.0849 -0.0611 -0.0897 -0.0765 -0.1121 -0.1113 -0.3055 -0.1351 -0.1716 -0.0568 -0.1242 -0.0601 -0.1077 -0.1179 -0.2404 -0.1234 -0.1189 -0.5779 -0.1412 -0.0660 -0.0265 -0.0626 -0.1083 -0.4218 -0.0284 -0.1078 -0.3154 -0.0201 -0.1070 -0.0886 -0.0911 -0.0682 -0.1074 -0.1152 -1.2334 -0.0745 -0.0922 -1.4230 -0.6544 -0.1146 -1.3646 -0.0148 -0.0748 -0.1092 -0.2759 -0.0701 -0.1454 -0.2897 -0.0718 -0.1598 -1.7865 -0.1074 -0.3348 -0.2339 -0.0927\n",
            "T-316\tBambo wina wovala suti atakhala pampando pomwe pali nyali m'mbali mwake ndipo kutsogolo kwake kuli nyimbo akuyimba Cello .\n",
            "H-316\t-0.2951517701148987\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ s u t i ▁ a t a k h a l a ▁ p a m p a n d o ▁ w o m w e ▁ p a l i ▁ n d i ▁ m a l i ▁ n d i p o ▁ w a k e ▁ k u t s o g o l o ▁ k w a k e ▁ a k u i m b a ▁ s i l i m b a ▁ .\n",
            "D-316\t-0.2951517701148987\tBambo wina wovala suti atakhala pampando womwe pali ndi mali ndipo wake kutsogolo kwake akuimba silimba .\n",
            "P-316\t-0.1256 -0.0782 -0.1036 -0.0846 -0.0951 -0.0881 -0.1211 -0.0699 -0.1015 -0.0837 -0.1049 -0.1200 -0.0704 -0.2403 -0.0484 -0.1140 -0.1021 -0.1163 -0.1063 -0.3487 -0.0344 -0.0711 -0.0635 -0.0779 -1.9230 -0.0237 -0.1165 -0.1531 -0.0456 -0.0999 -0.0685 -0.1031 -0.0886 -0.0124 -0.1027 -0.3190 -0.0488 -0.1390 -0.0388 -0.0171 -0.0507 -0.0924 -0.8989 -0.1600 -0.3491 -0.0755 -0.1035 -0.1196 -1.2879 -0.1288 -0.1510 -0.1014 -0.1226 -1.0745 -1.2791 -0.1163 -0.1275 -0.1320 -0.3563 -0.5650 -0.6823 -0.4181 -2.3270 -0.3287 -0.1381 -0.6097 -0.0797 -0.0972 -1.0765 -0.4358 -0.2685 -0.5473 -0.2200 -0.7362 -0.1177 -0.0897 -0.0954 -0.0792 -0.0359 -0.1411 -0.0648 -0.1134 -0.0904 -0.2376 -0.0584 -0.1151 -3.1699 -0.0661 -0.2334 -0.3229 -0.3382 -0.1310 -0.3901 -0.0766 -0.0201 -0.0884 -0.1302 -1.3726 -0.1101 -0.4535 -0.5714 -0.8874 -0.3682 -0.0965 -0.2382 -0.0603 -0.0912\n",
            "T-4\tPali mwamuna wina wovala zofiira ndi ana awiri akuyang'ana gudumu lalikulu, lozungulira komanso lamitundumitundu.\n",
            "H-4\t-0.27856743335723877\t▁ P a l i ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ z o f i i r a ▁ n d i ▁ a n a ▁ a k u y a n g ' a n a ▁ k u t u l u k a ▁ l i k u l u ▁ l o z u n g u l i r a ▁ z o k o n g o l e t s o ▁ .\n",
            "D-4\t-0.27856743335723877\tPali mwamuna wina wovala zofiira ndi ana akuyang'ana kutuluka likulu lozungulira zokongoletso .\n",
            "P-4\t-0.1178 -2.7588 -0.1309 -0.2416 -0.0805 -0.1209 -0.0754 -0.1154 -0.0901 -0.4217 -0.0919 -0.0535 -0.0859 -0.1276 -0.1224 -0.1499 -0.0720 -0.0941 -0.1303 -0.1562 -0.0929 -0.0636 -0.1110 -0.0867 -0.1106 -0.1089 -0.3042 -0.0992 -0.2038 -0.1072 -0.2840 -0.0822 -0.2644 -0.2496 -0.1242 -0.0929 -0.1182 -0.0955 -0.2746 -1.5676 -0.0923 -0.1820 -0.1286 -0.3010 -0.0946 -0.2967 -0.1528 -0.0940 -0.1830 -0.0597 -0.0888 -0.0831 -0.0976 -0.0966 -0.4049 -0.1008 -0.8067 -0.1174 -0.1654 -0.0757 -0.2674 -0.0671 -0.1250 -0.2600 -0.2673 -1.1423 -0.1368 -0.5123 -0.1114 -0.9658 -0.4161 -0.0945 -0.3311 -0.0395 -0.1124 -0.0461 -0.1835 -0.1096 -0.1003 -0.0968 -0.1432 -0.1500 -0.3164 -0.9624 -1.5246 -0.5154 -0.1055 -0.0525 -0.0779 -0.1529 -0.2886 -0.0622 -0.1597 -0.6054 -0.1433 -2.9443 -0.1320\n",
            "T-422\tAnthu anayi akhala pamipando ya buluu ndi yobiriwira, pamene munthu wachisanu anakhala pambali akuyang'ana, pansi pa mtengo wofiyira wotambalala.\n",
            "H-422\t-0.2900600731372833\t▁ A n t h u ▁ a n a y i ▁ a k h a l a ▁ p a m i p a n d o ▁ y a b u l u u ▁ y o b i r i w i r a ▁ p a m e n e ▁ m u n t h u ▁ w a c h i s a n u ▁ a k u y a n g ' a n a ▁ p a m b a l i ▁ p a ▁ m p a n d a ▁ w o f i i r a ▁ n d i ▁ m b a l a m e ▁ .\n",
            "D-422\t-0.2900600731372833\tAnthu anayi akhala pamipando yabuluu yobiriwira pamene munthu wachisanu akuyang'ana pambali pa mpanda wofiira ndi mbalame .\n",
            "P-422\t-0.1242 -0.0298 -0.1415 -0.0634 -0.1511 -0.0957 -0.0994 -0.3364 -0.0243 -0.2553 -0.0487 -0.0822 -0.1919 -0.2660 -2.2190 -0.3252 -0.1204 -0.0546 -0.1303 -0.1236 -0.0214 -0.1158 -0.0625 -0.7736 -0.4561 -0.1129 -0.0301 -0.1081 -0.1734 -0.1232 -0.1001 -0.1422 -2.1356 -0.1284 -0.0777 -0.0816 -0.0612 -0.1605 -1.3696 -0.1484 -0.3045 -0.1076 -0.0699 -0.1047 -0.0354 -0.1258 -0.0744 -0.0884 -0.2064 -0.0710 -0.1265 -0.0552 -0.0827 -0.0857 -0.1074 -0.0964 -0.0724 -1.0365 -0.1374 -0.0280 -0.0688 -0.1078 -0.1212 -0.3203 -0.2178 -0.0963 -0.0829 -0.1186 -1.1214 -0.0743 -0.1223 -0.3142 -0.1671 -0.5452 -0.3917 -0.1395 -0.0861 -0.0909 -0.1310 -0.0721 -0.0967 -0.1067 -0.0846 -0.1099 -0.1058 -1.1960 -0.1343 -0.3918 -1.5592 -0.0963 -0.0207 -0.3589 -0.1270 -0.3066 -0.1476 -0.3148 -0.3825 -0.5541 -0.8786 -0.1029 -0.0388 -1.1131 -0.1386 -0.0500 -0.3857 -0.2711 -0.0905 -0.3121 -0.0692 -0.2562 -0.4621 -1.2151 -0.1323 -0.1569 -0.0974 -2.1318 -0.1622 -0.0880 -0.0375 -0.2092 -0.2030 -1.1890 -0.2593 -1.3278 -0.1142\n",
            "T-241\tMwamuna wa Turbaned ndi apolisi awiri aima kutsogolo kwa denga loyera ndi mulu wa matumba otaya zinyalala\n",
            "H-241\t-0.3234262764453888\t▁ M w a m u n a ▁ w a v a l a ▁ t - s h e t i ▁ a l i ▁ n d i ▁ k a p u ▁ y o b i r i w i r a ▁ a k u t h a m a n g a ▁ k u t s o g o l o ▁ k w a ▁ n d i ▁ m u n t h u ▁ w o v a l a ▁ m a t h a l a u z a ▁ o t u w a ▁ .\n",
            "D-241\t-0.3234262764453888\tMwamuna wavala t-sheti ali ndi kapu yobiriwira akuthamanga kutsogolo kwa ndi munthu wovala mathalauza otuwa .\n",
            "P-241\t-0.1346 -0.0596 -0.0889 -0.1053 -0.5805 -0.0701 -0.0930 -0.0993 -0.1424 -0.1079 -0.5233 -1.5214 -0.1139 -0.0790 -0.0995 -0.1093 -0.4618 -0.6991 -0.1009 -0.0196 -0.4919 -0.0134 -0.0524 -0.1210 -0.7981 -2.4201 -0.1199 -0.1085 -0.9280 -0.1394 -0.1089 -0.1507 -1.3403 -0.1494 -0.4560 -0.2712 -0.2597 -0.3796 -0.4157 -1.0518 -0.0847 -0.3236 -0.1028 -0.3358 -0.1069 -0.1879 -0.1028 -0.2158 -0.2185 -1.2306 -0.1076 -0.3004 -2.3409 -0.0862 -0.1902 -0.0831 -0.1285 -0.0185 -0.3863 -0.1587 -0.5048 -0.0858 -0.0853 -0.0561 -0.0774 -0.0488 -0.0961 -0.0809 -0.0846 -0.1095 -0.4226 -0.0852 -0.1257 -0.1517 -1.5128 -0.4772 -0.5768 -0.0777 -0.2218 -0.5365 -0.3004 -0.3549 -0.1076 -0.0815 -0.1335 -0.0317 -1.1995 -1.3517 -0.1139 -0.0838 -0.0993 -0.1128 -0.3904 -0.0858 -0.8476 -0.1165 -0.1296 -0.0586 -0.1026 -0.0249 -0.0576 -0.1020 -0.2130 -0.2033 -0.5398 -0.2355 -0.2895 -0.1222 -0.4461 -0.7464 -0.1060\n",
            "T-302\tAtsikana angapo ali pagulu ndipo wina akumwetulira pomwe dzuwa likuwalira kumaso kwake .\n",
            "H-302\t-0.3503594994544983\t▁ M w a m u n a ▁ w i n a ▁ a t s i k a n a ▁ a l i ▁ p a g a l i m o t o ▁ n d i p o ▁ w i n a ▁ a k u m e t u l i r a ▁ p o m w e ▁ u l i ▁ d z u w a ▁ l i l i ▁ k u m b u y o ▁ .\n",
            "D-302\t-0.3503594994544983\tMwamuna wina atsikana ali pagalimoto ndipo wina akumetulira pomwe uli dzuwa lili kumbuyo .\n",
            "P-302\t-0.1160 -1.1028 -0.4261 -0.0969 -0.0529 -0.1677 -0.1085 -0.2532 -0.1484 -0.2625 -0.6870 -0.1455 -0.0951 -0.1378 -0.1325 -0.9604 -0.3124 -0.1561 -0.2811 -0.1511 -0.0792 -0.1024 -0.1538 -0.5556 -0.4026 -0.0758 -0.0981 -0.4748 -0.2417 -2.9246 -1.0084 -0.0555 -0.1568 -0.4722 -0.1187 -0.0890 -0.0514 -0.1446 -1.7195 -0.3683 -0.1226 -0.1206 -0.0393 -0.0955 -0.2453 -0.1044 -0.0993 -0.1093 -0.1360 -0.3921 -0.1004 -0.1085 -0.0786 -0.1577 -0.4849 -0.3463 -0.1356 -0.0972 -0.1859 -0.1007 -0.1363 -0.9783 -0.1253 -0.0498 -0.4998 -0.1297 -0.1075 -1.2082 -0.5537 -0.9665 -0.1035 -2.6904 -0.0120 -0.1826 -0.1580 -0.1037 -0.1815 -0.2549 -0.0900 -1.2193 -0.1255 -0.1636 -0.4246 -0.2444 -0.0605 -0.9673 -0.1441 -0.1360 -0.0834 -0.2405 -1.4304 -0.1148\n",
            "T-245\tAzimayi awiri a ku Asia akulankhula komanso kumwa zakumwa patebulo laling'ono lozungulira .\n",
            "H-245\t-0.24873511493206024\t▁ A z i m a y i ▁ a w i r i ▁ a k u ▁ A s i a ▁ a k u l a n k h u l a ▁ k u m a s o ▁ k w a ▁ z a k u m w a ▁ p a t e b u l o ▁ l a l i n g ' o n o ▁ l o z u n g u l i r a ▁ .\n",
            "D-245\t-0.24873511493206024\tAzimayi awiri aku Asia akulankhula kumaso kwa zakumwa patebulo laling'ono lozungulira .\n",
            "P-245\t-0.1393 -0.0421 -0.0294 -0.0972 -0.1056 -0.1221 -0.0273 -0.0794 -0.1049 -0.1551 -0.0517 -0.1293 -0.0763 -0.1003 -0.1662 -0.1399 -0.4487 -0.1097 -0.7976 -0.3230 -0.0384 -0.0808 -0.1273 -0.1711 -0.1643 -0.2013 -0.0862 -0.0716 -0.1513 -0.6430 -0.0154 -0.0276 -0.0391 -0.0550 -0.1210 -0.1209 -1.0153 -1.4696 -0.0454 -0.1625 -0.7606 -0.0564 -0.1167 -0.1842 -0.8075 -0.1182 -0.2456 -0.1010 -0.1804 -0.7017 -0.2176 -0.7529 -0.1705 -0.1610 -0.1355 -0.5247 -0.1774 -0.8803 -0.0423 -0.2207 -0.0525 -0.1110 -0.0535 -0.1105 -0.3476 -0.1775 -0.0514 -0.0956 -0.8958 -0.0191 -0.5340 -0.0690 -0.0719 -0.0598 -0.1199 -1.1234 -1.3186 -1.0673 -0.0415 -0.0830 -0.0096 -0.0455 -0.0937 -0.0725 -0.0976 -0.1230 -0.4967 -0.0763 -0.1128\n",
            "T-235\tAna akusewera m'makwalala wina atanyamula mfuti pamene mkazi wachikulire akudutsa.\n",
            "H-235\t-0.32538920640945435\t▁ A n a ▁ a k u s e w e r a ▁ m ' m a k w a t a l a ▁ w i n a ▁ a t a n y a m u l a ▁ m p a n d a ▁ w o t i ▁ p a m e n e ▁ m k a z i ▁ a k u d u t s a ▁ .\n",
            "D-235\t-0.32538920640945435\tAna akusewera m'makwatala wina atanyamula mpanda woti pamene mkazi akudutsa .\n",
            "P-235\t-0.1225 -0.0736 -0.0439 -1.1069 -0.1173 -0.1336 -1.2879 -0.1123 -0.2853 -0.1047 -0.0981 -0.0713 -0.0730 -0.1113 -0.1927 -0.1427 -0.2626 -0.1460 -0.1173 -1.4960 -0.3129 -0.1680 -2.3770 -0.5873 -0.3186 -0.1423 -0.1885 -1.6112 -0.1625 -0.0882 -0.0869 -0.1956 -0.6597 -0.1126 -0.1098 -0.3776 -0.0388 -0.1174 -0.0773 -0.0735 -0.0495 -0.1081 -0.1104 -0.1813 -1.0977 -1.3466 -0.0861 -0.4399 -0.1764 -0.1300 -0.4066 -1.0491 -0.8135 -0.7359 -0.3049 -0.0577 -0.1340 -0.0670 -0.0332 -0.0586 -0.0377 -0.0992 -0.0648 -0.3845 -0.0816 -0.0360 -0.0950 -0.1477 -0.2042 -0.3074 -0.1069 -0.5179 -0.2045 -0.3916 -0.1006 -0.0842 -0.3546 -1.0916 -0.1040\n",
            "T-151\tWosewera mpira watimu yachikasu akudumphira osewera awiri a timu ya buluu pomwe osewera ena akuthamangira kumbali .\n",
            "H-151\t-0.29966023564338684\t▁ W o y e n d e r a ▁ m p i r a ▁ w a ▁ t i m u ▁ y a c h i k a s u ▁ k u d u m p h i r a ▁ o s e w e r a ▁ a w i r i ▁ o m w e ▁ a b u l u u ▁ p o m w e ▁ o s e w e r a ▁ e n a ▁ a k u t h a m a n g i r a ▁ k u t h a m a n g i r a ▁ .\n",
            "D-151\t-0.29966023564338684\tWoyendera mpira wa timu yachikasu kudumphira osewera awiri omwe abuluu pomwe osewera ena akuthamangira kuthamangira .\n",
            "P-151\t-0.1182 -1.8382 -0.1423 -0.3037 -0.0910 -0.5902 -0.0932 -0.3161 -0.3819 -0.1034 -0.1581 -0.1596 -0.2982 -0.1225 -0.0832 -0.1066 -0.1810 -0.0818 -0.0926 -0.7979 -0.4426 -1.4893 -0.0948 -0.0319 -0.0798 -0.0195 -0.1617 -0.2479 -0.1263 -0.1059 -0.0733 -0.1102 -0.0446 -0.0734 -0.1947 -1.5817 -0.1114 -0.4590 -0.1023 -0.1705 -0.0228 -0.0375 -0.1745 -0.0695 -0.1286 -0.1785 -1.0428 -0.5394 -0.0868 -0.0538 -0.0877 -0.0629 -0.1495 -0.1968 -0.5689 -0.7030 -0.1456 -0.1002 -0.1081 -0.2284 -1.9831 -0.6718 -0.1167 -0.1303 -0.1103 -0.2919 -0.3624 -0.2521 -0.0997 -0.0898 -0.0610 -0.2572 -1.8016 -0.0872 -0.7834 -0.0799 -0.1300 -0.1016 -1.5960 -1.0988 -0.0560 -0.1203 -0.1714 -0.0655 -0.1116 -0.1994 -0.2114 -0.0454 -0.0810 -0.0998 -0.1287 -0.3220 -0.0756 -0.1872 -0.0703 -0.1004 -0.0359 -0.0746 -0.0551 -0.1049 -0.6032 -0.0727 -0.0927 -0.1885 -0.8855 -0.1179 -0.9240 -0.9173 -0.0902 -0.0943 -0.0755 -0.0692 -0.1237 -0.1635 -0.2439 -0.0853 -0.3805 -1.5576 -0.0870\n",
            "T-11\tMwamuna atavala nsonga ya thanki ndi mkazi atavala pamwamba pa bikini akuvina limodzi panja ndi nyali kutsogolo kwa anthu owonerera .\n",
            "H-11\t-0.3149491548538208\t▁ M w a m u n a ▁ a t a v a l a ▁ n s o n g a ▁ y a ▁ t h a n k i ▁ a t a v a l a ▁ z o v a l a ▁ p a m w a m b a ▁ p a ▁ b e n c h i ▁ y o f i i r a ▁ y o p a n d a ▁ n d i ▁ m n y a n j a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ .\n",
            "D-11\t-0.3149491548538208\tMwamuna atavala nsonga ya thanki atavala zovala pamwamba pa benchi yofiira yopanda ndi mnyanja kutsogolo kwa nyumba .\n",
            "P-11\t-0.1330 -0.0682 -0.0499 -0.1161 -0.1174 -0.0650 -0.1016 -0.1158 -0.1639 -0.1970 -0.0535 -0.1105 -0.0187 -0.1107 -0.0790 -0.1145 -0.1125 -0.6470 -0.0789 -0.0781 -0.4469 -0.0309 -0.0991 -0.1296 -0.1194 -0.1287 -0.2620 -0.4658 -0.2076 -0.3696 -0.0659 -0.3550 -0.1265 -0.2504 -0.7834 -0.0251 -0.0979 -0.2991 -0.1174 -0.0682 -0.1216 -0.1075 -0.8234 -1.5059 -0.9056 -0.2245 -0.0791 -0.1107 -0.1189 -0.4241 -0.1075 -0.0715 -0.2060 -0.0901 -0.0731 -0.0234 -0.3459 -0.1233 -0.7785 -0.1228 -0.4967 -1.3959 -0.2045 -0.1866 -0.4592 -0.2063 -0.0972 -0.1146 -0.1543 -0.3717 -2.1919 -0.0962 -0.6260 -0.2309 -0.5219 -0.2795 -0.7057 -1.1754 -1.5909 -0.1809 -0.0498 -0.3476 -0.0834 -0.2066 -0.2934 -0.6559 -0.3491 -0.1562 -0.1610 -1.3481 -0.1632 -0.0957 -1.2778 -0.4756 -0.1454 -0.2362 -0.5593 -0.6860 -0.2940 -0.0305 -0.0728 -0.0240 -0.0741 -0.0590 -0.0708 -0.1286 -0.0518 -0.0392 -0.1166 -0.1678 -0.2512 -0.0314 -0.0935 -0.1775 -0.7605 -0.1275 -0.5377 -2.3462 -0.1044\n",
            "T-155\tMwana atakutidwa ndi utoto amakhala pakati pa thireyi za utoto wamitundumitundu wothira bwino ndi utoto .\n",
            "H-155\t-0.3379196226596832\t▁ M w a n a ▁ a k u d i k i r i d w a ▁ n d i ▁ u d o ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ n d i ▁ z a u t o t o ▁ w a m i t u n d u m i t u n d u ▁ w o t h i r a ▁ n d i ▁ u d z u ▁ .\n",
            "D-155\t-0.3379196226596832\tMwana akudikiridwa ndi udo wovala malaya achikasu ndi zautoto wamitundumitundu wothira ndi udzu .\n",
            "P-155\t-0.1187 -0.0712 -0.0431 -0.1182 -0.0730 -0.0962 -0.1406 -0.0818 -0.2136 -0.0983 -0.2786 -1.3361 -0.1815 -0.0401 -0.4840 -0.0702 -0.9626 -0.0532 -0.0733 -0.1341 -0.1385 -0.0973 -0.1206 -0.2559 -2.6475 -0.9171 -0.9825 -0.3561 -0.2722 -0.1835 -0.3331 -0.1231 -0.1051 -0.0990 -0.1018 -0.1695 -0.2335 -0.4633 -0.1145 -0.1532 -0.0864 -0.1102 -0.1833 -0.8515 -0.0651 -0.0938 -0.3132 -0.1127 -0.4001 -0.0955 -0.1826 -1.8048 -0.0760 -0.1160 -0.2534 -0.8099 -0.1602 -0.4216 -0.3985 -0.8448 -0.2321 -0.0613 -0.1733 -0.7663 -0.3784 -0.1800 -0.3216 -0.1234 -0.0714 -0.1034 -0.0334 -0.0921 -0.2176 -0.0437 -0.2910 -0.1242 -0.0622 -0.0355 -0.1370 -0.1630 -1.0622 -0.1169 -0.5235 -1.6452 -0.1795 -1.0591 -0.1065 -0.2866 -1.3686 -0.1241 -0.1088 -0.1785 -1.3477 -0.5740 -0.1233 -0.1452 -0.5543 -0.3305 -0.0937\n",
            "T-254\tMtsikana wovala chovala choyera akuseweretsa thovu pamene mayi ndi mwana wake wamkazi amaimirira pambali .\n",
            "H-254\t-0.24328762292861938\t▁ M t s i k a n a ▁ w o v a l a ▁ c h o v a l a ▁ c h o y e r a ▁ a k u s e w e r a ▁ k u t u ▁ p a m e n e ▁ m w a m u n a ▁ y e m w e ▁ a l i ▁ n d i ▁ m k a z i ▁ a t a i m i r i r a ▁ p a m b a l i ▁ .\n",
            "D-254\t-0.24328762292861938\tMtsikana wovala chovala choyera akusewera kutu pamene mwamuna yemwe ali ndi mkazi ataimirira pambali .\n",
            "P-254\t-0.1266 -0.0598 -0.0466 -0.0796 -0.0938 -0.0629 -0.1202 -0.1008 -0.1097 -0.1475 -0.0992 -0.1103 -0.0622 -0.1208 -0.0831 -0.1141 -0.1030 -0.0420 -0.0814 -0.1854 -0.0177 -0.1165 -0.0896 -0.1169 -0.0987 -0.1213 -0.0994 -0.0811 -0.0648 -0.0836 -0.1052 -0.1035 -0.1621 -0.0752 -0.0839 -0.0915 -0.0532 -0.0442 -0.1680 -0.0822 -0.0942 -0.1107 -0.1451 -2.0098 -0.1574 -0.2151 -0.4920 -0.2439 -3.0004 -0.1272 -0.0802 -0.0476 -0.0546 -0.0784 -0.1030 -0.0601 -1.1806 -0.1340 -0.5267 -0.0637 -0.0816 -0.0826 -0.2383 -0.6235 -0.0422 -0.0825 -0.0637 -0.1102 -0.1126 -0.3338 -0.9662 -0.1432 -0.1034 -0.0633 -0.0821 -0.1239 -0.0716 -0.0730 -0.4293 -0.0969 -0.0124 -0.0976 -0.1215 -0.1119 -2.8446 -0.0836 -0.8661 -0.0387 -0.0606 -0.0942 -0.0725 -0.0806 -0.1160 -0.1304 -0.1297 -0.1195 -0.3303 -1.3998 -0.0887 -0.0248 -0.0689 -0.3471 -1.2976 -0.1087\n",
            "T-301\tWosewera wa Hockey amaletsa kuwombera kwa wosewera yemwe amapikisana naye momwe osewera ena amawonera.\n",
            "H-301\t-0.269790917634964\t▁ W o s e w e r a ▁ w a ▁ h o c k e y ▁ y a m a l e s a ▁ k u w o n d e r a ▁ w o s e w e r a ▁ w o s e w e r a ▁ m a p i k i s a n o ▁ o s e w e r a ▁ e n a ▁ a m a w o n e r a ▁ .\n",
            "D-301\t-0.269790917634964\tWosewera wa hockey yamalesa kuwondera wosewera wosewera mapikisano osewera ena amawonera .\n",
            "P-301\t-0.1243 -0.1696 -0.0761 -0.0528 -0.0540 -0.0980 -0.1031 -0.0777 -0.1459 -0.1590 -0.1226 -0.3126 -0.3568 -0.9053 -0.1053 -0.0974 -0.0479 -0.1995 -0.0133 -0.2400 -0.6257 -0.1102 -0.5944 -0.1269 -0.2345 -1.2343 -0.1906 -0.2255 -0.1865 -0.2236 -0.1063 -0.7484 -0.0854 -0.3969 -1.0300 -0.0599 -0.2734 -0.1124 -0.1644 -0.8505 -0.0824 -0.0950 -0.0450 -0.0851 -0.0844 -0.0741 -0.3035 -0.1868 -1.6107 -0.9280 -0.3445 -0.1294 -0.0341 -0.1502 -0.1044 -0.1326 -0.1764 -0.3049 -0.2874 -1.7085 -0.1077 -0.1472 -0.0787 -0.0779 -0.1006 -0.0880 -0.1483 -0.1310 -0.4138 -0.1310 -0.0490 -0.0830 -0.1308 -0.0767 -0.1348 -0.1905 -0.1763 -0.0331 -0.0941 -0.1149 -0.1554 -0.6572 -0.1203 -0.1417 -0.1263 -0.3770 -0.2141 -0.9326 -0.3390 -0.2832 -0.9553 -0.1031\n",
            "T-62\tMtsikana wina watsitsi lakuda, nambala 528, wovala zofiira ndi zoyera, akukonzekera kuponya mfuti.\n",
            "H-62\t-0.2887328863143921\t▁ M t s i k a n a ▁ w i n a ▁ w a t s i t s i ▁ l a k u d a ▁ a k u j a m b u l a ▁ p a n j i n g a ▁ y o t u w a ▁ w o v a l a ▁ z o f i i r a ▁ n d i ▁ z o y e r a ▁ a k u k o n z e k e r a ▁ k u p o n y a ▁ .\n",
            "D-62\t-0.2887328863143921\tMtsikana wina watsitsi lakuda akujambula panjinga yotuwa wovala zofiira ndi zoyera akukonzekera kuponya .\n",
            "P-62\t-0.1303 -0.0585 -0.0528 -0.0874 -0.1042 -0.0852 -0.0893 -0.1389 -0.1141 -0.1341 -0.0975 -0.1228 -0.0981 -0.0920 -0.1229 -0.1162 -0.1170 -0.4674 -0.0351 -0.0821 -0.1558 -0.0699 -0.0867 -0.0876 -0.1545 -0.0994 -0.3123 -0.1041 -0.1378 -0.1094 -0.1723 -0.6776 -0.5912 -0.1141 -1.1902 -0.0960 -0.0456 -0.1304 -0.1546 -0.0704 -0.1307 -0.2034 -1.4240 -0.1620 -2.2371 -0.5398 -0.3176 -0.2292 -0.1291 -0.1078 -0.2109 -0.0200 -1.0263 -1.4862 -0.9005 -0.0844 -0.2914 -0.1997 -2.2543 -0.1290 -0.3311 -0.1399 -0.1012 -0.1007 -0.0954 -0.1103 -0.0786 -0.9480 -0.0867 -0.2178 -0.0698 -0.1622 -0.1954 -0.4165 -0.0926 -0.1065 -0.1052 -0.0269 -0.0873 -0.1049 -0.0610 -0.1200 -0.0997 -0.1731 -0.1512 -0.0580 -0.1123 -0.4396 -0.1937 -0.1192 -0.0127 -0.1705 -0.0514 -0.0611 -0.0721 -0.1062 -0.1245 -0.4478 -0.1097 -0.2564 -0.9411 -0.0985 -0.0128 -0.3953 -0.2911 -3.5177 -0.1315\n",
            "T-48\tMunthu amene wavala juzi wanyamula nsana n'kuyenda pafupi ndi kamtsikana kovala chikwama akukankha ngolo .\n",
            "H-48\t-0.311272531747818\t▁ M u n t h u ▁ a m e n e ▁ w a v a l a ▁ j u z i ▁ w a n y a m u l a ▁ m o y a n g ' a n a ▁ p a f u p i ▁ n d i ▁ k a m t s i k a n a ▁ k o m a n s o ▁ k u k h a l a ▁ k w a ▁ m p a n d o ▁ w o l u k a ▁ .\n",
            "D-48\t-0.311272531747818\tMunthu amene wavala juzi wanyamula moyang'ana pafupi ndi kamtsikana komanso kukhala kwa mpando woluka .\n",
            "P-48\t-0.1261 -0.1017 -0.0233 -0.0858 -0.0706 -0.0843 -0.0830 -0.1561 -1.3183 -0.0325 -0.0555 -0.1187 -0.0609 -0.1664 -0.1061 -0.3007 -0.0198 -0.1178 -0.0673 -0.1088 -0.1113 -1.0373 -0.0955 -0.0286 -0.0953 -0.1139 -0.1674 -0.5800 -0.0191 -0.0162 -0.1134 -0.1091 -0.0566 -0.0462 -0.1026 -0.1215 -0.9370 -0.4934 -2.0203 -0.1894 -0.0638 -0.4033 -0.0440 -0.1090 -0.1236 -0.1435 -0.1019 -1.5559 -0.1525 -0.5295 -0.1077 -0.2022 -0.1356 -0.1064 -0.1436 -0.1071 -0.1267 -0.1117 -0.1176 -0.1964 -0.4370 -0.4885 -0.0435 -0.1013 -0.0282 -0.1027 -0.1814 -0.0957 -0.2003 -0.5435 -0.5288 -0.3713 -0.1173 -0.5636 -0.1603 -0.0619 -0.0887 -0.5158 -2.2981 -0.3036 -1.0184 -0.2523 -0.0793 -0.1099 -0.0896 -1.5510 -0.5138 -0.1135 -0.3116 -0.2531 -0.8747 -0.7882 -0.1345 -0.3377 -0.1130 -0.1288 -0.5448 -0.1979 -1.4756 -0.3267 -0.9044 -0.1010 -0.5723 -0.3125 -0.1070\n",
            "T-333\tMayi wina anawerenga pepala ndi zakumwa kuchokera mu kapu ya khofi kutsogolo kwa chithunzi chojambula zithunzi .\n",
            "H-333\t-0.2920193672180176\t▁ M a y i ▁ w i n a ▁ a n a y i ▁ a k u y e n d a ▁ p a n j a ▁ n d i ▁ z a k u c h o k e r a ▁ k u t i ▁ a k u v i n a ▁ k u t s o g o l o ▁ k w a ▁ c h i t h u n z i ▁ c h o j a m b u l a ▁ z i n t h u ▁ .\n",
            "D-333\t-0.2920193672180176\tMayi wina anayi akuyenda panja ndi zakuchokera kuti akuvina kutsogolo kwa chithunzi chojambula zinthu .\n",
            "P-333\t-0.1166 -0.0997 -0.0897 -0.0391 -0.0945 -0.1366 -0.2144 -0.1019 -0.1367 -0.1028 -0.1210 -0.0776 -0.2121 -0.1303 -1.0740 -0.4856 -0.2559 -2.9515 -0.8382 -0.1717 -1.0941 -0.0708 -0.0682 -0.2180 -0.1248 -0.1494 -0.1081 -0.1676 -0.6547 -0.7179 -0.4687 -0.1798 -0.8688 -0.4993 -0.1125 -0.7593 -0.9113 -0.1498 -0.2027 -0.0718 -0.9931 -0.0714 -0.1711 -0.0705 -0.0845 -0.0600 -0.1210 -0.1419 -0.5420 -0.1600 -0.6243 -0.7132 -0.0854 -0.1933 -0.6605 -0.3925 -0.8768 -0.1350 -0.2472 -0.5818 -0.1274 -0.1560 -0.1282 -0.4076 -0.1015 -0.0647 -0.0499 -0.1017 -0.0631 -0.0808 -0.1037 -0.7798 -0.2154 -0.1195 -0.1818 -0.2837 -0.0679 -0.1014 -0.3529 -0.4342 -0.0663 -0.0823 -0.0201 -0.0903 -0.2192 -0.1304 -0.0859 -0.2755 -0.0734 -0.0650 -0.0867 -0.0460 -0.1090 -0.0933 -0.1077 -0.9319 -1.1908 -0.0691 -0.4494 -0.0197 -0.0336 -0.1093 -0.2335 -0.0761 -0.1037\n",
            "T-243\tAnthu awiri akuyang'ana njinga zamoto ziwiri zofiira pamalo pomwe pali zojambula zachipembedzo pakhoma .\n",
            "H-243\t-0.2517906427383423\t▁ A n t h u ▁ a w i r i ▁ a k u y a n g ' a n a ▁ z a n j i n g a ▁ z a m o t o ▁ z i w i r i ▁ z o f i i r a ▁ p a m a l o ▁ o m w e ▁ p a l i ▁ z o j a m b u l a j a m b u l a ▁ .\n",
            "D-243\t-0.2517906427383423\tAnthu awiri akuyang'ana zanjinga zamoto ziwiri zofiira pamalo omwe pali zojambulajambula .\n",
            "P-243\t-0.1207 -0.0319 -0.2091 -0.0747 -0.1072 -0.0827 -0.1187 -0.1434 -0.0663 -0.1258 -0.0695 -0.1108 -0.1851 -0.1073 -0.0602 -0.1041 -0.0915 -0.1345 -0.0729 -0.0623 -0.0752 -0.1067 -0.0551 -0.1102 -0.1248 -2.1703 -0.3212 -0.3138 -0.1022 -0.2842 -0.0682 -0.0195 -0.0892 -0.1315 -0.0352 -0.1176 -0.1665 -0.0234 -0.1486 -0.1426 -0.1732 -0.0672 -0.2169 -0.6550 -0.1299 -0.0460 -0.0964 -0.1385 -0.3715 -0.0626 -0.0458 -0.1130 -0.2924 -0.0572 -0.1692 -0.2571 -0.3527 -0.2748 -0.0636 -1.6314 -0.0182 -0.2131 -0.1040 -0.0759 -0.2227 -1.3340 -0.0795 -0.1017 -1.2162 -0.1703 -0.2584 -0.1080 -0.1739 -0.4886 -0.1474 -0.2352 -0.0944 -0.0483 -0.0556 -0.0829 -0.0882 -0.1363 -0.9304 -1.0206 -0.1904 -0.0879 -0.0933 -0.0522 -0.1828 -0.2687 -2.8588 -0.1283\n",
            "T-218\tWosewera amayang'ana mpira wa tenisi womwe adagunda ukuwuluka, pomwe gulu limayang'ana.\n",
            "H-218\t-0.3584744334220886\t▁ W o s e w e r a ▁ a m a y a n g ' a n a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ l o m w e ▁ a d a g u l u ▁ a k u t h a m a n g a ▁ k u d u m p h a ▁ n d i ▁ m a y i ▁ w i n a ▁ .\n",
            "D-218\t-0.3584744334220886\tWosewera amayang'ana mpira wa tenisi lomwe adagulu akuthamanga kudumpha ndi mayi wina .\n",
            "P-218\t-0.1162 -0.4084 -0.0792 -0.1319 -0.4474 -0.0710 -0.0758 -0.0776 -0.1536 -0.1348 -1.6445 -0.1270 -0.1331 -0.0551 -0.1698 -0.0784 -0.1625 -0.1451 -0.0959 -0.0682 -0.1491 -0.1028 -0.1738 -1.1827 -0.1382 -0.1189 -0.1072 -0.1592 -0.0610 -0.1278 -0.5560 -0.2618 -0.1138 -1.4990 -0.2462 -0.0589 -0.3264 -0.0977 -1.6608 -0.1277 -0.4365 -0.6690 -0.0756 -0.0820 -0.1922 -0.5420 -0.1168 -1.0718 -1.0849 -1.1837 -0.3706 -0.1859 -1.0791 -0.3090 -0.1362 -2.2244 -0.2330 -0.1428 -0.1701 -0.1086 -0.1301 -0.0701 -0.2688 -0.1846 -1.4444 -0.1414 -1.5281 -0.2605 -0.5628 -0.1088 -0.0390 -0.2025 -0.1889 -0.7299 -0.1686 -0.1195 -0.0972 -0.0651 -0.1093 -0.5234 -0.0810 -0.2808 -0.8538 -0.3582 -0.0644 -0.0904 -0.6424 -0.4393 -0.0924\n",
            "T-233\tBambo wina wovala t-sheti yabuluu akupachika chinthu padenga lalitali mopanda chitetezo ataima pansanjika ya lift .\n",
            "H-233\t-0.3378811180591583\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ t - s h e t i ▁ y a ▁ b u l u u ▁ a k u k h a l a ▁ p a ▁ c h i d u m p h a ▁ a l i ▁ n d i ▁ t h a l a u z a ▁ l i t a l i ▁ p a n j a ▁ p a ▁ s k a t e b o a r d ▁ y a i m a ▁ p a f u p i ▁ n d i ▁ k a n t h u ▁ .\n",
            "D-233\t-0.3378811180591583\tBambo wina wovala t-sheti ya buluu akukhala pa chidumpha ali ndi thalauza litali panja pa skateboard yaima pafupi ndi kanthu .\n",
            "P-233\t-0.1254 -0.0422 -0.1101 -0.0891 -0.0919 -0.0999 -0.1185 -0.0807 -0.1305 -0.1139 -0.1014 -0.1141 -0.0852 -0.1073 -0.0665 -0.1148 -0.0938 -0.1080 -0.1055 -0.3302 -0.0383 -0.0660 -0.0299 -0.9860 -0.0200 -0.0734 -0.0915 -0.0160 -0.0970 -0.7060 -0.0321 -0.0941 -0.0736 -0.1045 -0.0527 -0.1063 -0.0926 -0.2251 -0.0883 -1.4353 -1.7633 -0.1131 -0.1771 -0.1034 -0.0841 -0.5033 -0.1142 -0.4724 -0.0607 -0.0821 -0.1164 -0.3064 -0.8505 -1.4668 -0.4322 -0.1394 -0.1345 -0.1187 -1.7818 -0.2513 -0.1193 -0.1077 -0.6032 -0.2090 -0.1376 -0.1272 -1.0587 -1.2161 -0.0609 -0.1200 -0.5551 -0.1191 -0.4459 -0.0905 -0.0804 -0.2186 -1.4017 -0.1831 -0.0966 -0.0887 -0.1200 -0.1675 -1.7980 -0.1771 -0.7283 -0.6331 -0.3961 -0.1055 -1.0409 -0.1348 -0.3240 -0.8384 -1.1511 -0.1019 -0.0130 -0.0549 -0.5583 -0.0610 -0.0832 -0.0257 -0.1552 -0.1492 -0.6416 -0.1505 -1.5883 -1.2541 -0.0957 -0.1219 -0.2930 -0.1491 -1.0955 -0.0800 -0.1610 -0.1204 -0.3173 -0.5640 -0.2726 -0.1112 -0.1331 -0.4560 -0.1062 -1.3238 -0.7925 -0.1796 -0.1059 -0.2546 -1.1895 -0.1057\n",
            "T-312\tBambo wina atanyamula msana paphewa lake ndipo ananyamula ndodo ndi manja awiri, akudutsa m'madzi a mumtsinje wamatope.\n",
            "H-312\t-0.2936114966869354\t▁ B a m b o ▁ w i n a ▁ a t a n y a m u l a ▁ m s a n a ▁ a k u y e n d a ▁ p a n y a m a t a ▁ n d i p o ▁ m n y a m a t a ▁ w i n a ▁ a l i ▁ n d i ▁ d z a n j a ▁ l a m a d z i ▁ k w a m b i r i ▁ .\n",
            "D-312\t-0.2936114966869354\tBambo wina atanyamula msana akuyenda panyamata ndipo mnyamata wina ali ndi dzanja lamadzi kwambiri .\n",
            "P-312\t-0.1159 -0.1444 -0.1168 -0.0697 -0.1229 -0.0861 -0.1019 -0.0655 -0.1038 -0.0936 -0.1100 -0.1347 -0.0648 -0.0304 -0.1019 -0.0595 -0.0266 -0.0815 -0.1028 -0.0678 -0.0712 -0.0967 -0.1215 -0.2029 -0.6905 -0.4552 -0.0863 -0.1438 -0.1304 -1.8937 -1.0922 -0.6051 -0.3318 -0.3883 -0.1494 -0.0446 -1.1617 -0.1344 -0.7221 -0.1280 -2.3605 -0.4945 -0.0999 -0.2028 -0.1765 -0.4526 -0.1100 -0.1224 -0.1924 -0.1385 -0.1863 -0.0965 -0.0914 -0.0983 -0.2851 -0.4611 -0.0572 -0.1071 -0.2185 -0.0764 -0.1260 -0.1079 -0.1484 -0.2607 -0.1145 -0.1061 -0.3374 -0.1325 -0.3183 -0.7237 -0.1269 -0.0950 -0.1020 -0.0742 -0.1292 -0.0825 -2.7254 -0.0989 -0.1524 -0.2345 -0.2822 -0.1480 -0.1458 -0.0705 -0.2154 -0.5015 -0.2533 -0.8530 -0.0480 -0.1245 -0.2219 -1.8003 -0.4860 -0.1288 -0.1705 -0.4213 -0.1325 -0.1622 -0.1049 -0.3721 -0.5021 -0.1288\n",
            "T-162\tBambo wina wovala sweti yakuda akuponya mivi molunjika pa bolodi la mivi yomwe ili pakhoma pafupi ndi nsalu yofiira.\n",
            "H-162\t-0.28103363513946533\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a ▁ b u l u u ▁ a k u k o n y a ▁ m o l o ▁ n d i ▁ n j i n g a ▁ y a b u l u u ▁ n d i ▁ j e k e t e ▁ y o m w e ▁ i l i ▁ p a f u p i ▁ n d i ▁ n s a l u ▁ y o f i i r a ▁ .\n",
            "D-162\t-0.28103363513946533\tBambo wina wovala yunifolomu ya buluu akukonya molo ndi njinga yabuluu ndi jekete yomwe ili pafupi ndi nsalu yofiira .\n",
            "P-162\t-0.1396 -0.0312 -0.1107 -0.0741 -0.0690 -0.0796 -0.1369 -0.0713 -0.1585 -0.0775 -0.1015 -0.1222 -0.2723 -0.0775 -0.0455 -0.1080 -0.0834 -0.1043 -0.1093 -1.6169 -0.0939 -0.0915 -0.0463 -0.2115 -0.2520 -0.0697 -0.0934 -0.1999 -0.0530 -0.1343 -0.1046 -0.1458 -0.6705 -0.7509 -0.2893 -0.1263 -0.1459 -0.0444 -0.1118 -0.1199 -0.0689 -0.0951 -0.5218 -0.3010 -0.1345 -1.0346 -0.1100 -0.1142 -0.2221 -1.4217 -0.3135 -0.4304 -0.3554 -0.3555 -0.1361 -0.1242 -0.1403 -1.4983 -1.9952 -0.0972 -0.2515 -0.1332 -0.0896 -0.1345 -0.4170 -0.1623 -0.5829 -0.1170 -0.0575 -0.1465 -0.0364 -0.1298 -0.4564 -0.0702 -0.1119 -0.2270 -2.8221 -0.1529 -0.5228 -0.1051 -0.0326 -0.1263 -0.1087 -0.4349 -0.1263 -1.3265 -0.1179 -0.1227 -0.0977 -0.1168 -0.0667 -0.1062 -0.0878 -0.1658 -0.1609 -0.6190 -0.1050 -0.1619 -0.0815 -0.1118 -0.0534 -0.0880 -0.0991 -0.0813 -0.5126 -1.4363 -0.1455 -0.0866 -0.0419 -0.1574 -0.0694 -0.0714 -0.5511 -0.0876 -0.2594 -0.0722 -0.2464 -0.7494 -0.9881 -0.1089\n",
            "T-10\tAmuna awiri ayimirira pafupi ndi Msika wa Pike Place pomwe banja lakumbuyo likujambula chithunzi chaukwati.\n",
            "H-10\t-0.3020630180835724\t▁ A m u n a ▁ a w i r i ▁ a i m i r i r a ▁ p a f u p i ▁ n d i ▁ k a b u d u l a ▁ w o s e w e r a ▁ p a n j a ▁ k u m b u y o ▁ k w a k e ▁ k u j a m b u l a ▁ c h i t h u n z i ▁ .\n",
            "D-10\t-0.3020630180835724\tAmuna awiri aimirira pafupi ndi kabudula wosewera panja kumbuyo kwake kujambula chithunzi .\n",
            "P-10\t-0.1107 -0.0608 -0.1036 -0.0659 -0.0768 -0.0835 -0.1215 -0.1487 -0.0969 -0.1401 -0.0670 -0.1074 -0.2754 -0.1132 -2.0391 -0.0678 -0.0973 -0.1378 -0.0946 -0.0658 -0.1100 -0.1316 -0.0208 -0.1204 -2.1858 -0.0745 -0.0729 -0.1139 -0.1133 -0.0361 -0.0694 -0.1028 -0.1023 -0.9567 -0.3219 -2.3257 -0.7258 -0.3443 -0.1931 -0.0650 -0.3032 -0.1278 -0.3879 -1.0727 -0.6436 -0.2618 -0.7601 -0.0804 -0.0690 -0.3936 -0.2025 -2.4610 -0.1916 -0.0403 -0.0587 -0.1304 -0.1933 -0.3574 -0.1499 -0.2033 -0.0290 -0.0729 -0.0501 -0.0668 -0.1387 -0.1636 -0.6493 -0.1596 -0.3495 -0.0527 -0.2600 -0.8305 -0.0892 -1.8502 -0.1046 -0.0984 -0.0314 -0.0850 -0.0681 -0.1168 -0.1988 -0.1033 -0.0889 -0.1180 -0.0613 -0.0229 -0.0572 -0.1230 -0.0132 -0.1015 -0.4744 -1.0071 -0.1070\n",
            "T-143\tAnthu awiri akwera pamwamba pa makwerero pamene mwamuna wina wovala buluu waima kuseri kwa makwerero apakati .\n",
            "H-143\t-0.2531352937221527\t▁ A n t h u ▁ a w i r i ▁ a k u y a n g ' a n a ▁ p a m w a m b a ▁ p a ▁ m a f u n d e ▁ o m w e ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ k u t s e r i ▁ k w a ▁ m a k w e r e r o ▁ .\n",
            "D-143\t-0.2531352937221527\tAnthu awiri akuyang'ana pamwamba pa mafunde omwe wina wovala malaya obiriwira kutseri kwa makwerero .\n",
            "P-143\t-0.1199 -0.0439 -0.0546 -0.0727 -0.1076 -0.0885 -0.1168 -0.1292 -0.1477 -0.1285 -0.0737 -0.1019 -0.1944 -0.3663 -0.1259 -0.1719 -0.3112 -0.2555 -0.8844 -0.3321 -0.0524 -0.0990 -0.0559 -0.0979 -0.1218 -0.1022 -0.1228 -0.8187 -0.3301 -0.0693 -0.0616 -0.0407 -0.0761 -0.1333 -0.0525 -0.1203 -0.1392 -0.5341 -0.9739 -0.3869 -0.2382 -0.0548 -0.5728 -0.1141 -0.1313 -0.5005 -1.6638 -0.1779 -0.0985 -0.1388 -1.7425 -0.1022 -0.1623 -0.1172 -0.1580 -0.1136 -0.1570 -0.0261 -0.1098 -0.1003 -0.1239 -0.1219 -0.2796 -0.1106 -0.3721 -0.1131 -0.0358 -0.0938 -0.1196 -0.2840 -1.4277 -0.2020 -0.1124 -0.0802 -0.0289 -0.1071 -0.1060 -0.1634 -0.2211 -0.0509 -0.5424 -0.4636 -0.0760 -0.2839 -1.3465 -0.6033 -0.1495 -0.2441 -0.0387 -0.1233 -0.3199 -0.2568 -0.0905 -0.1646 -0.5246 -0.0625 -0.1891 -0.2388 -0.2717 -0.1202 -0.2087 -0.7939 -0.1114\n",
            "T-296\tMayi wina wovala malaya ofiira ndi tsitsi lakuda atakhala pampando akumwetulira mtsikana wovala t-shirt ya Hello Kitty.\n",
            "H-296\t-0.2719464600086212\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ s k a t e b o a r d ▁ a t a k h a l a ▁ p a m p a n d o ▁ a k u m e t u l i r a ▁ w o v a l a ▁ c h i s o t i ▁ c h o y e r a ▁ .\n",
            "D-296\t-0.2719464600086212\tMayi wina wovala malaya ofiira ndi skateboard atakhala pampando akumetulira wovala chisoti choyera .\n",
            "P-296\t-0.1385 -0.0505 -0.0951 -0.0396 -0.1091 -0.1299 -0.0816 -0.1612 -0.1087 -0.0956 -0.1444 -0.1835 -0.1086 -0.0722 -0.1005 -0.0780 -0.1086 -0.1210 -0.0793 -0.1137 -0.0579 -0.1067 -0.0531 -0.0912 -0.1049 -0.0790 -0.0270 -0.1331 -0.2111 -0.0774 -0.1626 -0.1567 -0.1202 -0.1370 -0.1101 -0.0770 -0.6146 -2.8185 -0.1403 -0.1213 -0.1049 -1.3200 -0.2999 -0.0545 -0.0639 -0.0872 -0.2610 -0.1485 -0.2317 -0.1308 -0.0263 -0.0193 -0.1191 -0.0536 -0.1091 -0.1012 -0.0836 -0.1210 -0.2500 -0.6689 -0.1360 -0.0527 -0.0172 -0.0487 -0.0815 -0.7564 -0.1053 -0.1321 -0.2514 -0.8342 -0.5228 -0.2920 -1.0696 -0.1250 -0.4313 -0.0750 -0.1142 -2.7663 -0.1762 -0.4667 -0.1084 -0.0728 -0.1237 -0.0820 -1.3553 -0.1114 -0.1466 -0.2250 -0.5606 -0.0204 -0.0584 -0.2182 -0.4144 -0.0905 -1.3480 -1.5467 -0.1570 -0.1820 -0.0936 -0.3532 -0.1256 -0.1165\n",
            "T-25\tMnyamata wina wovala malaya achikasu wakwera bulu womangidwa pangolo atanyamula anyamata awiri achikasu mumsewu .\n",
            "H-25\t-0.25527140498161316\t▁ M n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ w a k h a l a ▁ b u l u u ▁ w o m a n g i d w a ▁ p a m p a n d o ▁ a t a n y a m u l a ▁ k a m n y a m a t a ▁ k a k a n g ' o n o ▁ .\n",
            "D-25\t-0.25527140498161316\tMnyamata wina wovala malaya achikasu wakhala buluu womangidwa pampando atanyamula kamnyamata kakang'ono .\n",
            "P-25\t-0.1307 -0.0691 -0.0976 -0.0494 -0.1205 -0.0840 -0.0993 -0.0479 -0.1125 -0.1227 -0.1897 -0.1046 -0.0824 -0.0962 -0.1116 -0.1025 -0.1124 -0.0766 -0.1126 -0.0842 -0.1171 -0.1071 -0.1084 -0.1347 -0.0619 -0.1152 -0.0736 -0.1015 -0.0981 -0.1957 -0.2032 -0.0932 -0.0943 -0.0435 -0.1225 -0.0382 -0.0617 -0.0965 -1.6571 -0.2666 -0.4567 -0.3294 -0.0901 -0.0681 -0.1036 -0.1068 -2.8173 -0.4640 -0.2516 -0.2002 -0.0804 -0.1274 -1.1936 -0.7003 -0.1628 -0.2609 -0.0624 -0.8064 -0.0920 -0.0182 -0.0357 -0.1181 -0.1267 -0.1710 -0.1333 -0.2793 -1.3707 -0.1995 -0.0686 -0.1284 -0.1071 -0.1063 -0.6789 -0.6108 -0.1312 -0.0707 -0.0180 -0.1104 -0.0764 -0.1109 -0.0495 -0.1191 -0.1149 -0.7062 -0.1148 -0.5063 -1.0817 -0.0396 -0.1214 -0.0761 -0.1079 -0.0440 -0.0966 -0.1164 -0.1309 -0.7658 -0.9724 -0.2857 -0.1530 -0.5633 -0.5214 -0.0699 -0.0432 -0.0609 -0.1136 -1.3927 -0.1062\n",
            "T-103\tBambo wina wadazi akuyesera kumenya mpira wa basketball pamasewera pomwe anthu ali pamalopo akuwonera.\n",
            "H-103\t-0.30136197805404663\t▁ B a m b o ▁ w i n a ▁ w a t a v a l a ▁ z i p e w a ▁ a k u y e n d a ▁ m u m l e n g a l e n g a ▁ w a ▁ b a s k e t b a l l ▁ p a m e n e ▁ a n t h u ▁ e n a ▁ a k u p o n y e r a ▁ .\n",
            "D-103\t-0.30136197805404663\tBambo wina watavala zipewa akuyenda mumlengalenga wa basketball pamene anthu ena akuponyera .\n",
            "P-103\t-0.1225 -0.0833 -0.1188 -0.0684 -0.0983 -0.1063 -0.1233 -0.0630 -0.1153 -0.0820 -0.1031 -0.1177 -0.1338 -1.3726 -0.7380 -0.2425 -0.5111 -0.1131 -0.0905 -0.1194 -0.0965 -0.6130 -0.1239 -1.2034 -0.1360 -0.2839 -0.1731 -0.1168 -0.3278 -0.0900 -0.1109 -0.4263 -0.1621 -0.6454 -0.1714 -0.1204 -0.1105 -0.3235 -0.4274 -0.2105 -2.0072 -0.0577 -0.3843 -0.1549 -0.0711 -0.3123 -0.1002 -0.6217 -0.1143 -0.0667 -0.1812 -0.3259 -0.1441 -0.2950 -0.2756 -0.0597 -0.0122 -0.9634 -0.1993 -0.0373 -0.1724 -0.0851 -0.0455 -0.4771 -0.3602 -0.0926 -0.3866 -0.4828 -1.6651 -0.0410 -0.1432 -0.1225 -0.5879 -0.4239 -0.0208 -0.0675 -0.0836 -0.0745 -0.5663 -0.1313 -0.0783 -0.1118 -0.1144 -0.9150 -0.1023 -0.6225 -2.8861 -0.0623 -0.0177 -0.1750 -0.0919 -0.0999 -0.2408 -0.2019 -0.0994\n",
            "T-209\tBambo wina wovala uta wopangidwa ndi dola imodzi ndipo wavala magalasi akuyang'ana mu kamera .\n",
            "H-209\t-0.26367780566215515\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ g a l u ▁ w a i m a ▁ p a f u p i ▁ n d i ▁ m o d z i ▁ w o v a l a ▁ m a g a l a s i ▁ a k u y a n g ' a n a ▁ m u ▁ k a m e r a ▁ .\n",
            "D-209\t-0.26367780566215515\tBambo wina wovala malaya abuluu ndi galu waima pafupi ndi modzi wovala magalasi akuyang'ana mu kamera .\n",
            "P-209\t-0.1298 -0.0883 -0.1238 -0.0737 -0.0725 -0.0930 -0.1520 -0.0810 -0.1556 -0.0809 -0.1034 -0.1318 -0.0906 -0.1092 -0.0666 -0.1211 -0.0899 -0.1174 -0.1099 -2.3780 -0.1427 -0.1430 -0.1139 -0.0705 -0.0961 -0.1228 -0.1361 -0.7049 -0.0740 -0.0895 -0.0880 -0.0355 -0.1276 -1.6295 -0.0931 -0.0930 -0.3393 -2.3896 -0.5838 -0.0470 -0.4795 -0.1088 -0.2730 -0.1535 -0.7072 -0.1989 -0.2146 -0.0936 -0.8530 -0.2435 -0.8439 -0.1622 -0.1499 -0.1139 -0.0898 -0.0815 -0.0580 -0.0929 -0.1062 -0.1596 -1.0331 -0.1184 -0.0976 -0.0859 -0.1549 -1.1465 -0.1569 -0.0559 -0.1074 -0.0829 -0.1037 -0.1046 -0.1598 -0.1603 -1.1308 -0.1123 -0.0820 -0.1047 -0.1151 -0.0779 -0.1426 -0.1488 -0.3199 -0.1300 -0.1474 -0.1189 -0.1095 -0.2372 -0.0986 -0.0935 -0.1035 -0.1062 -0.1128 -0.1518 -1.2305 -0.8180 -0.0839 -0.2214 -0.0421 -0.1012 -0.0405 -0.1008 -0.9905 -0.0700 -0.1037\n",
            " 46% 6/13 [00:16<00:15,  2.22s/it, wps=1030]T-92\tBambo amene akusuta ndudu aima ndi mwamuna wina kutsogolo kwa ndudu m'chikwama chowonetsera .\n",
            "H-92\t-0.2934936583042145\t▁ B a m b o ▁ a m e n e ▁ a k u t h a m a n g a ▁ m ' t u l u k a ▁ n d i ▁ m w a m u n a ▁ w i n a ▁ k u t s o g o l o ▁ k w a ▁ m a c h i k w a n g w a n i ▁ .\n",
            "D-92\t-0.2934936583042145\tBambo amene akuthamanga m'tuluka ndi mwamuna wina kutsogolo kwa machikwangwani .\n",
            "P-92\t-0.1272 -0.2715 -0.1165 -0.0767 -0.0853 -0.0772 -0.1363 -0.1390 -0.2490 -0.1206 -0.0696 -0.0828 -0.1197 -0.0898 -0.1500 -0.1172 -0.6133 -0.4618 -0.1153 -0.5239 -0.0792 -0.0942 -0.2646 -0.3239 -0.1572 -0.4666 -0.4939 -2.3317 -0.5096 -0.6865 -0.1607 -1.3481 -0.3496 -0.1686 -1.2649 -0.0625 -0.1281 -0.1698 -0.0712 -0.0381 -0.1008 -0.1324 -0.0679 -0.0834 -0.0888 -0.1299 -0.1750 -0.0889 -0.0766 -0.1101 -0.1243 -1.6713 -0.0749 -0.2474 -0.1096 -0.0611 -0.0403 -0.0971 -0.0752 -0.0709 -0.1173 -0.0409 -0.0894 -0.1163 -0.1123 -0.2163 -0.1243 -1.0830 -0.0820 -0.4380 -1.7369 -0.7523 -0.0916 -0.4626 -0.8110 -0.0351 -0.0869 -0.0673 -0.0734 -0.1270 -0.7574 -0.1075\n",
            "T-71\tMayi wamng'ono wa brunette wakhala pansi, atanyamula mwana yemwe akutafuna mphete yamitundu yosiyanasiyana.\n",
            "H-71\t-0.3110712766647339\t▁ M a y i ▁ w a m n g ' o n o ▁ w o v a l a ▁ t h u k u t a ▁ l o k h a l a ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ a k u j a m b u l a ▁ c h i n t h u ▁ m ' m p h e p e t e ▁ y o s i y a n a s i y a n a ▁ .\n",
            "D-71\t-0.3110712766647339\tMayi wamng'ono wovala thukuta lokhala ndi malaya oyera akujambula chinthu m'mphepete yosiyanasiyana .\n",
            "P-71\t-0.1260 -0.1140 -0.0728 -0.0780 -0.1068 -0.1319 -0.0930 -0.6783 -0.2197 -0.2425 -0.1160 -0.0754 -0.0859 -0.0786 -0.0621 -0.1538 -0.0508 -0.3029 -0.3033 -0.1097 -0.0941 -0.1010 -0.1088 -2.2330 -1.1687 -0.1328 -0.6328 -0.5807 -0.0742 -0.0811 -0.1143 -0.0527 -0.9185 -0.4675 -0.0550 -0.0982 -0.0806 -0.0940 -0.0988 -0.1221 -1.0552 -0.1061 -0.0706 -0.5697 -0.4811 -2.1767 -0.1130 -0.0316 -0.0876 -0.1048 -1.3844 -0.0922 -0.0557 -0.3551 -0.0889 -0.2122 -0.0997 -0.1129 -0.0927 -1.0604 -0.0981 -0.1966 -0.1148 -0.0836 -0.0511 -0.0912 -0.1511 -2.5019 -0.1058 -0.1786 -1.0898 -0.9215 -0.0268 -0.0526 -0.1048 -0.4779 -0.2421 -0.6460 -0.1230 -0.0127 -0.0759 -0.0349 -0.1847 -0.0477 -0.1735 -0.0827 -3.0118 -0.6324 -0.1395 -0.0598 -0.0032 -0.1364 -0.1081 -0.0820 -0.0159 -0.0700 -0.0139 -0.1498 -0.0618 -0.0756 -0.4789 -0.1647 -0.1060\n",
            "T-346\tMtsikana wovala magalasi agwire mtsikana wa msinkhu womwewo atavala thukuta lofiira ndi magalasi achikasu .\n",
            "H-346\t-0.25230804085731506\t▁ M t s i k a n a ▁ w o v a l a ▁ m a g a l a s i ▁ a b u l a u n i ▁ a k u w a l a ▁ m k a z i ▁ w o m w e ▁ w a v a l a ▁ t h u k u t a ▁ l o f i i r a ▁ n d i ▁ m a g a l a s i ▁ a c h i k a s u ▁ .\n",
            "D-346\t-0.25230804085731506\tMtsikana wovala magalasi abulauni akuwala mkazi womwe wavala thukuta lofiira ndi magalasi achikasu .\n",
            "P-346\t-0.1100 -0.4953 -0.0222 -0.1214 -0.1180 -0.0529 -0.1251 -0.0893 -0.1175 -0.1311 -0.1102 -0.1080 -0.0559 -0.1257 -0.0776 -0.1224 -0.1028 -0.0800 -0.1126 -0.1564 -0.3515 -0.0802 -0.1208 -0.0387 -0.0857 -0.1533 -0.1130 -2.3042 -0.1037 -0.0659 -0.1256 -0.0779 -0.1144 -0.1319 -0.1249 -0.9684 -0.1314 -0.0997 -0.5762 -0.2259 -0.0867 -0.1078 -0.1373 -0.1214 -1.8129 -1.2149 -0.3804 -0.1070 -0.1331 -0.0760 -0.5435 -0.6418 -0.4682 -0.0894 -0.1249 -1.0980 -0.1646 -0.0955 -0.0976 -0.1172 -0.1174 -0.1054 -0.2837 -0.3042 -0.1874 -0.1874 -0.0454 -0.0184 -0.0926 -0.1290 -0.0312 -1.0987 -0.0408 -0.1242 -0.2176 -0.0719 -0.1739 -0.2186 -0.2028 -0.0853 -0.1320 -0.0854 -0.0901 -0.1066 -0.4178 -0.1559 -0.1529 -0.1379 -0.0277 -0.0700 -0.2036 -0.7132 -2.2350 -0.2007 -0.1050 -0.0493 -0.1001 -0.0577 -0.1003 -0.6463 -0.0570 -0.1095\n",
            "T-30\tWosewera mpira wa jersey yobiriwira akulandira mpira, pamene wosewera mpira wa jersey yoyera wagona pansi.\n",
            "H-30\t-0.2757779061794281\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ j e r s e y ▁ y o b i r i w i r a ▁ a k u l a n k h u l a ▁ n d i ▁ m p i r a ▁ p a m e n e ▁ w o s e w e r a ▁ w a ▁ j e r s e y ▁ y o y e r a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-30\t-0.2757779061794281\tWosewera mpira wa jersey yobiriwira akulankhula ndi mpira pamene wosewera wa jersey yoyera kumbuyo kwake .\n",
            "P-30\t-0.1165 -0.0746 -0.0698 -0.0802 -0.8333 -0.0405 -0.0943 -0.0782 -0.1077 -0.1358 -0.0534 -0.0558 -0.1247 -0.0734 -0.1034 -0.1495 -0.0925 -0.1185 -0.2835 -0.1187 -0.0611 -0.2807 -0.8759 -0.3746 -0.0569 -0.1068 -0.0143 -0.2183 -0.5289 -0.0850 -0.0546 -0.1134 -0.0267 -0.1190 -0.1561 -0.0848 -0.2184 -0.0712 -0.0868 -0.0901 -0.3041 -0.8591 -0.0980 -0.3053 -0.0969 -0.0510 -0.0319 -0.1146 -0.1530 -0.1896 -0.0703 -0.1091 -0.1754 -2.8071 -0.2222 -0.1846 -0.0803 -0.0976 -0.1779 -0.1190 -0.1453 -0.0904 -0.0680 -0.0963 -0.1173 -0.1141 -0.2007 -0.1311 -0.0957 -0.1954 -0.0876 -0.1003 -0.0633 -0.0950 -0.1773 -0.3653 -0.2738 -1.0813 -1.1594 -0.1488 -0.4729 -0.9290 -0.2259 -0.1450 -0.1431 -0.5396 -0.1000 -0.6633 -0.1057 -0.0810 -0.0943 -0.1820 -2.5896 -0.4845 -0.2204 -0.8764 -0.1290 -0.0793 -0.0862 -0.2091 -0.6165 -0.1833 -0.1436 -1.8236 -0.1400 -0.9083 -0.0318 -0.0996\n",
            "T-112\tMayi wachikulire wakhala patebulo atavala blazer yofiirira kudikirira mbale yake ya pasitala .\n",
            "H-112\t-0.3303241431713104\t▁ M a y i ▁ w a c h i k u l i r e ▁ w a k h a l a ▁ p a t e b u l o ▁ l a ▁ b u l u u ▁ a t a i m a ▁ p a f u p i ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ e n a ▁ k u m b a l i ▁ k w a ▁ s i t a l a ▁ .\n",
            "D-112\t-0.3303241431713104\tMayi wachikulire wakhala patebulo la buluu ataima pafupi ndi gulu la anthu ena kumbali kwa sitala .\n",
            "P-112\t-0.1299 -0.0447 -0.0994 -0.0558 -0.0943 -0.1320 -0.0648 -0.1227 -0.1137 -0.0950 -0.0983 -0.0462 -0.0916 -0.1753 -0.0844 -0.0493 -0.0659 -0.1606 -0.3065 -0.2438 -0.2818 -0.0461 -0.1074 -0.0573 -0.1106 -0.1116 -0.1231 -0.1195 -0.8747 -0.0819 -0.0282 -0.0460 -0.0732 -0.0779 -0.0911 -0.2714 -1.2571 -0.2957 -1.1679 -1.0061 -0.0879 -0.2713 -0.0461 -0.1409 -2.1507 -0.2125 -0.1330 -1.8491 -0.4640 -0.1781 -0.1331 -0.8340 -0.1994 -0.2854 -0.2527 -0.1481 -0.1432 -0.1184 -0.2516 -0.0962 -0.1499 -0.0984 -1.1389 -0.1061 -0.9908 -0.0849 -0.1368 -0.0968 -0.1048 -0.3998 -1.3384 -1.5160 -0.0920 -0.1675 -0.1164 -0.1036 -2.1576 -0.1194 -0.0755 -0.1572 -0.8111 -0.3176 -0.5244 -0.0232 -0.2394 -0.1934 -0.6598 -0.1588 -2.1539 -0.0578 -0.1404 -0.2173 -0.3175 -0.1476 -0.2075 -0.3118 -0.0598 -0.4552 -0.5213 -0.0945 -0.1010\n",
            "T-169\tGulu la amuna linakwera galimoto ya buluu m'chipululu itanyamula zikwama, zipewa, makwerero ndi zinthu zina .\n",
            "H-169\t-0.28398236632347107\t▁ G u l u ▁ l a ▁ a m u n a ▁ l i n a ▁ l i k u y a n g ' a n a ▁ m u t u ▁ y a ▁ b u l u u ▁ n d i ▁ t a n y a m u l a ▁ m a s i t e p e ▁ w a ▁ m a s e w e r a ▁ n d i ▁ z i n t h u ▁ .\n",
            "D-169\t-0.28398236632347107\tGulu la amuna lina likuyang'ana mutu ya buluu ndi tanyamula masitepe wa masewera ndi zinthu .\n",
            "P-169\t-0.1155 -0.0794 -0.0781 -0.0807 -0.0786 -0.1016 -0.0651 -0.1155 -0.0846 -0.1456 -0.1169 -0.0898 -0.0653 -0.1063 -0.1285 -0.1231 -0.0950 -0.0726 -0.0826 -0.8723 -0.4977 -0.2032 -2.4047 -0.0924 -0.1160 -0.3766 -0.1303 -0.0920 -0.0622 -0.0998 -0.1426 -0.2294 -0.0957 -0.2032 -0.2819 -2.0377 -0.0635 -0.0819 -0.0958 -0.0797 -1.0105 -0.8871 -0.0734 -0.0696 -0.1346 -0.0547 -0.1667 -0.5951 -0.1025 -0.1393 -0.2882 -1.5608 -0.2582 -0.0855 -0.0286 -0.0934 -0.0981 -0.0887 -0.0660 -0.1239 -0.1113 -0.1066 -0.1068 -0.0470 -0.0984 -0.9379 -0.0591 -0.8828 -0.0561 -0.1254 -1.7477 -0.1176 -0.7716 -0.3535 -0.0657 -0.0914 -0.8527 -0.0957 -0.0808 -0.1043 -0.2112 -0.2052 -0.9110 -0.0929 -0.1153 -0.0792 -0.0472 -0.0688 -0.4581 -0.8936 -0.1292 -0.0984 -0.2281 -0.5198 -0.0996\n",
            "T-55\tMnyamata akanyamula ndi kunyamula mfuti ya makina, mnyamata wamkulu pang'ono kuposa iye akuveka chipewa pamutu pake .\n",
            "H-55\t-0.34858277440071106\t▁ M n y a m a t a ▁ a t a n y a m u l a ▁ m w a n a ▁ n d i ▁ k u n y a m u l a ▁ m f u t i ▁ y a ▁ m n y a m a t a ▁ w o m w e ▁ u l i ▁ p a f u p i ▁ n d i ▁ k a m w a ▁ p a k e ▁ .\n",
            "D-55\t-0.34858277440071106\tMnyamata atanyamula mwana ndi kunyamula mfuti ya mnyamata womwe uli pafupi ndi kamwa pake .\n",
            "P-55\t-0.1234 -0.0548 -0.0979 -0.0632 -0.0960 -0.0868 -0.0968 -0.0563 -0.0886 -0.1066 -0.2199 -0.3429 -0.1016 -0.4167 -0.0269 -0.1044 -0.1059 -0.0635 -0.0848 -0.0996 -0.0885 -0.3298 -0.5611 -0.1111 -0.0539 -0.0820 -0.1242 -0.3556 -0.1105 -0.0928 -0.5367 -0.5815 -1.0352 -1.0284 -0.0227 -0.0924 -0.0634 -0.0635 -0.0363 -0.0970 -0.0796 -0.1752 -2.4239 -0.0841 -0.7695 -0.0716 -0.1080 -0.1426 -0.1384 -0.7740 -0.5376 -2.7002 -0.2504 -0.1100 -0.0409 -0.0906 -0.0330 -0.1026 -0.1287 -0.1606 -0.5277 -0.3184 -0.6677 -0.0703 -0.1017 -0.7328 -0.0805 -0.1037 -0.0912 -1.7202 -0.2087 -1.6981 -0.1111 -0.0727 -0.1448 -0.1049 -0.6778 -0.8489 -0.1132 -0.1084 -0.2410 -0.1532 -1.3159 -1.6967 -0.0806 -0.1527 -0.7589 -0.2022 -1.2211 -0.1508 -0.2884 -0.7121 -0.1175\n",
            "T-98\tAnthu asanu adadikirira pamzere pomwe bambo wovala jekete labuluu akulipira ndalama .\n",
            "H-98\t-0.2970610558986664\t▁ A n t h u ▁ a s a n u ▁ a d a d i k i r i r a ▁ p a m z e r e ▁ p a m e n e ▁ m p a n d o ▁ w o v a l a ▁ j e k e t e ▁ y a b u l u u ▁ a k u l i k i r a ▁ k u m b u y o ▁ .\n",
            "D-98\t-0.2970610558986664\tAnthu asanu adadikirira pamzere pamene mpando wovala jekete yabuluu akulikira kumbuyo .\n",
            "P-98\t-0.1242 -0.0427 -0.1651 -0.0318 -0.1148 -0.0771 -0.0970 -0.1364 -0.2043 -0.0920 -0.0383 -0.0793 -0.1294 -0.2123 -1.3018 -0.1728 -1.7838 -0.8768 -0.6028 -0.0512 -0.2392 -0.0789 -0.3278 -0.1159 -0.1511 -0.1438 -0.1298 -0.7530 -0.0646 -0.0965 -0.0296 -0.0588 -0.2268 -0.2859 -0.3032 -0.2177 -2.4902 -0.0715 -0.1693 -0.1288 -0.6329 -0.4205 -0.4683 -0.2963 -0.5947 -0.1789 -0.0832 -0.2576 -0.0990 -0.0289 -0.1001 -0.0974 -0.1012 -0.1010 -0.0148 -0.2300 -0.0671 -0.1256 -0.0316 -0.1906 -0.0877 -1.2871 -0.1149 -0.6570 -0.1416 -0.0439 -0.0745 -0.0355 -0.1518 -0.0928 -0.1317 -0.1140 -0.9176 -0.0926 -0.7976 -0.0949 -0.2666 -0.6316 -0.1727 -1.2887 -0.1673 -0.8645 -0.0636 -0.2033 -0.1134 -0.0715 -0.3361 -0.7601 -0.1280\n",
            "T-170\tKhamu lalikulu la anthu , ena okhala ndi mbendera zobiriwira , zoyera ndi zofiirira zamizeremizere .\n",
            "H-170\t-0.2318713515996933\t▁ K h a m u ▁ l a l i k u l u ▁ l a ▁ a n t h u ▁ l e n a ▁ o k h a l a ▁ n d i ▁ n d i ▁ z o b i r i w i r a ▁ z o y e r a ▁ n d i ▁ z o f i i r a ▁ z a m i z e r e ▁ .\n",
            "D-170\t-0.2318713515996933\tKhamu lalikulu la anthu lena okhala ndi ndi zobiriwira zoyera ndi zofiira zamizere .\n",
            "P-170\t-0.1272 -0.3503 -3.1776 -0.1198 -0.0562 -0.0677 -0.0778 -0.0518 -0.1011 -0.0421 -0.1658 -0.1780 -0.0867 -0.0180 -0.1019 -0.1296 -0.1436 -0.1221 -0.0761 -0.0777 -0.0302 -0.0368 -0.0874 -0.0716 -0.1063 -0.5470 -0.9639 -0.0715 -0.0852 -0.1430 -1.0564 -0.1951 -0.0735 -0.1156 -0.0481 -0.0946 -0.1044 -0.0485 -0.0787 -0.1132 -0.0717 -0.3580 -0.1467 -0.8902 -0.1123 -0.1492 -0.0594 -0.1768 -0.0708 -0.0619 -0.0750 -0.1096 -0.0992 -0.0677 -0.1045 -0.1809 -0.0866 -0.0475 -0.5534 -0.1035 -0.0662 -0.0944 -0.2035 -0.4925 -0.1321 -0.1136 -0.0901 -0.0176 -0.2718 -0.1996 -0.1077 -0.1663 -0.0702 -0.5849 -0.3046 -0.6017 -0.4583 -0.2599 -0.2794 -0.3792 -0.1571 -0.0679 -0.0522 -1.3230 -0.4582 -0.1221\n",
            "T-130\tMwamuna wavala malaya ofiira, pamene mkazi waima naye ali ndi mikwingwirima yofiirira m'tsitsi lake .\n",
            "H-130\t-0.2952965795993805\t▁ M w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ n d i ▁ m a y i ▁ w i n a ▁ y e m w e ▁ a k u g w i r a ▁ n t c h i t o ▁ y o f i i r a ▁ .\n",
            "D-130\t-0.2952965795993805\tMwamuna wovala malaya ofiira wovala malaya achikasu ndi mayi wina yemwe akugwira ntchito yofiira .\n",
            "P-130\t-0.1163 -0.0476 -0.0453 -0.0986 -0.1084 -0.0720 -0.0905 -0.1029 -0.1361 -0.1320 -0.1175 -0.4448 -0.1545 -0.0750 -0.1314 -0.1016 -0.0639 -0.1098 -0.0435 -0.1145 -0.0619 -0.0995 -0.0951 -0.0801 -0.2772 -0.0920 -0.1494 -0.0983 -0.1201 -0.1583 -1.5929 -0.2029 -0.2353 -0.1262 -0.0813 -0.1015 -0.0982 -0.3639 -0.5358 -0.5764 -0.0845 -0.0574 -0.0740 -0.1074 -0.2258 -1.5657 -0.0838 -0.1132 -0.5353 -0.1027 -0.3287 -0.0490 -0.1074 -1.2693 -0.0747 -0.1116 -0.0884 -0.1192 -0.2182 -2.3428 -0.1239 -0.1340 -0.6403 -0.1649 -0.0890 -0.5283 -0.1300 -0.0890 -0.0657 -0.0701 -0.1290 -0.0828 -0.0928 -1.1911 -0.4168 -0.1266 -2.5047 -0.1551 -0.1715 -0.0453 -0.2290 -0.1063 -0.2988 -0.3286 -0.1113 -0.1524 -0.1177 -0.0139 -0.1185 -0.1037 -2.7494 -0.0837 -0.0273 -0.1054 -0.5891 -0.0656 -0.1625 -0.2085 -1.7654 -0.1303\n",
            "T-270\tAtsikana omwe anavala yunifolomu ya Broncos yofiira ndi yoyera anatsetsereka pa udzu pamene ankagwira mpira wofewa wachikasu .\n",
            "H-270\t-0.29368463158607483\t▁ M t s i k a n a ▁ w o m w e ▁ w a v a l a ▁ y u n i f o l o m u ▁ y a ▁ b a s e b a l l ▁ y o f i i r a ▁ a l i ▁ n d i ▁ y o y e r a ▁ a t s e k a ▁ p a m e n e ▁ a n t h u ▁ a m e n e ▁ a n a g w i r a ▁ m p i r a ▁ w a c h i k a s u ▁ .\n",
            "D-270\t-0.29368463158607483\tMtsikana womwe wavala yunifolomu ya baseball yofiira ali ndi yoyera atseka pamene anthu amene anagwira mpira wachikasu .\n",
            "P-270\t-0.1205 -0.3673 -0.0466 -0.0804 -0.1125 -0.0686 -0.1194 -0.0702 -0.1176 -0.1227 -0.1712 -0.8052 -0.2816 -0.4450 -0.1044 -0.1597 -2.8409 -0.1387 -0.0659 -0.0962 -0.0692 -0.1103 -0.1086 -0.3480 -0.0258 -0.0428 -0.0393 -0.0892 -0.0856 -0.0440 -0.0475 -0.0450 -0.0467 -0.1017 -0.0070 -0.1209 -0.2898 -0.0433 -1.7386 -0.1292 -0.0736 -0.0307 -0.0460 -0.0404 -0.5664 -0.2766 -0.2249 -0.1016 -0.0251 -0.0891 -0.4752 -0.0603 -0.1590 -0.2286 -0.4822 -0.4504 -0.1103 -0.1598 -1.5263 -0.4988 -0.0909 -0.1117 -0.9605 -0.1074 -0.1474 -0.0533 -0.1335 -0.0879 -0.1840 -0.2122 -1.0430 -0.9348 -0.0613 -0.7310 -0.2937 -0.1204 -0.2574 -0.1733 -1.4620 -0.1887 -0.0632 -0.0672 -0.0855 -0.5554 -0.3856 -1.2246 -0.0401 -0.0726 -0.1303 -1.8902 -0.1613 -0.7784 -0.0768 -0.0845 -0.0997 -0.1284 -0.4697 -0.2330 -1.0711 -1.1752 -0.3246 -0.0757 -0.1396 -0.1686 -0.1841 -0.0434 -0.1002 -0.0946 -0.1103 -0.3032 -0.1076 -0.9140 -0.1456 -0.1227 -0.1003 -0.0392 -0.0725 -0.0730 -0.0829 -0.3643 -0.5235 -0.0999\n",
            "T-216\tMnyamata wina wa ku Asia wovala jekete la pinki ndi lakuda akuyenda ndi mtsikana mu jekete ya bulauni .\n",
            "H-216\t-0.221113920211792\t▁ M n y a m a t a ▁ w i n a ▁ w a ▁ k u ▁ A s i a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ b l u e ▁ n d i ▁ m a t h a l a u z a ▁ a k u d a ▁ n d i ▁ t - s h i r t ▁ y a ▁ b u l u u ▁ .\n",
            "D-216\t-0.221113920211792\tMnyamata wina wa ku Asia wovala jekete la blue ndi mathalauza akuda ndi t-shirt ya buluu .\n",
            "P-216\t-0.1265 -0.3730 -0.0817 -0.0469 -0.0995 -0.0680 -0.1173 -0.0534 -0.1093 -0.1413 -0.1626 -0.1237 -0.0816 -0.1112 -0.1085 -0.0873 -0.1150 -0.5624 -0.0513 -0.0590 -0.0153 -0.2325 -0.1371 -0.1053 -0.0932 -0.1256 -0.0376 -0.1265 -0.0489 -0.1091 -0.0834 -0.1016 -0.0979 -0.0156 -0.0671 -0.0138 -0.0401 -0.0354 -0.0578 -0.0972 -0.0752 -0.1170 -0.3823 -0.5088 -1.4780 -0.6817 -0.0276 -0.1175 -0.1217 -0.1293 -0.1113 -0.0920 -2.0631 -0.2961 -0.4269 -0.6261 -0.1050 -0.3883 -0.1006 -0.0510 -0.1227 -0.0968 -0.1288 -0.0880 -0.1193 -0.0834 -0.3396 -0.8051 -0.1496 -0.3415 -0.0964 -0.1119 -0.0859 -0.8305 -1.4713 -0.0299 -0.0604 -0.2830 -0.0578 -0.0125 -0.1565 -0.0479 -0.1257 -0.4912 -0.1217 -0.1639 -0.0952 -0.6502 -0.0631 -0.2561 -0.5387 -0.0978\n",
            "T-246\tMayi akuphunzitsa kalasi yovina yopangidwa ndi ana ang'onoang'ono atanyamula masilafu okongola .\n",
            "H-246\t-0.31960949301719666\t▁ M a y i ▁ a k u p h u n z i t s a ▁ k a l a s i ▁ y o b i r i w i r a ▁ n d i ▁ b a n d e ▁ y a k h a l a ▁ p a m w a m b a ▁ p a ▁ m n y a m a t a ▁ w o n y a m u l a ▁ m a s i l a ▁ o k o n g o l a ▁ .\n",
            "D-246\t-0.31960949301719666\tMayi akuphunzitsa kalasi yobiriwira ndi bande yakhala pamwamba pa mnyamata wonyamula masila okongola .\n",
            "P-246\t-0.1498 -0.0773 -0.1086 -0.0725 -0.1162 -0.1254 -0.1014 -0.1096 -0.1527 -1.0327 -0.3719 -0.0553 -0.1581 -0.0215 -0.1037 -0.3139 -0.0437 -0.1164 -0.1191 -0.2661 -0.1575 -2.0206 -0.1211 -0.7605 -0.0475 -0.2660 -2.1766 -0.0902 -1.0758 -0.1517 -0.0562 -0.1078 -0.0423 -0.1054 -0.0781 -0.0781 -0.2941 -0.5890 -0.1150 -0.1049 -0.6453 -0.5724 -0.1212 -0.2228 -0.2028 -0.3696 -0.5465 -1.4179 -0.1732 -0.3586 -0.4791 -0.1357 -0.0926 -0.1207 -0.1569 -0.6901 -0.1390 -0.2055 -0.5747 -0.0985 -0.1585 -0.9879 -0.1149 -0.1784 -0.0472 -0.1216 -0.1541 -0.0904 -1.7030 -0.0294 -0.1029 -0.0324 -0.0765 -0.0497 -0.0892 -0.1466 -0.6848 -0.9995 -0.5376 -0.0706 -0.1069 -0.0781 -0.3085 -0.0688 -0.1136 -0.1656 -0.1242 -0.0914 -0.1530 -0.6442 -0.3024 -0.1846 -1.8092 -0.4844 -1.2471 -0.1409 -0.0826 -0.0202 -0.0573 -0.0993 -0.1191 -0.6934 -0.2963 -0.0962\n",
            "T-76\tGalu wonyezimira ali ndi lilime likulendewera kukamwa uku akuthamanga pa udzu .\n",
            "H-76\t-0.3643971085548401\t▁ G a l u ▁ w o n y e z i m i r a ▁ a l i ▁ n d i ▁ m i y e n d e ▁ i k u l e n d e w e r a ▁ k a m w a ▁ a k u t h a m a n g a ▁ p a m a l o ▁ o d z u w a ▁ .\n",
            "D-76\t-0.3643971085548401\tGalu wonyezimira ali ndi miyende ikulendewera kamwa akuthamanga pamalo odzuwa .\n",
            "P-76\t-0.1249 -0.0986 -0.1183 -0.0622 -0.0716 -0.1236 -0.0370 -0.9792 -2.4945 -0.1371 -0.1002 -0.0333 -0.0952 -0.0972 -0.1074 -0.1067 -0.1084 -0.1441 -0.2313 -0.2208 -0.0964 -0.1467 -0.0555 -0.0833 -0.1177 -0.0889 -0.1505 -0.6317 -2.2777 -0.1106 -0.1007 -0.0312 -0.7183 -0.7660 -0.7608 -0.0511 -0.0942 -0.2112 -0.7692 -1.1831 -0.5235 -0.1529 -0.1339 -0.0358 -0.0448 -0.1284 -0.1625 -0.7594 -0.2570 -0.6702 -0.2432 -0.0837 -0.3575 -1.5481 -0.2249 -0.1454 -0.0343 -0.0577 -0.1007 -0.0958 -0.0855 -0.0701 -0.0369 -0.0928 -0.1760 -0.0869 -0.1064 -1.7381 -0.2062 -0.3326 -0.1147 -0.1037 -0.4093 -1.6163 -0.6778 -1.0241 -1.7058 -0.0933 -0.9256 -0.1218 -0.0957\n",
            "T-139\tBambo wina wovala zitunda zamitundumitundu akusefukira pabwalo loyera la mafunde pamadzi .\n",
            "H-139\t-0.2611498236656189\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ z i t h u n z i ▁ z a ▁ m i t u n d u m i t u n d u ▁ a k u v u l a ▁ p a f u p i ▁ n d i ▁ m a l o ▁ o y e r a ▁ a m a f u n d e ▁ p a m a s o ▁ .\n",
            "D-139\t-0.2611498236656189\tBambo wina wovala zithunzi za mitundumitundu akuvula pafupi ndi malo oyera amafunde pamaso .\n",
            "P-139\t-0.1141 -0.2645 -0.1251 -0.0560 -0.1345 -0.1162 -0.1394 -0.0528 -0.1232 -0.1165 -0.1088 -0.1172 -0.0529 -0.0916 -0.0844 -0.1277 -0.0923 -0.1240 -0.1047 -0.8244 -0.1219 -3.1686 -0.6149 -0.0981 -0.0785 -0.1366 -0.0943 -0.1671 -0.1681 -0.0854 -0.2187 -0.9204 -0.1135 -0.0333 -0.0785 -0.1960 -0.0293 -0.0644 -1.0947 -0.0476 -0.1316 -0.0486 -0.0849 -0.0319 -0.1075 -0.0997 -0.4112 -0.0495 -0.1016 -1.2891 -0.6386 -0.4770 -0.1866 -0.1194 -0.4724 -0.1454 -1.1403 -0.0988 -0.0687 -0.1442 -0.1158 -0.0870 -0.1066 -0.1364 -0.1137 -1.1800 -0.0958 -0.2106 -0.1463 -0.0978 -0.1455 -0.2406 -0.0717 -0.0882 -0.1032 -0.1759 -0.1796 -0.8051 -0.1343 -0.5146 -0.0491 -0.0875 -0.0330 -0.0350 -0.1413 -0.6304 -0.1235 -0.1343 -0.1034 -0.7527 -0.6266 -0.1958 -0.4349 -0.1044\n",
            "T-6\tMtsikana wina wovala mkanjo wa pinki akutulutsa bulangete pansi pa kamnyamata komwe kanali .\n",
            "H-6\t-0.31408461928367615\t▁ M t s i k a n a ▁ w i n a ▁ w o v a l a ▁ m k a n j o ▁ w a p i n k i ▁ a k u t u l u t s a ▁ p a n j i n g a ▁ p a n s i ▁ p a ▁ m n y a m a t a ▁ a k u m u y a n g ' a n a ▁ .\n",
            "D-6\t-0.31408461928367615\tMtsikana wina wovala mkanjo wapinki akutulutsa panjinga pansi pa mnyamata akumuyang'ana .\n",
            "P-6\t-0.1415 -0.0762 -0.0557 -0.1313 -0.0995 -0.0537 -0.1188 -0.1154 -0.1134 -0.1342 -0.0811 -0.1066 -0.0870 -0.1054 -0.1114 -0.0753 -0.1395 -0.1628 -0.1126 -0.0788 -0.1166 -0.0918 -0.2532 -1.5945 -0.1572 -0.0929 -0.0254 -0.1111 -0.0732 -0.2355 -0.1208 -1.0011 -0.1450 -0.0255 -0.0353 -0.0989 -0.1336 -0.0903 -1.3192 -0.1454 -1.4684 -0.6842 -0.0583 -0.0364 -0.1536 -0.0744 -0.0986 -0.0896 -1.9071 -0.2696 -0.1326 -0.0995 -1.0217 -0.5863 -0.0732 -0.1107 -0.1356 -1.8393 -0.1828 -0.2239 -0.2001 -0.0846 -0.1392 -0.0837 -0.1693 -0.9164 -0.8030 -1.7365 -0.0282 -0.1212 -0.0530 -0.0738 -0.0381 -0.1012 -0.1398 -1.6904 -1.0530 -0.2012 -0.9154 -0.8996 -0.4938 -0.0854 -0.1417 -0.1160 -0.0434 -0.0989 -0.0853 -0.1198 -0.1372 -0.5059 -0.0942\n",
            "T-210\tAmuna awiri osowa pokhala akutsamira pa khoma la njerwa ndi kunyamula chikwangwani .\n",
            "H-210\t-0.30765458941459656\t▁ A m u n a ▁ a w i r i ▁ o s a v a l a ▁ k a b u d u l a ▁ a k u t s a m i r a ▁ p a k h o m a ▁ n d i ▁ n y a m a ▁ k u n y a m u l a ▁ c h i k w a n g w a n i ▁ .\n",
            "D-210\t-0.30765458941459656\tAmuna awiri osavala kabudula akutsamira pakhoma ndi nyama kunyamula chikwangwani .\n",
            "P-210\t-0.1057 -0.0424 -0.0833 -0.0729 -0.0621 -0.1300 -0.1260 -0.1065 -0.0927 -0.1198 -0.0682 -0.1103 -0.1422 -0.1075 -0.3512 -0.5479 -1.4931 -0.1399 -0.0861 -0.1130 -0.0967 -1.1744 -0.7368 -1.4179 -0.1323 -0.5530 -0.0963 -0.0620 -0.0865 -0.1062 -0.2408 -0.5736 -0.1281 -1.3374 -1.0203 -0.2193 -0.2110 -0.2009 -0.0678 -0.1117 -0.0896 -0.2630 -0.1620 -2.2587 -0.6364 -0.0319 -0.0702 -0.0813 -0.1732 -0.3482 -0.0912 -0.1057 -0.1687 -0.4958 -0.1413 -0.1142 -0.5341 -0.2408 -0.1430 -0.6611 -0.0966 -1.3496 -0.4494 -0.1293 -0.1331 -0.0743 -0.0833 -0.1041 -0.1251 -2.0766 -0.1932 -0.1020 -0.2910 -0.0372 -0.0963 -0.1062 -0.0206 -0.0382 -0.1019 -0.0639 -0.0579 -0.3410 -0.1851 -0.1028\n",
            "T-91\tPabwalo lotchingidwa ndi mpanda ndi nyumba yoyera kumbuyo, galu woyera akudumpha m'mwamba pafupi ndi galu wabulauni.\n",
            "H-91\t-0.31485891342163086\t▁ G a l u ▁ w a b u l a u n i ▁ n d i ▁ w o c h i t i d w a ▁ n d i ▁ m i y e n d o ▁ y o y e r a ▁ a k u m b u y o ▁ n g a l u ▁ w o y e r a ▁ a k u d u m p h a ▁ p a f u p i ▁ n d i ▁ g a l u ▁ w a b u l a u n i ▁ .\n",
            "D-91\t-0.31485891342163086\tGalu wabulauni ndi wochitidwa ndi miyendo yoyera akumbuyo ngalu woyera akudumpha pafupi ndi galu wabulauni .\n",
            "P-91\t-0.1140 -1.9419 -0.1043 -0.1029 -0.0973 -0.1245 -0.0398 -0.1522 -1.5365 -0.0876 -0.0627 -0.7416 -0.0665 -0.0844 -0.1693 -0.1226 -0.2520 -0.1422 -0.1491 -0.1288 -0.3984 -1.3604 -0.9854 -0.0677 -0.0942 -1.1753 -0.5670 -1.3229 -0.0329 -0.1455 -0.1386 -0.1362 -0.1327 -0.1279 -0.1037 -0.4790 -0.9378 -1.0164 -0.1722 -0.1868 -0.0914 -0.3416 -0.1201 -0.0694 -0.3252 -0.1987 -0.0950 -0.0760 -0.1014 -0.1929 -0.8128 -0.1876 -0.1170 -0.2718 -0.1956 -0.1102 -0.0595 -0.0927 -0.1433 -2.5055 -1.3542 -0.1506 -0.3693 -0.1085 -0.1368 -0.1387 -0.1778 -0.0469 -0.0929 -0.1136 -0.0934 -0.2014 -0.2943 -0.1596 -0.1371 -1.1231 -0.0776 -0.0513 -0.1090 -0.0697 -0.1191 -0.1682 -0.4289 -0.1157 -3.1577 -0.1031 -0.0519 -0.1106 -0.1151 -0.0868 -0.1439 -0.1237 -0.0906 -0.1522 -0.2348 -0.0405 -0.0598 -0.1490 -0.0961 -0.5440 -0.5056 -0.0818 -0.0690 -0.1445 -0.0622 -0.0617 -0.0849 -0.4133 -0.1169 -0.0881\n",
            "T-248\tAtsikana awiri atanyamula manja awo mtsikana atavala malaya abuluu ndi lamba wakuda kumtunda kwake .\n",
            "H-248\t-0.27503928542137146\t▁ A t s i k a n a ▁ a n a ▁ a w i r i ▁ a t a n y a m u l a ▁ m a n j a ▁ a w o ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ l a m b a ▁ w a k u d a ▁ m ' m p h e p e t e ▁ m w a ▁ k h o n d a ▁ .\n",
            "D-248\t-0.27503928542137146\tAtsikana ana awiri atanyamula manja awo atavala malaya abuluu ndi lamba wakuda m'mphepete mwa khonda .\n",
            "P-248\t-0.1178 -0.0629 -0.0890 -0.0642 -0.1071 -0.0592 -0.1258 -0.1105 -0.1070 -0.1424 -0.1240 -0.8429 -0.1855 -1.9536 -0.0863 -0.0228 -0.1192 -0.0632 -0.0911 -0.2051 -0.0908 -0.0358 -0.1101 -0.3031 -0.0402 -0.0974 -0.0820 -0.1032 -0.0572 -0.0975 -0.1319 -0.0807 -0.1398 -0.9693 -0.6539 -0.1027 -0.1384 -0.2050 -0.1059 -0.3466 -0.1152 -0.6412 -0.0804 -0.1365 -0.0146 -0.1109 -0.0835 -0.1166 -0.1010 -0.0542 -0.1467 -0.1755 -0.1248 -0.0542 -0.0865 -0.1090 -0.1824 -0.3318 -0.1075 -0.0618 -0.1300 -0.0434 -0.2115 -0.4823 -0.0937 -0.1238 -0.1128 -2.9968 -0.1528 -0.8365 -0.1647 -0.0795 -0.1501 -0.0730 -0.1125 -0.2254 -0.0945 -0.1395 -0.0935 -0.2530 -0.6885 -0.2532 -2.3186 -0.5356 -0.0394 -0.5891 -0.0541 -0.0979 -0.0174 -0.6366 -0.1415 -0.1336 -0.2312 -0.1109 -0.4720 -0.8080 -1.7582 -0.1597 -0.5180 -0.0123 -0.1865 -0.4541 -0.2998 -0.1132\n",
            "T-304\tGalu woyera wokhala ndi mawanga akuda akuthamanga m'munda wokutidwa ndi chipale chofewa .\n",
            "H-304\t-0.23556207120418549\t▁ G a l u ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ m w a n a ▁ a k u j a m b u l a ▁ a k u t h a m a n g a ▁ m ' n k h a l a n g o ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-304\t-0.23556207120418549\tGalu woyera wokhala ndi mwana akujambula akuthamanga m'nkhalango ndi chipale chofewa .\n",
            "P-304\t-0.1103 -0.0885 -0.1243 -0.0693 -0.1090 -0.1226 -0.0245 -0.0869 -0.0471 -0.1238 -0.0672 -0.1040 -0.1654 -0.4473 -0.0650 -0.1094 -0.1158 -0.1027 -0.0637 -0.0959 -0.1177 -0.0563 -0.1983 -0.1134 -0.1026 -0.0737 -0.1971 -0.1226 -0.3100 -0.0820 -0.1204 -0.1273 -0.0659 -0.0958 -0.7171 -0.0904 -0.2469 -0.1132 -0.0703 -0.0585 -0.1256 -0.1358 -3.2961 -0.1122 -0.1059 -0.2697 -0.0621 -0.0955 -0.0855 -0.0883 -0.0627 -0.0401 -0.0872 -0.1310 -0.0537 -0.3621 -1.4869 -0.1438 -0.0742 -0.1125 -0.1078 -0.0937 -0.0218 -0.4225 -0.0455 -0.1372 -1.8320 -0.1563 -0.0848 -0.1581 -2.1751 -0.1224 -0.1147 -0.7660 -0.6150 -0.3607 -0.0653 -0.0694 -0.1060 -0.1028 -0.0576 -0.0043 -0.0832 -0.0571 -0.0876 -0.3563 -0.1737 -0.0993\n",
            "T-273\tAgalu atatu ovala majuzi achikuda amathamanga paudzu, ali ndi makwerero ndi manja kumbuyo.\n",
            "H-273\t-0.27425575256347656\t▁ A g a l u ▁ a t a t u ▁ o v a l a ▁ m a ▁ j u z i ▁ a c h i k u l u ▁ a m a j a m b u l a ▁ p a m a l o ▁ a w u z u n g u l i r i d w a ▁ n d i ▁ m a n j a ▁ k u m b u y o ▁ .\n",
            "D-273\t-0.27425575256347656\tAgalu atatu ovala ma juzi achikulu amajambula pamalo awuzunguliridwa ndi manja kumbuyo .\n",
            "P-273\t-0.1147 -0.0520 -0.0320 -0.0954 -0.0479 -0.0923 -0.1363 -0.1020 -0.0313 -0.1109 -0.0200 -0.0488 -0.1978 -0.8230 -0.0449 -0.1149 -0.0717 -0.1019 -0.1110 -0.1205 -0.1225 -1.1831 -0.0336 -0.0661 -0.0171 -0.1190 -0.0936 -0.2745 -0.1847 -0.1613 -0.1125 -0.1063 -0.2025 -1.7347 -0.7023 -0.1799 -0.3882 -0.8392 -0.1042 -1.3089 -0.1137 -0.1313 -0.1748 -0.0799 -0.0755 -0.1179 -0.1848 -0.0820 -0.1438 -0.2474 -0.0876 -0.4358 -0.2828 -0.1085 -0.5003 -2.1784 -0.7432 -0.0824 -0.0715 -0.5485 -0.0983 -0.0851 -0.1307 -0.0798 -0.2800 -0.4155 -0.1032 -0.1550 -0.1376 -0.1363 -0.0998 -0.0874 -0.1146 -0.0771 -0.0586 -0.0984 -1.6258 -0.0410 -0.0979 -0.0938 -2.4053 -0.3403 -0.0725 -0.1226 -0.0711 -0.0393 -0.0502 -0.2977 -0.3599 -0.1148\n",
            "T-214\tMwamuna ndi mnzake wamkazi akuwonera kuwombera kwake pamene akusewera mpira wa pong .\n",
            "H-214\t-0.2962820827960968\t▁ M w a m u n a ▁ n d i ▁ m t s i k a n a ▁ w a ▁ b u l u u ▁ a k u w o n e r a ▁ k u t s o g o l o ▁ k w a ▁ m e n e ▁ a k u s e w e r a ▁ m p i r a ▁ w a ▁ k o n z e k e r a ▁ .\n",
            "D-214\t-0.2962820827960968\tMwamuna ndi mtsikana wa buluu akuwonera kutsogolo kwa mene akusewera mpira wa konzekera .\n",
            "P-214\t-0.1182 -0.0969 -0.1290 -0.0994 -0.0670 -0.0670 -0.0942 -0.1035 -0.1840 -0.1033 -0.0395 -0.1267 -0.0841 -0.1465 -0.4591 -0.0807 -0.2311 -0.1860 -0.0819 -0.1291 -0.0843 -0.1725 -0.3917 -0.1342 -1.3589 -0.7362 -1.0520 -0.1734 -0.3252 -0.0469 -0.1211 -0.1606 -0.0522 -0.1238 -0.6686 -0.3039 -0.3693 -0.1335 -0.3634 -0.0963 -0.1126 -1.0108 -0.0727 -1.6758 -0.4893 -0.1232 -0.0957 -0.0780 -0.0585 -0.0852 -0.0831 -0.1726 -0.0386 -0.1105 -0.2562 -0.4594 -0.4153 -1.6046 -0.2971 -0.0901 -0.0984 -0.1015 -0.0927 -0.3009 -0.0896 -0.1862 -0.0867 -0.0925 -0.1092 -0.1421 -0.3919 -0.3873 -0.0593 -0.0880 -0.0994 -0.4839 -0.1115 -0.1970 -0.6711 -1.7253 -1.3884 -0.2000 -0.5838 -0.2478 -0.2283 -0.3555 -0.3654 -0.3254 -0.3997 -0.4374 -0.0905\n",
            "T-60\tMayi wina wachikulire wovala magalasi apinki wanyamula magazini awiri mumsewu wodutsa anthu ambiri .\n",
            "H-60\t-0.20319899916648865\t▁ M a y i ▁ w i n a ▁ w a c h i k u l i r e ▁ w o v a l a ▁ m a g a l a s i ▁ a k u y a n g ' a n a ▁ m a g a l a s i ▁ n d i ▁ m n y a m a t a ▁ w o d u t s a ▁ a n t h u ▁ a m b i r i ▁ .\n",
            "D-60\t-0.20319899916648865\tMayi wina wachikulire wovala magalasi akuyang'ana magalasi ndi mnyamata wodutsa anthu ambiri .\n",
            "P-60\t-0.1373 -0.0723 -0.0811 -0.0497 -0.0885 -0.1367 -0.0615 -0.1137 -0.1066 -0.0978 -0.1328 -0.0743 -0.0889 -0.0628 -0.0864 -0.0814 -0.1642 -0.0971 -0.0783 -0.0814 -0.0511 -0.0774 -0.1583 -0.0903 -0.0765 -0.0879 -0.1035 -0.1019 -0.1156 -0.1042 -0.0642 -0.1066 -0.8478 -0.1152 -0.0828 -0.1164 -0.0440 -0.1042 -0.1054 -0.1779 -0.8619 -0.3796 -0.2631 -0.1747 -0.1311 -0.2006 -0.0351 -0.1020 -0.1181 -0.0977 -0.0919 -0.1035 -1.1169 -0.3119 -0.0929 -0.6203 -0.1420 -0.1776 -0.0812 -0.1560 -1.0134 -0.2243 -0.1004 -0.1273 -0.2021 -1.5710 -0.1209 -0.0937 -0.1070 -0.0857 -0.1282 -0.0967 -0.1383 -0.0787 -0.3327 -0.1787 -0.7528 -0.1008 -0.0516 -0.0719 -0.1903 -1.1453 -0.1997 -0.0136 -0.0724 -0.0670 -0.1182 -0.9845 -0.1263 -0.1689 -0.0953 -0.0520 -0.0765 -0.3389 -0.2957 -0.1036\n",
            "T-329\tBambo wina wokalamba wovala malaya akuda akudula nkhuni pogwiritsa ntchito macheka amagetsi\n",
            "H-329\t-0.25196903944015503\t▁ M w a m u n a ▁ w i n a ▁ w o k h a l a ▁ n d i ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u d u l a ▁ n k h u n i ▁ p o g w i r i t s a ▁ n t c h i t o ▁ m a n j a ▁ a k e ▁ .\n",
            "D-329\t-0.25196903944015503\tMwamuna wina wokhala ndi wovala malaya akuda akudula nkhuni pogwiritsa ntchito manja ake .\n",
            "P-329\t-0.1117 -2.6732 -0.3438 -0.0956 -0.0853 -0.1576 -0.0911 -0.1004 -0.1311 -0.0781 -0.1301 -0.0719 -0.1024 -0.1239 -0.0583 -0.0955 -0.1135 -0.3993 -0.1179 -0.0445 -0.1049 -0.1234 -0.2299 -0.7795 -0.1370 -0.1092 -0.5393 -0.0741 -0.1097 -0.1139 -0.0868 -0.1173 -0.1283 -0.0996 -0.1169 -0.0778 -0.1200 -0.1065 -0.1031 -0.1384 -0.1206 -0.4691 -0.1079 -0.1158 -0.1005 -0.1489 -0.1319 -0.0991 -0.1275 -1.3485 -0.0845 -0.6232 -0.1237 -0.1537 -0.3468 -0.5929 -0.1395 -0.3836 -0.3500 -1.2431 -0.2820 -0.9087 -0.0728 -0.0517 -0.3902 -0.1002 -0.1043 -0.0716 -0.0318 -0.1183 -0.0936 -0.1037 -0.0592 -0.0479 -0.0277 -0.0925 -0.1272 -0.0436 -0.0448 -0.0736 -0.1218 -0.4990 -2.0594 -0.2834 -0.1705 -0.1161 -0.1262 -0.3989 -0.0430 -0.1816 -0.8567 -0.1277\n",
            "T-389\tAnthu ena ovala malaya abuluu akuimirira ndi zilembo zazikulu zomasulira mawu akuti KRUNCH.\n",
            "H-389\t-0.21170954406261444\t▁ A n t h u ▁ e n a ▁ o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u i m i r i r a ▁ n d i ▁ z i n g w e ▁ z a z i k u l u ▁ z o m a s u l i r a ▁ .\n",
            "D-389\t-0.21170954406261444\tAnthu ena ovala malaya abuluu akuimirira ndi zingwe zazikulu zomasulira .\n",
            "P-389\t-0.1253 -0.0271 -0.1065 -0.0372 -0.0972 -0.0765 -0.1031 -0.2250 -0.0255 -0.0930 -0.1674 -0.0607 -0.0558 -0.1246 -0.0742 -0.1314 -0.1085 -0.0762 -0.1394 -0.0423 -0.1098 -0.0266 -0.0987 -0.1213 -0.1351 -0.4000 -0.0767 -0.0591 -0.0787 -0.0324 -0.1484 -0.2150 -0.1612 -0.0791 -1.4003 -0.0695 -0.2164 -0.1470 -0.4365 -0.0787 -0.0986 -0.0915 -0.0597 -0.0622 -0.1132 -0.1090 -0.1247 -0.5335 -0.9864 -0.0232 -0.3081 -0.0510 -0.1627 -0.0288 -0.1538 -0.0253 -0.1170 -0.0442 -0.1097 -0.0422 -0.1191 -0.1819 -0.3351 -0.1488 -0.1390 -0.3494 -0.6915 -0.3451 -0.0746 -0.0866 -0.0504 -0.0995 -0.1965 -3.6773 -0.1512\n",
            "T-176\tAnthu awiri ovala mwansangala atayima pa chipale chofewa pamene utsi ukutuluka m'mwamba .\n",
            "H-176\t-0.25526493787765503\t▁ A n t h u ▁ a w i r i ▁ o v a l a ▁ m a s a n g a l a l a ▁ a t a n y a m u l a ▁ c h i p a l e ▁ c h o f e w a ▁ p a m e n e ▁ g u l u ▁ l a ▁ a n t h u ▁ k u m b u y o ▁ .\n",
            "D-176\t-0.25526493787765503\tAnthu awiri ovala masangalala atanyamula chipale chofewa pamene gulu la anthu kumbuyo .\n",
            "P-176\t-0.1121 -0.0294 -0.0904 -0.0304 -0.0801 -0.0846 -0.1072 -0.1247 -0.2388 -0.1160 -0.0685 -0.0866 -0.1871 -0.1635 -0.0770 -0.1118 -0.0811 -0.1240 -0.1058 -0.1330 -0.3662 -0.2580 -0.1592 -1.3977 -0.0387 -0.1002 -0.0301 -0.1362 -0.1160 -0.1137 -0.1474 -0.0928 -0.0892 -0.0963 -0.3293 -0.2211 -0.4675 -0.1052 -0.1167 -0.0422 -0.1197 -0.1115 -0.0365 -0.0666 -0.0994 -0.2957 -0.1293 -0.0736 -0.1082 -0.1166 -0.0193 -0.0778 -0.0482 -0.0169 -0.0675 -0.0493 -0.0895 -0.2256 -0.0459 -0.1303 -0.0721 -0.0499 -0.0565 -0.0654 -0.1006 -3.0386 -0.0472 -0.3694 -0.0819 -0.1823 -0.3926 -2.1303 -0.2717 -1.0090 -0.2744 -0.2162 -0.1435 -0.0831 -0.1169 -1.4800 -0.0986 -0.3563 -0.1100 -0.5825 -0.2342 -0.1022 -0.2753 -2.1524 -0.1225\n",
            "T-410\tMnyamata wina wovala malaya amizeremizere yakuda ndi yoyera akutsamira pa udzu pamene magalimoto akudutsa pafupi ndi msewu .\n",
            "H-410\t-0.1480351984500885\t▁ M n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a k u d a ▁ n d i ▁ y o y e r a ▁ a k u t s a m i r a ▁ p a m e n e ▁ m a g a l i m o t o ▁ a k u d u t s a ▁ p a f u p i ▁ n d i ▁ m s e w u ▁ .\n",
            "D-410\t-0.1480351984500885\tMnyamata wina wovala malaya amizeremizere yakuda ndi yoyera akutsamira pamene magalimoto akudutsa pafupi ndi msewu .\n",
            "P-410\t-0.1262 -0.0634 -0.0286 -0.0551 -0.0972 -0.1207 -0.1083 -0.0787 -0.1042 -0.1156 -0.1288 -0.1083 -0.0938 -0.1101 -0.1057 -0.1433 -0.0946 -0.0854 -0.1185 -0.0889 -0.1236 -0.0963 -0.0529 -0.1154 -0.0689 -0.1147 -0.0823 -0.0927 -0.0933 -0.2469 -0.1351 -0.1155 -0.2115 -0.0811 -0.0495 -0.0626 -0.0378 -0.0893 -0.2488 -0.0811 -0.0815 -0.0688 -0.1360 -0.8995 -0.1460 -0.2209 -0.1109 -0.1935 -0.1503 -0.1546 -0.0741 -0.0853 -0.1117 -0.1258 -0.0504 -0.1066 -0.0505 -0.0608 -0.0832 -0.1017 -0.1832 -0.2465 -0.0779 -0.1233 -0.3689 -0.0495 -0.1120 -0.2673 -0.0524 -0.0633 -0.1075 -0.1244 -0.0215 -0.1573 -0.1288 -0.0859 -0.0944 -0.0947 -0.0896 -0.0803 -0.3688 -0.2490 -0.0889 -0.0564 -0.1563 -0.0488 -0.0409 -0.0237 -0.0511 -0.1210 -0.4385 -0.1752 -0.1276 -0.1526 -0.0833 -0.0456 -0.1303 -0.0875 -0.1281 -0.3167 -0.1418 -0.2116 -0.0739 -0.0383 -0.1123 -0.1592 -0.0446 -0.1323 -0.1398 -0.0707 -0.7466 -1.9375 -0.0644 -0.0493 -0.1110 -0.3839 -0.3374 -0.1085\n",
            "T-49\tGalu wonyezimira woyera ndi wabulauni akudumpha pa chinthu china n'kunyamula mpira m'kamwa mwake .\n",
            "H-49\t-0.26280826330184937\t▁ G a l u ▁ w o n y e z i m i r a ▁ w o y e r a ▁ n d i ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ c h i t h u n z i ▁ k u n y a m u l a ▁ m p i r a ▁ .\n",
            "D-49\t-0.26280826330184937\tGalu wonyezimira woyera ndi wabulauni akuthamanga chithunzi kunyamula mpira .\n",
            "P-49\t-0.1145 -0.1789 -0.1268 -0.0676 -0.0655 -0.1142 -0.0556 -0.2124 -0.5020 -0.2401 -0.1024 -0.0469 -0.2414 -0.1823 -0.1008 -0.1172 -0.1150 -0.1317 -0.0989 -0.0953 -0.2039 -0.0904 -0.1151 -0.1152 -0.1628 -0.1163 -0.1270 -0.1207 -0.1221 -0.0290 -0.2949 -0.4686 -0.1079 -0.0742 -0.1195 -0.0429 -0.0532 -0.0761 -0.1314 -0.0913 -0.0927 -0.1021 -0.4627 -0.7534 -0.1429 -0.3096 -0.1024 -0.0698 -0.0733 -0.6233 -0.1044 -0.9316 -0.1172 -0.1589 -1.3043 -0.5540 -0.0769 -0.0881 -0.1796 -0.1010 -0.1088 -0.9436 -0.4247 -2.1065 -0.0562 -0.0836 -0.0991 -0.7247 -0.0385 -0.1128 -0.0994 -0.3179 -1.0275 -0.1701 -0.0780 -0.1128 -0.2284 -1.9934 -0.1156\n",
            "T-84\tMunthu wadazi ameneyu, yemwe akuoneka kuti wagona, wakhala patebulo pa laibulale.\n",
            "H-84\t-0.32638394832611084\t▁ M u n t h u ▁ w a v a l a ▁ z a m i l u ▁ y o b i r i w i r a ▁ a k u w o n e k a ▁ k u t i ▁ w a k h a l a ▁ p a k a t i ▁ p a ▁ t e b u l o ▁ l a l i t h u n z i ▁ .\n",
            "D-84\t-0.32638394832611084\tMunthu wavala zamilu yobiriwira akuwoneka kuti wakhala pakati pa tebulo lalithunzi .\n",
            "P-84\t-0.1193 -0.1036 -0.0501 -0.0516 -0.0946 -0.0846 -0.0785 -0.1395 -0.0665 -0.1521 -4.1011 -0.1422 -0.0659 -0.1047 -0.1219 -0.6336 -0.1986 -0.3903 -0.2682 -0.5959 -0.1057 -0.2862 -0.3929 -0.8404 -1.9722 -0.0906 -0.1190 -0.0964 -0.0183 -0.1048 -0.0811 -0.1032 -0.1970 -0.0941 -0.2911 -0.0955 -0.6586 -0.7355 -0.0825 -0.0856 -0.0147 -0.0894 -0.1043 -0.3140 -0.0955 -0.0231 -0.4731 -0.1165 -0.0975 -0.4821 -1.0511 -0.4776 -0.1376 -0.1004 -0.1498 -0.1170 -0.1849 -0.1466 -2.1247 -0.1076 -0.0675 -0.2621 -0.3266 -0.2457 -0.1316 -0.0742 -1.2965 -0.1445 -0.0897 -0.0684 -0.0829 -0.0465 -0.1312 -0.5020 -0.4533 -0.1183 -0.0885 -0.0944 -1.3990 -0.1089 -0.1828 -0.8530 -0.1125 -0.5005 -0.1677 -0.0997\n",
            "T-360\tMayi akuyang'ana mokayikira yemwe akumujambula iye ndi atsikana atatu omwe ali panja .\n",
            "H-360\t-0.3193550407886505\t▁ M a y i ▁ a k u y a n g ' a n a ▁ m w a n a ▁ y e m w e ▁ a k u m w e t u l i r a ▁ n j a n j i ▁ y a s i l i k a l i ▁ n d i ▁ k a t a l i ▁ w o m w e ▁ m n y a n j a ▁ .\n",
            "D-360\t-0.3193550407886505\tMayi akuyang'ana mwana yemwe akumwetulira njanji yasilikali ndi katali womwe mnyanja .\n",
            "P-360\t-0.1433 -0.1018 -0.1093 -0.0634 -0.1057 -0.1156 -0.2104 -0.0767 -0.0981 -0.0790 -0.1327 -0.0724 -0.2581 -0.0944 -0.0982 -0.0704 -0.0948 -0.1113 -0.0876 -0.9790 -0.1108 -0.3994 -0.0954 -0.3246 -0.2164 -0.0338 -0.1116 -0.0463 -0.0871 -0.0912 -0.3906 -0.2220 -0.0958 -0.1965 -0.3088 -0.0601 -0.1370 -0.1757 -0.0459 -0.1441 -0.1197 -0.0995 -0.1421 -2.6071 -0.2677 -0.2874 -0.7882 -0.1608 -0.1012 -0.1594 -0.0482 -0.4135 -1.6436 -0.0582 -0.5067 -0.0705 -0.4131 -0.1685 -0.7611 -0.0689 -0.2248 -2.7019 -0.1354 -0.1278 -0.1056 -1.0949 -0.1064 -0.4269 -0.2885 -0.1339 -0.0851 -0.2050 -1.1619 -0.4838 -0.5309 -0.1561 -0.0791 -0.1176 -0.6644 -1.1178 -0.0557 -0.0934 -0.4926 -0.0172 -0.0886 -0.4944 -1.5416 -0.0918\n",
            "T-47\tAmuna awiri ogwira ntchito akuima pamalo okonzera njinga, yemwe ali kutsogolo ali ndi chida m'manja mwake.\n",
            "H-47\t-0.2854752540588379\t▁ A m u n a ▁ a w i r i ▁ o v a l a ▁ m a g w i r a ▁ n t c h i t o ▁ a k u y e n d a ▁ o k o n z e r a ▁ n j i n g a ▁ y a i k u l u ▁ y e m w e ▁ a l i ▁ n d i ▁ m a n j a ▁ m w a k e ▁ .\n",
            "D-47\t-0.2854752540588379\tAmuna awiri ovala magwira ntchito akuyenda okonzera njinga yaikulu yemwe ali ndi manja mwake .\n",
            "P-47\t-0.1126 -0.1104 -0.0714 -0.0639 -0.0887 -0.0890 -0.1451 -0.3529 -0.0854 -0.1792 -0.0627 -0.1187 -0.1826 -0.0666 -0.3629 -0.1450 -0.0892 -0.1005 -0.1030 -0.9989 -0.6062 -1.1362 -1.1077 -0.1297 -0.1239 -0.1773 -0.1540 -0.2522 -0.0955 -0.0479 -0.1186 -0.0972 -0.0193 -0.0518 -0.0800 -0.3542 -0.5639 -0.1101 -0.5441 -0.2199 -0.2670 -0.1376 -0.1023 -0.1176 -1.2674 -0.2821 -0.5573 -0.0319 -0.2653 -0.0465 -0.0807 -0.1082 -0.1482 -0.7795 -0.0597 -0.0928 -0.0955 -0.1026 -0.0680 -0.1411 -0.1729 -0.1370 -3.3554 -0.4884 -0.1266 -0.1258 -0.1659 -0.1405 -0.1202 -1.8401 -0.1043 -0.1188 -0.1184 -0.0912 -0.1595 -0.0596 -0.0937 -0.0908 -0.2362 -0.0969 -0.0946 -0.1045 -0.6615 -0.1865 -0.2495 -0.0180 -0.1000 -0.1208 -1.4040 -0.9008 -0.1082 -0.2852 -0.1286 -0.6571 -0.1636 -0.1105\n",
            "T-261\tAzimayi angapo amavala zovala za kum'mawa kwa golide, zabuluu, zachikasu ndi zofiira ndipo akuvina.\n",
            "H-261\t-0.27286383509635925\t▁ A z i m a y i ▁ a n g a p o ▁ a t a v a l a ▁ m a l a y a ▁ a z i k u l u ▁ m ' m a w a ▁ a b u l u u ▁ n d i ▁ z a b u l u u ▁ z a c h i k a s u ▁ n d i ▁ z o f i i r a ▁ a k u v i n a ▁ .\n",
            "D-261\t-0.27286383509635925\tAzimayi angapo atavala malaya azikulu m'mawa abuluu ndi zabuluu zachikasu ndi zofiira akuvina .\n",
            "P-261\t-0.1317 -0.0354 -0.0514 -0.1053 -0.0910 -0.1185 -0.0348 -0.0886 -0.0968 -0.1649 -0.0658 -0.1833 -0.0947 -0.0431 -0.0674 -0.1638 -0.1846 -0.7835 -0.1914 -0.1730 -0.1061 -0.1028 -0.1069 -0.0939 -0.3146 -0.2012 -0.4697 -0.1117 -0.0910 -0.0983 -0.1083 -0.2221 -0.3209 -0.3004 -1.2501 -0.6180 -0.1499 -0.1153 -0.1985 -0.8152 -1.1499 -0.1560 -0.5032 -0.4398 -0.1148 -0.2961 -2.5291 -1.3613 -0.3032 -0.0937 -0.3314 -0.0432 -0.1835 -0.3612 -0.0909 -0.1232 -0.0988 -0.8576 -0.1539 -0.5791 -0.0761 -0.0851 -0.0970 -0.0482 -0.2651 -0.1294 -0.1575 -0.0497 -0.0649 -0.1172 -0.0719 -0.1385 -0.0447 -0.0639 -0.1551 -0.4090 -0.0834 -0.1035 -1.3123 -0.0921 -0.0959 -0.2213 -0.1113 -0.2016 -0.0481 -0.3726 -0.3267 -0.5017 -0.1549 -0.1257 -1.1030 -0.1086 -0.0638 -0.1307 -0.4320 -0.3670 -0.1048\n",
            "T-78\tMwamuna wovala magalasi ndi malaya oyera olembedwa dzina lakuti Jim akumwetulira .\n",
            "H-78\t-0.22150109708309174\t▁ M w a m u n a ▁ w o v a l a ▁ m a g a l a s i ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ o l e m b e d w a ▁ n d i ▁ n y a l a ▁ z i n a ▁ a k u m w e t u l i r a ▁ k u m w e t u l i r a ▁ .\n",
            "D-78\t-0.22150109708309174\tMwamuna wovala magalasi ndi malaya oyera olembedwa ndi nyala zina akumwetulira kumwetulira .\n",
            "P-78\t-0.1238 -0.0587 -0.0661 -0.0978 -0.1645 -0.0741 -0.1210 -0.0997 -0.1341 -0.1110 -0.1123 -0.0828 -0.1234 -0.0858 -0.1175 -0.1028 -0.0699 -0.1027 -0.0602 -0.1241 -0.0694 -0.1150 -0.0259 -0.0857 -0.1519 -0.0612 -0.0755 -0.1076 -0.0970 -0.0774 -0.1179 -0.0677 -0.1217 -0.0730 -0.1094 -0.1101 -0.0628 -0.0717 -0.0672 -0.0913 -0.1078 -0.1868 -0.5157 -0.5430 -0.4378 -0.0638 -0.1301 -0.0400 -0.2323 -0.0754 -0.0921 -0.2041 -1.1109 -0.2549 -0.1470 -0.0771 -1.5617 -0.2763 -0.1069 -0.0892 -0.4797 -0.2829 -1.5113 -0.1120 -0.1238 -0.6138 -0.1365 -0.2624 -0.1011 -0.1060 -2.0030 -0.0829 -0.0684 -0.0761 -0.1690 -0.0421 -0.1395 -0.1341 -0.0913 -0.1524 -1.6960 -0.0883 -0.3219 -0.6242 -0.1938 -0.0355 -0.0766 -0.0340 -0.1109 -0.0532 -0.0933 -0.2832 -0.3612 -0.1160\n",
            "T-104\tMtsikana wofiirira wovala chovala chofiirira komanso nsapato zofiira kudumpha ali m'galimoto yapansi panthaka .\n",
            "H-104\t-0.30102843046188354\t▁ M t s i k a n a ▁ w o f i i r i r a ▁ w o v a l a ▁ c h o v a l a ▁ c h o f i i r a ▁ k o m a n s o ▁ z o v a l a ▁ z a k u d a ▁ a k u d u m p h a ▁ g a l i m o t o ▁ y a ▁ p a n s i ▁ p a d a n t h w a ▁ .\n",
            "D-104\t-0.30102843046188354\tMtsikana wofiirira wovala chovala chofiira komanso zovala zakuda akudumpha galimoto ya pansi padanthwa .\n",
            "P-104\t-0.1104 -2.1235 -0.1434 -0.0911 -0.1139 -0.0663 -0.1242 -0.0875 -0.1104 -0.1243 -0.0781 -0.6826 -2.2626 -0.1015 -0.2308 -0.0621 -0.0862 -0.0917 -0.1055 -0.2191 -0.0493 -0.0814 -0.0495 -0.1124 -0.0961 -0.1113 -0.1083 -0.1533 -0.0799 -0.0914 -0.0381 -0.1141 -0.0721 -0.1067 -0.1099 -0.1157 -0.0982 -0.1172 -0.1771 -0.0912 -0.3546 -0.0756 -0.8142 -0.2381 -0.1572 -0.2350 -0.0487 -0.1203 -0.1031 -0.0695 -0.0878 -0.0833 -0.5862 -1.1419 -1.0936 -0.1227 -0.0762 -0.0971 -0.1192 -0.3161 -0.1997 -0.4624 -0.0879 -0.0605 -0.2514 -0.1372 -0.9902 -0.6443 -0.0856 -1.4451 -0.0541 -0.0665 -0.0849 -0.1082 -0.1135 -0.1155 -0.8908 -0.1246 -0.0305 -0.0723 -0.0474 -0.0492 -0.0575 -0.0398 -0.1925 -0.0422 -0.1354 -1.9494 -0.9532 -0.2735 -0.1000 -0.0803 -0.0781 -0.1695 -0.2228 -0.1366 -1.5500 -0.3448 -0.4092 -0.8960 -0.0208 -1.0740 -1.0429 -0.4700 -0.5147 -0.1054\n",
            "T-415\tGalu wabulauni wokhala ndi kolala yofiirira akuyang'ana kumanzere ndi thambo loyera la buluu kumbuyo kwake .\n",
            "H-415\t-0.2551771104335785\t▁ G a l u ▁ w a k u d a ▁ w o k h a l a ▁ n d i ▁ k o l a l a ▁ y o f i i r a ▁ a k u y a n g ' a n a ▁ k u m a n z e r e ▁ n d i ▁ m a b o k o ▁ o y e r a ▁ a k u m b u y o ▁ k w a k e ▁ .\n",
            "D-415\t-0.2551771104335785\tGalu wakuda wokhala ndi kolala yofiira akuyang'ana kumanzere ndi maboko oyera akumbuyo kwake .\n",
            "P-415\t-0.1179 -0.3843 -0.1263 -0.0593 -0.1034 -0.1319 -0.0560 -0.2156 -1.2796 -0.1143 -1.3541 -0.1107 -0.2136 -0.6556 -0.0861 -0.0637 -0.0725 -0.1082 -0.0649 -0.0972 -0.1303 -0.0514 -0.1465 -0.1015 -0.1240 -0.7670 -0.3177 -0.0556 -0.1501 -0.0494 -0.1074 -0.1939 -0.0994 -0.0822 -0.0551 -0.0996 -0.4408 -0.0851 -0.8339 -0.2520 -0.0953 -0.0722 -0.0801 -0.1048 -0.1350 -0.0887 -0.1052 -0.0721 -0.0996 -0.0996 -0.0978 -0.0992 -0.2394 -0.2313 -0.1112 -0.0647 -0.3161 -0.1217 -0.0723 -0.0508 -0.0651 -0.1379 -0.0737 -0.0659 -0.1371 -0.1305 -0.7555 -0.1009 -0.4256 -0.3338 -2.4040 -0.0536 -0.5955 -0.5465 -0.1155 -0.0892 -0.0935 -0.1063 -0.1841 -0.6708 -1.2708 -0.1050 -0.3351 -0.6939 -0.0920 -0.1020 -0.0710 -0.1574 -0.3140 -0.1198 -0.1107 -1.2476 -0.1141 -0.5893 -0.0573 -0.1167\n",
            "T-159\tMwamuna wayima kumbuyo ndi desiki ndipo pali mbali ya galimoto yofiyira yomwe ili pamwamba pamutu pake.\n",
            "H-159\t-0.2597907483577728\t▁ M w a m u n a ▁ w a i m a ▁ k u m b u y o ▁ n d i ▁ t s i t s i ▁ l a l i t a l i ▁ p a ▁ g a l i m o t o ▁ y o f i i r a ▁ y o f i i r a ▁ y o m w e ▁ i l i ▁ p a m w a m b a ▁ p a ▁ m u t u ▁ p a k e ▁ .\n",
            "D-159\t-0.2597907483577728\tMwamuna waima kumbuyo ndi tsitsi lalitali pa galimoto yofiira yofiira yomwe ili pamwamba pa mutu pake .\n",
            "P-159\t-0.1150 -0.0627 -0.0442 -0.0893 -0.1145 -0.0730 -0.1042 -0.1033 -0.2421 -0.0978 -0.1276 -2.7953 -0.0659 -0.1439 -0.1023 -0.0910 -0.1208 -0.5419 -0.0695 -0.0889 -0.1951 -0.0768 -0.1322 -0.0579 -0.0614 -0.1203 -0.1018 -2.0182 -0.6526 -0.0820 -0.0393 -0.1159 -0.0836 -0.0992 -0.0846 -0.4430 -0.0989 -0.0897 -0.0314 -0.0651 -0.0366 -0.0953 -0.1703 -1.7375 -0.1297 -0.8876 -1.0788 -0.1169 -0.0373 -0.0846 -0.0428 -0.0991 -0.0552 -0.0364 -0.1485 -0.0358 -0.4739 -0.0725 -0.1041 -0.5980 -0.1063 -0.1538 -0.2390 -0.1256 -0.5852 -1.0625 -0.0886 -0.7278 -0.0923 -0.2265 -0.2659 -0.2305 -0.8223 -0.1389 -0.0350 -0.0962 -0.0780 -0.2879 -0.4043 -0.0815 -0.1081 -0.0105 -0.1330 -0.1448 -0.2344 -0.0764 -0.0443 -0.0891 -0.1202 -0.1860 -0.0204 -0.1255 -0.1564 -0.2592 -0.2416 -0.1108 -0.0779 -0.1241 -1.2255 -0.1304 -0.5007 -0.1283 -1.1826 -0.0200 -0.0968\n",
            "T-164\tWonyamula golide ataima panja pachipale chofewa ndipo munthu waima ndi ma ski ndi mitengo .\n",
            "H-164\t-0.3017556965351105\t▁ W o n y a m u l a ▁ b u l u u ▁ n d i ▁ a t a y i m a ▁ p a n j a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ b u l u u ▁ w a i m a ▁ m ' m a d z i ▁ n d i ▁ m a s i t e p e ▁ .\n",
            "D-164\t-0.3017556965351105\tWonyamula buluu ndi atayima panja pa chipale chofewa ndi buluu waima m'madzi ndi masitepe .\n",
            "P-164\t-0.1197 -0.2421 -0.0618 -1.2537 -0.0780 -0.0942 -0.1318 -0.1089 -0.1976 -0.1101 -0.1339 -1.4343 -0.3139 -0.0702 -0.7014 -0.1508 -0.1363 -0.9981 -0.1280 -0.1128 -0.1073 -3.1372 -0.0457 -0.1160 -1.0472 -0.0627 -0.1045 -0.0859 -0.0960 -0.0172 -0.1483 -0.5428 -0.0209 -0.1280 -0.1515 -0.0962 -0.1626 -0.2242 -0.0629 -0.0777 -0.0822 -0.5650 -0.1299 -0.0634 -0.0574 -0.1205 -0.0144 -0.1000 -0.0519 -0.6503 -0.1113 -0.0739 -0.0855 -0.2161 -0.3428 -0.2088 -0.1006 -0.3791 -1.0584 -2.0729 -0.1829 -0.3573 -0.1393 -0.1422 -0.5444 -0.1744 -0.2970 -0.0463 -0.0828 -0.0989 -1.0323 -0.6331 -0.1357 -0.0815 -0.6707 -0.0879 -0.0620 -0.2458 -0.4683 -0.0607 -0.0984 -0.1250 -0.1051 -0.1666 -0.9184 -0.2997 -0.0934 -0.0710 -0.1645 -0.0658 -0.2623 -0.5531 -0.0991\n",
            "T-189\tMnyamata wovala chisoti panjinga akuwuluka mumlengalenga pamene akukwera pakati pa mapiri afumbi ndi mtsinje kumbuyo kwake .\n",
            "H-189\t-0.2659590244293213\t▁ M n y a m a t a ▁ w o v a l a ▁ c h i s o t i ▁ p a n j i n g a ▁ a k u w u l u k a ▁ m l e n g a l e n g a ▁ a k u k w e r a ▁ p a k a t i ▁ p a ▁ m p i r i ▁ n d i ▁ m u n t h u ▁ w o v a l a ▁ j e k e t e ▁ l a c h i k u l u ▁ .\n",
            "D-189\t-0.2659590244293213\tMnyamata wovala chisoti panjinga akuwuluka mlengalenga akukwera pakati pa mpiri ndi munthu wovala jekete lachikulu .\n",
            "P-189\t-0.1268 -0.0366 -0.0586 -0.0524 -0.0951 -0.0870 -0.1071 -0.0503 -0.1074 -0.1149 -0.0905 -0.1100 -0.0528 -0.1227 -0.0656 -0.1102 -0.0923 -0.3948 -0.0720 -0.0996 -0.2928 -0.0531 -0.0291 -0.0624 -0.1134 -2.2392 -0.1149 -0.1398 -0.0275 -0.0885 -0.0474 -0.0993 -0.0888 -0.1291 -0.0930 -0.1541 -0.1084 -2.1848 -0.0836 -0.0411 -0.0427 -0.0395 -0.1043 -0.1016 -0.0884 -0.8968 -0.0761 -0.3645 -0.3130 -0.1222 -0.0461 -0.0638 -0.0467 -0.2942 -0.0900 -0.1861 -2.1877 -0.1085 -0.0712 -0.0739 -0.1335 -0.0446 -0.1073 -0.1268 -0.1235 -0.0434 -0.1582 -0.6491 -0.1107 -0.4480 -0.1046 -0.1272 -0.0058 -0.1402 -0.1513 -0.5455 -0.0818 -0.1545 -0.2699 -1.6365 -0.1814 -1.2581 -0.0958 -0.1099 -0.1209 -0.1944 -0.8794 -0.1391 -0.5168 -0.1636 -0.0651 -0.1088 -0.1854 -0.7603 -1.4434 -0.2179 -0.0857 -0.0992 -0.0966 -0.3797 -0.2748 -0.1493 -0.1425 -0.0394 -0.1210 -0.1273 -0.2771 -0.9500 -0.3380 -0.1257 -0.0927 -0.0891 -1.7792 -0.1949 -0.2132 -0.2372 -0.3041 -0.1094\n",
            "T-258\tAnthu angapo akhala mozungulira kukoka matebulo okhala ndi zinthu zamaofesi pamwamba pake.\n",
            "H-258\t-0.2585824429988861\t▁ A n t h u ▁ a n g a p o ▁ a k h a l a ▁ m o z u n g u l i r a ▁ k u k a m w a ▁ n d i ▁ g u l u ▁ l o k h a l a ▁ n d i ▁ z i z i n d i k i r o ▁ z a ▁ m w a m b a ▁ p a ▁ m w a m b a ▁ p a k e .\n",
            "D-258\t-0.2585824429988861\tAnthu angapo akhala mozungulira kukamwa ndi gulu lokhala ndi zizindikiro za mwamba pa mwamba pake.\n",
            "P-258\t-0.1281 -0.0590 -0.1636 -0.0355 -0.0805 -0.0624 -0.1015 -0.1303 -0.0310 -0.0253 -0.0835 -0.0095 -0.0598 -0.1238 -0.0827 -0.4782 -0.4668 -0.1163 -0.0375 -0.0912 -0.1198 -0.1873 -0.2880 -0.1073 -0.0674 -0.0509 -0.0191 -0.0813 -0.0477 -0.1088 -0.1002 -0.1007 -0.1685 -0.2216 -0.7904 -0.7979 -0.6504 -0.0364 -1.4499 -0.1589 -0.1620 -1.1531 -0.1024 -0.1886 -0.2790 -0.7636 -0.9754 -0.0922 -0.1018 -0.1234 -0.0351 -0.1007 -1.0845 -0.1241 -0.1312 -0.0637 -0.1187 -0.1222 -0.1006 -0.0766 -0.1287 -0.0831 -0.0182 -0.1166 -0.3135 -0.0768 -0.1313 -0.6099 -0.0825 -0.1580 -0.0713 -1.9011 -0.1823 -0.1775 -0.0384 -0.1616 -0.7116 -0.1105 -0.7869 -0.0965 -0.0595 -0.2367 -0.1055 -0.2384 -0.4972 -0.1222 -1.1473 -0.1065 -0.3669 -0.0902 -0.0675 -0.1952 -0.0911 -0.2972 -0.8188 -0.1304 -0.3858 -0.0280 -0.9784 -0.1210\n",
            "T-318\tKamera imayang'ana pansi mkati mwa chubu chobiriwira pamene mwana akutsetsereka.\n",
            "H-318\t-0.2828660011291504\t▁ K a m e r a ▁ i m a y a n g ' a n a ▁ p a n s i ▁ n d i ▁ m k a t i ▁ m w a ▁ c h o b i r i w i r a ▁ p a m e n e ▁ m w a n a ▁ a k u s e w e r a ▁ .\n",
            "D-318\t-0.2828660011291504\tKamera imayang'ana pansi ndi mkati mwa chobiriwira pamene mwana akusewera .\n",
            "P-318\t-0.1287 -0.1084 -0.1630 -0.0864 -0.5296 -0.2943 -0.1446 -0.1869 -1.1721 -0.1441 -0.3758 -0.1465 -0.1219 -0.0674 -0.1477 -0.0648 -0.1051 -0.0585 -0.1169 -0.1197 -1.6649 -0.1436 -0.1271 -0.3715 -0.0859 -0.1467 -0.8126 -1.3197 -0.1252 -0.1278 -0.3101 -0.2244 -0.0951 -0.7088 -0.0817 -0.2857 -0.0476 -0.0929 -0.0909 -0.1492 -0.4935 -0.0893 -0.8564 -2.4294 -0.1016 -0.0560 -0.1118 -0.0393 -0.1162 -0.0565 -0.1129 -0.2340 -0.5909 -0.1393 -0.2131 -0.0901 -0.1113 -0.0691 -0.1037 -0.1375 -0.1212 -0.1054 -0.3727 -0.1088 -0.1578 -0.1219 -0.0776 -0.0782 -0.1524 -0.0626 -0.6269 -0.0815 -0.0747 -0.6641 -0.2179 -1.2108 -0.1009\n",
            " 54% 7/13 [00:18<00:12,  2.02s/it, wps=1149]T-373\tAnthu angapo ali papaki akuwonera masewera a chess omwe akuseweredwa ndi zidutswa zazikulu.\n",
            "H-373\t-0.36918821930885315\t▁ A n t h u ▁ a t a t u ▁ a l i ▁ p a ▁ k a t i ▁ a k u w o n e r a ▁ m a s e w e r a ▁ o m w e ▁ a k u s e w e r a ▁ n d i ▁ z i d a ▁ z a z i k u l u ▁ .\n",
            "D-373\t-0.36918821930885315\tAnthu atatu ali pa kati akuwonera masewera omwe akusewera ndi zida zazikulu .\n",
            "P-373\t-0.1264 -0.0266 -0.1276 -0.0378 -0.1178 -0.0762 -0.0978 -0.1315 -0.4664 -0.1025 -2.0260 -0.0501 -0.1321 -0.2598 -0.5903 -0.0880 -0.1154 -0.0560 -0.1343 -0.5446 -1.0261 -1.4869 -2.0911 -0.1202 -0.1420 -1.1278 -0.1553 -0.1222 -0.4065 -0.1020 -0.1021 -0.1927 -0.2538 -0.1000 -0.1331 -0.0844 -0.0889 -0.0849 -0.0631 -0.1367 -0.0678 -0.0939 -0.1244 -0.1400 -1.1888 -0.2952 -0.7914 -0.0916 -0.0980 -0.3029 -0.5538 -0.1118 -0.3803 -0.0727 -1.3417 -0.1110 -0.1141 -0.1220 -0.1271 -2.1510 -0.1140 -0.1232 -0.1087 -0.5155 -0.0888 -0.4987 -1.9391 -0.1083 -0.0509 -0.1193 -2.2328 -0.1021 -0.1840 -0.1210 -0.0480 -0.0934 -0.7473 -0.2385 -0.1258\n",
            "T-207\tMtsikana akuyang'ana mnyamata wa blond akugwedezeka pampando ndi nyumba zowonekera kumbuyo kwake .\n",
            "H-207\t-0.31501856446266174\t▁ G u l u ▁ l a ▁ a n t h u ▁ l i k u y a n g ' a n a ▁ m a t h a l a u z a ▁ a k u d y a ▁ p a m p h e p e t e ▁ m w a ▁ n y u m b a ▁ y o k o n g o l a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-207\t-0.31501856446266174\tGulu la anthu likuyang'ana mathalauza akudya pamphepete mwa nyumba yokongola kumbuyo kwake .\n",
            "P-207\t-0.1192 -1.1357 -0.2163 -0.1814 -0.1185 -0.1092 -0.1020 -0.1981 -0.6387 -0.1456 -0.6783 -1.3873 -0.0898 -0.0719 -0.1741 -0.5290 -1.0375 -0.2826 -0.1041 -0.0491 -0.1382 -0.0891 -0.1700 -0.0909 -0.0934 -0.0835 -0.1132 -0.1101 -0.1141 -0.1226 -0.4699 -0.3101 -0.0991 -0.3817 -0.1903 -0.0623 -0.0775 -0.1038 -0.1020 -0.5962 -1.1164 -0.1393 -0.7439 -0.8392 -0.9442 -0.1740 -1.0691 -0.1334 -0.4708 -1.8839 -0.4309 -0.2604 -0.2004 -0.4878 -0.0338 -0.0653 -0.0955 -0.5018 -0.2376 -0.1185 -0.1037 -0.0527 -0.6660 -0.0601 -0.1631 -0.0375 -0.0917 -0.1654 -0.3027 -0.1316 -1.5689 -0.6119 -0.0468 -0.6917 -0.0517 -0.0944 -0.1433 -0.1472 -0.3937 -0.2341 -0.9011 -0.3162 -0.0594 -0.0449 -0.0575 -0.1815 -0.2695 -0.1265 -0.1139 -0.0574 -0.0911 -0.6167 -0.0674 -0.1180\n",
            "T-185\tMunthu wovala mathalauza akuda ndi kusindikiza pamwamba pa ski mumlengalenga pamwamba pa chipale chofewa.\n",
            "H-185\t-0.24038051068782806\t▁ M u n t h u ▁ w o v a l a ▁ m a t h a l a u z a ▁ a l i ▁ n d i ▁ k u s i n d i k i z a ▁ p a m w a m b a ▁ p a ▁ s i t e j i ▁ m ' m w a m b a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-185\t-0.24038051068782806\tMunthu wovala mathalauza ali ndi kusindikiza pamwamba pa siteji m'mwamba pa chipale chofewa .\n",
            "P-185\t-0.1139 -0.1557 -0.0906 -0.0583 -0.0617 -0.0730 -0.0734 -0.1397 -0.1006 -0.0738 -0.0823 -0.1279 -0.0821 -0.1106 -0.0953 -0.2333 -0.1155 -0.5870 -0.0121 -0.1067 -0.1281 -0.1155 -0.0296 -0.0087 -0.0983 -0.0992 -0.1251 -3.4508 -0.3460 -0.0925 -0.0991 -0.0860 -0.1339 -0.1114 -1.5546 -0.0914 -0.4430 -0.1432 -0.4125 -1.3863 -0.0862 -0.1265 -0.0424 -0.2014 -0.1151 -0.1436 -0.3226 -0.1548 -0.1524 -0.2079 -0.1107 -0.0786 -0.1253 -0.1108 -0.0984 -0.0252 -0.1282 -0.1091 -0.0613 -0.4425 -0.0769 -0.7660 -0.6408 -0.0693 -0.2350 -0.5493 -1.1935 -0.2033 -0.7481 -0.0979 -0.0864 -0.0814 -0.1060 -0.1514 -0.0383 -0.1196 -1.1711 -0.4125 -0.0721 -0.1411 -0.0674 -0.0994 -0.0582 -0.0822 -0.0841 -0.0308 -0.1082 -0.0549 -0.0132 -0.0788 -0.0447 -0.1106 -0.5897 -0.0569 -0.1059\n",
            "T-182\tMwamuna wovala malaya abuluu akukwera mwala pamene anthu kumbuyo kwake atavala malaya ofiira akuonera .\n",
            "H-182\t-0.2281106859445572\t▁ M w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u k w e r a ▁ m i y i ▁ a k u y e n d a ▁ m ' b w a l o ▁ l a ▁ m a l a y a ▁ o f i i r a ▁ a k u w o n e r a ▁ .\n",
            "D-182\t-0.2281106859445572\tMwamuna wovala malaya abuluu akukwera miyi akuyenda m'bwalo la malaya ofiira akuwonera .\n",
            "P-182\t-0.1196 -0.0602 -0.0439 -0.1234 -0.2836 -0.0906 -0.0867 -0.1050 -0.1355 -0.0863 -0.1214 -0.0740 -0.1298 -0.0782 -0.1220 -0.1050 -0.0581 -0.1085 -0.0566 -0.1091 -0.0853 -0.0960 -0.1077 -0.1238 -0.1168 -0.1309 -0.0628 -0.0807 -0.0410 -0.1289 -0.1094 -0.1982 -0.0859 -0.5572 -0.2315 -0.0931 -0.1436 -0.1045 -0.1140 -0.1209 -1.2777 -1.0044 -0.4584 -0.1368 -0.7516 -1.3938 -0.4979 -0.3646 -0.4776 -0.1586 -0.0261 -0.1846 -0.1190 -1.5886 -0.0442 -0.6426 -0.0649 -0.1128 -0.0988 -0.1000 -0.0914 -0.0341 -0.1783 -0.4128 -0.1989 -0.1057 -1.1057 -0.3924 -0.0814 -0.0966 -0.0971 -0.0446 -0.1988 -0.1016 -0.1184 -0.0669 -0.2417 -0.2976 -0.3986 -0.1703 -0.1075 -0.3518 -0.0765 -0.1011 -0.1985 -0.1570 -0.1246 -0.2834 -0.2628 -0.1018\n",
            "T-309\tMayi wovala malaya oyera akuyang'ana mayi yemwe wakhala pafupi naye yemwe akupanga nkhope yoseketsa .\n",
            "H-309\t-0.2525366246700287\t▁ M a y i ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u y a n g ' a n a ▁ m a y i ▁ w a k h a l a ▁ p a f u p i ▁ n a y e ▁ y e m w e ▁ w a v a l a ▁ m a g o l o s i ▁ o f i i r a ▁ .\n",
            "D-309\t-0.2525366246700287\tMayi wovala malaya oyera akuyang'ana mayi wakhala pafupi naye yemwe wavala magolosi ofiira .\n",
            "P-309\t-0.1215 -0.2122 -0.0863 -0.0735 -0.1005 -0.1018 -0.1108 -0.1451 -0.0737 -0.1278 -0.0699 -0.1088 -0.1144 -0.0941 -0.1367 -0.0871 -0.0954 -0.0496 -0.0858 -0.1185 -0.0573 -0.0765 -0.0924 -0.1140 -0.0940 -0.1635 -0.4715 -0.0915 -0.0700 -0.0843 -0.1490 -0.0964 -0.1122 -0.0886 -0.0973 -0.1711 -0.0949 -0.0991 -0.3714 -0.6045 -1.3938 -0.1330 -0.0947 -0.1086 -0.1701 -2.4504 -0.0183 -0.1151 -0.0643 -0.1178 -0.1104 -0.0199 -0.1640 -0.1029 -0.0763 -0.0593 -0.1271 -0.0825 -0.0497 -1.0314 -0.0413 -0.0970 -0.2692 -0.8362 -0.3386 -0.1005 -0.0641 -0.1836 -0.0927 -0.7424 -0.1316 -1.0470 -0.0998 -0.1182 -0.1220 -0.0909 -0.4365 -0.1222 -0.2467 -0.2209 -0.9058 -0.2271 -1.0705 -0.0885 -0.1526 -0.4317 -2.0639 -0.1204 -0.1485 -0.1192 -0.3830 -0.5980 -0.1145 -0.1109\n",
            "T-156\tAna amasewera mumchenga wozunguliridwa ndi mchenga wokhala ndi mazenera ambiri ngati otsegula .\n",
            "H-156\t-0.308243066072464\t▁ A n a ▁ a m a s e w e r a ▁ m ' c h e n g o ▁ w o z u n g u l i r i d w a ▁ n d i ▁ m k a z i ▁ w a ▁ m k a z i ▁ n d i ▁ m a s e w e r a ▁ a ▁ m p i r a ▁ o s e w e r a ▁ .\n",
            "D-156\t-0.308243066072464\tAna amasewera m'chengo wozunguliridwa ndi mkazi wa mkazi ndi masewera a mpira osewera .\n",
            "P-156\t-0.1142 -0.0566 -0.0691 -0.1405 -0.1378 -0.1376 -0.3028 -0.1219 -0.0482 -0.0453 -0.1673 -0.0935 -0.0590 -0.1089 -0.1639 -2.4261 -0.0810 -0.4994 -0.1220 -1.5718 -1.6487 -0.0475 -0.2153 -0.1622 -0.8412 -0.1286 -0.7781 -0.0611 -0.0810 -0.0298 -0.0735 -0.0469 -0.0894 -0.1150 -0.1550 -0.0412 -0.1027 -0.0863 -0.1556 -0.0561 -0.0615 -0.1142 -0.0923 -0.1861 -0.3844 -0.1001 -1.1891 -0.1023 -0.1778 -0.2594 -0.6469 -0.6775 -0.1811 -1.5428 -0.1786 -0.2438 -0.1166 -0.1543 -0.1195 -0.0555 -0.1221 -0.1043 -0.0683 -0.1776 -0.2925 -0.1029 -0.2016 -0.0783 -0.0917 -0.1072 -0.1408 -0.2007 -0.6047 -0.1623 -0.5940 -0.1035 -0.2874 -0.2493 -0.2870 -1.1974 -0.2592 -0.1743 -0.4448 -0.3422 -0.0950 -0.1958 -0.3214 -2.3603 -0.1008\n",
            "T-295\tMbalame yotuwa ya m'madzi yokhala ndi zizindikiro zakuda ndi zoyera ikuuluka pafupi ndi madzi.\n",
            "H-295\t-0.2874409854412079\t▁ M a y i ▁ a m e n e ▁ w a v a l a ▁ y u n i f o l o m u ▁ y o k h a l a ▁ n d i ▁ z i z i n d i k i r o ▁ z a k u d y a ▁ n d i ▁ z o y e r a ▁ p a f u p i ▁ n d i ▁ m a t a b w a ▁ .\n",
            "D-295\t-0.2874409854412079\tMayi amene wavala yunifolomu yokhala ndi zizindikiro zakudya ndi zoyera pafupi ndi matabwa .\n",
            "P-295\t-0.1185 -2.1791 -0.2091 -0.6397 -0.0865 -0.1090 -0.8017 -0.1794 -0.0796 -0.4715 -0.1117 -0.2425 -0.4562 -0.1319 -2.1357 -0.1093 -0.0813 -0.1049 -0.1228 -1.0690 -0.1095 -0.0527 -0.0455 -0.2194 -0.1476 -0.0898 -0.1105 -0.0737 -0.0694 -0.1263 -0.0104 -0.2276 -0.0264 -0.1101 -0.1014 -0.0384 -0.0888 -0.1014 -0.0440 -0.0847 -0.0952 -0.0713 -0.1300 -0.0802 -0.3421 -0.1308 -0.1808 -0.1462 -0.1251 -0.3081 -0.0579 -0.1546 -0.0446 -0.1183 -0.5735 -0.1848 -1.4634 -0.0957 -0.8721 -0.6758 -0.2703 -0.1595 -0.1541 -0.1152 -0.1062 -0.1233 -0.0140 -0.0724 -0.1036 -0.0832 -0.0976 -0.1031 -0.1623 -0.4388 -0.1146 -0.0567 -0.0706 -0.1329 -0.1264 -0.1370 -0.0776 -0.1482 -0.1102 -0.0911 -0.1188 -0.1357 -2.1621 -1.6376 -1.2656 -0.0853 -0.0619 -0.3262 -0.8661 -0.1241\n",
            "T-407\tMnyamata watsitsi lakuda wovala malaya abuluu , mpango wobiriwira ndi magalasi akupanga mbale pagudumu ladothi .\n",
            "H-407\t-0.1942070871591568\t▁ M n y a m a t a ▁ w a t s i t s i ▁ l a k u d a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ w o b i r i w i r a ▁ n d i ▁ m a g a l a s i ▁ a k u d u m p h a ▁ m ' m w a m b a ▁ .\n",
            "D-407\t-0.1942070871591568\tMnyamata watsitsi lakuda wovala malaya abuluu wobiriwira ndi magalasi akudumpha m'mwamba .\n",
            "P-407\t-0.1282 -0.0670 -0.0281 -0.0749 -0.1018 -0.0702 -0.1076 -0.0343 -0.0928 -0.1131 -0.0830 -0.1556 -0.1880 -0.0485 -0.0904 -0.0411 -0.0397 -0.0900 -0.0693 -0.1629 -0.1072 -0.0878 -0.0906 -0.0872 -0.1013 -0.1615 -0.1048 -0.1408 -0.0450 -0.1093 -0.0826 -0.1123 -0.1027 -0.0687 -0.1099 -0.0697 -0.1143 -0.0929 -0.0983 -0.1435 -0.1286 -0.1444 -0.0770 -0.0570 -0.1092 -0.0485 -0.1398 -1.3589 -0.2357 -0.0973 -0.0925 -0.0856 -0.0970 -0.0672 -0.1327 -0.0755 -0.1079 -0.2130 -0.3269 -0.0908 -0.1122 -0.0964 -0.0653 -0.1282 -0.4207 -0.3575 -0.0966 -0.1070 -0.0226 -0.0987 -0.1865 -0.2053 -0.1864 -0.1078 -1.4096 -0.1087 -0.0363 -0.3240 -0.0972 -0.1076 -0.1456 -0.5267 -0.5782 -1.1797 -1.4522 -0.0984 -0.0337 -0.0543 -0.1078 -0.2918 -1.5089 -0.1126\n",
            "T-286\tBambo wina wovala jeans ndi jekete yabuluu akuyenda m'manda masana ali ndi manja m'matumba .\n",
            "H-286\t-0.24774880707263947\t▁ A m u n a ▁ a w i r i ▁ o v a l a ▁ j e k e t e ▁ y a ▁ b u l u u ▁ a k u y e n d a ▁ m ' m a s o ▁ a n t h u ▁ a m a s o n k h a n a ▁ n d i ▁ m a n j a ▁ m ' t a m b o .\n",
            "D-286\t-0.24774880707263947\tAmuna awiri ovala jekete ya buluu akuyenda m'maso anthu amasonkhana ndi manja m'tambo.\n",
            "P-286\t-0.1213 -0.0793 -0.0715 -0.0886 -0.0867 -0.0974 -0.1615 -0.1938 -0.0486 -0.1053 -0.0907 -0.0940 -0.3594 -0.7066 -0.0633 -0.1147 -0.0831 -0.1196 -0.1128 -0.0772 -0.1164 -0.1361 -0.0753 -0.0203 -0.0969 -0.1187 -0.1729 -0.1140 -0.4278 -0.0409 -0.1332 -0.0666 -0.0721 -0.0347 -0.1431 -0.0947 -0.0594 -0.0747 -0.3173 -0.3202 -0.1240 -0.0396 -0.1188 -0.1196 -0.0794 -0.4961 -0.0751 -0.1049 -0.3031 -0.3701 -0.0985 -0.2090 -1.3653 -0.6231 -0.0637 -0.0956 -0.1392 -0.1392 -0.4379 -0.1839 -0.1273 -2.4152 -0.3784 -0.1330 -0.0531 -0.1160 -0.0451 -0.1552 -0.1700 -1.9096 -0.1357 -0.1018 -0.0891 -0.0572 -0.1279 -0.7450 -0.0603 -0.0966 -0.1989 -0.8996 -0.6228 -0.2248 -0.1192 -0.6789 -0.0321 -0.2299 -1.0716 -0.1109\n",
            "T-326\tAmuna awiri achikulire akukambitsirana panja m'dera lokhala ndi makoma amiyala ndi pansi .\n",
            "H-326\t-0.30661138892173767\t▁ A m u n a ▁ a w i r i ▁ a c h i k u l i r e ▁ a k u k a m b i r a n a ▁ p a n j a ▁ p a n j a ▁ n d i ▁ a n a ▁ o k h a l a ▁ n d i ▁ m a k o m a ▁ a ▁ m i y a l a ▁ .\n",
            "D-326\t-0.30661138892173767\tAmuna awiri achikulire akukambirana panja panja ndi ana okhala ndi makoma a miyala .\n",
            "P-326\t-0.1085 -0.1230 -0.0853 -0.0896 -0.0751 -0.1014 -0.1298 -0.1372 -0.0456 -0.1195 -0.0665 -0.1192 -0.3020 -0.1556 -0.0900 -0.0985 -0.1099 -0.3179 -0.0906 -0.1165 -0.0702 -0.0828 -0.1663 -0.1693 -0.1698 -0.2664 -0.1169 -1.7795 -0.4689 -0.2385 -0.0491 -0.0851 -0.1578 -0.1059 -0.8010 -0.0728 -0.1530 -1.4507 -0.1226 -0.5440 -1.1049 -0.1991 -0.2183 -0.2823 -0.1435 -0.9321 -1.1191 -0.1688 -0.1749 -1.0758 -0.1169 -0.1713 -0.6829 -0.2894 -0.1729 -1.1537 -0.1166 -0.0382 -0.1130 -0.1802 -0.1225 -0.0500 -0.1154 -0.1323 -0.0599 -0.0766 -0.1304 -0.1396 -0.0456 -0.1030 -0.7945 -0.4718 -1.1095 -0.2849 -0.1698 -0.1849 -0.7557 -0.9388 -0.3348 -0.1679 -0.1115 -0.0279 -0.1080 -0.2573 -1.5596 -0.1107\n",
            "T-147\tWokwera pa chipale chofewa akudumpha mozondoka pamalo osungiramo mapiri a terrain park.\n",
            "H-147\t-0.23934973776340485\t▁ W o k w e r a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ a k u d u m p h a ▁ m u m z i n d a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ m a p i r i ▁ a ▁ s k a t e b o a r d .\n",
            "D-147\t-0.23934973776340485\tWokwera pa chipale chofewa akudumpha mumzinda wovala malaya ofiira ndi mapiri a skateboard.\n",
            "P-147\t-0.1216 -0.1483 -0.0521 -0.1140 -0.1024 -0.1541 -0.0678 -0.1421 -0.1744 -0.0384 -0.1530 -0.4940 -0.0720 -0.2152 -0.0793 -0.0521 -0.0973 -0.0322 -0.1035 -0.0886 -0.0229 -0.1233 -0.0642 -0.0735 -0.0980 -0.0401 -0.1017 -0.2052 -0.4560 -0.0492 -0.0925 -0.0822 -0.0847 -0.0852 -0.1221 -0.0956 -0.1022 -0.1478 -0.1159 -1.2650 -0.4712 -0.7242 -1.1812 -0.1509 -0.1415 -0.6190 -0.2808 -0.0447 -0.1308 -1.5137 -0.1155 -0.0846 -0.1155 -0.1125 -0.1191 -0.1201 -0.2469 -0.1289 -0.0638 -0.1038 -0.1004 -0.1308 -0.4321 -0.1163 -0.1367 -0.0625 -0.3750 -0.2086 -0.7740 -0.1483 -0.1195 -0.0826 -0.3117 -0.0921 -1.5418 -0.6525 -0.0490 -0.0829 -0.1726 -0.2994 -0.3000 -0.9236 -0.8453 -0.0893 -0.0169 -0.0817 -0.3217 -0.0459 -0.0962 -0.0413 -0.0955 -1.0091 -0.1056\n",
            "T-242\tGalimoto yoyaka moto yofiira yayimitsidwa pafupi ndi gulu la anthu ndi ana omwe aima mumsewu .\n",
            "H-242\t-0.27454283833503723\t▁ G a l i m o t o ▁ y o y e r a ▁ p a m u t u ▁ y o f i y i r a ▁ y a y i t s i d w a ▁ p a f u p i ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ a n a y i ▁ m u m s e w u ▁ .\n",
            "D-242\t-0.27454283833503723\tGalimoto yoyera pamutu yofiyira yayitsidwa pafupi ndi gulu la anthu anayi mumsewu .\n",
            "P-242\t-0.1199 -0.1293 -0.1077 -0.0666 -0.1348 -0.1086 -0.0590 -0.0990 -0.0295 -0.2594 -0.0491 -0.2092 -0.1077 -0.1607 -0.2167 -0.1330 -0.1609 -3.4085 -0.1197 -0.5202 -0.1680 -0.3275 -0.0888 -0.0913 -0.1583 -0.1079 -0.0814 -0.1282 -0.8178 -0.1407 -0.0997 -0.0980 -0.1796 -0.3828 -0.1486 -1.1060 -0.1117 -1.5242 -0.5956 -0.0689 -0.1359 -0.0841 -0.1218 -0.1528 -0.0691 -0.1339 -0.0238 -0.0761 -0.0955 -0.0917 -0.1019 -0.1088 -0.1262 -0.1385 -0.1201 -0.0078 -0.0757 -0.1802 -0.0368 -0.1415 -0.1245 -0.1132 -0.1358 -0.0992 -0.0406 -0.0303 -0.1047 -0.0643 -0.1034 -0.5778 -1.7519 -0.2696 -0.6197 -0.1031 -0.2129 -1.6612 -1.4564 -0.1096 -0.0223 -0.0879 -0.1038 -0.1023 -0.4551 -0.2434 -0.0967\n",
            "T-88\tMtsikana yemwe wakhala pafupi ndi bambo yemwe wavala t-shirt yoyera akudya zokazinga zachi french .\n",
            "H-88\t-0.25469961762428284\t▁ M t s i k a n a ▁ y e m w e ▁ w a v a l a ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ j e k e t e ▁ y o y e r a ▁ a k u j a z i ▁ z o k h a l a ▁ n d i ▁ c h i s a n u ▁ .\n",
            "D-88\t-0.25469961762428284\tMtsikana yemwe wavala pafupi ndi bambo wa malaya oyera ndi jekete yoyera akujazi zokhala ndi chisanu .\n",
            "P-88\t-0.1174 -0.0636 -0.0345 -0.0912 -0.1017 -0.0599 -0.1170 -0.0884 -0.1008 -0.2072 -0.2655 -0.0437 -0.0260 -0.0790 -0.1086 -0.0944 -0.0151 -0.1078 -0.0975 -0.1061 -0.0992 -0.0932 -0.1066 -0.9951 -0.8876 -0.1570 -0.0621 -0.0586 -0.1214 -0.1011 -0.0541 -0.0769 -0.1149 -0.0954 -0.3394 -0.0844 -0.0590 -0.0357 -0.0547 -0.0925 -0.6281 -0.2042 -1.7480 -0.3470 -0.1859 -0.3297 -0.1040 -0.1987 -0.0972 -0.0995 -1.5950 -0.8654 -0.0532 -0.1271 -0.1083 -0.1851 -0.3891 -0.1183 -0.1416 -0.1102 -0.2296 -0.1078 -0.3088 -0.0740 -0.0377 -0.2134 -0.1058 -0.1596 -0.1031 -0.2442 -0.0637 -0.1457 -0.0979 -0.1883 -0.1347 -0.1022 -0.1026 -1.2815 -0.2377 -1.0655 -0.1043 -0.1332 -0.6400 -0.2958 -0.0756 -0.7313 -0.1212 -0.4693 -0.1108 -0.1111 -0.4514 -0.2531 -0.1168 -0.0889 -0.4662 -0.0905 -0.0900 -2.0458 -0.5837 -0.4195 -0.1201 -0.4952 -0.1136 -0.1077\n",
            "T-408\tMunthu wovala mofiyira komanso mathalauza obisala wapindika m'chiuno ndipo manja ake ali pamtengo waukulu .\n",
            "H-408\t-0.2157621830701828\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ k o m a n s o ▁ m a t h a l a u z a ▁ o b i r i w i r a ▁ n d i ▁ c h i n g ' o n o ▁ n d i p o ▁ m a n j a ▁ a l i ▁ p a m t e n g o ▁ w a u k u l u ▁ .\n",
            "D-408\t-0.2157621830701828\tMunthu wovala malaya ofiira komanso mathalauza obiriwira ndi ching'ono ndipo manja ali pamtengo waukulu .\n",
            "P-408\t-0.1179 -0.1221 -0.0260 -0.0679 -0.0623 -0.0702 -0.0830 -0.1403 -0.0601 -0.1080 -0.0510 -0.1243 -0.0799 -0.1171 -0.1052 -0.2488 -0.9296 -0.5558 -0.1097 -0.1428 -0.0854 -0.1129 -0.1668 -0.0247 -0.0966 -0.1442 -0.1031 -0.1769 -0.2120 -0.4897 -0.4449 -0.0511 -0.1008 -0.0608 -0.1076 -0.0623 -0.0632 -0.1088 -0.1119 -0.4760 -0.0246 -0.0912 -0.0341 -0.1059 -0.0306 -0.0424 -0.1034 -0.0876 -0.6657 -0.4391 -0.0887 -0.4084 -0.1035 -0.1496 -0.2870 -0.3178 -0.1018 -0.1566 -0.1298 -0.0903 -0.1027 -0.1095 -2.3779 -0.0996 -0.1029 -0.3544 -0.3764 -1.9962 -0.0599 -0.0928 -0.0293 -0.1228 -0.6722 -0.0800 -0.1003 -0.2578 -0.0777 -0.0976 -0.1120 -0.1664 -0.1781 -0.0096 -0.1398 -0.0793 -0.3256 -1.7689 -0.1012 -0.0740 -0.0347 -0.1410 -0.1289 -0.1391 -0.1386 -0.0773 -0.0106 -0.0651 -0.1495 -0.0928 -1.0703 -0.1201 -0.1482 -0.0734 -0.0750 -0.0740 -0.3575 -0.0506 -0.0949\n",
            "T-140\tMtsikana wablond wavala chisoti chasiliva, chigongono ndi zoyala pamabondo, ndi Rollerblades.\n",
            "H-140\t-0.3455756902694702\t▁ M t s i k a n a ▁ w a ▁ b l o n d ▁ w a v a l a ▁ c h i s o t i ▁ c h a c h i k a s u ▁ n d i ▁ n g o m b o ▁ z o y e r a ▁ p a m w a m b a ▁ p a ▁ b o l o d i ▁ l o n s e ▁ .\n",
            "D-140\t-0.3455756902694702\tMtsikana wa blond wavala chisoti chachikasu ndi ngombo zoyera pamwamba pa bolodi lonse .\n",
            "P-140\t-0.1226 -0.5848 -0.0741 -0.0686 -0.0960 -0.0755 -0.1204 -0.1022 -0.1120 -0.1408 -0.0776 -1.1074 -1.5567 -0.5827 -0.0570 -0.0871 -0.0398 -0.0264 -0.2285 -0.0340 -0.6344 -0.0214 -0.1195 -0.0910 -0.1157 -0.0991 -0.5339 -0.1061 -0.1295 -0.0446 -0.1109 -0.0138 -0.0882 -0.1145 -0.0493 -0.0900 -0.1094 -1.3397 -0.1066 -0.0799 -2.2309 -0.1134 -0.0866 -0.2497 -0.1601 -0.7638 -0.3151 -0.0952 -0.1284 -1.1058 -0.2444 -0.3232 -0.8475 -1.7072 -1.3960 -0.1199 -1.2781 -0.1010 -0.1296 -0.9713 -0.0902 -0.1268 -0.1811 -0.1696 -0.1235 -0.2426 -1.1097 -0.0985 -0.2570 -0.0664 -0.3010 -0.1311 -0.2401 -0.1289 -0.1036 -0.5338 -0.0601 -1.8288 -0.0937 -0.1810 -0.3451 -0.2271 -0.0488 -0.1956 -1.7848 -0.1319 -0.0829 -0.2017 -0.2524 -0.1050\n",
            "T-101\tGalu wabulauni wovala malaya apinki amatafuna choyera pamene galu wabulauni atavala mawotchi achikasu .\n",
            "H-101\t-0.20425407588481903\t▁ G a l u ▁ w a b u l a u n i ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a t a v a l a ▁ c h o y e r a ▁ p a m e n e ▁ g a l u ▁ w a b u l a u n i ▁ a t a v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ .\n",
            "D-101\t-0.20425407588481903\tGalu wabulauni wovala malaya apinki atavala choyera pamene galu wabulauni atavala malaya achikasu .\n",
            "P-101\t-0.1150 -0.1483 -0.1218 -0.0612 -0.0748 -0.1279 -0.0442 -0.1943 -0.6513 -0.0985 -0.0627 -0.0988 -0.0934 -0.0615 -0.0848 -0.1417 -0.0893 -0.0634 -0.0605 -0.1161 -0.0739 -0.1286 -0.0989 -0.0629 -0.1137 -0.0533 -0.1043 -0.1175 -0.1012 -0.0971 -0.1179 -1.1397 -0.1285 -0.0487 -0.0389 -0.0849 -0.1609 -0.0863 -2.0087 -0.1004 -1.7174 -0.1122 -0.0801 -0.0987 -0.0837 -0.2320 -0.0720 -0.0821 -0.0742 -0.1242 -0.1420 -0.0904 -0.1416 -0.1534 -0.1314 -0.5164 -0.0574 -0.0679 -0.0711 -0.0730 -0.0457 -0.1944 -0.0547 -0.0709 -0.1004 -0.0508 -0.2205 -0.3179 -0.1087 -0.0863 -0.0962 -0.0661 -0.0577 -0.0614 -0.1184 -0.0625 -0.8393 -0.1160 -0.2051 -0.1151 -0.0762 -0.1422 -0.0820 -1.0662 -0.1221 -1.6288 -0.1339 -0.2564 -0.0990 -0.0849 -0.3944 -0.0264 -0.1031 -0.0955 -0.0686 -0.1184 -0.0471 -0.0654 -0.3487 -1.0818 -0.1032\n",
            "T-123\tAmuna awiri , m'modzi wovala jekete yobiriwira ndipo m'modzi wa jekete yofiira akufuna kuyatsa moto m'nkhalango .\n",
            "H-123\t-0.2553578019142151\t▁ A m u n a ▁ a w i r i ▁ , ▁ m ' m o d z i ▁ w a v a l a ▁ j e k e t e ▁ y o b i r i w i r a ▁ n d i p o ▁ m m o d z i ▁ w a ▁ j e k e t e ▁ y o f i i r a ▁ a k u f u n a ▁ k u m w e t u l i r a ▁ .\n",
            "D-123\t-0.2553578019142151\tAmuna awiri , m'modzi wavala jekete yobiriwira ndipo mmodzi wa jekete yofiira akufuna kumwetulira .\n",
            "P-123\t-0.1282 -0.0604 -0.0799 -0.0785 -0.0787 -0.0974 -0.1487 -0.1136 -0.0637 -0.1283 -0.0607 -0.1140 -0.5608 -1.0802 -0.1952 -0.1027 -0.7739 -0.1281 -0.0426 -0.0724 -0.0519 -0.1046 -0.1275 -0.1127 -0.4066 -0.2717 -0.0954 -0.0908 -0.1020 -0.1111 -0.0362 -0.0943 -0.0663 -0.0674 -0.0357 -0.2336 -0.1265 -0.6475 -0.0946 -0.0286 -0.0776 -0.0716 -0.0906 -0.0302 -0.1076 -0.1200 -0.0888 -0.2812 -0.4070 -0.1038 -0.0818 -0.0157 -0.0541 -0.1359 -0.0324 -1.0239 -0.6117 -0.3448 -0.0457 -0.0953 -0.1608 -0.5120 -0.1296 -2.2965 -0.2875 -0.0505 -0.0207 -0.0624 -0.0522 -0.0854 -0.1363 -0.2658 -0.0956 -0.0056 -0.1032 -0.7922 -0.0809 -0.1144 -0.3694 -0.0836 -0.0368 -0.0886 -1.8487 -0.0723 -0.0566 -0.1925 -0.1784 -0.5591 -0.1138 -0.2130 -2.4108 -0.9137 -0.3372 -0.1200 -0.0669 -0.1366 -0.1216 -0.1072 -0.1951 -1.3734 -0.1120\n",
            "T-215\tMayi wagona pansi ndi kamera ndipo mwamuna akutsamira pa iye akujambula chithunzi .\n",
            "H-215\t-0.3305797874927521\t▁ M a y i ▁ w a g o n a ▁ p a ▁ s i t e j i ▁ a t a v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ a k u t s a m i r a ▁ p a f u p i ▁ n d i ▁ n j a n j i ▁ .\n",
            "D-215\t-0.3305797874927521\tMayi wagona pa siteji atavala malaya obiriwira akutsamira pafupi ndi njanji .\n",
            "P-215\t-0.1344 -0.2159 -0.0979 -0.0813 -0.1052 -0.1508 -0.1166 -0.2370 -0.7862 -0.9626 -0.1807 -0.0777 -0.1137 -0.0479 -0.1357 -0.0755 -0.9703 -0.5052 -0.2285 -1.1727 -0.0951 -0.0609 -0.1449 -1.1754 -1.4300 -0.0983 -0.4453 -0.0999 -0.0813 -0.1027 -0.1009 -0.6072 -0.2321 -1.3299 -0.1104 -0.0599 -0.0824 -0.1070 -0.2538 -1.8148 -0.4794 -0.1333 -0.0923 -0.0312 -0.0765 -0.1183 -0.0955 -0.1621 -0.0843 -0.0924 -0.0988 -0.1056 -0.3166 -0.1127 -0.0734 -0.3965 -0.0523 -0.1153 -0.1205 -0.0770 -0.1322 -3.4782 -0.1019 -0.1116 -0.0966 -0.0977 -0.2362 -0.1950 -0.1232 -0.0843 -1.5142 -0.0634 -0.3150 -0.6024 -0.0961 -0.0533 -0.2038 -0.8481 -0.1000\n",
            "T-247\tBanja lachiyuda likudyera limodzi chakudya chamadzulo Lamlungu kuti lilambire .\n",
            "H-247\t-0.3540228009223938\t▁ B a n j a ▁ l a c h i n y a m b a ▁ l i k u d a ▁ y e m w e ▁ a k u j a m b u l a ▁ c h a k u d y a ▁ c h a ▁ m a d z u l o ▁ a m b i r i ▁ .\n",
            "D-247\t-0.3540228009223938\tBanja lachinyamba likuda yemwe akujambula chakudya cha madzulo ambiri .\n",
            "P-247\t-0.1196 -1.7652 -0.1160 -0.2675 -0.0573 -0.1052 -0.1226 -0.0439 -0.1293 -0.1643 -0.1024 -0.0861 -1.1661 -0.8765 -0.7836 -0.1574 -1.6015 -0.1175 -0.1159 -0.0548 -0.1647 -0.0732 -0.0757 -1.4603 -0.6102 -0.1762 -1.5714 -0.2001 -0.0418 -0.1795 -0.0784 -0.0856 -0.4675 -0.2760 -0.0949 -0.3772 -0.0890 -0.2067 -0.0824 -0.0491 -0.1229 -0.1847 -0.1275 -0.0453 -0.0969 -0.1097 -0.3004 -0.0849 -0.1213 -0.1000 -0.0937 -0.1984 -0.4485 -0.1524 -0.0986 -0.8013 -0.3179 -0.1148 -1.7497 -0.0867 -0.1099 -0.1904 -0.0765 -0.1132 -0.4434 -1.9914 -0.6063 -0.1231 -0.0719 -0.0797 -0.1933 -2.0629 -0.1135\n",
            "T-118\tGalu watsitsi lagolide akuthamanga panjira yofiyira pomwe anthu amangoyang'ana pafupi .\n",
            "H-118\t-0.2332736700773239\t▁ G a l u ▁ w a t s i t s i ▁ l a b u l a u n i ▁ a k u t h a m a n g a ▁ p a n j i r a ▁ y o f i i r a ▁ p o m w e ▁ a n t h u ▁ e n a ▁ a n g a p o ▁ .\n",
            "D-118\t-0.2332736700773239\tGalu watsitsi labulauni akuthamanga panjira yofiira pomwe anthu ena angapo .\n",
            "P-118\t-0.1175 -0.0885 -0.0993 -0.0635 -0.0670 -0.1196 -0.0254 -0.1170 -0.9504 -0.1759 -0.0885 -0.1156 -0.0971 -0.0977 -0.0884 -0.1639 -0.1550 -0.9920 -0.1566 -0.0772 -0.2151 -0.0552 -0.0786 -0.1094 -0.1675 -0.2311 -0.1646 -0.0835 -0.2235 -0.0793 -0.0976 -0.0586 -0.0937 -0.1064 -0.0729 -0.1236 -0.1206 -1.1644 -0.1180 -0.2963 -0.0298 -0.0871 -0.1254 -0.0939 -0.1349 -0.0530 -0.1395 -0.1675 -0.0958 -0.5561 -0.0826 -0.2134 -0.2801 -0.1581 -0.1407 -0.8320 -0.2217 -0.1040 -0.0977 -1.5943 -0.7788 -0.9129 -0.0810 -0.0771 -0.1118 -0.2538 -0.0325 -0.1143 -0.1151 -0.3678 -0.7029 -0.0505 -0.1084 -0.0503 -0.4600 -0.1593 -0.9907 -0.1047\n",
            "T-1\tMayi wina wakummawa atavala malaya akuda, ma leggings ndi nsapato, wayima panja pa sitolo yogulitsa zinthu.\n",
            "H-1\t-0.28456544876098633\t▁ M a y i ▁ w i n a ▁ w a k u m w a ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m a l a y a ▁ a p i n k i ▁ n d i ▁ m t s i k a n a ▁ w a i m a ▁ p a ▁ s k a t e b o a r d ▁ .\n",
            "D-1\t-0.28456544876098633\tMayi wina wakumwa atavala malaya abuluu ndi malaya apinki ndi mtsikana waima pa skateboard .\n",
            "P-1\t-0.1302 -0.0663 -0.0847 -0.0530 -0.0922 -0.1103 -0.0607 -0.1111 -0.0739 -0.1062 -0.1213 -0.1310 -0.0833 -1.3966 -0.1802 -0.1242 -0.9313 -0.0834 -0.1669 -1.1809 -0.0410 -0.1091 -0.1076 -0.1004 -0.1066 -0.1063 -0.1073 -0.0793 -0.1167 -0.0467 -0.1111 -0.0527 -0.0949 -0.0998 -0.1100 -0.8537 -0.0517 -0.0631 -0.4268 -0.0340 -0.1164 -0.3425 -0.1069 -0.1187 -0.1233 -0.0939 -0.1231 -1.9402 -0.1468 -0.1444 -0.0951 -0.1016 -0.4006 -1.6343 -0.1171 -0.0608 -0.1207 -0.0741 -0.2287 -0.5900 -0.0711 -0.1096 -0.1192 -1.3614 -0.7485 -0.9623 -0.6759 -0.5053 -0.0636 -0.1231 -0.0846 -0.1881 -0.3216 -0.3916 -0.7539 -0.0385 -0.0988 -0.0838 -0.2349 -0.1124 -0.8858 -0.3297 -1.2137 -0.1484 -0.0380 -0.4224 -0.1060 -0.0363 -0.1584 -0.0858 -0.0809 -0.2848 -1.0159 -0.1093\n",
            "T-364\tMkwati ndi mkwatibwi kudumphira wina ndi mzake manja atatambasula .\n",
            "H-364\t-0.3313624858856201\t▁ M w a n a ▁ w a ▁ t i m u ▁ y e m w e ▁ a k u d u m p h i r a ▁ m u m l e n g a l e n g a ▁ n d i ▁ m k a z i ▁ a t a v a l a ▁ m a g a l a s i ▁ a t a t u ▁ .\n",
            "D-364\t-0.3313624858856201\tMwana wa timu yemwe akudumphira mumlengalenga ndi mkazi atavala magalasi atatu .\n",
            "P-364\t-0.1272 -0.1124 -0.1076 -0.1251 -0.4011 -0.1072 -0.1893 -0.8633 -0.1117 -0.6952 -1.1233 -0.8398 -0.0971 -0.1202 -0.0879 -0.6868 -0.3647 -0.0907 -0.0500 -0.0825 -0.1143 -0.2253 -1.1112 -0.1675 -1.5341 -0.1104 -0.1358 -0.0476 -0.0452 -0.0667 -0.1479 -0.0887 -0.1117 -0.1460 -0.2037 -1.4665 -1.1410 -0.1440 -0.0980 -0.1391 -0.0776 -0.0668 -0.0776 -0.0529 -0.1803 -0.0765 -0.2162 -0.2026 -0.1132 -0.0962 -0.0865 -0.1020 -1.1846 -0.0792 -0.1712 -0.0914 -0.1596 -0.1993 -0.0270 -0.0836 -1.8754 -0.0931 -0.0974 -0.0911 -0.1187 -1.0274 -1.0010 -0.6418 -0.1141 -0.1271 -0.0876 -0.0344 -0.3437 -0.3356 -0.2894 -1.4016 -0.0816 -1.4166 -0.1285 -0.5816 -0.2108 -0.1012\n",
            "T-115\tSkateboarder watsitsi lalitali amawuluka pamwamba pa masitepe a simenti ndi Bannister yachitsulo.\n",
            "H-115\t-0.32876676321029663\t▁ G u l u ▁ l a ▁ a t a t s i t s i ▁ l a l i t a l i ▁ l a ▁ m a l u w a ▁ p a m w a m b a ▁ p a ▁ m a s i t e p u ▁ a ▁ s i m e n t i ▁ n d i ▁ b a n j i ▁ l a c h i t s u l o ▁ .\n",
            "D-115\t-0.32876676321029663\tGulu la atatsitsi lalitali la maluwa pamwamba pa masitepu a simenti ndi banji lachitsulo .\n",
            "P-115\t-0.1236 -0.9435 -0.3330 -0.1120 -0.1226 -0.1161 -0.2774 -0.4062 -0.2887 -1.3781 -0.5567 -0.1854 -1.8419 -0.7033 -0.0879 -0.3391 -0.0668 -0.0942 -0.0920 -0.0570 -0.1214 -0.0303 -0.0928 -0.0167 -0.0931 -0.0200 -0.0787 -0.1941 -0.6563 -0.1099 -0.5796 -1.0165 -0.1189 -1.9227 -0.1152 -0.2386 -0.1121 -0.2137 -0.6798 -0.1187 -0.1365 -0.0924 -0.0834 -0.0512 -0.0482 -0.1187 -0.1073 -0.0062 -0.1067 -0.1371 -0.3118 -0.0723 -0.1771 -0.0556 -0.0411 -0.0439 -0.0118 -1.3496 -0.1712 -0.1347 -0.4679 -0.4096 -0.2784 -0.8877 -0.1639 -0.1686 -0.1150 -0.0513 -0.1846 -1.1052 -0.0604 -0.1215 -0.2146 -0.0846 -0.1659 -2.2745 -2.2348 -0.0903 -0.1833 -0.3990 -0.1057 -0.0924 -0.0959 -0.0867 -0.4839 -0.8781 -0.0266 -0.0461 -0.0454 -0.4696 -0.2320 -0.1121\n",
            "T-66\tWotsukira zenera akugwira kapu yoyamwa kuti azithandizira kukwapula pawindo lagalasi.\n",
            "H-66\t-0.4180326461791992\t▁ W o s e w e r a ▁ z i m i r i r a ▁ a k u m w e t u l i r a ▁ a k u y a n g ' a n a ▁ k u t i ▁ a z i z i r a ▁ k w a ▁ k u k w a l a ▁ p a f u p i ▁ n d i ▁ n d o d o ▁ l a c h i k a s u ▁ .\n",
            "D-66\t-0.4180326461791992\tWosewera zimirira akumwetulira akuyang'ana kuti azizira kwa kukwala pafupi ndi ndodo lachikasu .\n",
            "P-66\t-0.1250 -0.1498 -0.0853 -0.5736 -1.5755 -0.1364 -0.1115 -0.0660 -0.1226 -0.1288 -0.9146 -0.1126 -0.8340 -1.4753 -0.2748 -0.4212 -0.3842 -0.1092 -0.1402 -0.1018 -0.1092 -0.0932 -1.5552 -1.2190 -0.0760 -0.3843 -0.0596 -0.1759 -0.1024 -0.0810 -0.1072 -0.1280 -2.1830 -0.2096 -0.1127 -0.2303 -0.5987 -0.5077 -0.3730 -0.0400 -0.1013 -0.1285 -0.1068 -0.1009 -0.7477 -0.1474 -0.5083 -1.2956 -0.1142 -0.1175 -0.3082 -0.1151 -2.0467 -0.0703 -0.2705 -0.2273 -0.1371 -0.2881 -2.2321 -0.1372 -0.2922 -0.6989 -0.9798 -0.1948 -0.4324 -0.3190 -0.9666 -0.0837 -0.1665 -0.6420 -0.1438 -1.7248 -0.0737 -0.2398 -0.1076 -0.1180 -0.0992 -0.1037 -0.2356 -0.0819 -1.0669 -1.3873 -0.0418 -0.0906 -0.0803 -0.2400 -1.2137 -0.1295 -1.0811 -0.1472 -0.1135 -0.7969 -0.1083 -0.0988 -0.0513 -1.0508 -0.0790 -0.0973\n",
            "T-85\tKamtsikana kakuimba chitoliro chofiyira chojambulira pamene mtsikana wina akuimba gitala lapinki .\n",
            "H-85\t-0.20146597921848297\t▁ K a m t s i k a n a ▁ k a k u i m b a ▁ c h i t h u n z i ▁ c h o f i i r a ▁ c h o j a m b u l i r a ▁ p a m e n e ▁ m t s i k a n a ▁ w i n a ▁ a k u i m b a ▁ g i t a l a ▁ .\n",
            "D-85\t-0.20146597921848297\tKamtsikana kakuimba chithunzi chofiira chojambulira pamene mtsikana wina akuimba gitala .\n",
            "P-85\t-0.1327 -0.1193 -0.1097 -0.0507 -0.0537 -0.0899 -0.1087 -0.0706 -0.1430 -0.1131 -0.1173 -0.1480 -0.0517 -0.0965 -0.1275 -0.2769 -0.4195 -0.1442 -0.0552 -0.1099 -0.0978 -0.4654 -0.1271 -0.1188 -1.8379 -0.6823 -0.0677 -0.0759 -0.3059 -0.0995 -0.2717 -0.0372 -0.0761 -0.1055 -0.1726 -0.0972 -0.7158 -0.1035 -0.5747 -0.2488 -0.2749 -0.0881 -0.8636 -0.8704 -0.1045 -0.0489 -0.0763 -0.0939 -0.0936 -0.1003 -0.1137 -0.0881 -0.1749 -0.0062 -0.1544 -0.0852 -0.0620 -0.0984 -0.1679 -0.1034 -0.0804 -0.8567 -0.1223 -0.0834 -0.0629 -0.1054 -0.1643 -0.0882 -0.1538 -0.6467 -0.0891 -0.1284 -0.1049 -0.1313 -0.1588 -0.1206 -0.0578 -0.7186 -0.0942 -0.0424 -0.1143 -0.1340 -0.5959 -0.0623 -0.0370 -0.0924 -0.0413 -0.1435 -0.1844 -0.3202 -0.1095\n",
            "T-334\tmwamuna wovala malaya ofiirira akuyang'ana mwamuna wovala malaya akuda akukoka nkhope yoseketsa .\n",
            "H-334\t-0.21768738329410553\t▁ M w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r i r a ▁ a k u y a n g ' a n a ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u k o k a ▁ k u ▁ A s i a ▁ .\n",
            "D-334\t-0.21768738329410553\tMwamuna wovala malaya ofiirira akuyang'ana mwamuna wovala malaya akuda akukoka ku Asia .\n",
            "P-334\t-0.1192 -0.0692 -0.2504 -0.1136 -1.2775 -0.0705 -0.0846 -0.1029 -0.1285 -0.0934 -0.1238 -0.0467 -0.1342 -0.0822 -0.1327 -0.1089 -0.0634 -0.0975 -0.0612 -0.0986 -0.0711 -0.0961 -0.1131 -0.0357 -0.1175 -0.0906 -0.1124 -0.1053 -1.1359 -0.1102 -0.0979 -0.1995 -0.0932 -0.1295 -0.0930 -0.1420 -0.1182 -0.0663 -0.1661 -0.0457 -0.0962 -0.0744 -0.0989 -0.0898 -0.1168 -0.1339 -0.0955 -0.4283 -0.0727 -0.0836 -0.0872 -0.1397 -0.1119 -0.1044 -0.0225 -0.1010 -0.0868 -0.1212 -0.1048 -0.0405 -0.1176 -0.0808 -0.1118 -0.0550 -0.0946 -0.1054 -0.4139 -0.4095 -0.1036 -0.1013 -0.0935 -0.1582 -0.1981 -0.0994 -0.1065 -0.1757 -2.5840 -0.2860 -0.3758 -0.1339 -0.6796 -0.2069 -0.5560 -2.2882 -0.1025 -0.2284 -0.2210 -0.3252 -0.4359 -0.1351\n",
            "T-382\tMwana watsitsi komanso wamaso abuluu wanyamula ndege yamatabwa m'manja mwake .\n",
            "H-382\t-0.3113144040107727\t▁ M w a n a ▁ w a t s i t s i ▁ l a ▁ m a d z i ▁ w a ▁ m n y a m a t a ▁ w a n y a m u l a ▁ c h i d e b e ▁ c h a ▁ m n y a m a t a ▁ w a v a l a ▁ m a l a y a ▁ o t u w a ▁ .\n",
            "D-382\t-0.3113144040107727\tMwana watsitsi la madzi wa mnyamata wanyamula chidebe cha mnyamata wavala malaya otuwa .\n",
            "P-382\t-0.1240 -0.0577 -0.1252 -0.1505 -0.0619 -0.1133 -0.1468 -0.0918 -0.1164 -0.1106 -0.0452 -0.0850 -0.1453 -0.0915 -0.0937 -0.1226 -0.2430 -0.1496 -0.6302 -0.2416 -0.3428 -1.1436 -0.0821 -1.0710 -0.1671 -1.7795 -0.2146 -0.7638 -0.2880 -0.7686 -0.0452 -0.0990 -0.0517 -0.0838 -0.1053 -0.1594 -0.1274 -0.0628 -0.1378 -0.3800 -0.0328 -0.0971 -0.0774 -0.0624 -0.0425 -0.1184 -0.1053 -1.7265 -0.0895 -0.2066 -1.7519 -0.1106 -0.1980 -0.0586 -0.1023 -0.6362 -0.1517 -0.8026 -0.0723 -0.2262 -0.4255 -0.1185 -0.1103 -0.0985 -0.0798 -0.0548 -0.1027 -0.1545 -0.2120 -1.1220 -0.5715 -0.1175 -0.1108 -0.1162 -0.1062 -0.2322 -0.2412 -1.4808 -0.0966 -0.1566 -0.1033 -0.1230 -1.5962 -1.5360 -0.8370 -0.0430 -0.0806 -0.2765 -0.0991 -0.1267\n",
            "T-423\tAmuna awiri ndi akazi awiri ali kukhitchini ndi vinyo ndi zokhwasula-khwasula .\n",
            "H-423\t-0.33041685819625854\t▁ A m u n a ▁ a w i r i ▁ n d i ▁ a k a z i ▁ a w i r i ▁ a l i ▁ k u c h i t i n i ▁ n d i ▁ n y a n j a ▁ k w a ▁ s u t i ▁ y o k h a l a ▁ .\n",
            "D-423\t-0.33041685819625854\tAmuna awiri ndi akazi awiri ali kuchitini ndi nyanja kwa suti yokhala .\n",
            "P-423\t-0.1116 -0.1225 -0.0790 -0.1264 -0.0856 -0.1051 -0.1346 -0.2082 -0.0612 -0.1217 -0.0557 -0.1020 -0.2030 -1.4074 -0.1082 -0.1311 -0.0883 -0.1047 -1.0311 -0.2091 -0.0990 -0.1079 -0.1428 -0.1428 -0.9603 -0.1011 -0.0703 -0.0840 -0.1255 -0.2549 -0.1340 -0.0926 -0.1062 -1.5506 -0.1252 -0.4824 -0.0642 -0.0720 -0.1106 -0.6947 -0.6661 -0.1653 -0.2587 -0.1036 -0.0629 -0.1250 -0.1316 -0.1832 -0.1824 -0.2439 -0.7137 -0.1880 -0.1334 -0.1952 -0.3952 -0.1956 -0.1265 -0.1419 -0.7658 -0.2236 -1.8922 -0.6521 -0.1586 -1.3970 -0.6745 -1.0346 -0.6521 -0.1557 -0.3604 -0.0790 -0.1358 -1.5190 -0.0903\n",
            "T-249\tGulu la amuna likuyenda mumsewu wokhala ndi riboni yachikasu kutsogolo kwa nyumba yoyera ndi yofiira .\n",
            "H-249\t-0.21316860616207123\t▁ G u l u ▁ l a ▁ a m u n a ▁ l i k u y e n d a ▁ m u m s e w u ▁ w a ▁ n k h a l a n g o ▁ y a c h i k a s u ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y o y e r a ▁ .\n",
            "D-249\t-0.21316860616207123\tGulu la amuna likuyenda mumsewu wa nkhalango yachikasu kutsogolo kwa nyumba yoyera .\n",
            "P-249\t-0.1263 -0.0386 -0.1042 -0.0832 -0.0821 -0.1154 -0.1663 -0.1117 -0.0945 -0.1464 -0.1812 -0.0620 -0.0559 -0.0868 -0.1236 -0.0971 -0.1189 -0.0723 -0.1003 -0.1942 -0.1176 -0.0958 -0.0824 -0.1062 -0.1154 -0.0272 -0.4765 -0.1007 -0.0339 -0.0872 -0.0486 -0.0504 -0.1308 -0.0492 -0.2259 -0.6463 -2.5116 -1.3959 -0.0857 -0.1887 -0.1224 -0.1065 -0.2061 -0.2417 -0.0949 -0.1475 -1.1460 -0.1209 -0.0818 -0.0933 -0.1122 -0.0739 -0.1345 -0.0233 -0.0510 -0.1271 -1.4322 -0.3377 -0.0547 -0.0832 -0.0702 -0.0445 -0.0712 -0.0831 -0.0753 -0.0825 -0.0220 -0.0909 -0.1068 -0.1911 -0.9348 -0.0560 -0.0353 -0.0671 -0.0365 -0.0938 -0.1648 -0.1482 -0.1022 -0.8775 -0.1853 -0.0766 -0.1034 -0.2458 -0.7303 -0.1099\n",
            "T-12\tBambo wina wovala magalasi wakhala kuseri kwa tebulo lodzaza ndi zinthu zokumbukira zankhondo .\n",
            "H-12\t-0.26409634947776794\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ m a g a l a s i ▁ w a k h a l a ▁ k u s e r i ▁ k w a ▁ g u l u ▁ l o d z a z a ▁ n d i ▁ n s a p a t o ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-12\t-0.26409634947776794\tBambo wina wovala magalasi wakhala kuseri kwa gulu lodzaza ndi nsapato kumbuyo kwake .\n",
            "P-12\t-0.1144 -0.6683 -0.1183 -0.0781 -0.1157 -0.0968 -0.1465 -0.1079 -0.1002 -0.0799 -0.1059 -0.1237 -0.1296 -0.0884 -0.0856 -0.1161 -0.0868 -0.1226 -0.1158 -0.1256 -0.1017 -0.2405 -0.1653 -0.0877 -0.1044 -0.0687 -0.1228 -0.1121 -2.3686 -0.1390 -0.3855 -0.2001 -0.0903 -0.0568 -0.1004 -0.1126 -0.0956 -0.0669 -0.3254 -0.0978 -0.0685 -0.0579 -0.1065 -0.2127 -0.0796 -0.1128 -0.1299 -2.6500 -0.2176 -0.0870 -0.1872 -0.1273 -0.0960 -0.1195 -0.7051 -0.0618 -0.1574 -0.0286 -0.1166 -0.1130 -0.1779 -0.0881 -0.1159 -0.0825 -1.3873 -1.4452 -0.5128 -0.4152 -0.3050 -0.0306 -0.0439 -0.1088 -1.3295 -0.1054 -0.1128 -0.0227 -0.1210 -0.0829 -0.1258 -0.2445 -0.4287 -0.2049 -0.1231 -1.4698 -0.1997 -0.5988 -0.0481 -0.1061\n",
            "T-107\tGulu lalikulu la amuna ovala zoyera likuwoneka kuti likugwira ntchito pa grill yamtundu wina.\n",
            "H-107\t-0.2245679348707199\t▁ G u l u ▁ l a l i k u l u ▁ l a ▁ a m u n a ▁ o v a l a ▁ z o y e r a ▁ n d i k u w o n e k a ▁ k u g w i r a ▁ n j i n g a ▁ y a m o t o ▁ y a m t u n d u ▁ w i n a ▁ .\n",
            "D-107\t-0.2245679348707199\tGulu lalikulu la amuna ovala zoyera ndikuwoneka kugwira njinga yamoto yamtundu wina .\n",
            "P-107\t-0.1221 -0.1046 -0.1036 -0.0967 -0.0771 -0.1068 -0.0856 -0.1314 -0.1375 -0.0986 -0.0431 -0.1189 -0.0387 -0.0772 -0.1312 -0.8994 -0.0740 -0.0989 -0.3079 -0.1815 -0.0463 -0.0437 -0.0667 -0.1324 -0.1046 -0.0628 -0.1093 -0.0674 -0.1214 -0.1077 -0.0140 -0.0863 -0.1696 -0.0569 -0.0909 -0.1030 -0.1634 -2.0350 -0.3076 -0.1187 -0.5901 -0.1009 -0.2868 -0.1594 -0.2094 -0.0687 -0.0297 -0.0860 -0.0955 -0.4492 -0.0712 -0.3873 -0.0985 -0.1273 -0.0729 -0.1136 -0.1091 -0.1131 -1.3768 -0.1439 -0.6663 -0.0518 -0.0873 -0.1177 -0.3063 -0.1865 -0.3439 -0.1539 -0.0665 -0.0783 -0.2181 -0.8746 -0.4433 -0.7233 -1.3946 -0.1010 -0.0714 -0.0797 -0.1080 -0.2697 -0.2302 -0.3587 -0.0803 -0.0853 -0.5551 -0.0639 -0.0904\n",
            "T-175\tMunthu wovala chipewa chakuda , jekete , mathalauza ndi nsapato atakhala pamphepete mwa konkire kumbuyo kwa njerwa .\n",
            "H-175\t-0.2410130798816681\t▁ M u n t h u ▁ w o v a l a ▁ c h i p e w a ▁ c h a k u d a ▁ n d i ▁ j e k e t e ▁ m a t h a l a u z a ▁ a t a k h a l a ▁ p a m p h e p e t e ▁ m w a ▁ k o n k i r e ▁ k u n j i r a ▁ k w a ▁ n j e r w a ▁ .\n",
            "D-175\t-0.2410130798816681\tMunthu wovala chipewa chakuda ndi jekete mathalauza atakhala pamphepete mwa konkire kunjira kwa njerwa .\n",
            "P-175\t-0.1204 -0.0981 -0.0583 -0.0652 -0.0659 -0.0791 -0.0817 -0.1316 -0.0416 -0.0694 -0.0281 -0.1257 -0.0878 -0.1070 -0.0992 -0.4316 -0.0960 -0.1075 -0.4490 -0.1779 -0.0464 -0.1131 -0.1297 -0.0244 -0.0931 -0.1081 -0.4183 -0.0930 -0.1741 -0.3501 -0.1373 -1.8114 -0.2378 -0.1153 -0.0886 -2.3917 -0.6633 -0.3103 -0.0659 -0.0280 -0.1052 -0.1497 -1.3781 -0.3072 -0.1640 -0.0142 -0.1111 -0.1030 -0.1148 -0.0361 -0.0163 -0.0970 -0.1071 -0.1982 -0.5303 -0.1199 -0.0440 -0.0287 -0.1113 -0.0879 -0.1204 -0.0902 -0.0098 -0.1221 -0.5314 -0.0252 -0.1943 -0.0482 -0.0406 -0.0885 -0.0861 -0.0947 -0.0941 -1.5514 -0.0861 -0.0997 -0.1049 -1.3683 -0.1959 -0.1608 -0.3353 -0.9377 -0.0945 -0.3516 -0.2225 -0.5612 -0.3543 -0.8358 -0.0382 -0.6436 -0.0684 -0.0836 -0.1611 -0.2063 -0.0513 -0.1152 -0.0971 -0.1553 -0.4599 -0.1660 -0.0355 -0.0503 -0.0754 -0.3369 -0.1563 -0.0958\n",
            "T-331\tBambo amachita chinyengo pagalimoto yake yaying'ono, mwendo umodzi ukuwuluka kumwamba.\n",
            "H-331\t-0.3102128505706787\t▁ B a m b o ▁ a m a c h i t a ▁ c h i n y e n g o ▁ p a ▁ g a l i m o t o ▁ y a k e ▁ y a i n g ' o n o ▁ y o m w e ▁ i l i ▁ n d i ▁ m o d z i ▁ k u m b u y o ▁ k w a ▁ m w a m b a .\n",
            "D-331\t-0.3102128505706787\tBambo amachita chinyengo pa galimoto yake yaing'ono yomwe ili ndi modzi kumbuyo kwa mwamba.\n",
            "P-331\t-0.1324 -0.0538 -0.1061 -0.1077 -0.1041 -0.1047 -0.1116 -1.5778 -0.2814 -0.1185 -0.1503 -0.0614 -0.2032 -0.0984 -0.2864 -0.1339 -0.0476 -0.0795 -0.1188 -0.4207 -0.0766 -0.0519 -0.0560 -0.0527 -0.0444 -0.1162 -0.0219 -0.1267 -0.4121 -1.6500 -0.1114 -0.0501 -0.0681 -0.0576 -0.0655 -0.0534 -0.0369 -0.2412 -0.0600 -0.1435 -0.5099 -0.0364 -0.1420 -0.0703 -0.2050 -1.4762 -1.9831 -0.1160 -0.0337 -0.0442 -0.0641 -0.0590 -0.1426 -1.6227 -0.4565 -0.4927 -0.1345 -0.1370 -0.1048 -0.1502 -1.5913 -0.1453 -0.1224 -0.4670 -0.2109 -0.3054 -0.1092 -0.9756 -1.2444 -0.2403 -0.0304 -0.1049 -0.1597 -0.3182 -0.2112 -0.3921 -0.1924 -0.4097 -0.0804 -0.0782 -0.2183 -0.3818 -0.4428 -0.1118 -0.7460 -0.4823 -0.1284 -0.0844 -0.2519 -0.0811 -0.0954 -2.5594 -0.1018\n",
            "T-122\tWoyimba gitala ali pa siteji akukweza mkono wake n'kukweza manja kwa oonerera .\n",
            "H-122\t-0.32000163197517395\t▁ W o y e n d e t s a ▁ n d i ▁ p a ▁ s k a t e b o a r d ▁ a k u k w e z a ▁ m w a k e ▁ k u k w e z a ▁ m a n j a ▁ o n e r e r a ▁ .\n",
            "D-122\t-0.32000163197517395\tWoyendetsa ndi pa skateboard akukweza mwake kukweza manja onerera .\n",
            "P-122\t-0.1145 -0.1893 -0.1167 -0.0813 -0.4996 -0.0827 -0.0862 -0.6633 -0.5964 -0.6891 -0.1783 -0.1155 -1.6635 -1.7235 -0.2169 -0.1501 -2.0831 -0.1788 -0.7363 -0.0467 -0.3694 -0.1351 -0.1536 -0.0291 -0.1932 -0.4016 -0.0459 -0.0207 -0.0288 -0.5869 -0.0889 -0.0890 -0.1141 -0.4906 -0.1650 -0.0782 -0.0131 -0.0966 -0.1116 -0.1085 -0.6158 -0.1195 -0.6574 -0.0979 -0.2105 -0.8469 -0.1130 -0.1205 -0.1748 -0.0776 -0.0491 -0.1107 -0.1461 -0.0879 -0.1833 -0.0563 -0.0606 -0.1418 -0.1380 -0.4361 -0.4197 -0.6209 -0.3076 -0.2175 -0.1683 -0.1169 -0.2868 -1.8645 -0.1021\n",
            "T-184\tMtsikana wina amene wavala bulawuzi wonyezimira akusonyeza kamtsikana zomera zomwe zakhala pa shelufu .\n",
            "H-184\t-0.2935044765472412\t▁ M t s i k a n a ▁ w i n a ▁ w a ▁ m e n e ▁ w a v a l a ▁ b u l a w u z i ▁ w o n y e z i m i r a ▁ a k u s o n y e z a ▁ p a m s i k a n a ▁ z o m e r a ▁ p a m e n e ▁ a k u k h a l a ▁ p a ▁ s i t e l o ▁ .\n",
            "D-184\t-0.2935044765472412\tMtsikana wina wa mene wavala bulawuzi wonyezimira akusonyeza pamsikana zomera pamene akukhala pa sitelo .\n",
            "P-184\t-0.1419 -0.0685 -0.0516 -0.1248 -0.0971 -0.0538 -0.1295 -0.1039 -0.1035 -0.1290 -0.0858 -0.0933 -0.1148 -0.1085 -0.1347 -0.2039 -0.4563 -0.7001 -3.0938 -0.9886 -0.0855 -0.1486 -0.0869 -0.0377 -0.1099 -0.4412 -0.1151 -0.1187 -0.1107 -0.1184 -0.3382 -0.0507 -0.1446 -0.1090 -0.9718 -0.0353 -0.1071 -0.1030 -0.1472 -0.1512 -0.0804 -0.1734 -0.0255 -0.0800 -0.0178 -0.0933 -0.0868 -0.1332 -0.0615 -0.1172 -0.1341 -0.2475 -0.0529 -0.0970 -0.3200 -0.4099 -0.1690 -0.0398 -0.0903 -0.5057 -0.1725 -0.0963 -0.1458 -0.1743 -0.2490 -0.6847 -0.1301 -0.0117 -0.1175 -0.7323 -0.0932 -0.1739 -1.0011 -0.0551 -0.0714 -1.7108 -0.4492 -0.1286 -0.2373 -1.1103 -0.1493 -0.2401 -0.0640 -0.0758 -0.0516 -0.1182 -1.2632 -0.5196 -0.4397 -1.7834 -1.4285 -0.1070 -0.0916 -0.1089 -0.0903 -0.2668 -0.1349 -0.2606 -0.5172 -0.4554 -0.2331 -0.5247 -0.5111 -0.1992 -0.3985 -0.2779 -0.0997\n",
            "T-83\tMwana wamng'ono akuthamanga m'chithaphwi chachikulu m'mphepete mwa nyanja mozunguliridwa ndi mitengo.\n",
            "H-83\t-0.1813991218805313\t▁ M w a n a ▁ w a m n g ' o n o ▁ a k u t h a m a n g a ▁ m ' c h i p i n d a ▁ c h a c h i k u l u ▁ m ' m p h e p e t e ▁ m w a ▁ n y a n j a ▁ .\n",
            "D-83\t-0.1813991218805313\tMwana wamng'ono akuthamanga m'chipinda chachikulu m'mphepete mwa nyanja .\n",
            "P-83\t-0.1142 -0.0587 -0.3273 -0.1349 -0.0640 -0.1216 -0.1798 -0.1063 -0.1677 -0.4742 -0.0556 -0.1173 -0.0651 -0.0935 -0.0455 -0.0550 -0.1257 -0.5288 -0.1804 -0.0620 -0.0294 -0.0798 -0.0997 -0.0526 -0.0893 -0.0703 -0.0303 -0.1026 -0.1066 -0.5466 -0.2825 -0.0202 -0.0528 -0.1016 -0.3024 -0.0908 -0.1314 -0.3844 -0.3251 -0.2336 -0.0107 -0.0738 -0.1039 -0.2329 -0.0739 -0.1070 -0.3832 -0.0988 -0.0737 -0.0976 -0.1479 -0.1266 -0.1255 -0.0983 -0.0441 -0.0667 -0.0720 -0.0398 -0.0683 -0.0144 -0.0825 -0.0770 -0.0607 -0.0664 -0.1003 -0.0878 -0.0840 -0.0313 -0.1087 -0.2693 -0.0953 -0.1071 -0.1959 -3.8674 -0.1023\n",
            "T-195\tMunthu wovala zovala zofiira ndi zakuda akukwera m'mbali mwa phiri lozizira kwambiri .\n",
            "H-195\t-0.18902680277824402\t▁ M u n t h u ▁ w o v a l a ▁ z o v a l a ▁ z o f i i r a ▁ n d i ▁ z a k u d a ▁ a k u k w e r a ▁ m ' m b a l i ▁ m w a ▁ p h i r i ▁ l o s i z i r a ▁ k w a m b i r i ▁ .\n",
            "D-195\t-0.18902680277824402\tMunthu wovala zovala zofiira ndi zakuda akukwera m'mbali mwa phiri losizira kwambiri .\n",
            "P-195\t-0.1331 -0.0890 -0.0732 -0.0789 -0.0764 -0.1029 -0.0804 -0.1487 -0.0604 -0.0878 -0.0464 -0.1468 -0.0853 -0.1224 -0.1005 -0.0228 -0.0926 -0.0862 -0.1189 -0.0835 -0.1121 -0.0919 -0.0247 -0.1335 -0.2233 -0.0946 -0.1611 -0.0720 -0.1546 -0.1505 -0.0676 -0.1157 -0.0974 -0.0793 -0.4312 -0.1155 -0.6008 -0.0527 -0.4387 -0.0882 -0.1482 -0.0584 -0.0789 -0.0852 -0.0534 -0.2094 -0.0662 -0.0726 -0.1308 -0.1138 -0.3345 -1.3693 -0.3586 -0.8431 -0.1077 -0.0415 -0.0748 -0.1029 -0.8111 -0.0208 -0.1031 -0.2946 -1.0164 -0.4726 -0.0895 -0.0517 -0.0918 -0.1620 -0.3088 -0.2732 -0.2118 -0.1731 -0.7251 -0.1083 -0.2874 -0.0996 -0.1676 -0.0637 -0.2136 -0.1152 -0.1155 -0.0376 -0.0850 -0.0724 -0.0915 -0.5360 -0.3317 -0.1128\n",
            "T-265\tGalu wakuda ndi galu wonyezimira amalimbana mu udzu wouma pafupi ndi madzi ambiri .\n",
            "H-265\t-0.28570178151130676\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ g a l u ▁ w a n y e z i ▁ a m a y i m b a ▁ m u ▁ u d z u ▁ w o u m a ▁ p a f u p i ▁ n d i ▁ m a d z i ▁ a m b i r i ▁ .\n",
            "D-265\t-0.28570178151130676\tGalu wakuda ndi galu wanyezi amayimba mu udzu wouma pafupi ndi madzi ambiri .\n",
            "P-265\t-0.1108 -0.0854 -0.1131 -0.0650 -0.0695 -0.1124 -0.0655 -0.1837 -0.1784 -0.0747 -0.1000 -0.1432 -0.1363 -0.1771 -0.0571 -0.0961 -0.0761 -0.4572 -0.1343 -0.0515 -0.0642 -0.1210 -0.0264 -0.1593 -0.2316 -0.0187 -1.6515 -0.1906 -0.0855 -0.2172 -1.4689 -0.2082 -0.1681 -0.7074 -0.9403 -0.6808 -0.2056 -0.1120 -0.1227 -0.4449 -0.2455 -1.4125 -0.1623 -0.8683 -0.0085 -0.0510 -0.1566 -0.3972 -0.1973 -1.7767 -0.2110 -0.1243 -0.1817 -0.9538 -0.1366 -0.0422 -0.0821 -0.3062 -0.1159 -0.1151 -0.0608 -0.1289 -0.1322 -0.0739 -0.1509 -0.1847 -0.5626 -0.0543 -0.0885 -0.2615 -0.6080 -1.1318 -0.0411 -0.1110 -0.0453 -0.0804 -0.8405 -0.0564 -0.1006\n",
            "T-154\tWachichepere akuyang'ana paphewa lake pamene akuthamanga, kumbuyo kuli mitengo ndi kasupe wamadzi.\n",
            "H-154\t-0.3233201503753662\t▁ W a c h i c h e p e r e ▁ a k u y a n g ' a n a ▁ p a ▁ k a p e r e ▁ w a k e ▁ p a m e n e ▁ a k u t h a m a n g a ▁ k u m b u y o ▁ n d i ▁ g u l u ▁ l a ▁ a c h i k a s u ▁ .\n",
            "D-154\t-0.3233201503753662\tWachichepere akuyang'ana pa kapere wake pamene akuthamanga kumbuyo ndi gulu la achikasu .\n",
            "P-154\t-0.1088 -0.1670 -0.4305 -0.0850 -0.1001 -0.1602 -1.2403 -0.1276 -0.0510 -0.0824 -0.0912 -0.0930 -0.0868 -0.1282 -0.4545 -0.0468 -0.0790 -0.0878 -0.1556 -0.0914 -0.1229 -0.1388 -0.0979 -0.0690 -0.1131 -0.1094 -0.0841 -0.2566 -0.1750 -1.3035 -0.4108 -0.4869 -0.0598 -0.9560 -1.5678 -0.2988 -1.4493 -0.1332 -1.5836 -0.3188 -0.2067 -0.2860 -0.1456 -0.2713 -0.1133 -0.0564 -0.1149 -0.0992 -0.2581 -0.1609 -0.1271 -1.1137 -0.4086 -0.0800 -0.0756 -0.1073 -0.1114 -0.0304 -0.0978 -0.1405 -0.3452 -0.0946 -0.1267 -0.0859 -0.1389 -0.0421 -0.0525 -0.1294 -1.1576 -0.1883 -0.1242 -0.2802 -0.7556 -0.6593 -0.1372 -0.0713 -0.1500 -0.0882 -0.1387 -0.1858 -1.2348 -1.6033 -0.2017 -0.1398 -1.3938 -0.4099 -0.0963 -0.0570 -0.3266 -1.2969 -0.1030\n",
            "T-199\tMwamuna wovala zovala za chipale chofewa ndi chisoti akuyendetsa galimoto ya chipale chofewa m'chipale chofewa .\n",
            "H-199\t-0.23375602066516876\t▁ M w a m u n a ▁ w o v a l a ▁ z o v a l a ▁ z a c h i p a l e ▁ c h o f e w a ▁ n d i ▁ j e a n s ▁ a k u y e n d e t s a ▁ g a l i m o t o ▁ y a c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-199\t-0.23375602066516876\tMwamuna wovala zovala zachipale chofewa ndi jeans akuyendetsa galimoto yachipale chofewa .\n",
            "P-199\t-0.1400 -0.0817 -0.1152 -0.1157 -0.3122 -0.0813 -0.1179 -0.0956 -0.1429 -0.1055 -0.0924 -0.0733 -0.1210 -0.0911 -0.1213 -0.1137 -0.0255 -0.1038 -0.0299 -0.1011 -0.0802 -0.1057 -0.1064 -0.0424 -0.2356 -0.3594 -0.0780 -0.0589 -0.6225 -0.1115 -0.0941 -0.1175 -0.0918 -0.2589 -0.1410 -0.0743 -0.1167 -0.1023 -0.0588 -0.1033 -0.1582 -0.0552 -0.1131 -0.1420 -0.0792 -1.4172 -0.3769 -0.5510 -0.1056 -0.1592 -0.1216 -0.3043 -0.0803 -0.0842 -0.4406 -0.0801 -1.4691 -0.0400 -0.1794 -0.0241 -0.0446 -0.1113 -0.0960 -2.8442 -0.1610 -0.0394 -0.0944 -0.0630 -0.0552 -0.0395 -0.0352 -0.1863 -0.0143 -0.1157 -0.2523 -0.0932 -0.0761 -2.0600 -0.1150 -0.0710 -0.1318 -0.0975 -0.0983 -0.1137 -0.0682 -0.0308 -0.0770 -0.0326 -0.1064 -0.2405 -2.7049 -0.1140\n",
            " 62% 8/13 [00:19<00:09,  1.86s/it, wps=1244]T-340\tChonyamulira chopanda kanthu komanso chonyamulira chomwe chili ndi anthu awiri chikusuntha .\n",
            "H-340\t-0.328595370054245\t▁ M t s i k a n a ▁ w i n a ▁ c h o v a l a ▁ c h o k h a l a ▁ n d i ▁ k o m a n s o ▁ c h o y e r a ▁ c h o m w e ▁ c h i l i ▁ n d i ▁ c h i k u l u ▁ c h o f i i r i r a ▁ .\n",
            "D-340\t-0.328595370054245\tMtsikana wina chovala chokhala ndi komanso choyera chomwe chili ndi chikulu chofiirira .\n",
            "P-340\t-0.1062 -3.2824 -0.5321 -0.1960 -0.3452 -0.2276 -0.0996 -0.1032 -0.1031 -0.1775 -0.2157 -0.1766 -0.1238 -0.1001 -0.1465 -2.0976 -0.1429 -0.0833 -0.3020 -0.1126 -0.0800 -0.1029 -0.1035 -0.0694 -0.0929 -0.1052 -1.3856 -0.2293 -0.1047 -0.0612 -0.0967 -0.1299 -0.2022 -0.0957 -0.1502 -0.3970 -0.6985 -0.7610 -0.0566 -0.0984 -0.1149 -0.1384 -0.0913 -0.0687 -0.2792 -0.0557 -0.6599 -0.4548 -0.8584 -0.1306 -0.1113 -0.1940 -0.4334 -0.0468 -0.1681 -0.1188 -0.2837 -0.1154 -0.0928 -0.1102 -0.0765 -0.1279 -0.0477 -0.1114 -0.0910 -0.0321 -0.0928 -0.1078 -0.0853 -2.4376 -0.0896 -0.1306 -1.7467 -0.4782 -0.3333 -0.0725 -0.3267 -0.8851 -0.0735 -0.7789 -0.8301 -0.1995 -0.2809 -0.0989 -0.4908 -0.2323 -0.1267 -0.6240 -0.2380 -0.1051\n",
            "T-238\tMwamuna wovala suti yakuda atakhala ndi mkazi watsitsi lakuda atavala jekete labuluu padoko .\n",
            "H-238\t-0.15811602771282196\t▁ M w a m u n a ▁ w o v a l a ▁ s u t i ▁ y a k u d a ▁ a t a k h a l a ▁ n d i ▁ m k a z i ▁ w a t s i t s i ▁ l a k u d a ▁ a t a v a l a ▁ j e k e t e ▁ y a b u l u u ▁ .\n",
            "D-238\t-0.15811602771282196\tMwamuna wovala suti yakuda atakhala ndi mkazi watsitsi lakuda atavala jekete yabuluu .\n",
            "P-238\t-0.1237 -0.0580 -0.0453 -0.1102 -0.3424 -0.0788 -0.0876 -0.1001 -0.1387 -0.0713 -0.0918 -0.1530 -0.1210 -0.0772 -0.1103 -0.1126 -0.2097 -0.0597 -0.0418 -0.1208 -0.0975 -0.1019 -0.1188 -0.3867 -0.0969 -0.1570 -0.0955 -0.1252 -0.2648 -0.3395 -0.1193 -0.1107 -0.0497 -0.0950 -0.0490 -0.1015 -0.0934 -0.1984 -0.1199 -0.0973 -0.0743 -0.1291 -0.0493 -0.1078 -0.0382 -0.0808 -0.1124 -0.0818 -0.1140 -2.6585 -0.0178 -0.1085 -0.2292 -0.0337 -0.1046 -0.0955 -0.1821 -0.1234 -0.2107 -0.0791 -0.0895 -0.1000 -0.1506 -0.1498 -0.1078 -0.1036 -0.0221 -0.1130 -0.0875 -0.1019 -0.0930 -0.0251 -0.0962 -0.0412 -0.1042 -0.0372 -0.1436 -0.0891 -0.3758 -0.1393 -0.4374 -0.1416 -0.0880 -0.0959 -0.0381 -0.2381 -0.8779 -0.1236\n",
            "T-146\tBanja likugwirana chanza ndipo mayi wina waimirira pambali pawo akujambula mumsewu wafumbi.\n",
            "H-146\t-0.3351840674877167\t▁ M t s i k a n a ▁ a k u g w i r a ▁ c h a n z a ▁ n d i p o ▁ m a y i ▁ w i n a ▁ w a i m i r i r a ▁ p a m e n e ▁ b a m b o ▁ a k u j a m b u l a ▁ m u m s e w u ▁ w o v a l a ▁ m a ▁ j e a n s ▁ .\n",
            "D-146\t-0.3351840674877167\tMtsikana akugwira chanza ndipo mayi wina waimirira pamene bambo akujambula mumsewu wovala ma jeans .\n",
            "P-146\t-0.1096 -2.8206 -1.9453 -0.1613 -0.1223 -0.1596 -0.1127 -0.0863 -0.0936 -0.1294 -0.2426 -0.0782 -0.0943 -0.9053 -0.0887 -0.1301 -0.0281 -0.1032 -0.2502 -0.8358 -0.0519 -0.1530 -0.8888 -1.0864 -0.0973 -0.3386 -0.0622 -0.0565 -0.0944 -0.8694 -0.0600 -0.1192 -0.0506 -0.7580 -0.0969 -0.0746 -0.1164 -0.0481 -0.2281 -0.1190 -0.0972 -0.2067 -0.1291 -0.1132 -0.3083 -0.0547 -0.1937 -0.0428 -0.0619 -0.0521 -0.1211 -0.1433 -0.0694 -0.1376 -0.9264 -1.9404 -0.0526 -0.0467 -0.1105 -1.0666 -0.1741 -0.6022 -0.0447 -0.0649 -0.0951 -1.4258 -0.0535 -0.1047 -0.1622 -0.0956 -0.0717 -0.0557 -0.0862 -0.0586 -0.1003 -0.1741 -0.1200 -1.1848 -0.4655 -0.0624 -0.3170 -0.1149 -0.0480 -0.1429 -0.4482 -0.7469 -0.9130 -0.6350 -0.0860 -0.1101 -0.1261 -0.4843 -0.1533 -1.1803 -1.1371 -0.3689 -0.8963 -0.0396 -0.2273 -0.1719 -0.7724 -0.1264\n",
            "T-278\tMunthu wovala skis amakhalanso ndi paragliding yokhala ndi parachuti yofiira.\n",
            "H-278\t-0.26866859197616577\t▁ M u n t h u ▁ w o v a l a ▁ m a g a l a s i ▁ a m a k h a l a ▁ n d i ▁ k a b u d u l a ▁ y o k h a l a ▁ n d i ▁ k a p u ▁ y o f i i r a ▁ .\n",
            "D-278\t-0.26866859197616577\tMunthu wovala magalasi amakhala ndi kabudula yokhala ndi kapu yofiira .\n",
            "P-278\t-0.1258 -0.1011 -0.0701 -0.0673 -0.0763 -0.1263 -0.0966 -0.1575 -0.0639 -0.0891 -0.0490 -0.1126 -0.0735 -0.1113 -0.1001 -1.5746 -0.1399 -1.9225 -0.1059 -0.0873 -0.1170 -0.0500 -0.0574 -0.1356 -0.1656 -0.3318 -0.1571 -0.1813 -0.0897 -0.1073 -0.0618 -0.1037 -0.1021 -0.2863 -0.0749 -0.0925 -0.1687 -2.7896 -0.3620 -0.5417 -0.0768 -0.1258 -0.1231 -0.0483 -0.0751 -0.1106 -0.3376 -1.9845 -0.1010 -0.0201 -0.1184 -0.0932 -0.1100 -0.0781 -0.1857 -0.1569 -0.1156 -0.0695 -0.5252 -0.1968 -1.8656 -0.1528 -0.1553 -0.0160 -0.0863 -0.1042 -0.0812 -0.3788 -0.0821 -0.1398 -0.4990 -0.0688 -0.1045\n",
            "T-3\tWokwera njingayo akugwira panjinga yake ali mumlengalenga ndi phiri kumbuyo kwake .\n",
            "H-3\t-0.29939004778862\t▁ W o k w e r a ▁ j i n z i ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a k e ▁ a l i ▁ m u m l e n g a l e n g a ▁ n d i ▁ m p i r a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-3\t-0.29939004778862\tWokwera jinzi wovala yunifolomu yake ali mumlengalenga ndi mpira kumbuyo kwake .\n",
            "P-3\t-0.1209 -0.2355 -0.0994 -0.2347 -0.0524 -0.0778 -0.0670 -0.1287 -0.1321 -2.2823 -0.2747 -0.0606 -0.1834 -0.2021 -0.1088 -1.1343 -0.1586 -0.7636 -0.1078 -0.0879 -0.1225 -0.1242 -0.7914 -0.1133 -0.0693 -0.0601 -0.2953 -0.1509 -0.0625 -0.4971 -0.0824 -0.0776 -0.1125 -0.6897 -0.1480 -2.2680 -0.1644 -0.1100 -0.0874 -0.1478 -0.1035 -0.0952 -0.7367 -0.7138 -1.2937 -0.1757 -0.0753 -0.0821 -0.0839 -0.0934 -0.0428 -0.0923 -0.0309 -0.1411 -0.0826 -0.1850 -0.9803 -0.0828 -0.0984 -0.1545 -1.6472 -0.2338 -0.0817 -0.1867 -0.1819 -0.2330 -0.6325 -0.0755 -0.8652 -0.5551 -0.0606 -0.0665 -0.0637 -0.2206 -0.1607 -0.0592 -0.0975 -0.1010 -0.0587 -0.7770 -0.0691 -0.0920\n",
            "T-14\tGalu wakuda akuthamanga kumbuyo kwa mbalame zitatu pamphepete mwa nyanja ndi mafunde kumbuyo .\n",
            "H-14\t-0.25617220997810364\t▁ G a l u ▁ w a k u d a ▁ a k u t h a m a n g a ▁ m ' b w a l o ▁ l a ▁ m i y e n d o ▁ p a m p h e p e t e ▁ m w a ▁ n y a n j a ▁ n d i ▁ m a f u n d e ▁ .\n",
            "D-14\t-0.25617220997810364\tGalu wakuda akuthamanga m'bwalo la miyendo pamphepete mwa nyanja ndi mafunde .\n",
            "P-14\t-0.1159 -0.5647 -0.1256 -0.0567 -0.0833 -0.1347 -0.1128 -0.1017 -0.0712 -0.0782 -0.4734 -0.0955 -0.1718 -1.4095 -0.0707 -0.0888 -0.2321 -0.0490 -0.0786 -0.0538 -0.0910 -0.1214 -0.0761 -0.0862 -0.1251 -1.9240 -0.0474 -0.5732 -0.4825 -0.1020 -0.0659 -0.1147 -0.1084 -0.0413 -0.9963 -0.2523 -0.6146 -1.4895 -0.3006 -0.0666 -0.1103 -0.1017 -0.2790 -0.1271 -0.3473 -0.1279 -0.5042 -0.9653 -0.3744 -0.0434 -0.0972 -0.0403 -0.0166 -0.0725 -0.1111 -0.0647 -0.0854 -0.1247 -0.1174 -0.5155 -0.0080 -0.0833 -0.0835 -0.0163 -0.0959 -0.1722 -0.3320 -0.0668 -0.1138 -0.1221 -0.0421 -0.1033 -0.1248 -0.0644 -0.1356 -0.0215 -0.1063 -0.2665 -2.3662 -0.0961\n",
            "T-174\tKamtsikana kaimilira kumpanda uku akusuzumira mkati mwa kavaloyo .\n",
            "H-174\t-0.3448038101196289\t▁ K a m t s i k a n a ▁ k a k a n g ' o n o ▁ k a w u k u l u ▁ a k u s u n j i r a ▁ m ' k a m w a ▁ .\n",
            "D-174\t-0.3448038101196289\tKamtsikana kakang'ono kawukulu akusunjira m'kamwa .\n",
            "P-174\t-0.1318 -0.3194 -0.1256 -0.0530 -0.0197 -0.0888 -0.1026 -0.0560 -0.1555 -0.1055 -0.1037 -0.1446 -0.0506 -0.1336 -2.9126 -0.1663 -0.0864 -0.1154 -0.4360 -0.1451 -0.0627 -0.1089 -0.1012 -0.0473 -0.3137 -1.3546 -0.5030 -0.5826 -0.1500 -0.0385 -0.0944 -0.1905 -0.0917 -0.1294 -0.0708 -0.3838 -0.0257 -0.2667 -2.8758 -0.7543 -0.5625 -0.0931 -0.1289 -0.3225 -0.6344 -0.8511 -0.1365 -0.3053 -0.2229 -0.1093 -0.1663 -1.0319 -0.1122\n",
            "T-234\tBambo wina wovala malaya amizeremizere yabuluu akudikirira chakudya chimene waitanitsa .\n",
            "H-234\t-0.2017037272453308\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a ▁ b u l u u ▁ a k u d i k i r i r a ▁ c h a k u d y a ▁ c h a c h i n y e n g o ▁ .\n",
            "D-234\t-0.2017037272453308\tBambo wina wovala malaya amizeremizere ya buluu akudikirira chakudya chachinyengo .\n",
            "P-234\t-0.1242 -0.0435 -0.1121 -0.0801 -0.1175 -0.0855 -0.1172 -0.0850 -0.1086 -0.0852 -0.1060 -0.1199 -0.0858 -0.0994 -0.0477 -0.1190 -0.0947 -0.1255 -0.1065 -0.0718 -0.1148 -0.0650 -0.1107 -0.0671 -0.0978 -0.0967 -0.1238 -0.1937 -0.0731 -0.0226 -0.0844 -0.0416 -0.0839 -0.0571 -0.0626 -0.0196 -0.0844 -0.0784 -0.0796 -0.1229 -1.3084 -0.1234 -1.1712 -0.0237 -0.1334 -0.0545 -0.0749 -0.0585 -0.1078 -0.1911 -0.0560 -0.1091 -0.6699 -1.1656 -0.0744 -0.0479 -0.0958 -0.0677 -0.0967 -0.1085 -0.0980 -0.1945 -0.1005 -0.4160 -0.5964 -0.1051 -0.0827 -0.7188 -0.1241 -0.1526 -0.0734 -0.0870 -0.5302 -0.8516 -0.1116 -0.0887 -0.7738 -0.2042 -0.1829 -0.1525 -0.1864 -0.1721 -0.1379 -1.5368 -0.1136\n",
            "T-116\tKhamu la anthu ovala nyengo yofunda likuima pamzere kutsogolo kwa nyumba kudikirira chinachake .\n",
            "H-116\t-0.26825636625289917\t▁ A m u n a ▁ a n t h u ▁ o v a l a ▁ n y e n g o ▁ y o f u n d a ▁ n ' k u i m a ▁ p a m z e r e ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y a c h i n g w e ▁ .\n",
            "D-116\t-0.26825636625289917\tAmuna anthu ovala nyengo yofunda n'kuima pamzere kutsogolo kwa nyumba yachingwe .\n",
            "P-116\t-0.1059 -0.7859 -0.1393 -0.0704 -0.1192 -0.1765 -0.1287 -0.1354 -0.1080 -0.1382 -0.1886 -0.0859 -0.1175 -0.0580 -0.0778 -0.1228 -0.0789 -0.1118 -0.1094 -0.7042 -0.0996 -1.0527 -0.0657 -0.0995 -0.0686 -0.1520 -0.0469 -0.1396 -0.5246 -0.5182 -1.3507 -0.1323 -0.0892 -0.1686 -0.9752 -1.9472 -0.1724 -0.1199 -0.4522 -0.0362 -0.3092 -0.1149 -1.0116 -0.1384 -0.4026 -0.0803 -0.0743 -0.2410 -0.1744 -0.1455 -0.8010 -0.1357 -0.2418 -0.1115 -0.0780 -0.0549 -0.1397 -0.0935 -0.0775 -0.1057 -0.0720 -0.1104 -0.1328 -0.0935 -0.0581 -0.0493 -0.0393 -0.3575 -0.0586 -0.1182 -0.1193 -1.3045 -0.1887 -0.5433 -0.0976 -0.1052 -1.0237 -0.3344 -0.1795 -0.0542 -0.2079 -0.5979 -0.1143\n",
            "T-220\tGulu la anthu lili pansi ndi manja ndi mawondo kupanga chinachake pansi.\n",
            "H-220\t-0.3425031304359436\t▁ G a l u ▁ w a b u l a u n i ▁ n d i ▁ p a n s i ▁ n d i ▁ m a n j a ▁ a w a w o ▁ a k u t h a m a n g a ▁ c h i n a c h a k e ▁ .\n",
            "D-220\t-0.3425031304359436\tGalu wabulauni ndi pansi ndi manja awawo akuthamanga chinachake .\n",
            "P-220\t-0.1218 -0.0821 -0.1191 -0.0715 -0.0801 -0.1149 -2.1104 -0.3408 -1.3146 -0.0585 -0.0791 -0.1046 -0.0799 -0.0932 -0.0972 -0.1105 -0.5099 -0.0988 -0.1163 -0.1251 -0.5980 -0.1879 -0.0896 -2.2975 -0.0755 -0.1029 -1.2797 -0.1348 -0.1034 -0.0996 -0.4574 -0.1529 -1.4481 -0.3061 -0.1212 -0.1245 -0.7965 -0.2555 -0.5257 -1.1779 -0.6012 -0.1164 -0.4327 -0.5965 -0.1124 -0.2558 -0.1056 -0.1133 -0.3132 -0.0788 -0.0664 -0.0530 -0.0933 -0.1138 -0.6833 -0.0896 -0.0908 -0.1290 -0.2181 -0.0976 -0.0700 -0.1043 -0.1197 -0.0715 -0.1700 -1.7887 -0.0994\n",
            "T-33\tMa brunettes awiri, m'modzi ali ndi ma tattoo, kukumbatirana ndi kumwetulira pa kamera m'nyumba.\n",
            "H-33\t-0.3611506521701813\t▁ M a y i ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ j e a n s ▁ n d i ▁ m a t h a l a u k a ▁ a k u k a m b i r a n a ▁ n d i ▁ k u m e t u l i r a ▁ p a m e n e ▁ a n t h u ▁ e n a ▁ .\n",
            "D-33\t-0.3611506521701813\tMayi wina yemwe wavala jeans ndi mathalauka akukambirana ndi kumetulira pamene anthu ena .\n",
            "P-33\t-0.1263 -0.3947 -0.4452 -3.0895 -0.1439 -0.1517 -0.6413 -0.2992 -0.0875 -0.2082 -0.1281 -2.9189 -0.1628 -0.2557 -0.0896 -0.1143 -0.1149 -0.2814 -0.0759 -0.1800 -0.2369 -0.0764 -0.0855 -0.1126 -0.4767 -0.2800 -0.6175 -0.0395 -0.1198 -0.1487 -2.7382 -0.1367 -0.1133 -0.1542 -0.1566 -0.1606 -0.1420 -0.8754 -0.7343 -0.0887 -0.0929 -0.0420 -1.2952 -0.0911 -0.1422 -0.3974 -0.3925 -0.0935 -0.4458 -0.3790 -0.8320 -0.0568 -0.0898 -0.1278 -0.1022 -0.1212 -0.0736 -0.1568 -0.2773 -0.1005 -0.1401 -0.3383 -0.2763 -0.4660 -0.7883 -0.1156 -0.5301 -0.1622 -0.2019 -0.0849 -0.0772 -0.0856 -0.1412 -1.1464 -0.1162 -0.1445 -0.1055 -0.0492 -0.0881 -0.0975 -0.3106 -0.4484 -1.4412 -0.0991 -0.0650 -0.2089 -0.7630 -0.0258 -0.0790 -0.3639 -1.4509 -0.1026\n",
            "T-325\tApolisi anayi kapena apolisi akujambula chithunzi pomwe awiri a iwo akukumbatirana .\n",
            "H-325\t-0.31972524523735046\t▁ A p o l i s i ▁ a n a y i ▁ a t a t u ▁ e n a ▁ a w i r i ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ p o m w e ▁ a w i r i ▁ a k u k u l u ▁ a k u k u m b a t i r a n a ▁ .\n",
            "D-325\t-0.31972524523735046\tApolisi anayi atatu ena awiri akujambula chithunzi pomwe awiri akukulu akukumbatirana .\n",
            "P-325\t-0.1129 -0.1802 -1.4504 -0.0820 -0.0381 -0.0851 -0.0268 -0.0926 -0.1745 -0.1547 -0.0805 -0.0993 -0.0351 -0.0805 -0.1608 -0.1321 -0.5125 -0.1153 -2.6616 -0.0964 -0.1639 -2.7034 -0.0534 -0.0824 -0.1395 -0.0859 -1.1689 -0.0976 -0.1361 -0.0935 -0.2810 -0.1898 -0.1399 -0.1116 -1.5123 -0.0893 -0.1321 -0.1562 -0.0716 -0.0595 -0.1004 -0.1220 -0.1576 -0.0791 -0.1151 -1.2739 -0.0888 -0.0705 -0.0726 -0.0201 -0.0999 -0.1602 -0.8577 -0.0729 -0.0547 -0.2929 -0.1913 -0.1226 -0.3580 -1.3291 -0.1398 -0.0849 -0.1023 -0.1294 -0.1462 -0.3528 -0.1584 -0.0595 -1.6273 -1.5259 -0.1396 -0.4666 -0.4438 -0.2791 -0.1204 -0.1898 -0.7843 -0.4932 -0.0205 -0.1639 -0.0747 -0.1232 -0.0329 -0.0973 -0.1627 -0.0846 -0.6057 -0.2493 -0.1187\n",
            "T-54\tMayi wina wovala thalauza lofiira komanso malaya abuluu wotuwa akukwera panjinga yake kudutsa mlatho .\n",
            "H-54\t-0.2769026756286621\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ t h a l a u z a ▁ l o f i i r a ▁ k o m a n s o ▁ m a l a y a ▁ a b u l u u ▁ a k u k w e r a ▁ p a n j i n g a ▁ y a k e ▁ k u t s a m a l a ▁ .\n",
            "D-54\t-0.2769026756286621\tMayi wina wovala thalauza lofiira komanso malaya abuluu akukwera panjinga yake kutsamala .\n",
            "P-54\t-0.1342 -0.0762 -0.0882 -0.0583 -0.0987 -0.1290 -0.0578 -0.1075 -0.0942 -0.1044 -0.1153 -0.0788 -0.1078 -0.0700 -0.1235 -0.0766 -0.1178 -0.1112 -3.2630 -0.2116 -0.1064 -0.0408 -0.1201 -0.0300 -0.0237 -0.0951 -0.1133 -1.2370 -0.0430 -0.0728 -0.1135 -0.1598 -0.0808 -0.1606 -0.2373 -0.7088 -0.0828 -0.0542 -0.0991 -0.0575 -0.0853 -0.0670 -0.0966 -0.0539 -0.1151 -0.0538 -0.1287 -0.0862 -0.0926 -0.1073 -0.1912 -0.0382 -0.0887 -0.0591 -0.0927 -0.0309 -0.1277 -2.4892 -0.0992 -0.1044 -2.3864 -0.3580 -0.0857 -0.0606 -0.1176 -0.1098 -0.1624 -0.1442 -0.0746 -0.0225 -0.0747 -0.0414 -0.0860 -0.0931 -0.1141 -0.0231 -0.1314 -0.4379 -0.1371 -0.1563 -1.6998 -0.1447 -1.2507 -0.4616 -1.0536 -0.1024 -0.3881 -1.0932 -0.1129 -0.1587 -0.9990 -0.1248\n",
            "T-188\tMayi wina wovala malaya akuda akuima kutsogolo kwa nthochi pamalo oikapo zipatso .\n",
            "H-188\t-0.2085372805595398\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u y i m a ▁ k u t s o g o l o ▁ k w a ▁ m a n j a ▁ o i k a ▁ p a m a s o ▁ .\n",
            "D-188\t-0.2085372805595398\tMayi wina wovala malaya akuda akuyima kutsogolo kwa manja oika pamaso .\n",
            "P-188\t-0.1173 -0.0676 -0.1156 -0.0819 -0.0985 -0.1133 -0.0651 -0.1010 -0.1436 -0.1097 -0.1167 -0.1055 -0.1363 -0.0912 -0.1353 -0.0891 -0.1256 -0.1088 -0.0631 -0.1326 -0.0530 -0.1154 -0.0770 -0.1000 -0.1148 -0.1326 -0.2445 -0.0871 -0.2178 -0.1024 -0.1311 -0.2019 -0.1191 -0.0900 -1.2300 -0.1210 -0.0704 -0.0985 -0.0917 -0.0430 -0.0483 -0.1502 -0.1135 -0.0708 -0.0356 -0.1138 -0.0792 -0.0678 -0.0762 -0.0548 -0.0885 -0.1355 -0.1242 -0.1720 -0.1420 -1.0021 -0.0321 -0.2149 -0.1275 -0.1790 -0.3064 -0.8508 -0.1425 -0.1911 -0.4590 -0.2856 -0.8283 -0.1285 -0.7127 -0.2542 -0.0636 -2.3142 -0.0992\n",
            "T-239\tWosewera wa skateboard akukwera pa skateboard panja pazitsulo kutsogolo kwa nyumba ya konkire.\n",
            "H-239\t-0.16928157210350037\t▁ W o s e w e r a ▁ w a ▁ s k a t e b o a r d ▁ a k u k w e r a ▁ p a ▁ s k a t e b o a r d ▁ p a n j a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y a k e ▁ .\n",
            "D-239\t-0.16928157210350037\tWosewera wa skateboard akukwera pa skateboard panja kutsogolo kwa nyumba yake .\n",
            "P-239\t-0.1121 -0.1451 -0.0612 -0.0562 -0.0665 -0.1238 -0.1072 -0.0842 -0.1398 -0.1358 -0.2193 -0.1556 -0.3402 -0.1062 -0.1748 -0.0825 -0.0369 -0.0354 -0.1340 -0.0362 -0.0559 -0.0279 -0.0478 -0.5833 -0.0799 -0.1248 -0.1023 -0.5020 -0.0686 -0.1295 -0.1534 -0.1040 -0.1076 -0.0496 -0.1294 -0.1456 -0.0736 -0.6478 -0.1106 -0.0279 -0.0657 -0.1749 -0.0258 -0.0901 -0.0304 -0.0359 -0.2078 -0.5827 -0.1420 -0.8443 -0.0594 -0.2361 -0.1701 -0.4762 -0.0562 -0.3075 -0.0442 -0.0913 -0.0334 -0.1077 -0.0755 -0.0890 -0.1168 -0.0187 -0.1917 -0.1141 -0.1708 -0.1948 -0.1737 -0.0530 -0.0941 -0.0531 -0.0940 -0.8614 -0.0852 -0.1590 -0.6890 -0.1492 -0.3360 -0.4655 -0.1210\n",
            "T-53\tWothamanga akudumpha mumlengalenga pafupi ndi mtengo wautali, pamene mwamuna akumujambula pavidiyo.\n",
            "H-53\t-0.25286391377449036\t▁ W o t h a m a n g a ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ p a f u p i ▁ n d i ▁ m t e n g o ▁ w o t h a m a n g a ▁ p a m o d z i ▁ .\n",
            "D-53\t-0.25286391377449036\tWothamanga akudumpha mumlengalenga pafupi ndi mtengo wothamanga pamodzi .\n",
            "P-53\t-0.1154 -0.1712 -0.1045 -0.0802 -0.0139 -0.0964 -0.0783 -0.0873 -0.1052 -0.0421 -0.0800 -0.1330 -0.3055 -0.0926 -0.1085 -0.1740 -0.0746 -0.0236 -0.0886 -0.0462 -0.1399 -0.1348 -0.4711 -1.0405 -0.3188 -0.0268 -0.0702 -0.0522 -0.1039 -0.0979 -0.0465 -0.0794 -0.0482 -0.1342 -0.0814 -0.2182 -0.0803 -0.1363 -0.7318 -0.1032 -0.0391 -0.1152 -0.0970 -0.0623 -0.1352 -0.0989 -0.0741 -0.1634 -1.3794 -1.8463 -0.1605 -0.1035 -0.0782 -0.0798 -0.1075 -0.2704 -2.0875 -0.0291 -0.1114 -0.1323 -0.0850 -0.0940 -0.1048 -0.2937 -0.1660 -1.0186 -0.1202 -0.3755 -0.6099 -0.3037 -0.0678 -0.1196 -0.1933 -1.9834 -0.1205\n",
            "T-320\tAnyamata awiri akugwira magalasi pomwe amatha kuona chidindo chikusambira.\n",
            "H-320\t-0.27149099111557007\t▁ A n y a m a t a ▁ a w i r i ▁ a k u g w i r a ▁ m a s i t o l o ▁ o m a n g a ▁ a k u w o n a ▁ c h i n t h u ▁ c h o s a m b i r a ▁ .\n",
            "D-320\t-0.27149099111557007\tAnyamata awiri akugwira masitolo omanga akuwona chinthu chosambira .\n",
            "P-320\t-0.1229 -0.0580 -0.0544 -0.1249 -0.0926 -0.0753 -0.0929 -0.0691 -0.1174 -0.1185 -0.1263 -0.0860 -0.1165 -0.0704 -0.1079 -0.2218 -0.2883 -0.1765 -0.1157 -0.0429 -0.2406 -0.1542 -0.0696 -0.1172 -0.1319 -0.7782 -0.1078 -0.8705 -0.1255 -1.1313 -0.2307 -0.1194 -0.4183 -0.1388 -0.9926 -1.1348 -0.3638 -0.1856 -0.5164 -0.2173 -0.1668 -0.1244 -2.1721 -0.1167 -0.2459 -0.0706 -0.0735 -0.4526 -0.1739 -0.0315 -0.0726 -0.1102 -0.2268 -0.2630 -0.0606 -0.1147 -0.1453 -0.2453 -0.0904 -0.6181 -1.0213 -0.0707 -0.7412 -0.1206 -0.0895 -0.1101 -0.0899 -0.4267 -0.3377 -0.0989\n",
            "T-208\tAgalu akuda ndi akuda pa matalala, kusonyeza mano ndi kuuwa wina ndi mzake.\n",
            "H-208\t-0.3167290687561035\t▁ A g a l u ▁ a k u d a ▁ n d i ▁ a k u d a ▁ a t a v a l a ▁ m a t h a l a u z a ▁ o s o n y e z a ▁ m ' m a d z i ▁ n d i ▁ m w a m u n a ▁ w i n a ▁ .\n",
            "D-208\t-0.3167290687561035\tAgalu akuda ndi akuda atavala mathalauza osonyeza m'madzi ndi mwamuna wina .\n",
            "P-208\t-0.1133 -0.0735 -0.1800 -0.1112 -0.0511 -0.0864 -0.1291 -0.1140 -1.1765 -0.1265 -0.0598 -0.1155 -0.1866 -0.0523 -0.0681 -0.0889 -0.1032 -0.7539 -0.7678 -0.1434 -0.1287 -0.1389 -0.2346 -0.1235 -2.1509 -0.1322 -0.8725 -0.1145 -0.0880 -0.1200 -0.1003 -0.1675 -0.0941 -0.6333 -0.0263 -0.1239 -0.0472 -0.1169 -0.0422 -0.1672 -0.0935 -0.1242 -0.4274 -2.2075 -0.2073 -0.0708 -0.0233 -0.0902 -0.0160 -0.1060 -0.1506 -0.0969 -1.9800 -0.2843 -0.1431 -0.9382 -0.3890 -0.0698 -0.2169 -0.8078 -0.0476 -0.1099 -0.2293 -1.7056 -1.0176 -0.1798 -0.6382 -0.0987 -0.1371 -0.0908 -0.2316 -0.3291 -0.1685 -0.0734 -0.1082 -0.3323 -0.5293 -0.1112\n",
            "T-20\tMayi wina atanyamula galu wakuda ndi woyera m'mphepete mwa msewu kutsogolo kwa magalimoto oimika .\n",
            "H-20\t-0.24900008738040924\t▁ M a y i ▁ w i n a ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m p h e p e t e ▁ m w a ▁ m s e w u ▁ k u t s o g o l o ▁ k w a ▁ m a g a l i m o t o ▁ .\n",
            "D-20\t-0.24900008738040924\tMayi wina atavala malaya abuluu ndi mphepete mwa msewu kutsogolo kwa magalimoto .\n",
            "P-20\t-0.1360 -0.0684 -0.0942 -0.0782 -0.0853 -0.1114 -0.0977 -0.1072 -0.0876 -0.1062 -0.1200 -0.4387 -0.2786 -0.1033 -1.3402 -0.1047 -0.0870 -0.1167 -0.1004 -0.8808 -0.5362 -0.5245 -0.1045 -0.1146 -0.0899 -0.1168 -0.5756 -0.9929 -0.0772 -0.0656 -0.1245 -0.0404 -0.1161 -0.3671 -0.0716 -0.1096 -0.0827 -0.5960 -0.0596 -1.2898 -0.1043 -0.4557 -0.1158 -0.3799 -0.0760 -0.1051 -0.1930 -0.0913 -0.0933 -0.1506 -0.4789 -0.3661 -0.0496 -0.1106 -0.0492 -0.1605 -0.0812 -0.0655 -0.0561 -0.1167 -0.0542 -0.0494 -0.1011 -0.0956 -0.1008 -0.1083 -0.0220 -0.2297 -0.1058 -0.1460 -0.5967 -0.1184 -2.7781 -0.8237 -0.0753 -0.0549 -0.0227 -0.0303 -0.0473 -0.0315 -0.2072 -0.8738 -0.0968\n",
            "T-61\tmunthu woyenda pa snowboard atavala zofiira akutsika phiri lokutidwa ndi chipale chofewa .\n",
            "H-61\t-0.28322628140449524\t▁ M u n t h u ▁ w o y e n d a ▁ p a ▁ s n o w b o a r d ▁ a t a v a l a ▁ z o f i i r a ▁ a k u s i k a ▁ k u t i ▁ l i p a l e ▁ c h o f e w a ▁ .\n",
            "D-61\t-0.28322628140449524\tMunthu woyenda pa snowboard atavala zofiira akusika kuti lipale chofewa .\n",
            "P-61\t-0.1206 -0.2153 -0.0291 -0.0861 -0.0669 -0.1250 -0.0870 -0.1594 -0.0650 -1.0050 -0.4441 -0.0566 -0.2342 -0.2501 -0.1155 -0.1505 -0.0442 -0.1547 -0.7234 -0.0779 -0.3726 -0.0577 -0.0985 -0.3575 -0.0665 -0.1126 -0.1476 -0.0405 -1.2678 -0.1127 -0.0359 -0.1379 -0.0150 -0.1047 -0.1006 -0.1173 -0.0967 -1.2413 -0.1020 -0.2743 -0.1052 -0.2796 -0.1217 -0.2171 -0.1988 -0.1582 -0.0888 -0.0927 -0.1326 -0.2235 -0.0429 -0.1535 -0.1245 -2.2059 -0.1855 -0.1083 -0.0580 -0.1074 -2.9011 -0.3081 -1.5042 -0.1676 -0.5498 -0.1344 -0.0901 -0.1637 -0.0943 -0.1269 -0.4501 -0.0989 -0.1552 -0.1045 -0.4508 -0.1612 -0.1065\n",
            "T-358\tAnthu ena ayima m'chipinda mozungulira desiki yozungulira yolandirira alendo.\n",
            "H-358\t-0.24085374176502228\t▁ A n t h u ▁ e n a ▁ a n a y i ▁ a l i ▁ m ' c h i p i n d a ▁ m o z u n g u l i r a ▁ t e s i t i ▁ y o z u n g u l i r a ▁ n d i ▁ a n t h u ▁ e n a ▁ .\n",
            "D-358\t-0.24085374176502228\tAnthu ena anayi ali m'chipinda mozungulira tesiti yozungulira ndi anthu ena .\n",
            "P-358\t-0.1117 -0.0324 -0.5093 -0.0413 -0.1067 -0.0748 -0.0967 -0.3382 -0.0498 -0.0912 -0.1425 -0.0913 -0.2552 -0.1588 -0.1704 -0.0688 -0.2225 -0.4976 -2.0181 -0.1528 -0.1104 -0.1109 -0.1007 -0.0590 -0.0887 -0.0816 -0.1535 -0.1471 -0.1274 -0.1608 -0.1123 -0.1532 -0.4025 -0.2746 -0.1190 -0.4111 -0.0578 -0.0145 -0.0941 -0.0406 -0.0689 -0.0878 -0.1115 -0.1104 -0.3995 -0.0521 -2.6654 -0.0997 -0.4948 -0.0818 -0.2672 -0.0880 -0.1429 -0.1136 -0.0363 -0.0705 -0.0083 -0.0561 -0.0742 -0.0985 -0.0870 -0.1138 -0.1956 -0.3752 -0.1096 -0.1096 -0.1038 -0.3839 -1.2513 -0.2699 -0.1550 -0.0605 -0.2095 -0.5063 -0.0324 -0.1066 -0.3609 -1.3089 -0.1103\n",
            "T-356\tMayi wina wachiafirika waku America wovala malalanje akumenya mpira wa tenisi ndi racquet .\n",
            "H-356\t-0.32934972643852234\t▁ M a y i ▁ w i n a ▁ w a c h i c h e p e r e ▁ w a v a l a ▁ m a l a y a ▁ o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ n d i ▁ n y a l i ▁ w a t e n i s i ▁ n d i ▁ t - s h i r t ▁ .\n",
            "D-356\t-0.32934972643852234\tMayi wina wachichepere wavala malaya ovala malaya abulauni ndi nyali watenisi ndi t-shirt .\n",
            "P-356\t-0.1198 -0.0559 -0.0988 -0.0706 -0.0907 -0.1131 -0.0531 -0.1008 -0.0989 -0.0994 -0.1211 -0.1242 -0.1238 -0.1303 -0.0886 -0.2758 -0.6757 -0.1049 -0.0643 -0.4814 -1.2328 -0.1619 -0.1301 -0.1537 -0.5563 -0.1833 -2.1900 -0.1248 -0.1017 -0.1050 -0.0936 -0.1288 -0.7618 -0.2578 -0.1099 -0.1071 -0.0858 -0.0975 -0.1921 -1.2596 -0.1038 -0.0941 -0.1058 -0.1068 -0.1308 -0.1396 -0.4386 -0.1157 -0.1914 -0.0942 -0.1036 -0.1682 -2.0194 -0.2671 -0.0771 -0.6554 -0.1466 -0.1035 -0.0754 -0.1102 -0.3954 -0.2412 -0.1174 -0.0778 -0.5861 -0.0728 -0.0785 -0.6503 -0.7387 -0.1142 -0.3273 -0.1142 -1.6633 -0.9511 -0.3666 -0.5213 -0.2953 -0.5365 -0.1447 -0.4484 -0.0700 -0.1283 -0.1500 -1.1808 -2.5420 -0.1168 -0.2339 -0.7869 -0.0656 -0.0609 -0.1562 -0.2245 -0.1003\n",
            "T-427\tMwamuna wina wovala zakuda akuwomba m'manja munthu wothamanga yemwe wavala jeresi yofiira komanso nambala 281 .\n",
            "H-427\t-0.28310391306877136\t▁ M w a m u n a ▁ w i n a ▁ w o v a l a ▁ z a k u d a ▁ a k u w o m b a ▁ m ' m a n j a ▁ m w a m u n a ▁ a t a v a l a ▁ j e k e t e ▁ y o v a l a ▁ j e k e t e ▁ y o f i i r a ▁ k o m a n s o ▁ m b a l a m e ▁ .\n",
            "D-427\t-0.28310391306877136\tMwamuna wina wovala zakuda akuwomba m'manja mwamuna atavala jekete yovala jekete yofiira komanso mbalame .\n",
            "P-427\t-0.1369 -0.0554 -0.0664 -0.0973 -0.1421 -0.0785 -0.0978 -0.1043 -0.1539 -0.1056 -0.1025 -0.0766 -0.1060 -0.1317 -0.1036 -0.1110 -0.0644 -0.1238 -0.0845 -0.1163 -0.1144 -0.2459 -0.1150 -0.1571 -0.0742 -0.4056 -0.0901 -0.1731 -2.0891 -0.0836 -0.0996 -0.6275 -0.1265 -0.6967 -0.0944 -0.0913 -0.1767 -0.0605 -0.6279 -0.1906 -0.1202 -0.0432 -0.0985 -0.0936 -0.1407 -0.1542 -0.1363 -0.0908 -1.7501 -0.0728 -0.3512 -0.0729 -0.1295 -1.1343 -0.1227 -0.0961 -0.3348 -0.0951 -0.0793 -0.1086 -0.0883 -1.2903 -0.0478 -0.8748 -0.1801 -0.0663 -0.1253 -0.0900 -0.3692 -0.0767 -2.2919 -0.1068 -0.0851 -0.0893 -0.0909 -0.1834 -0.1282 -0.2751 -0.1401 -0.1298 -0.1337 -0.0934 -1.2820 -0.1652 -0.0287 -0.0740 -0.4571 -0.0770 -0.1160 -0.1929 -0.2737 -1.2803 -0.0628 -0.1148 -0.1621 -0.0407 -0.0522 -0.1210 -0.4417 -2.1649 -0.1109 -0.1253 -0.2130 -0.5620 -0.9016 -0.2802 -0.5928 -0.1020\n",
            "T-72\tMayi wovala mpango wa silika wofiira ndi wachikasu akusewera cello .\n",
            "H-72\t-0.26216280460357666\t▁ M a y i ▁ w o v a l a ▁ m p a n g o ▁ w a ▁ s i t e j i ▁ y o f i i r a ▁ n d i ▁ w a c h i k a s u ▁ a k u s e w e r a ▁ s i l o ▁ .\n",
            "D-72\t-0.26216280460357666\tMayi wovala mpango wa siteji yofiira ndi wachikasu akusewera silo .\n",
            "P-72\t-0.1457 -0.0793 -0.0682 -0.0367 -0.1011 -0.1531 -0.0771 -0.2352 -0.0622 -0.1244 -0.0830 -0.1106 -0.1137 -0.1715 -1.2049 -0.3780 -1.0068 -0.1756 -0.0935 -0.0953 -0.0772 -0.1504 -0.4696 -0.1946 -0.2123 -2.4041 -0.6437 -0.4725 -0.0812 -0.1217 -0.2068 -0.2508 -0.0481 -0.1063 -0.8708 -0.1017 -0.2785 -0.1884 -0.1407 -0.1065 -0.1217 -0.1709 -0.1532 -0.1552 -0.0420 -0.0515 -0.1006 -0.0228 -0.1384 -0.0483 -0.0715 -0.1363 -0.1261 -0.0385 -0.0920 -0.0344 -0.0885 -0.1316 -0.0821 -0.1160 -0.1579 -0.1632 -0.4752 -0.4373 -0.0441 -0.6870 -0.8777 -1.5969 -0.0867\n",
            "T-194\tMunthu ameneyu wavala malaya abuluu akusenga thabwa la boti limene akulimanga .\n",
            "H-194\t-0.24317432940006256\t▁ M u n t h u ▁ w a m e n e ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u s e w e r a ▁ t h a l a u z a ▁ l o t c h i n g i d w a ▁ .\n",
            "D-194\t-0.24317432940006256\tMunthu wamene wavala malaya abuluu akusewera thalauza lotchingidwa .\n",
            "P-194\t-0.1198 -0.0819 -0.0601 -0.0771 -0.0861 -0.0847 -0.0838 -0.2271 -0.1752 -0.1319 -0.8285 -0.6764 -0.2505 -0.2266 -0.1852 -0.0960 -0.1425 -0.0840 -0.1267 -0.0880 -0.1298 -0.1166 -0.1382 -0.1443 -0.0518 -0.1190 -0.1213 -0.1037 -0.0960 -0.1486 -0.0627 -0.1155 -0.0685 -0.1751 -0.0428 -0.1581 -0.0971 -0.0722 -0.0909 -0.0661 -0.0622 -0.6667 -0.1153 -0.1261 -0.1088 -0.1227 -1.7195 -0.1872 -0.1026 -0.9579 -0.2377 -0.1026 -0.2109 -0.1065 -0.0996 -0.3240 -0.8636 -1.1222 -0.5307 -0.0726 -0.0671 -0.1301 -0.1879 -0.1134 -1.5912 -0.0601 -0.1074 -0.1576 -0.7131 -0.1046\n",
            "T-377\tWosewera mpira wa tennis akumenya mpira ndi racquet yake, pomwe ena amawonera masewerawo.\n",
            "H-377\t-0.3705832362174988\t▁ M m o s e w e r a ▁ m p i r a ▁ w a ▁ t e n i s ▁ a k u n y a m u l a ▁ n d i ▁ j e k e t e ▁ l a k e ▁ k u m u y e n d a ▁ m w a m u n a ▁ w o v a l a ▁ m a s e w e r a ▁ o b i r i w i r a .\n",
            "D-377\t-0.3705832362174988\tMmosewera mpira wa tenis akunyamula ndi jekete lake kumuyenda mwamuna wovala masewera obiriwira.\n",
            "P-377\t-0.1294 -0.0914 -2.9075 -0.1113 -0.5024 -0.1208 -0.1590 -0.1545 -0.0950 -0.1582 -0.1586 -1.0859 -0.5003 -0.0955 -0.0603 -0.1198 -0.1730 -0.0753 -0.1081 -0.6622 -0.2582 -0.4340 -0.2250 -0.4317 -0.2674 -0.3852 -1.2300 -0.0711 -0.0986 -0.9107 -0.1429 -0.1359 -0.1353 -0.8416 -0.0857 -0.0981 -0.0965 -0.5577 -0.2225 -0.3663 -0.2428 -1.8400 -0.2995 -0.1514 -0.0509 -0.0527 -0.1450 -0.1050 -0.1928 -0.1211 -0.4963 -0.1580 -0.1574 -0.4458 -0.3039 -0.2580 -0.8392 -0.4976 -0.2745 -0.0814 -0.1635 -0.1558 -0.1370 -0.4413 -2.1430 -0.1111 -0.1588 -0.0594 -0.0822 -0.0847 -0.1584 -0.3363 -0.6471 -0.9934 -0.1395 -0.0966 -0.1210 -0.1125 -1.2269 -0.1206 -0.1908 -0.7024 -0.1311 -0.1095 -0.1220 -0.1314 -0.2823 -0.2579 -2.8957 -0.1173 -0.1042 -0.1272 -0.0313 -0.1392 -0.1587 -0.1298 -1.9059 -0.1155\n",
            "T-253\tAnthu angapo atayima ndi kukhala m'kalasi kapena m'chipinda chochitira misonkhano .\n",
            "H-253\t-0.2473604530096054\t▁ A n t h u ▁ a n g a p o ▁ a t a y i m a ▁ n d i ▁ k u k h a l a ▁ m ' k a l a s i ▁ n d i ▁ c h i p i n d a ▁ c h o t i k a ▁ m ' n k h a l a n g o ▁ .\n",
            "D-253\t-0.2473604530096054\tAnthu angapo atayima ndi kukhala m'kalasi ndi chipinda chotika m'nkhalango .\n",
            "P-253\t-0.1232 -0.0516 -0.0789 -0.0350 -0.0972 -0.0716 -0.1006 -0.1321 -0.1038 -0.0230 -0.0799 -0.0086 -0.0804 -0.1151 -0.0735 -0.0426 -0.1142 -0.2685 -0.1285 -0.0748 -0.0727 -0.1022 -0.4461 -0.1248 -0.1032 -0.5139 -0.3733 -0.4410 -0.0875 -0.6250 -0.1079 -0.0626 -0.1100 -0.0924 -0.1620 -0.1765 -1.1374 -0.1134 -1.4224 -0.0973 -0.1347 -0.0728 -0.1732 -0.5065 -0.1002 -0.1082 -0.6015 -0.3473 -0.1062 -0.1042 -0.1206 -0.1317 -0.3883 -0.1088 -0.7242 -0.2080 -0.0156 -0.0856 -0.5439 -0.8941 -0.5334 -0.4020 -0.0840 -0.2248 -0.3838 -0.7570 -0.7268 -0.7051 -0.1090 -0.0944 -0.0727 -0.1001 -0.0289 -0.0699 -0.0661 -0.8245 -0.3499 -0.1116\n",
            "T-342\tMayi wina wokalamba akuyeretsa mazenera pasitolo pafupi ndi msewu .\n",
            "H-342\t-0.2769950032234192\t▁ M a y i ▁ w i n a ▁ w o k h a l a ▁ n d i ▁ a k u y e s a ▁ m a z e r e ▁ a ▁ p a ▁ s i t o l o ▁ p a f u p i ▁ n d i ▁ n j i n g a ▁ .\n",
            "D-342\t-0.2769950032234192\tMayi wina wokhala ndi akuyesa mazere a pa sitolo pafupi ndi njinga .\n",
            "P-342\t-0.1247 -0.1069 -0.1190 -0.0513 -0.1068 -0.1303 -0.1675 -0.1107 -0.0771 -0.1016 -0.1087 -0.4379 -0.0941 -0.0816 -1.0697 -0.1100 -0.0546 -0.1134 -0.1015 -0.9765 -0.7841 -0.1327 -0.1393 -0.6977 -0.6375 -0.1086 -0.1695 -0.1403 -0.0816 -0.3982 -0.0984 -0.1772 -0.1732 -0.5663 -0.0911 -0.1595 -0.1251 -0.1564 -1.0604 -0.4382 -1.0661 -0.2877 -1.1881 -0.5133 -0.0796 -0.0153 -0.0808 -0.0552 -0.0990 -0.1624 -0.1900 -0.1543 -0.4119 -0.0899 -0.0389 -0.1076 -0.1398 -0.0594 -0.0889 -0.1332 -0.0831 -0.3823 -1.3954 -0.3168 -0.2519 -0.2525 -0.0969 -0.2783 -0.6982 -0.0940\n",
            "T-19\tWoyenda pa skateboard wovala t-shirt yakuda ndi mathalauza akuda ali kutsogolo kwa nyumba ya njerwa zofiira .\n",
            "H-19\t-0.25901365280151367\t▁ W o y e n d a ▁ p a ▁ s k a t e b o a r d ▁ w o v a l a ▁ j e k e t e ▁ y a b u l u u ▁ n d i ▁ m a t h a l a u z a ▁ o v a l a ▁ n y u m b a ▁ y a ▁ n j e r w a ▁ z o f i i r a ▁ .\n",
            "D-19\t-0.25901365280151367\tWoyenda pa skateboard wovala jekete yabuluu ndi mathalauza ovala nyumba ya njerwa zofiira .\n",
            "P-19\t-0.1253 -0.1140 -0.0662 -0.0860 -0.1718 -0.0712 -0.0453 -0.1392 -0.1306 -0.0222 -0.1266 -0.1911 -0.0250 -0.0765 -0.0969 -0.0288 -0.0393 -0.0267 -0.0970 -0.0774 -0.0604 -0.0309 -0.8674 -1.4418 -0.6237 -0.1208 -0.1066 -0.0996 -0.0960 -0.1049 -0.2345 -0.0870 -0.7537 -0.0892 -0.0568 -0.0723 -0.1196 -0.2901 -0.1068 -2.1499 -0.0682 -0.1008 -0.2257 -0.0373 -0.1590 -0.6100 -0.1048 -0.1322 -0.0827 -0.5834 -0.1384 -0.8772 -0.0400 -0.0878 -0.0552 -0.1377 -0.0452 -0.0807 -0.0890 -0.1124 -0.3066 -2.2672 -0.1186 -0.1015 -0.1135 -0.0942 -1.7104 -0.1899 -0.2011 -0.1796 -0.0610 -0.0871 -0.1349 -0.0291 -0.2744 -1.2648 -0.5337 -0.0603 -0.1143 -0.0183 -0.0677 -0.0654 -0.2735 -0.9164 -0.0378 -0.0213 -0.0819 -0.1618 -0.0887 -0.1200 -1.2213 -0.0268 -0.1086\n",
            "T-299\tKamnyamata kakang'ono kovala malaya amizeremizere yakuda ndi yofiira akuyenda pansi paphiri laudzu .\n",
            "H-299\t-0.1832478940486908\t▁ K a m n y a m a t a ▁ k a k a n g ' o n o ▁ k o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a k u d a ▁ n d i ▁ y o f i i r a ▁ a k u y e n d a ▁ p a n s i ▁ p a ▁ u d z u ▁ .\n",
            "D-299\t-0.1832478940486908\tKamnyamata kakang'ono kovala malaya amizeremizere yakuda ndi yofiira akuyenda pansi pa udzu .\n",
            "P-299\t-0.1277 -0.1211 -0.1759 -0.0721 -0.0522 -0.0547 -0.1015 -0.0561 -0.0950 -0.0737 -0.0901 -0.1197 -0.0471 -0.1311 -0.3173 -0.1560 -0.1079 -0.0623 -0.0545 -0.0827 -0.0717 -0.1381 -0.1074 -0.0274 -0.1186 -0.0869 -0.1008 -0.0875 -0.1080 -0.1120 -0.0534 -0.1178 -0.1084 -0.1012 -0.0317 -0.0910 -0.1109 -0.1787 -0.4438 -0.1717 -0.0423 -0.0798 -0.0492 -0.0769 -0.1000 -0.0560 -0.0520 -0.0886 -0.0531 -0.0830 -0.1311 -0.2172 -0.2193 -0.6712 -0.1113 -1.4311 -0.1674 -0.1930 -0.0866 -0.0807 -0.1020 -0.1313 -0.2056 -0.0716 -0.1277 -0.0923 -0.5824 -0.0983 -0.2178 -0.2359 -2.0657 -0.0822 -0.0673 -0.0933 -0.1010 -0.0845 -0.1688 -0.1183 -0.1276 -0.0080 -0.1527 -0.0204 -0.1526 -0.0672 -0.1442 -0.3847 -0.1290 -0.7044 -0.4029 -0.3003 -0.0394 -0.1098 -0.3358 -1.1131 -0.1146\n",
            "T-335\tKamtsikana kakang'ono kovala pinki kakugwera m'madzi pamene mtsikana wina atavala mawotchi ofiira .\n",
            "H-335\t-0.23329007625579834\t▁ K a m t s i k a n a ▁ k a k a n g ' o n o ▁ k o v a l a ▁ p i n k i ▁ k a k u k w e r a ▁ m ' m a d z i ▁ p a m e n e ▁ m t s i k a n a ▁ w i n a ▁ a t a v a l a ▁ m a l a y a ▁ o f i i r a ▁ .\n",
            "D-335\t-0.23329007625579834\tKamtsikana kakang'ono kovala pinki kakukwera m'madzi pamene mtsikana wina atavala malaya ofiira .\n",
            "P-335\t-0.1236 -0.4670 -0.1041 -0.0620 -0.0276 -0.1379 -0.1011 -0.1200 -0.1438 -0.1081 -0.1242 -0.1520 -0.1112 -0.1320 -0.3236 -0.1111 -0.1123 -0.0246 -0.0850 -0.0720 -0.0602 -0.0685 -0.1197 -0.5960 -0.1276 -0.0990 -0.1176 -0.0775 -0.1150 -0.1100 -1.0504 -0.2058 -0.0999 -0.1977 -0.0978 -0.1731 -1.1648 -0.1344 -0.2097 -0.0862 -2.7345 -0.1741 -0.0448 -0.2771 -0.1032 -0.1261 -0.1996 -0.9146 -0.1452 -0.1058 -0.1199 -0.0229 -0.0938 -0.2502 -0.0399 -0.1232 -0.0514 -0.0708 -0.0884 -0.0741 -0.0874 -0.1066 -1.3050 -0.0831 -0.0935 -0.0697 -0.1133 -0.1082 -0.1013 -0.2229 -0.9018 -0.1709 -0.0746 -0.1095 -0.1525 -0.5240 -0.0232 -0.1018 -0.0205 -0.1058 -0.0691 -0.1498 -0.1106 -0.6607 -0.4805 -1.5082 -0.2041 -0.0940 -0.1212 -0.1177 -0.1180 -0.3792 -0.0872 -0.1593 -0.0909 -0.1244 -0.6338 -0.0934 -0.1037\n",
            "T-109\tGalu woyera wokhala ndi makutu abulauni amathamanga panjira ya miyala ndi mpira m'kamwa .\n",
            "H-109\t-0.21880891919136047\t▁ G a l u ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ m a k u t u ▁ a b u l a u n i ▁ a t a v a l a ▁ m a l a y a ▁ a m i y a l a ▁ n d i ▁ m p i r a ▁ m ' k a m w a ▁ .\n",
            "D-109\t-0.21880891919136047\tGalu woyera wokhala ndi makutu abulauni atavala malaya amiyala ndi mpira m'kamwa .\n",
            "P-109\t-0.1317 -0.1181 -0.1043 -0.0757 -0.0728 -0.1388 -0.0430 -0.0592 -0.0414 -0.1021 -0.0786 -0.0904 -0.1523 -0.2150 -0.0962 -0.4973 -0.2340 -0.1119 -0.0421 -0.1002 -0.1211 -0.0539 -0.1361 -0.1002 -0.0727 -0.0791 -0.1087 -3.5489 -0.0684 -0.0469 -0.0593 -0.1449 -0.1545 -0.3035 -0.1152 -0.0839 -0.7796 -0.0600 -0.0997 -0.1274 -0.1266 -0.1131 -0.7672 -0.1274 -0.5930 -0.0980 -0.1089 -0.1007 -0.0932 -0.0979 -0.1287 -0.2787 -0.0881 -0.0786 -0.0782 -0.1108 -0.5754 -0.2381 -0.0704 -0.1350 -0.1545 -0.0529 -0.1058 -0.1371 -1.2175 -0.0920 -0.1204 -0.0914 -0.1928 -0.0561 -0.1228 -0.1025 -0.0976 -0.1796 -1.0198 -0.5820 -0.2592 -0.2045 -0.1461 -0.0638 -0.1048 -0.2077 -0.1919 -0.0999\n",
            "T-338\tMunthu wopanda pokhala akugona pansi pa bulangete lobiriwira m'mbali mwa khoma la simenti .\n",
            "H-338\t-0.34036633372306824\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o k h a l a ▁ a k u g o n a ▁ p a b w a l o ▁ l a ▁ n j e k e t i ▁ l o b i r i w i r a ▁ m ' m b a l i ▁ m w a ▁ k u m a s i t s i ▁ .\n",
            "D-338\t-0.34036633372306824\tMunthu wovala malaya okhala akugona pabwalo la njeketi lobiriwira m'mbali mwa kumasitsi .\n",
            "P-338\t-0.1176 -0.1032 -0.2973 -0.0813 -0.0949 -0.0949 -0.0751 -0.1319 -0.0615 -0.1412 -1.1012 -0.1238 -0.0951 -0.1090 -0.1107 -2.2148 -0.5792 -0.3096 -0.1184 -0.0919 -0.1030 -0.0979 -0.1461 -0.4001 -0.2479 -0.1064 -0.0699 -0.0983 -0.1048 -1.5908 -0.1243 -0.0913 -1.3178 -0.5011 -0.0239 -0.0918 -0.1075 -0.0838 -0.1289 -2.7975 -0.8919 -0.1176 -0.1508 -0.1467 -0.0979 -0.0733 -0.2167 -0.1532 -0.6040 -0.6251 -0.1099 -0.5677 -0.0990 -0.0158 -0.6213 -0.0746 -0.5841 -0.0693 -0.2597 -0.1044 -0.1052 -0.0839 -0.0769 -0.0963 -0.0768 -0.1053 -0.1608 -0.2438 -0.0806 -0.6906 -1.3306 -0.1065 -0.0342 -0.0779 -0.1231 -0.2323 -0.0230 -0.0844 -0.1710 -2.1118 -0.4514 -0.1294 -0.1103 -0.1714 -1.1106 -0.6203 -1.4140 -0.2998 -0.5592 -0.1128 -0.1107\n",
            "T-173\tMwamuna wovala malaya abulauni akugwira dzanja la mwana watsitsi lalitali kutsogolo kwa chithunzi .\n",
            "H-173\t-0.19194495677947998\t▁ M w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u g w i r a ▁ z a n j a ▁ l a ▁ m w a n a ▁ w a t s i t s i ▁ l a l i t a l i ▁ k u t s o g o l o ▁ k w a ▁ c h i t h u n z i ▁ .\n",
            "D-173\t-0.19194495677947998\tMwamuna wovala malaya abuluu akugwira zanja la mwana watsitsi lalitali kutsogolo kwa chithunzi .\n",
            "P-173\t-0.1195 -0.0573 -0.0505 -0.1001 -0.1301 -0.1015 -0.1126 -0.1015 -0.1432 -0.1139 -0.1204 -0.0997 -0.1384 -0.0774 -0.1296 -0.1056 -0.0669 -0.1270 -0.0552 -0.1086 -0.0671 -0.1015 -0.1049 -0.1429 -0.0689 -0.0837 -0.0632 -0.9425 -0.0533 -0.1379 -0.1591 -0.1493 -0.0777 -0.1017 -0.1813 -0.6979 -0.0834 -0.1089 -0.1009 -1.1495 -0.1304 -0.1423 -0.0684 -0.1024 -0.1073 -2.4749 -0.1038 -1.0354 -0.1243 -0.4301 -0.1141 -0.1392 -0.0980 -0.1300 -0.1938 -0.1239 -1.8197 -0.0311 -0.0810 -0.0689 -0.0290 -0.0934 -0.1052 -0.0791 -0.1147 -0.0211 -0.0915 -0.0225 -0.0655 -0.0213 -0.0944 -0.1709 -0.1746 -0.0722 -0.0327 -0.1164 -0.1266 -0.0738 -0.1207 -0.0954 -0.0990 -0.0981 -0.0481 -0.1031 -0.1221 -0.1998 -0.5162 -0.0701 -0.0868 -0.1423 -0.2517 -0.0611 -0.0416 -0.0274 -0.0847 -0.7939 -0.0740 -0.1159\n",
            "T-222\tAnyamata anayi amasewera m'gulu lawo, akuimba ndi kusewera gitala ndi bass.\n",
            "H-222\t-0.28794339299201965\t▁ A n y a m a t a ▁ a n a y i ▁ a i m a ▁ m a s e w e r a ▁ m ' b u l u u ▁ a k u i m b a ▁ n d i ▁ k u s e w e r a ▁ g i t a l a ▁ l a ▁ b e i g e ▁ .\n",
            "D-222\t-0.28794339299201965\tAnyamata anayi aima masewera m'buluu akuimba ndi kusewera gitala la beige .\n",
            "P-222\t-0.1169 -0.0686 -0.0453 -0.0203 -0.1008 -0.0782 -0.1014 -0.0568 -0.1030 -0.1227 -0.1489 -0.4950 -0.1882 -0.0244 -0.0901 -0.1382 -0.1464 -2.6510 -0.1035 -0.2949 -0.0852 -0.8620 -1.0067 -0.4302 -0.0854 -0.0773 -0.0754 -0.1551 -0.1132 -0.1343 -0.8080 -0.3267 -0.7472 -0.2207 -0.1181 -0.2188 -0.1269 -0.1414 -0.1894 -0.4323 -0.1063 -0.3883 -0.0612 -0.0393 -0.1160 -0.1243 -0.1500 -0.0994 -0.1176 -0.7972 -0.4801 -0.1235 -0.1817 -0.1035 -0.6574 -0.0996 -0.1360 -0.1152 -0.0900 -0.2000 -0.1317 -0.0185 -0.1054 -0.0281 -0.1187 -0.1636 -1.0947 -0.2081 -0.2426 -2.1772 -0.2766 -0.8848 -0.0883 -0.0686 -0.2954 -0.5289 -0.1050\n",
            "T-336\tOvodafone amathandizira timu ya mpira wa Emirates nthawi yayitali ku Barcelona.\n",
            "H-336\t-0.4149493873119354\t▁ O g w i r a ▁ n t c h i t o ▁ a m a t h a m a n g i r a ▁ n d i ▁ m u n t h u ▁ w i n a ▁ w a i m i r i r a ▁ k u t a l i ▁ k w a ▁ n y u m b a ▁ .\n",
            "D-336\t-0.4149493873119354\tOgwira ntchito amathamangira ndi munthu wina waimirira kutali kwa nyumba .\n",
            "P-336\t-0.1148 -1.3225 -0.2601 -0.3101 -1.6081 -0.1877 -0.0946 -0.1279 -0.8881 -0.7698 -1.0520 -0.1266 -0.5894 -0.0476 -0.0863 -0.0950 -0.1520 -0.1176 -0.1093 -0.0243 -0.2570 -0.1315 -1.7245 -0.3015 -0.0871 -0.0812 -0.0509 -0.4124 -0.1304 -0.1363 -1.7953 -0.3389 -0.1059 -0.1207 -0.4441 -0.9045 -0.4260 -0.0887 -0.0419 -0.1354 -0.1374 -0.1441 -1.1984 -0.2392 -0.0911 -0.1579 -0.8629 -0.2743 -0.4784 -0.2587 -0.2230 -0.0696 -0.0730 -0.2026 -0.1444 -0.1161 -1.2884 -0.0896 -0.3927 -0.7570 -0.0837 -0.0607 -0.3593 -0.9243 -1.4221 -0.1064 -0.1529 -2.9169 -0.1239 -0.1877 -0.0765 -0.0237 -0.0979 -0.3442 -1.5711 -0.0884\n",
            "T-205\tokwatirana ovala zovala zowala akuyenda manja ndi manja m'mphepete mwa msewu .\n",
            "H-205\t-0.22033144533634186\t▁ O k w a t i r a n a ▁ o v a l a ▁ z o v a l a ▁ z o v a l a ▁ a k u y e n d a ▁ m a n j a ▁ a k u y e n d a ▁ m ' m p h e p e t e ▁ m w a ▁ m s e w u ▁ .\n",
            "D-205\t-0.22033144533634186\tOkwatirana ovala zovala zovala akuyenda manja akuyenda m'mphepete mwa msewu .\n",
            "P-205\t-0.1259 -1.2118 -0.3511 -0.0478 -0.5830 -0.0158 -0.0812 -0.1682 -0.1212 -1.7215 -0.0974 -0.1723 -0.3433 -0.0678 -0.1110 -0.0889 -0.1116 -0.1306 -0.3941 -0.0990 -0.0324 -0.1057 -0.0830 -0.1135 -0.1248 -0.0203 -0.1113 -0.5289 -0.1074 -0.1067 -0.1159 -0.1159 -0.4040 -0.0920 -0.0794 -0.4699 -0.1225 -0.1333 -0.2335 -0.1079 -0.1300 -0.0676 -0.2678 -0.0890 -0.0189 -0.1178 -0.1184 -0.6139 -1.3049 -0.1515 -0.3705 -0.1940 -0.1097 -0.0870 -0.0811 -0.1131 -0.1385 -0.1494 -0.0570 -1.3139 -0.0221 -0.1732 -0.0264 -0.0652 -0.0401 -0.1018 -0.1027 -0.0297 -0.0335 -0.1025 -0.1303 -0.1427 -0.6128 -0.1335 -0.1095 -0.0633 -0.6131 -0.0425 -0.1152\n",
            "T-388\tWothamanga amadula miyendo yake pamene akuwuluka mumlengalenga pamwamba pa phiri la ski .\n",
            "H-388\t-0.30392545461654663\t▁ W o t h a m a n g a ▁ a m a d u m p h a ▁ m ' n y e n d o ▁ y a k e ▁ p a m e n e ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ p a m w a m b a ▁ p a ▁ m a s i t e p e .\n",
            "D-388\t-0.30392545461654663\tWothamanga amadumpha m'nyendo yake pamene akudumpha mumlengalenga pamwamba pa masitepe.\n",
            "P-388\t-0.1111 -0.3160 -0.0465 -0.0526 -0.0385 -0.1035 -0.0703 -0.1059 -0.0822 -0.0281 -0.0917 -0.1257 -0.0961 -1.0397 -0.1270 -0.2848 -0.0577 -0.7994 -0.4246 -0.0705 -0.2876 -0.2389 -0.2679 -1.1693 -1.4971 -0.1551 -0.1220 -0.0463 -0.4471 -0.1217 -0.1328 -0.0395 -0.1365 -0.4005 -0.0612 -0.1449 -0.1084 -0.1109 -0.0809 -0.1739 -0.0554 -0.1287 -0.0923 -0.3029 -0.2767 -0.2027 -1.2414 -0.1074 -0.7958 -0.2908 -0.1186 -0.1397 -0.1523 -0.2030 -1.8521 -0.0773 -0.5782 -0.0635 -0.0747 -0.1065 -0.1041 -0.0534 -0.1036 -0.0389 -0.1259 -0.0973 -0.2444 -0.0450 -0.1467 -0.4179 -0.5880 -0.0817 -0.0544 -0.1087 -0.1068 -0.1720 -0.0442 -0.1488 -0.2327 -2.1527 -0.2207 -1.3727 -0.1181 -0.1659 -0.1679 -0.2300 -0.4427 -2.4861 -0.1035\n",
            "T-36\tBambo wa jekete la imvi ndi magalasi ofiira ali ndi makamera ndipo waima kutsogolo kwa galimoto .\n",
            "H-36\t-0.263945609331131\t▁ B a m b o ▁ w a c h i k u l i r e ▁ a l i ▁ n d i ▁ m a g a l a s i ▁ o f i i r a ▁ a l i ▁ n d i ▁ m a k a m e r a ▁ o i m a ▁ k u t s o g o l o ▁ k w a ▁ g a l i m o t o ▁ .\n",
            "D-36\t-0.263945609331131\tBambo wachikulire ali ndi magalasi ofiira ali ndi makamera oima kutsogolo kwa galimoto .\n",
            "P-36\t-0.1281 -0.0683 -0.1013 -0.0774 -0.0597 -0.0890 -0.1364 -0.0758 -0.1285 -0.9820 -0.0550 -0.3069 -0.4346 -0.3814 -0.0849 -0.0622 -0.0415 -0.1302 -0.1275 -0.6517 -0.8167 -0.1134 -0.1147 -0.2938 -0.0882 -0.0960 -0.0922 -0.0829 -0.1038 -1.2844 -0.1029 -0.0691 -0.0995 -0.0241 -0.0745 -0.1279 -0.9155 -0.1039 -0.1053 -0.2125 -0.0762 -0.2210 -0.1764 -0.2839 -0.2071 -0.1084 -0.0968 -0.0600 -0.0672 -0.0947 -0.0969 -0.1266 -0.1764 -0.1872 -0.2714 -0.1986 -1.7713 -0.0987 -0.1538 -0.1296 -0.0987 -1.8942 -0.0299 -0.6605 -0.1479 -0.8296 -0.0646 -0.0756 -0.1300 -0.0747 -0.0617 -0.0948 -0.0687 -0.0806 -0.1049 -0.1511 -0.1061 -0.0990 -0.2321 -2.0571 -1.7002 -0.0508 -0.3622 -0.0284 -0.0391 -0.0493 -0.0430 -0.4777 -0.1971 -0.0996\n",
            "T-376\tBambo wina atanyamula chitenje akuyang'ana chapatali ndi dzanja lake pakamwa .\n",
            "H-376\t-0.289204865694046\t▁ B a m b o ▁ w i n a ▁ a t a n y a m u l a ▁ c h i t e n g e ▁ a k u p e n y a ▁ c h a l a l a n j e ▁ n d i ▁ d z a n j a ▁ l a k e ▁ p a m w a m b a ▁ .\n",
            "D-376\t-0.289204865694046\tBambo wina atanyamula chitenge akupenya chalalanje ndi dzanja lake pamwamba .\n",
            "P-376\t-0.1415 -0.0377 -0.0983 -0.0717 -0.0915 -0.1244 -0.1215 -0.0558 -0.0986 -0.1027 -0.1167 -0.1292 -0.0670 -0.0426 -0.1054 -0.1308 -0.0304 -0.0883 -0.1155 -0.0812 -0.0726 -0.0914 -0.1123 -0.6157 -0.0897 -0.0932 -0.5801 -0.0853 -0.3701 -0.7793 -0.1802 -1.0334 -0.9098 -0.1551 -0.0983 -1.5154 -0.5614 -0.2820 -0.9055 -0.1046 -0.1649 -1.0708 -0.1225 -0.1546 -2.3152 -0.3102 -0.1308 -0.5072 -0.1099 -0.0665 -0.1534 -0.1897 -0.4597 -0.1190 -0.1255 -0.1076 -0.5729 -0.0480 -0.1332 -0.0656 -0.0081 -0.1319 -0.1094 -0.0510 -0.1663 -0.1053 -0.0914 -0.0997 -0.5842 -0.1523 -0.8938 -0.6069 -0.0899 -0.2062 -0.2660 -0.1280 -0.2323 -1.3945 -0.1166\n",
            "T-369\tWosewera mpira wa tenesi yemwe wavala chovala chobiriwira kumutu ali wokonzeka kumenya mpira .\n",
            "H-369\t-0.2140161395072937\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ y e m w e ▁ w a v a l a ▁ c h o v a l a ▁ c h a m b i r i ▁ m u n t h u ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ m p i r a ▁ .\n",
            "D-369\t-0.2140161395072937\tWosewera mpira wa tenisi yemwe wavala chovala chambiri munthu ali kutsogolo kwa mpira .\n",
            "P-369\t-0.1104 -0.1371 -0.0766 -0.1093 -0.0723 -0.0992 -0.0910 -0.0660 -0.0961 -0.1289 -0.0549 -0.0441 -0.1013 -0.0615 -0.1023 -0.1569 -0.1296 -0.1038 -0.2389 -0.3644 -0.0916 -0.2692 -0.5950 -0.0928 -1.0457 -0.0992 -0.5276 -0.0983 -0.0503 -0.0603 -0.0721 -0.0987 -0.1576 -0.1119 -0.0173 -0.0927 -0.0960 -0.1024 -0.1105 -0.0658 -0.0889 -0.1608 -0.0564 -0.1029 -0.0671 -0.0986 -0.1148 -0.0416 -0.1395 -0.4791 -0.5589 -0.5483 -0.1009 -0.0551 -0.1031 -0.1558 -0.9655 -0.1858 -0.7626 -0.0365 -0.0468 -0.1006 -0.1118 -0.2016 -0.2358 -0.0997 -0.1507 -0.2825 -0.3825 -1.0510 -1.1455 -0.0959 -0.1164 -0.0598 -0.0982 -0.1092 -0.1212 -0.5907 -0.2402 -0.2082 -0.1723 -0.1472 -0.7577 -0.0818 -0.1078 -0.1319 -0.5799 -0.4906 -0.1081\n",
            "T-393\tGalu wa Dalmation aluma kanthambi kakang'ono pamtengo ali ndi miyendo yakumbuyo .\n",
            "H-393\t-0.4066547751426697\t▁ G a l u ▁ w o m e t a ▁ w a m i s o n k h a n o ▁ a t a k h a l a ▁ n d i ▁ k a m w a n a ▁ p a m t e n g o ▁ w a k e ▁ n d i ▁ m i t u n d u ▁ .\n",
            "D-393\t-0.4066547751426697\tGalu wometa wamisonkhano atakhala ndi kamwana pamtengo wake ndi mitundu .\n",
            "P-393\t-0.1189 -0.1451 -0.0984 -0.0709 -0.0803 -0.1131 -0.0574 -0.3954 -1.7524 -0.2020 -0.1961 -0.0926 -0.1789 -1.3383 -0.2846 -1.0720 -1.1636 -1.3435 -0.5318 -0.0885 -0.1046 -0.0249 -0.0917 -0.0593 -0.5062 -0.1685 -0.1718 -0.9189 -0.1435 -1.9009 -0.0296 -0.1013 -0.1113 -0.0763 -0.1123 -0.8411 -0.1959 -0.0896 -0.2797 -0.2320 -0.1426 -0.1289 -0.6667 -0.1066 -1.3137 -0.1269 -0.1587 -0.9764 -0.1328 -0.7031 -0.7205 -0.0702 -0.0562 -0.0581 -0.0742 -0.0925 -0.3702 -0.1437 -2.7411 -0.6922 -0.1935 -0.6417 -0.0820 -0.1111 -0.0644 -0.5975 -0.5181 -1.8595 -0.2029 -0.1130 -0.0202 -0.1034 -0.2215 -0.7177 -0.0941\n",
            "T-158\tMayi wina amene wavala chovala akudumphira kavalo wabulauni pamwamba pa chinthu chooneka ngati ndege .\n",
            "H-158\t-0.2636336386203766\t▁ M a y i ▁ w i n a ▁ w o v a l a ▁ c h o v a l a ▁ c h o f i i r a ▁ a k u d u m p h i r a ▁ p a b w a l o ▁ l a ▁ m w a m u n a ▁ w o v a l a ▁ c h o y e r a ▁ n d i ▁ c h o y e r a ▁ .\n",
            "D-158\t-0.2636336386203766\tMayi wina wovala chovala chofiira akudumphira pabwalo la mwamuna wovala choyera ndi choyera .\n",
            "P-158\t-0.1260 -0.0817 -0.0902 -0.0478 -0.0927 -0.1293 -0.0786 -0.1129 -0.1425 -0.0985 -0.1266 -1.8343 -0.1837 -0.1252 -0.1034 -0.0805 -0.0988 -0.1060 -0.1589 -0.1236 -0.0821 -0.0434 -0.1120 -0.0748 -0.1180 -0.1093 -0.1105 -0.1191 -0.1753 -2.1243 -0.0987 -0.2154 -0.0789 -0.1390 -0.1568 -1.1681 -0.1350 -0.0916 -0.5309 -0.0637 -0.4101 -0.0387 -0.0581 -0.7198 -0.0670 -0.0984 -0.1589 -0.6342 -0.1295 -1.1019 -0.0290 -0.0749 -0.0521 -0.0567 -0.0761 -0.0291 -0.1353 -0.7495 -0.1950 -0.1227 -0.1225 -0.1122 -0.2397 -0.1004 -0.0825 -0.1288 -1.2930 -0.3093 -0.4591 -0.1016 -0.0863 -0.0794 -0.0957 -0.1092 -0.0983 -1.6935 -0.1358 -0.1815 -0.1829 -0.1013 -0.1938 -0.1009 -0.1336 -0.1062 -0.0914 -1.5359 -0.0764 -0.1872 -0.2602 -0.1388 -0.2372 -0.1202 -0.3287 -1.0843 -0.1124\n",
            "T-404\tBasi yaima mumsewu pomwe bambo wina akuyendetsa njinga ndipo wachiwiri akuyenda mumsewu .\n",
            "H-404\t-0.3386416733264923\t▁ B a s i ▁ w a ▁ i m a ▁ m u m s e w u ▁ p a m e n e ▁ b a m b o ▁ w i n a ▁ a k u y e s a ▁ n d i ▁ n j i n g a ▁ y a c h i k o n i ▁ a k u w e r e n g a ▁ m u m s e w u ▁ .\n",
            "D-404\t-0.3386416733264923\tBasi wa ima mumsewu pamene bambo wina akuyesa ndi njinga yachikoni akuwerenga mumsewu .\n",
            "P-404\t-0.1119 -1.3181 -0.1127 -0.2735 -0.2937 -0.2002 -1.5619 -0.1484 -0.4072 -1.5519 -0.1427 -0.3962 -0.1585 -0.0548 -0.2912 -0.2313 -0.0913 -0.0661 -0.0730 -0.0462 -0.1146 -0.6529 -1.3784 -0.2778 -0.1812 -0.0716 -0.0776 -0.0865 -1.2311 -0.1286 -0.1050 -0.0760 -0.0592 -0.0786 -0.0389 -0.1226 -0.1025 -0.0974 -0.1060 -0.1258 -0.0485 -0.0841 -0.9040 -0.0685 -0.7202 -0.2122 -0.0830 -0.1848 -0.7211 -0.1571 -0.7062 -0.1632 -0.1121 -0.1119 -0.0877 -0.0361 -0.0869 -0.1072 -1.1069 -0.1326 -0.7269 -0.0686 -0.1094 -0.1135 -0.8744 -0.6172 -0.8463 -0.2366 -0.5584 -0.1209 -0.1132 -1.7985 -0.8845 -0.3136 -0.4458 -0.0723 -0.2285 -0.1314 -0.1323 -1.1760 -0.8678 -0.2458 -0.1110 -0.0809 -0.0920 -0.0646 -0.3290 -0.2009 -0.1014\n",
            "T-142\tMunthu akukwera madzi pa bolodi limodzi, atagwira pa chothandizira ndi dzanja limodzi.\n",
            "H-142\t-0.2875780165195465\t▁ M u n t h u ▁ a k u k w e r a ▁ m a d z i ▁ p a b w a l o ▁ n d i ▁ m m m o d z i ▁ a t a g w i r a ▁ p a n j i r a ▁ n d i ▁ z i n g w e ▁ z a ▁ n j i n g a ▁ .\n",
            "D-142\t-0.2875780165195465\tMunthu akukwera madzi pabwalo ndi mmmodzi atagwira panjira ndi zingwe za njinga .\n",
            "P-142\t-0.1234 -0.1646 -0.0431 -0.1123 -0.0592 -0.1005 -0.0792 -0.1393 -0.7816 -0.0506 -0.0988 -0.0866 -0.2598 -0.1329 -0.0897 -0.1083 -0.1388 -0.2742 -0.3294 -0.4379 -0.0278 -0.0992 -0.1894 -0.2059 -0.1147 -0.1012 -0.6170 -0.0827 -0.0915 -0.1512 -0.1293 -1.2920 -0.0752 -0.1007 -0.0818 -0.1430 -0.6490 -0.9859 -0.1304 -0.0744 -0.0373 -0.0889 -0.1134 -0.1649 -1.1933 -0.1014 -1.4093 -0.1226 -0.1415 -0.0811 -0.1197 -0.1195 -1.1919 -0.1486 -0.2809 -0.3682 -0.0933 -0.6187 -0.1034 -0.1637 -1.2550 -0.1000 -0.1075 -0.0792 -0.2290 -0.2276 -0.8233 -1.1013 -0.0848 -0.1530 -0.2188 -0.2998 -0.1499 -0.8051 -0.3775 -0.5563 -0.1455 -0.1869 -0.0891 -0.1270 -0.1691 -0.8691 -0.1001\n",
            "T-343\tamuna awiri aima pamwamba pa thanthwe moyang'anizana ndi gombe lamchenga .\n",
            "H-343\t-0.2817939221858978\t▁ A m u n a ▁ a w i r i ▁ a i m a ▁ p a m w a m b a ▁ p a ▁ m a y a n g ' a n a ▁ n d i ▁ z a m b i r i ▁ a m a c h i n g a ▁ .\n",
            "D-343\t-0.2817939221858978\tAmuna awiri aima pamwamba pa mayang'ana ndi zambiri amachinga .\n",
            "P-343\t-0.1098 -0.0565 -0.1401 -0.0761 -0.1013 -0.0975 -0.1370 -0.1279 -0.0663 -0.1220 -0.0631 -0.1137 -0.2033 -0.0989 -0.8071 -0.0871 -0.1873 -0.1238 -0.0454 -0.1152 -0.3671 -0.1397 -0.0963 -0.1654 -0.1092 -0.1053 -0.1219 -1.6100 -0.1246 -0.1511 -0.7005 -0.9037 -0.2524 -0.3624 -0.1180 -0.1874 -0.0343 -0.0901 -0.1125 -0.1731 -0.0837 -0.1195 -0.1428 -0.1166 -0.0809 -0.5346 -0.2407 -1.6916 -0.9970 -0.1083 -0.0444 -0.0824 -0.2469 -0.6407 -0.1145 -0.1168 -1.8282 -0.0695 -0.5911 -0.3579 -0.0469 -0.2635 -0.8255 -0.0620 -0.1059\n",
            "T-378\tMnyamata wina wothamanga wavala thukuta la teaal ndi malaya amtundu wa Nike ndipo ali ndi racket ya tenisi .\n",
            "H-378\t-0.2577904760837555\t▁ M n y a m a t a ▁ w i n a ▁ w o t h a m a n g a ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m a t u m b a ▁ a n a y i ▁ n d i p o ▁ a l i ▁ n d i ▁ j e k e t e ▁ l a k e ▁ .\n",
            "D-378\t-0.2577904760837555\tMnyamata wina wothamanga wavala malaya abuluu ndi matumba anayi ndipo ali ndi jekete lake .\n",
            "P-378\t-0.1238 -0.0903 -0.0545 -0.0628 -0.1018 -0.2235 -0.1159 -0.0535 -0.1060 -0.1407 -0.0823 -0.1076 -0.0683 -0.1017 -0.1198 -0.0926 -0.8847 -0.2532 -0.3323 -0.0978 -0.2203 -0.1105 -0.1045 -0.0639 -0.1043 -0.1238 -0.0610 -0.2148 -0.0789 -0.1036 -0.0846 -0.1030 -0.1236 -0.3231 -0.1377 -0.3279 -0.1158 -0.1898 -0.0928 -0.1349 -0.1095 -2.3812 -0.0813 -0.0681 -0.1084 -0.0324 -0.1414 -0.0586 -0.1118 -0.1171 -0.1080 -0.0738 -0.1279 -0.2273 -1.3225 -0.8120 -0.1676 -0.0914 -0.1421 -0.1342 -0.4944 -0.8878 -0.1556 -0.0905 -0.1438 -1.6855 -0.0466 -0.0982 -0.3017 -0.0888 -0.0739 -0.1989 -0.6869 -0.1112 -0.0849 -0.1905 -0.0896 -0.0877 -0.0810 -2.4559 -0.2554 -0.0659 -0.0915 -0.0401 -0.4127 -0.1755 -0.2020 -0.1699 -0.5655 -0.4772 -0.2708 -0.6309 -0.1147\n",
            "T-412\tGulu la anthu akuluakulu aimirira m'bafa akuyang'ana pansi mwana wamng'ono akusamba .\n",
            "H-412\t-0.2641686499118805\t▁ G u l u ▁ l a ▁ a n t h u ▁ l a k u l a n k h u l a ▁ l a i m i r i r a ▁ a k u y a n g ' a n a ▁ p a n j i n g a ▁ p a m o d z i ▁ .\n",
            "D-412\t-0.2641686499118805\tGulu la anthu lakulankhula laimirira akuyang'ana panjinga pamodzi .\n",
            "P-412\t-0.1138 -0.0694 -0.0694 -0.0736 -0.0919 -0.1104 -0.1434 -0.1159 -0.0881 -0.1472 -0.0517 -0.0498 -0.1235 -0.0905 -0.1009 -1.2774 -0.1349 -0.2624 -0.1354 -0.1647 -0.3511 -0.1359 -0.0195 -0.0298 -0.0485 -0.0626 -0.1391 -0.1576 -0.6050 -2.0488 -1.0771 -0.0955 -0.2771 -0.3047 -0.0782 -0.0645 -0.1212 -0.1180 -1.4688 -0.2889 -0.0980 -0.1202 -0.1604 -0.0578 -0.0637 -0.0690 -0.1036 -0.0675 -0.1043 -0.0811 -0.1078 -0.1717 -0.2596 -1.0764 -0.1128 -0.0848 -0.0609 -0.0962 -0.1124 -2.0357 -0.1886 -0.1915 -0.1312 -0.6552 -0.1003 -0.0804 -0.1522 -0.6669 -0.1114\n",
            " 69% 9/13 [00:21<00:07,  1.75s/it, wps=1343]T-400\tBambo wandevu wavala chovala chamutu chosokedwa chokhala ndi zithunzi za Spiderman.\n",
            "H-400\t-0.22114606201648712\t▁ B a m b o ▁ w a ▁ n d e v u ▁ w a v a l a ▁ c h o v a l a ▁ c h a ▁ m u n t h u ▁ c h o f i i r i r a ▁ c h o k h a l a ▁ n d i ▁ z i n t h u ▁ z a c h i k a s u ▁ .\n",
            "D-400\t-0.22114606201648712\tBambo wa ndevu wavala chovala cha munthu chofiirira chokhala ndi zinthu zachikasu .\n",
            "P-400\t-0.1212 -0.0950 -0.1095 -0.0809 -0.0820 -0.0788 -0.1405 -0.1427 -0.0994 -0.2866 -0.6622 -0.1088 -0.0486 -0.2084 -0.1126 -0.1154 -0.1817 -0.2146 -0.0960 -0.1149 -0.0757 -0.1104 -0.0974 -0.0264 -0.1119 -0.1292 -0.0241 -0.1096 -0.0719 -0.1176 -0.1033 -0.0173 -0.1115 -0.2582 -0.8195 -0.4938 -0.0802 -0.5021 -0.0681 -0.1460 -0.0895 -0.0957 -0.2079 -0.1090 -0.0672 -0.7624 -0.2602 -0.5826 -0.0673 -1.1928 -0.4011 -0.1128 -0.1659 -0.5059 -0.1132 -0.1194 -0.0180 -0.0164 -0.1137 -0.0466 -0.1199 -0.1023 -0.0787 -0.2380 -0.1150 -0.0772 -0.2825 -0.0654 -0.2941 -0.0882 -0.0263 -0.0691 -0.1350 -0.0147 -0.1499 -3.3121 -0.1914 -0.0840 -0.4400 -0.1016 -0.2770 -0.1138 -0.3083 -0.3871 -0.1047\n",
            "T-23\tWosewera mpira wa basketball akulendewera pamphepete pomwe mpira uli mudengu\n",
            "H-23\t-0.3178834319114685\t▁ W o s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ n d i ▁ m p i r a ▁ a t a z u n g u l i r i d w a ▁ p o m w e ▁ m p i r a ▁ u l i ▁ n d i ▁ m p i r a .\n",
            "D-23\t-0.3178834319114685\tWosewera mpira wa basketball ndi mpira atazunguliridwa pomwe mpira uli ndi mpira.\n",
            "P-23\t-0.1332 -0.1493 -0.0889 -0.0369 -0.0730 -0.0776 -0.0910 -0.0747 -0.1180 -0.1409 -0.0676 -0.0482 -0.0869 -0.0695 -0.1065 -0.1664 -0.0533 -0.1103 -0.2846 -0.1366 -0.0802 -0.0197 -0.0511 -0.1586 -0.0337 -0.0636 -0.0661 -0.0328 -0.1555 -0.2285 -3.0220 -0.0535 -0.1131 -0.1990 -0.2811 -0.8400 -0.0745 -0.1415 -0.7428 -0.1183 -0.7866 -0.2847 -0.3029 -1.2794 -0.4738 -0.1464 -0.1000 -0.0524 -0.1463 -0.1039 -0.1579 -0.1655 -0.1314 -0.8819 -0.0821 -0.1314 -0.9228 -0.1326 -0.0390 -1.2053 -0.0805 -0.1015 -0.7580 -0.4583 -0.0661 -0.5937 -0.7149 -0.4095 -0.6352 -0.0469 -0.1658 -0.1222 -2.4342 -0.1666 -0.0988 -0.1379 -0.1844 -1.3005 -0.0684 -0.3242 -0.2538 -1.0501 -0.0975\n",
            "T-419\tGulu la anthu ovala masuti laima mozungulira bambo wina wovala malaya apinki amene amaphunzitsa .\n",
            "H-419\t-0.25569483637809753\t▁ G u l u ▁ l a ▁ a n t h u ▁ o v a l a ▁ m a s u t i ▁ a ▁ i m a ▁ m o z u n g u l i r a ▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a k u n y a m u l a ▁ m a p i k i s a n o .\n",
            "D-419\t-0.25569483637809753\tGulu la anthu ovala masuti a ima mozungulira bambo wina wovala malaya apinki akunyamula mapikisano.\n",
            "P-419\t-0.1169 -0.0659 -0.0932 -0.0638 -0.0907 -0.1202 -0.0804 -0.1129 -0.1085 -0.1088 -0.0531 -0.0961 -0.1385 -0.0822 -0.1174 -0.1149 -0.0301 -0.1142 -0.0706 -0.1202 -0.1095 -0.0697 -0.2897 -0.0872 -0.0828 -0.0348 -0.0600 -0.1110 -0.1318 -1.8088 -1.2178 -0.0496 -0.1387 -0.0964 -0.3466 -0.5668 -0.8074 -0.0642 -0.0610 -0.0585 -0.0782 -0.0333 -0.0680 -0.0816 -0.1107 -0.1439 -1.9120 -0.3036 -0.3172 -0.0186 -0.0547 -0.1148 -0.1359 -0.0839 -0.0704 -0.1165 -0.1172 -1.6156 -0.1048 -0.0260 -0.1073 -0.0763 -0.1255 -0.0981 -0.0882 -0.0946 -0.0628 -0.1151 -0.0494 -0.0901 -0.1097 -0.2212 -0.4683 -0.1021 -0.0325 -0.0189 -0.0972 -0.1993 -0.4520 -1.5326 -0.1434 -0.8045 -0.1498 -0.0937 -0.0900 -0.2436 -0.2167 -0.2365 -0.1699 -0.5786 -0.2396 -1.3022 -0.2855 -0.6648 -0.2299 -0.1120 -0.2471 -0.1093 -0.1830 -1.8886 -0.0979\n",
            "T-367\tMunthu watsitsi lofiira ndi malaya akuda waima panja, akulankhula ndi manja ndi manja .\n",
            "H-367\t-0.16390985250473022\t▁ M u n t h u ▁ w a t s i t s i ▁ l o f i i r a ▁ n d i ▁ m a l a y a ▁ a k u d a ▁ w a i m a ▁ p a n j a ▁ a k u l a n k h u l a ▁ n d i ▁ m a n j a ▁ .\n",
            "D-367\t-0.16390985250473022\tMunthu watsitsi lofiira ndi malaya akuda waima panja akulankhula ndi manja .\n",
            "P-367\t-0.1188 -0.1007 -0.0761 -0.0745 -0.0565 -0.1186 -0.0768 -0.1315 -0.0433 -0.2191 -0.2817 -0.0510 -0.0961 -0.0605 -0.0892 -0.1089 -0.0871 -0.1884 -0.1259 -0.0679 -0.1152 -0.2996 -0.0844 -0.3405 -0.1760 -0.0870 -0.0891 -0.1127 -0.0935 -0.0959 -0.1263 -0.0688 -0.1165 -0.0494 -0.1015 -0.1129 -0.6159 -0.0420 -0.1084 -0.0486 -0.0950 -0.1608 -0.4389 -0.1178 -0.3174 -0.0738 -0.0815 -0.0940 -0.0581 -0.1227 -0.1249 -0.0181 -0.1330 -0.2494 -0.4942 -0.1125 -0.1035 -0.0838 -0.3537 -0.0890 -1.6976 -0.0649 -0.0460 -0.0456 -0.1012 -0.1695 -0.0738 -0.1091 -0.1106 -0.0843 -0.0586 -0.1078 -0.1060 -0.0151 -0.1262 -0.2399 -1.1390 -0.1110\n",
            "T-172\tAtsikana awiri achichepere ovala madiresi a denim akusewera pafupi ndi mpando wakumanja .\n",
            "H-172\t-0.23993678390979767\t▁ A t s i k a n a ▁ a w i r i ▁ a c h i c h e p e r e ▁ o v a l a ▁ m a l a y a ▁ o f i i r a ▁ a k u s e w e r a ▁ p a f u p i ▁ n d i ▁ m p a n d o ▁ w a k u m a n j a ▁ .\n",
            "D-172\t-0.23993678390979767\tAtsikana awiri achichepere ovala malaya ofiira akusewera pafupi ndi mpando wakumanja .\n",
            "P-172\t-0.1171 -0.0442 -0.0789 -0.0738 -0.1190 -0.0424 -0.1377 -0.0831 -0.1070 -0.1330 -0.1276 -0.0903 -0.1168 -0.0651 -0.0975 -0.1623 -0.1268 -1.1752 -0.0904 -0.1172 -0.7103 -0.0877 -0.0460 -0.0257 -0.0580 -0.1339 -0.1125 -0.1149 -0.1111 -0.0676 -0.1146 -0.0811 -0.1083 -0.1241 -0.0724 -0.1095 -1.4627 -0.1198 -0.0993 -0.0857 -0.1191 -0.5568 -1.6008 -0.2220 -0.2093 -0.0973 -0.4177 -0.1634 -0.3161 -0.3660 -0.0898 -0.4276 -0.0743 -0.3448 -0.1513 -0.0663 -0.1128 -0.1062 -0.6156 -0.1417 -1.8753 -0.0916 -0.1200 -0.1494 -0.1021 -0.0708 -0.0643 -0.0964 -0.0743 -0.1355 -1.1007 -0.9100 -0.1117 -0.0461 -0.1285 -0.1026 -0.1694 -0.0959 -0.4930 -0.2248 -0.4282 -0.1741 -0.2360 -0.0625 -0.1307 -0.4023 -0.2720 -0.0968\n",
            "T-102\tGalu woyera watsitsi lalitali ali m'dera lomwe lili ndi masamba abulauni akugwa .\n",
            "H-102\t-0.21803706884384155\t▁ G a l u ▁ w o y e r a ▁ w a t s i t s i ▁ l a l i t a l i ▁ l a l i t a l i ▁ l o m w e ▁ l i l i ▁ n d i ▁ m a s a m b a ▁ a k u g w a ▁ .\n",
            "D-102\t-0.21803706884384155\tGalu woyera watsitsi lalitali lalitali lomwe lili ndi masamba akugwa .\n",
            "P-102\t-0.1173 -0.0788 -0.0998 -0.0655 -0.0973 -0.1707 -0.0675 -0.0644 -0.0331 -0.0658 -0.0721 -0.0971 -0.1524 -0.1286 -0.5573 -0.8712 -0.0503 -0.0927 -0.0930 -0.0629 -0.1181 -0.0927 -0.1146 -0.1212 -0.0396 -0.0939 -0.0138 -0.1013 -0.0251 -0.0909 -0.1585 -0.8852 -0.1154 -0.2318 -0.1140 -1.0735 -0.0771 -0.0456 -0.0883 -0.1567 -0.2923 -2.2086 -0.1068 -0.4068 -0.0923 -0.0801 -0.1414 -0.1260 -0.1054 -0.1206 -0.1160 -1.0247 -0.2460 -0.1028 -0.1093 -0.1252 -0.1243 -0.0930 -0.1226 -0.0398 -0.1017 -0.1046 -0.1366 -0.1196 -0.6166 -0.1344 -0.4922 -0.8170 -0.0903 -0.2478 -0.1632 -0.0954\n",
            "T-237\tGalu wakuda akuyandikira kamera ndi miyendo yake yakumbuyo ndi makutu ake kutsogolo .\n",
            "H-237\t-0.2723201513290405\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ w o y e r a ▁ a k u y e n d a ▁ k a m e r a ▁ y a k u m b u y o ▁ n d i ▁ m a f u n d e ▁ a k u t u l u k a ▁ .\n",
            "D-237\t-0.2723201513290405\tGalu wakuda ndi woyera akuyenda kamera yakumbuyo ndi mafunde akutuluka .\n",
            "P-237\t-0.1186 -0.0671 -0.1227 -0.0687 -0.0819 -0.1194 -0.0308 -0.1551 -0.2725 -0.0783 -0.1647 -0.2432 -0.1437 -0.7735 -0.0761 -0.1204 -0.0892 -0.5381 -0.7040 -0.0331 -0.2639 -0.1095 -0.1051 -0.1402 -0.2184 -0.2463 -0.1623 -0.2052 -0.6704 -0.1457 -0.0606 -0.9723 -0.0994 -2.0821 -0.2426 -0.0586 -0.0659 -0.1129 -0.1048 -0.1435 -0.0928 -0.1165 -0.4260 -0.8346 -0.1921 -1.1434 -0.0674 -0.0325 -0.0563 -0.1543 -0.1315 -0.0606 -0.1243 -0.4532 -0.1779 -0.1130 -2.2285 -0.0524 -0.1247 -0.0424 -0.1430 -0.1143 -0.1335 -0.1985 -0.2258 -0.4463 -0.0995 -0.0614 -0.0718 -0.1285 -0.0949 -0.1304 -1.3656 -0.1035\n",
            "T-226\tAnthu angapo atakhala pamipando yopindika pafupi ndi mapangidwe a geological.\n",
            "H-226\t-0.2961248457431793\t▁ A n t h u ▁ a n g a p o ▁ a t a k h a l a ▁ p a m i p a n d o ▁ y o p i n d i k a ▁ p a f u p i ▁ n d i ▁ m a p i r i ▁ a ▁ d z u w a ▁ l o d y e r a .\n",
            "D-226\t-0.2961248457431793\tAnthu angapo atakhala pamipando yopindika pafupi ndi mapiri a dzuwa lodyera.\n",
            "P-226\t-0.1166 -0.0697 -0.1125 -0.0817 -0.0896 -0.0720 -0.1090 -0.2227 -0.1149 -0.0607 -0.0997 -0.0059 -0.0589 -0.1489 -0.0748 -0.0535 -0.1210 -0.7238 -0.0221 -0.0980 -0.0430 -0.1045 -0.0976 -0.0230 -0.1127 -0.9463 -0.0553 -1.4024 -0.1106 -0.0838 -0.0200 -0.1055 -0.1356 -0.1053 -0.0569 -0.2278 -0.5248 -0.1075 -0.1220 -0.4538 -0.0957 -0.0889 -0.2132 -0.6986 -0.1250 -0.1215 -0.1087 -0.0321 -0.1009 -0.1048 -0.0488 -0.0925 -0.1051 -0.0734 -0.0907 -0.1112 -3.2141 -0.4401 -0.5456 -0.0853 -0.1299 -0.5835 -1.4800 -0.9849 -0.3752 -0.4597 -0.8249 -0.2656 -0.3267 -0.1107 -0.0949 -1.6139 -0.4471 -0.1584 -0.2937 -0.0703 -0.9767 -0.1112\n",
            "T-240\tMwana wovala chijasi chofiyira ndi chipewa chanyamula chipale chofewa chachikulu .\n",
            "H-240\t-0.304788738489151\t▁ M w a n a ▁ w o v a l a ▁ j e k e t e ▁ l a c h i f u p i ▁ n d i ▁ j e k e t e ▁ l a ▁ c h i p a l e ▁ c h o f e w a ▁ a l i ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-240\t-0.304788738489151\tMwana wovala jekete lachifupi ndi jekete la chipale chofewa ali pa chipale chofewa .\n",
            "P-240\t-0.1313 -0.0670 -0.1264 -0.1271 -0.0829 -0.1028 -0.1779 -0.0732 -0.1008 -0.0605 -0.1164 -0.0725 -0.1070 -0.1164 -1.0051 -0.1885 -0.5982 -0.1047 -0.0485 -0.1759 -0.1204 -0.2977 -0.1520 -0.7842 -0.0977 -0.0822 -0.7112 -1.3450 -1.3732 -0.0942 -0.1741 -0.9943 -0.0978 -0.1226 -0.0841 -0.9993 -0.9940 -0.5573 -0.0602 -0.0538 -0.0952 -0.1048 -0.2001 -0.1159 -0.5215 -1.2170 -0.0912 -0.1261 -2.0383 -0.1109 -1.0660 -0.3817 -0.0962 -0.0563 -0.0916 -0.8670 -0.1000 -0.0766 -0.1169 -0.1130 -0.1761 -0.8657 -0.2580 -0.1428 -0.0722 -0.0514 -0.1354 -0.7526 -0.0307 -0.0635 -0.1064 -1.0280 -0.1150 -0.0592 -0.0961 -0.0657 -0.0066 -0.0960 -0.2278 -0.0856 -0.0857 -0.1177 -0.1177 -0.3911 -0.5991 -0.1010\n",
            "T-252\tmunthu akuyika pa zenera kunja kwa nyumba yozunguliridwa ndi malalanje ochenjeza .\n",
            "H-252\t-0.22347292304039001\t▁ M u n t h u ▁ a k u y e n d a ▁ p a ▁ z e n e r a ▁ k u n j a ▁ k w a ▁ n y u m b a ▁ y o z u n g u l i r i d w a ▁ n d i ▁ m a l o ▁ o c h e z a ▁ .\n",
            "D-252\t-0.22347292304039001\tMunthu akuyenda pa zenera kunja kwa nyumba yozunguliridwa ndi malo ocheza .\n",
            "P-252\t-0.1274 -0.1285 -0.0474 -0.0927 -0.0667 -0.0788 -0.0871 -0.1371 -0.1245 -0.2047 -0.0904 -0.6423 -0.5845 -0.1609 -0.2283 -0.1114 -0.1231 -0.3853 -0.1473 -0.9385 -0.0730 -0.1275 -0.1269 -0.3344 -0.0626 -0.0909 -0.1515 -0.1278 -0.0997 -0.6094 -0.0771 -0.1033 -0.1549 -0.0873 -0.1784 -0.1144 -0.1156 -0.7919 -0.1472 -0.0441 -0.1018 -0.0869 -0.0998 -0.1242 -0.9513 -0.0885 -0.0592 -0.0579 -0.1029 -0.0199 -0.1719 -0.0485 -0.0985 -0.0985 -1.0312 -0.0527 -0.0495 -0.1126 -0.1342 -0.5929 -0.0808 -0.1227 -0.1213 -0.0544 -0.1259 -0.1551 -1.1300 -0.1104 -0.1293 -0.3642 -0.0965 -0.1298 -1.2506 -0.1335 -0.1887 -0.7073 -0.0991\n",
            "T-119\tMwamuna wovala chijasi chofiira amasainira mapepala kwa mwamuna wina wovala malaya abuluu .\n",
            "H-119\t-0.22906829416751862\t▁ M w a m u n a ▁ w o v a l a ▁ c h i j a s i ▁ c h o f i y i r a ▁ a m a s a m b i r a ▁ p a m i y e n d o ▁ k w a ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ .\n",
            "D-119\t-0.22906829416751862\tMwamuna wovala chijasi chofiyira amasambira pamiyendo kwa mwamuna wina wovala malaya abuluu .\n",
            "P-119\t-0.1269 -0.0543 -0.0464 -0.1143 -0.0892 -0.1075 -0.0967 -0.1018 -0.1416 -0.0979 -0.1018 -0.0324 -0.1309 -0.0864 -0.1103 -0.1003 -1.4048 -0.1405 -0.1001 -0.6344 -0.0997 -0.0418 -0.0483 -0.1274 -0.6474 -0.1398 -0.1801 -0.0410 -0.1133 -1.0872 -0.0878 -0.0651 -0.1076 -0.1733 -0.0804 -0.1757 -0.1154 -0.4273 -0.1209 -0.9452 -0.5618 -0.2868 -0.0696 -0.1050 -0.1205 -0.1734 -0.1398 -2.0662 -0.6354 -0.2675 -0.1838 -0.3883 -0.1726 -0.2874 -0.0986 -1.1712 -0.1864 -0.1157 -0.3883 -0.1030 -0.2125 -0.0883 -0.1220 -0.1137 -0.0956 -0.1185 -0.1406 -0.0971 -0.2182 -0.0620 -0.1069 -0.1417 -1.3070 -0.2390 -0.0406 -0.0944 -0.0795 -0.1217 -0.1099 -0.0686 -0.1048 -0.0782 -0.1124 -0.0807 -0.0994 -0.1482 -0.3204 -0.0089 -0.1582 -0.0843 -0.0853 -0.0422 -0.5653 -0.0214 -0.1094\n",
            "T-37\tAnthu atatu akuchita masewera olimbitsa thupi a ballet atavala zovala zapamwamba.\n",
            "H-37\t-0.1982080489397049\t▁ A n t h u ▁ a t a t u ▁ a k u c h i t a ▁ m a s e w e r a ▁ o l i m b i t s a ▁ t h u p i ▁ y a k a l e ▁ a t a v a l a ▁ z o v a l a ▁ z o w a l a ▁ p a m w a m b a ▁ .\n",
            "D-37\t-0.1982080489397049\tAnthu atatu akuchita masewera olimbitsa thupi yakale atavala zovala zowala pamwamba .\n",
            "P-37\t-0.1224 -0.0699 -0.0767 -0.0427 -0.0918 -0.0634 -0.0982 -0.1189 -0.0238 -0.0949 -0.0225 -0.0522 -0.1437 -0.1847 -0.0953 -0.0778 -1.8119 -0.0887 -0.0720 -0.1220 -0.0857 -0.1042 -0.0650 -0.1064 -0.0314 -0.0377 -0.1557 -0.0909 -0.0854 -0.1073 -0.1295 -0.0592 -0.3067 -0.0897 -0.0767 -0.0189 -0.0900 -0.0966 -0.0400 -0.0854 -0.0933 -0.0105 -0.1237 -0.0490 -0.0298 -0.0585 -0.1961 -0.4251 -0.1426 -1.0164 -0.5562 -0.1070 -0.0890 -0.1838 -0.5726 -0.0231 -0.1172 -0.1379 -0.1029 -0.0749 -0.1034 -0.0938 -0.1745 -0.0547 -1.4622 -0.1060 -0.0989 -0.1106 -0.1010 -0.0295 -0.8378 -0.9332 -0.1768 -0.1186 -0.1022 -0.1661 -1.2759 -0.1137 -0.1088 -0.0399 -0.0934 -0.1300 -0.0785 -0.0852 -0.3215 -0.7734 -0.1087\n",
            "T-200\tMnyamata wovala kabudula wofiira akudumphira mumtsinje pamene ana ena akusambira .\n",
            "H-200\t-0.22706981003284454\t▁ M n y a m a t a ▁ w o v a l a ▁ k a b u d u l a ▁ w o f i i r a ▁ a k u d u m p h i r a ▁ m u m s e w u ▁ p a m e n e ▁ a k u s a m b i r a ▁ .\n",
            "D-200\t-0.22706981003284454\tMnyamata wovala kabudula wofiira akudumphira mumsewu pamene akusambira .\n",
            "P-200\t-0.1323 -0.0709 -0.0617 -0.0603 -0.0961 -0.0793 -0.1083 -0.0579 -0.0947 -0.1276 -0.1212 -0.1114 -0.0352 -0.1200 -0.0790 -0.1052 -0.1058 -0.4946 -1.4079 -0.1588 -0.0718 -0.0220 -0.0753 -0.0515 -0.3546 -0.1172 -0.0483 -0.1525 -1.8784 -0.1006 -0.1464 -0.0830 -0.1719 -0.1749 -0.9124 -0.0552 -0.0842 -0.0514 -0.0355 -0.2057 -0.1541 -0.0784 -0.1422 -0.0710 -0.0866 -0.1187 -0.3786 -1.2549 -0.4287 -0.1989 -0.4420 -0.0804 -0.1023 -0.1527 -0.1088 -0.1375 -0.0932 -0.0922 -0.1048 -0.0950 -0.1117 -0.0800 -1.1474 -0.0882 -0.0537 -0.1385 -1.3574 -0.1221 -0.0836 -0.1051 -0.0835 -0.3030 -0.2810 -0.1057\n",
            "T-327\tMtsikana wovala malaya amaluwa ndi jinzi waima pagombe lamiyala akuyang'ana kumadzi\n",
            "H-327\t-0.2111622542142868\t▁ M t s i k a n a ▁ w o v a l a ▁ m a l a y a ▁ a m a l u w a ▁ n d i ▁ j i n z i ▁ w a i m a ▁ p a m p h e p e t e ▁ a k u y a n g ' a n a ▁ k u m a s o ▁ .\n",
            "D-327\t-0.2111622542142868\tMtsikana wovala malaya amaluwa ndi jinzi waima pamphepete akuyang'ana kumaso .\n",
            "P-327\t-0.1207 -0.4563 -0.0745 -0.2046 -0.0878 -0.0599 -0.1243 -0.0918 -0.1189 -0.1285 -0.1341 -0.1122 -0.1344 -0.1260 -0.0799 -0.1208 -0.1056 -0.0545 -0.1580 -0.0500 -0.1054 -0.0834 -0.0997 -0.1105 -0.1886 -1.0288 -0.3029 -0.0751 -0.1721 -0.0408 -0.0873 -0.1513 -0.0931 -0.0695 -0.0972 -0.0882 -0.1405 -1.1473 -0.0631 -0.0827 -0.0709 -0.1045 -0.1725 -0.1227 -0.1310 -0.0357 -0.0984 -0.0837 -0.0100 -0.1172 -0.3488 -2.1825 -0.3489 -0.0351 -0.1151 -0.1402 -0.2175 -0.1497 -0.0912 -0.8690 -0.1419 -0.1060 -0.0729 -0.1033 -0.1149 -0.1012 -0.1053 -0.0985 -0.1044 -0.1152 -0.1023 -0.3060 -0.1728 -0.0806 -0.1259 -1.7254 -0.5296 -0.2339 -0.2222 -0.1158\n",
            "T-168\tMtsikana wina akudumpha m'manja mwa munthu wina yemwe ali m'dziwe lomwe lili pafupi ndi nyanja .\n",
            "H-168\t-0.19384604692459106\t▁ M t s i k a n a ▁ w i n a ▁ a k u d u m p h a ▁ m ' m a n j a ▁ m w a m u n a ▁ y e m w e ▁ a l i ▁ m ' d z i w e ▁ l o m w e ▁ l i l i ▁ p a f u p i ▁ n d i ▁ n y a n j a ▁ .\n",
            "D-168\t-0.19384604692459106\tMtsikana wina akudumpha m'manja mwamuna yemwe ali m'dziwe lomwe lili pafupi ndi nyanja .\n",
            "P-168\t-0.1328 -0.0831 -0.1207 -0.0594 -0.1020 -0.0583 -0.1305 -0.0922 -0.0933 -0.1245 -2.0407 -0.1098 -0.1149 -0.1054 -0.1176 -0.1473 -0.1182 -0.0843 -0.0466 -0.0657 -0.0457 -0.0390 -0.1017 -0.0882 -0.1582 -0.1740 -0.2346 -0.0819 -0.1702 -0.2496 -0.0688 -0.0919 -0.1271 -0.0616 -0.3795 -0.0921 -1.5188 -0.1631 -0.2854 -0.1195 -0.1147 -1.4796 -0.0406 -0.1273 -0.0453 -0.1029 -0.0942 -0.1324 -0.0519 -0.0959 -0.1020 -1.3613 -0.6048 -0.3675 -0.1175 -0.1058 -0.1624 -0.0388 -0.1385 -0.0471 -0.0850 -0.0954 -0.0839 -0.1191 -0.0987 -0.0971 -0.0796 -0.1450 -0.1024 -0.1341 -0.1374 -0.1215 -0.0296 -0.1235 -0.0930 -0.1223 -0.1313 -0.0955 -0.1440 -0.1052 -0.0755 -0.1852 -0.0331 -0.0992 -0.4191 -0.0191 -0.1652 -0.5993 -0.0781 -0.0999\n",
            "T-290\tAzimayi angapo amitundu ya pastel amaima pamzere, wina atanyamula mwana pamapewa ake.\n",
            "H-290\t-0.37683191895484924\t▁ M a y i ▁ a n g a p o ▁ a n g a p o ▁ a ▁ m i t u n d u ▁ y a ▁ k a s e w e r a ▁ p a m z e r e ▁ w i n a ▁ a t a n y a m u l a ▁ m a p e p a l a ▁ p a m w a m b a ▁ p a k e ▁ .\n",
            "D-290\t-0.37683191895484924\tMayi angapo angapo a mitundu ya kasewera pamzere wina atanyamula mapepala pamwamba pake .\n",
            "P-290\t-0.1175 -0.1539 -0.3790 -1.0040 -0.1186 -0.0880 -0.0985 -1.2965 -1.4294 -0.0861 -0.2562 -0.0977 -0.0874 -0.0976 -0.5095 -1.1644 -0.0927 -0.0400 -0.0800 -0.0872 -0.0644 -1.8295 -0.4762 -0.4995 -1.1061 -0.1407 -0.1390 -0.0331 -0.0476 -0.1747 -0.0257 -0.4024 -0.4746 -2.1685 -0.4031 -0.9918 -0.7706 -0.9563 -0.1691 -0.0418 -0.0704 -0.1473 -0.1408 -0.1408 -0.4073 -0.3873 -0.0626 -0.0495 -0.0486 -0.2160 -1.9929 -0.2122 -0.0617 -0.0848 -0.1202 -0.2916 -0.3007 -0.0951 -0.8938 -0.0303 -0.1469 -0.0706 -0.1002 -0.0552 -0.1022 -0.1135 -0.6543 -0.9884 -1.1154 -0.1923 -0.9954 -0.0996 -0.0820 -0.0716 -0.1243 -0.8427 -0.2736 -0.2796 -0.8041 -0.0983 -0.3539 -0.0807 -0.1253 -0.1473 -0.0539 -0.2200 -1.2786 -0.0337 -0.4092 -0.3197 -0.1065\n",
            "T-58\tWoyenda panjinga atavala chisoti chakuda ndi jekete yabuluu amalumphira pa mulu wa m'munda .\n",
            "H-58\t-0.23341764509677887\t▁ W o y e n d a ▁ p a n j i n g a ▁ a t a v a l a ▁ c h i s o t i ▁ c h a ▁ b u l u u ▁ n d i ▁ j e k e t e ▁ y a ▁ b u l u u ▁ p a m u n d a ▁ w a m n g ' o n o ▁ .\n",
            "D-58\t-0.23341764509677887\tWoyenda panjinga atavala chisoti cha buluu ndi jekete ya buluu pamunda wamng'ono .\n",
            "P-58\t-0.1218 -0.2264 -0.1230 -0.0618 -0.0953 -0.0715 -0.0438 -0.1100 -0.1656 -0.0283 -0.1418 -0.0959 -0.2297 -0.0781 -0.0608 -0.0539 -0.0689 -0.1509 -0.1839 -0.0179 -0.1169 -0.0169 -0.1099 -0.0929 -0.1076 -0.0994 -0.1094 -0.1010 -0.1155 -0.0331 -0.1920 -0.0180 -0.0957 -0.1527 -0.0166 -0.0892 -0.0961 -1.2359 -0.7664 -0.0623 -0.1506 -0.1193 -0.0427 -0.1217 -1.2594 -0.1296 -0.1241 -0.1104 -1.3589 -0.3162 -0.0365 -0.0658 -0.0419 -0.1558 -0.1095 -0.1428 -0.1406 -1.0804 -0.2707 -0.2998 -0.0619 -0.1642 -0.0562 -0.1472 -0.6722 -0.1329 -0.0873 -1.5328 -0.1768 -0.5709 -0.1234 -0.1133 -0.5857 -0.2493 -0.5457 -0.7794 -0.0923 -0.1247 -0.1226 -0.1397 -0.0993 -0.2548 -0.8438 -0.0976\n",
            "T-191\tGalu wokhala ndi malaya abulauni ndi oyera amathamanga m'munda wa udzu wobiriwira kwambiri .\n",
            "H-191\t-0.22040361166000366\t▁ G a l u ▁ w o k h a l a ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ w o y e r a ▁ a m a t h a m a n g a ▁ m ' m u n d a ▁ w o y i m b i r a ▁ k w a m b i r i ▁ .\n",
            "D-191\t-0.22040361166000366\tGalu wokhala ndi malaya oyera ndi woyera amathamanga m'munda woyimbira kwambiri .\n",
            "P-191\t-0.1188 -0.5583 -0.1260 -0.0628 -0.0790 -0.1066 -0.0324 -0.0678 -0.0950 -0.0952 -0.1204 -0.0561 -0.1035 -0.1212 -0.0551 -0.1038 -0.0951 -0.0725 -0.1176 -0.1024 -0.2351 -0.1077 -0.0366 -0.1008 -0.1028 -1.1023 -0.3753 -0.0773 -0.1214 -0.0979 -0.1670 -0.2466 -0.1029 -0.0918 -0.1298 -0.2882 -0.0881 -0.0212 -0.1091 -0.1041 -0.1049 -0.1714 -0.1876 -1.6045 -0.1412 -0.1945 -0.2458 -0.0971 -0.2809 -0.1112 -0.0925 -0.0633 -0.0832 -0.1004 -0.6991 -1.1132 -0.8837 -0.2391 -0.1422 -0.0306 -0.0975 -0.1087 -0.1177 -0.9598 -0.3324 -0.4872 -0.1473 -0.1502 -0.0762 -0.2621 -0.1091 -0.1672 -0.7195 -0.5092 -0.1141 -0.1579 -0.0517 -0.0730 -0.0722 -0.0843 -0.3255 -0.4890 -0.0997\n",
            "T-51\tGalu wakuda ndi wakhungu akusewera ndi chidole ndikugudubuzika paudzu .\n",
            "H-51\t-0.26644209027290344\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ w a b u l a u n i ▁ a k u s e w e r a ▁ n d i ▁ c h i d o l e ▁ k u t u l u t s a ▁ p a u d z i ▁ .\n",
            "D-51\t-0.26644209027290344\tGalu wakuda ndi wabulauni akusewera ndi chidole kutulutsa paudzi .\n",
            "P-51\t-0.1200 -0.1408 -0.1184 -0.0712 -0.0711 -0.1153 -0.0642 -0.1207 -0.1389 -0.0842 -0.1582 -0.1046 -0.1545 -0.0574 -0.0835 -0.1129 -0.1002 -0.0128 -0.1341 -1.2550 -0.1095 -0.0733 -0.2765 -0.0553 -0.0969 -0.0737 -0.1298 -0.0832 -0.0522 -0.1235 -0.5000 -0.0917 -0.0713 -0.0791 -0.0742 -0.1310 -0.1037 -0.1134 -0.1449 -0.1494 -0.1383 -0.4341 -0.0919 -0.0973 -0.8989 -0.0806 -0.0516 -0.0474 -0.1078 -2.5839 -0.0836 -1.3980 -0.3262 -0.0490 -0.1309 -0.4964 -0.3861 -0.0985 -0.1243 -0.8061 -0.1531 -0.9867 -0.4635 -0.0572 -1.1054 -0.5256 -0.5364 -0.1087\n",
            "T-421\tMkazi wanyamula mwana pamene mwamuna akumuyang'ana ngati mwamuna wina atanyamula mwana akuyang'ana .\n",
            "H-421\t-0.21756476163864136\t▁ M k a z i ▁ w a ▁ n y a m u l a ▁ p a m e n e ▁ m w a m u n a ▁ a k u m e n y a n a ▁ n g a t i ▁ m w a m u n a ▁ w i n a ▁ a t a n y a m u l a ▁ m w a n a ▁ a k u y a n g ' a n a ▁ .\n",
            "D-421\t-0.21756476163864136\tMkazi wa nyamula pamene mwamuna akumenyana ngati mwamuna wina atanyamula mwana akuyang'ana .\n",
            "P-421\t-0.1167 -0.0495 -0.4230 -0.1026 -0.0178 -0.0782 -0.1460 -0.0646 -0.1750 -0.9122 -0.4196 -0.0409 -0.0981 -0.0716 -0.5492 -0.0650 -0.1202 -0.1214 -2.1000 -0.1537 -0.1510 -0.4393 -0.0641 -0.0630 -0.0994 -0.7251 -0.0375 -0.0923 -0.0965 -0.0714 -0.0707 -0.0804 -0.1439 -0.6406 -0.0865 -0.0837 -0.2615 -0.9312 -0.1154 -0.2598 -0.1102 -0.1455 -0.2109 -0.1647 -1.2037 -1.0219 -0.1267 -0.1811 -0.0996 -0.1148 -0.1920 -0.9007 -0.1012 -0.0791 -0.1335 -0.1053 -0.0917 -0.1604 -0.0949 -0.0851 -0.1089 -0.1123 -0.1346 -0.2126 -0.0305 -0.1029 -0.0683 -0.0246 -0.1076 -0.0809 -0.1377 -0.0647 -0.1064 -0.1255 -0.5467 -0.1108 -0.1027 -0.1039 -0.1080 -0.2053 -0.5438 -0.2769 -0.1197 -0.1359 -0.1019 -0.0520 -0.0789 -0.1073 -0.1134 -0.0493 -0.1133 -0.1776 -0.2287 -0.0959\n",
            "T-426\tKayaker atanyamula nkhafi, akukweza manja ake onse m'mwamba, pamene mafunde akuwomba mozungulira.\n",
            "H-426\t-0.3023321330547333\t▁ K a g a l u ▁ k a k a n y a m u l a ▁ k a m p i r a ▁ a k u k w e r a ▁ n j i n g a ▁ y a m o t o ▁ p a m e n e ▁ m a f u n d e ▁ a k u o m b a ▁ m o z u n g u l i r a ▁ .\n",
            "D-426\t-0.3023321330547333\tKagalu kakanyamula kampira akukwera njinga yamoto pamene mafunde akuomba mozungulira .\n",
            "P-426\t-0.1261 -0.2548 -0.2222 -4.1439 -0.1452 -0.0480 -0.2035 -0.0932 -0.8000 -0.1267 -0.8484 -0.5072 -0.0642 -0.6186 -0.1193 -0.1610 -0.0513 -0.0794 -0.1040 -0.1165 -0.7458 -0.1347 -0.5636 -0.5585 -0.2294 -0.1187 -0.1581 -0.1803 -0.1259 -0.0927 -0.0824 -0.7335 -0.0498 -0.0711 -0.1007 -0.0955 -0.1199 -1.0339 -0.1435 -0.1435 -0.1537 -0.0440 -0.0857 -0.1109 -1.2957 -0.3797 -0.3086 -0.3135 -0.3914 -0.1946 -0.1470 -0.1610 -0.1287 -0.3636 -0.0659 -0.0735 -0.1389 -0.0959 -0.0490 -0.3128 -0.0637 -0.0529 -0.0345 -0.0810 -0.1140 -0.1469 -0.0854 -0.1194 -0.1352 -2.1872 -1.0464 -0.4383 -0.1052 -0.1763 -0.3671 -0.1868 -0.0671 -0.0409 -0.0727 -0.0296 -0.0441 -0.0775 -0.0773 -0.0736 -0.0992 -0.8694 -0.5781 -0.1061\n",
            "T-64\tGalu wabulauni akuyang'ana hatchi yakuda yomwe ikulowetsa mutu wake kumpanda .\n",
            "H-64\t-0.2893257141113281\t▁ G a l u ▁ w a b u l a u n i ▁ a k u y a n g ' a n a ▁ c h i n a c h a k e ▁ y o m w e ▁ i k u l o w e t s a ▁ m o d z i ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-64\t-0.2893257141113281\tGalu wabulauni akuyang'ana chinachake yomwe ikulowetsa modzi kumbuyo kwake .\n",
            "P-64\t-0.1187 -0.1529 -0.1343 -0.0760 -0.0588 -0.1249 -0.0469 -0.1382 -0.0676 -0.0842 -0.0556 -0.0887 -0.0705 -0.0527 -0.0913 -0.1293 -0.1098 -0.0988 -0.0715 -0.0978 -0.2099 -0.0686 -0.1439 -0.1377 -0.1006 -0.0547 -0.1049 -0.0936 -1.1896 -0.0873 -0.1038 -0.2752 -0.8816 -0.1448 -0.0612 -0.0990 -0.2444 -0.4012 -0.0993 -2.6124 -0.2352 -0.0920 -0.4893 -0.0858 -0.0665 -1.0458 -0.1600 -0.0873 -0.3634 -0.9244 -0.4106 -0.0643 -0.1006 -0.0771 -0.1200 -0.1012 -0.1264 -1.0594 -1.8778 -0.1815 -0.2970 -0.1829 -1.3383 -0.6790 -0.0986 -0.3840 -0.1282 -0.0582 -0.0834 -0.2514 -0.2190 -0.4129 -0.1147 -1.1444 -0.0553 -0.3319 -0.0311 -0.1062\n",
            "T-372\tMnyamata wovala malaya a New York Mets atakhala pa chidole chamoto cha Harly Davison pa bwalo la tennis.\n",
            "H-372\t-0.3048917055130005\t▁ M n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ o g u l i t s a ▁ a t a k h a l a ▁ p a ▁ c h i t h u n z i ▁ c h a ▁ a l i ▁ n d i ▁ n s a l u ▁ w a k e ▁ .\n",
            "D-372\t-0.3048917055130005\tMnyamata wovala malaya abuluu ndi ogulitsa atakhala pa chithunzi cha ali ndi nsalu wake .\n",
            "P-372\t-0.1264 -0.1421 -0.0550 -0.0410 -0.0833 -0.0789 -0.1026 -0.0388 -0.0993 -0.1138 -0.0948 -0.1117 -0.0594 -0.1224 -0.0787 -0.1239 -0.1033 -0.0639 -0.1089 -0.0590 -0.1102 -0.0676 -0.0996 -0.1091 -0.1384 -0.6179 -0.1629 -0.0477 -0.1295 -0.0482 -0.1206 -1.0731 -0.1346 -0.1488 -0.1035 -0.4125 -1.3550 -0.9501 -0.2294 -0.2435 -0.1617 -0.0659 -0.1073 -0.1098 -0.7822 -0.2409 -0.1333 -0.3514 -0.0479 -0.1056 -0.0409 -0.1225 -0.0918 -0.3423 -0.1181 -0.5207 -0.2492 -0.0750 -0.1166 -0.2771 -2.6278 -0.2952 -0.0782 -0.4448 -0.1078 -0.1537 -0.1241 -0.0761 -0.2354 -0.1304 -1.2527 -0.2504 -0.0893 -0.1499 -1.7756 -0.1253 -0.1047 -0.0657 -1.7561 -0.3265 -0.4169 -0.2351 -0.0645 -0.1707 -1.5088 -0.1374 -1.1560 -0.2914 -0.3108 -1.0100 -0.1038\n",
            "T-262\tMnyamata wokwera njinga yamapiri akutera atadumpha atakwera m'nkhalango .\n",
            "H-262\t-0.24524343013763428\t▁ M n y a m a t a ▁ w o k w e r a ▁ n j i n g a ▁ y a m a p i r i ▁ a k u t h a m a n g i t s a ▁ g u l u ▁ l a ▁ a n t h u ▁ e n a ▁ .\n",
            "D-262\t-0.24524343013763428\tMnyamata wokwera njinga yamapiri akuthamangitsa gulu la anthu ena .\n",
            "P-262\t-0.1205 -0.0810 -0.0491 -0.0562 -0.1006 -0.0631 -0.1093 -0.0705 -0.1015 -0.1369 -0.1533 -0.3174 -0.0992 -0.0414 -0.1027 -0.1006 -0.0943 -0.1210 -0.0848 -0.0118 -0.0873 -0.0524 -0.0450 -0.0946 -0.2912 -0.0198 -0.1502 -0.2871 -0.1460 -0.4743 -0.1345 -0.0430 -0.0851 -0.0969 -0.0755 -0.2374 -0.1298 -0.0624 -0.2510 -0.0921 -1.6746 -0.0722 -0.2958 -0.0324 -1.6629 -1.1980 -0.1766 -0.1091 -0.1026 -0.7146 -1.4587 -0.1674 -0.0595 -0.1264 -0.0339 -0.1086 -0.3655 -0.2137 -0.0864 -0.6792 -0.0535 -0.0796 -0.1469 -1.3681 -0.1521 -0.0798 -0.2175 -0.5306 -0.0849\n",
            "T-26\tBambo wovala malaya akuda ndi magalasi akukweza manja atakhala patebulo la poker .\n",
            "H-26\t-0.1823025345802307\t▁ B a m b o ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ n d i ▁ m a g a l a s i ▁ a k u k w e z a ▁ m a n j a ▁ a t a k h a l a ▁ p a t e b u l o ▁ .\n",
            "D-26\t-0.1823025345802307\tBambo wovala malaya akuda ndi magalasi akukweza manja atakhala patebulo .\n",
            "P-26\t-0.1187 -0.1571 -0.1090 -0.0883 -0.0815 -0.0857 -0.1220 -0.1442 -0.1877 -0.1286 -0.1134 -0.0800 -0.1113 -0.1038 -0.0816 -0.1357 -0.0514 -0.1073 -0.0767 -0.0915 -0.1040 -0.1615 -0.4455 -0.0801 -0.2904 -0.0797 -0.1159 -0.1427 -0.1040 -0.0956 -0.0675 -0.0907 -0.1179 -1.3756 -0.1357 -0.0974 -0.1100 -0.0190 -0.0847 -0.1131 -0.0987 -0.0569 -0.0895 -0.3213 -0.1074 -0.1519 -0.4217 -0.0945 -0.1073 -0.3432 -0.1280 -0.3525 -0.0176 -0.1067 -0.1009 -0.1158 -0.0984 -0.0935 -0.9572 -1.1409 -0.1849 -0.0702 -0.1094 -0.0978 -0.1145 -0.1354 -0.4523 -0.0507 -0.2062 -0.0771 -0.1120 -0.0730 -0.1027 -0.8646 -0.1112\n",
            "T-44\tGalu wotuwa komanso woyera akuwoneka wamantha pamene akukwaza m'madzi .\n",
            "H-44\t-0.30511829257011414\t▁ G a l u ▁ w o t u w a ▁ w a b u l a u n i ▁ w o y e r a ▁ a k u w o n e k a ▁ m a n j a ▁ a t a n y a m u l a ▁ n y u m b a ▁ z a m a s a m b a ▁ .\n",
            "D-44\t-0.30511829257011414\tGalu wotuwa wabulauni woyera akuwoneka manja atanyamula nyumba zamasamba .\n",
            "P-44\t-0.1211 -0.1094 -0.1263 -0.0772 -0.0695 -0.1558 -0.0483 -0.7743 -0.0340 -0.1418 -0.0608 -0.0964 -0.2224 -0.9936 -0.4525 -0.3062 -0.1722 -0.0545 -1.5316 -0.0567 -0.0806 -0.0888 -0.1560 -0.7654 -0.0783 -0.5019 -0.0630 -0.0868 -0.0961 -0.1597 -0.1386 -0.1333 -0.0844 -0.1799 -1.2872 -0.0739 -0.0740 -0.0330 -0.0954 -0.0889 -0.1440 -0.8738 -1.1701 -0.7312 -0.1112 -0.1373 -0.2524 -0.8515 -0.1005 -1.3633 -0.0456 -0.1079 -0.0518 -0.0806 -0.0708 -0.1030 -0.1061 -2.5405 -0.2223 -0.5033 -0.1941 -0.1390 -0.1063 -0.1327 -0.3326 -0.1580 -0.5615 -0.2580 -0.4826 -0.3815 -0.2304 -0.1008 -0.1360 -0.4200 -0.0157 -0.1033\n",
            "T-224\tMayi akumwetulira wovala malaya abulauni atsamira mwamuna wovala juzi .\n",
            "H-224\t-0.2160806506872177\t▁ A m a y i ▁ a k u t e m b a ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a t a n y a m u l a ▁ m w a m u n a ▁ w o v a l a ▁ j u z i ▁ .\n",
            "D-224\t-0.2160806506872177\tAmayi akutemba wovala malaya abulauni atanyamula mwamuna wovala juzi .\n",
            "P-224\t-0.1202 -0.1315 -0.1040 -0.3240 -0.0509 -0.1574 -0.1308 -0.1732 -0.1857 -0.1064 -0.0905 -0.1687 -0.1757 -0.1649 -1.1875 -0.2091 -1.6040 -0.1994 -0.0254 -0.1198 -0.0730 -0.1140 -0.1157 -0.0736 -0.1215 -0.0583 -0.1092 -0.0369 -0.1092 -0.1097 -0.2224 -0.0577 -0.0692 -0.0685 -0.2615 -0.0443 -0.0739 -0.0809 -0.1231 -0.0831 -0.9593 -0.1613 -2.1559 -0.0810 -0.1907 -0.1011 -0.0777 -0.0610 -0.1119 -0.1055 -0.1616 -0.8845 -0.0953 -0.3574 -0.0985 -0.0809 -0.0959 -0.1488 -0.3499 -0.0574 -0.0255 -0.1117 -0.0741 -0.1132 -0.1155 -0.0285 -0.6530 -0.0534 -0.0759 -0.2521 -0.1721 -0.1125\n",
            "T-354\tWothamanga mumsewu akutsetsereka motsetsereka kwambiri ndipo kumbuyo kwake kuli phiri .\n",
            "H-354\t-0.3780171871185303\t▁ W o t h a m a n g a ▁ m u m s e w u ▁ w a ▁ k u ▁ A s i a ▁ m ' m o d z i ▁ a k u s e r e k a ▁ k w a ▁ n d i p o ▁ m ' b w a l o ▁ l o f i i r i r a ▁ .\n",
            "D-354\t-0.3780171871185303\tWothamanga mumsewu wa ku Asia m'modzi akusereka kwa ndipo m'bwalo lofiirira .\n",
            "P-354\t-0.1034 -0.2072 -0.5039 -0.0781 -0.0659 -0.1146 -0.0926 -0.1037 -0.1199 -0.0425 -0.0808 -0.1285 -0.1130 -0.3678 -1.0817 -0.1298 -0.1071 -0.1120 -0.0347 -0.1414 -0.2810 -0.1743 -0.6836 -0.5685 -0.0666 -0.6315 -0.7986 -0.0511 -0.2260 -0.1355 -0.1530 -1.3538 -1.0490 -0.2468 -0.7180 -0.1038 -0.0608 -0.2127 -0.1366 -0.8739 -0.2583 -0.1209 -1.1432 -0.0527 -1.5168 -0.6886 -0.0961 -0.1267 -0.1187 -1.1365 -0.0595 -0.1237 -0.3099 -0.8487 -0.2155 -0.3983 -0.3578 -0.0728 -0.0883 -1.2988 -1.5037 -1.2703 -0.2284 -0.0866 -0.1339 -0.2505 -0.1437 -0.1442 -0.7019 -1.0119 -0.0974 -0.1866 -0.0948 -1.2158 -0.2031 -0.1418 -0.7188 -0.3497 -0.0943\n",
            "T-375\tGulu la anthu litakhala pansi pa mtengo wamaluwa wa pinki ndi woyera womwe uli ndi udzu .\n",
            "H-375\t-0.2540675103664398\t▁ G u l u ▁ l a ▁ a n t h u ▁ l i t a k h a l a ▁ p a n s i ▁ p a ▁ m t e n g o ▁ w a ▁ m a l u w a ▁ a p i n k i ▁ n d i ▁ w o y e r a ▁ k u m b u y o ▁ .\n",
            "D-375\t-0.2540675103664398\tGulu la anthu litakhala pansi pa mtengo wa maluwa apinki ndi woyera kumbuyo .\n",
            "P-375\t-0.1182 -0.0451 -0.0807 -0.0605 -0.0879 -0.1071 -0.2580 -0.1176 -0.1142 -0.1353 -0.1266 -0.0243 -0.0870 -0.0867 -0.1132 -0.0394 -0.1535 -0.2332 -0.1215 -0.0552 -0.0284 -0.1099 -0.0563 -0.1230 -0.1006 -0.0235 -0.1379 -0.5838 -0.0859 -0.1130 -0.1244 -0.0114 -0.1298 -1.0098 -0.0635 -0.7052 -0.0695 -0.0922 -0.0513 -0.1371 -0.0821 -0.0349 -0.1907 -0.4210 -0.2462 -0.1243 -1.3080 -0.2067 -0.0521 -0.0953 -0.1639 -1.5015 -1.1430 -0.1797 -0.1040 -0.1313 -0.1214 -0.1845 -0.1791 -0.0646 -0.1380 -0.1088 -2.4458 -0.0550 -0.1662 -0.1272 -0.1467 -0.0764 -0.1839 -1.7631 -0.0866 -0.1677 -1.0130 -0.1319 -0.1092 -0.0893 -0.3783 -0.3153 -0.1130\n",
            "T-198\tGulu la anthu lasonkhana m'mphepete mwa sitolo pafupi ndi msewu womwe uli ndi zinyalala .\n",
            "H-198\t-0.2727034389972687\t▁ G u l u ▁ l a ▁ a n t h u ▁ o s o n k h a n a ▁ m ' m a s i t e p o ▁ p a f u p i ▁ n d i ▁ n j i n g a ▁ y o m w e ▁ u l i ▁ n d i ▁ z i n y a l a l a ▁ .\n",
            "D-198\t-0.2727034389972687\tGulu la anthu osonkhana m'masitepo pafupi ndi njinga yomwe uli ndi zinyalala .\n",
            "P-198\t-0.1040 -0.7142 -0.0847 -0.0685 -0.0776 -0.1099 -0.2102 -0.1180 -0.0772 -0.1014 -0.0674 -0.0325 -0.1025 -0.0980 -0.1043 -0.0600 -0.0698 -1.3001 -0.2943 -0.4411 -0.1224 -0.0941 -0.0480 -0.0978 -0.1257 -0.6190 -0.7212 -0.0416 -0.2066 -0.0653 -0.5053 -0.0650 -0.0458 -0.0565 -0.5135 -0.0990 -2.4081 -0.1162 -0.6963 -0.0730 -0.0334 -0.0857 -0.0997 -0.0960 -0.0906 -0.0988 -0.0879 -0.8633 -1.1621 -0.1468 -0.1369 -0.1210 -0.1092 -0.1512 -2.6627 -0.3798 -0.0841 -0.1474 -0.1100 -0.0972 -0.8980 -0.3107 -0.1186 -0.1275 -0.2890 -0.2880 -0.1081 -0.1329 -0.2859 -0.0783 -0.0666 -0.2950 -0.1054 -0.0248 -0.1111 -0.1394 -0.1104 -0.4328 -0.0653 -0.1085\n",
            "T-132\tGalu waubweya wa beige akusewera m'madzi amtsinje wakuda.\n",
            "H-132\t-0.29050523042678833\t▁ G a l u ▁ w a b u l a u n i ▁ w o v a l a ▁ b e i g e ▁ a k u s e w e r a ▁ m ' m a d z i ▁ o k u t i d w a ▁ .\n",
            "D-132\t-0.29050523042678833\tGalu wabulauni wovala beige akusewera m'madzi okutidwa .\n",
            "P-132\t-0.1182 -0.0798 -0.1182 -0.0725 -0.0816 -0.1387 -0.0553 -0.6712 -0.8814 -0.0800 -0.0630 -0.1779 -0.0395 -0.0588 -0.1916 -0.1200 -0.5005 -1.9421 -0.3813 -0.1010 -0.1080 -0.1036 -0.0902 -1.1081 -0.3566 -0.1726 -0.2745 -0.0605 -0.0861 -0.1576 -0.0718 -0.0896 -0.2003 -0.0413 -0.0767 -0.0843 -0.0893 -0.1060 -0.1240 -0.3080 -0.3298 -0.1089 -0.1065 -0.0894 -0.0422 -0.0824 -0.1822 -0.5310 -1.8903 -0.6905 -0.2569 -0.3100 -0.3464 -0.1189 -0.0780 -0.2380 -1.7672 -0.0988\n",
            "T-414\tGalu wabulauni akugona pamunda waudzu pamene mphepo ikuwomba ubweya wake.\n",
            "H-414\t-0.34141889214515686\t▁ G a l u ▁ w a b u l a u n i ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ w a u d z u ▁ n d i p o ▁ w i n a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-414\t-0.34141889214515686\tGalu wabulauni wovala malaya abulauni waudzu ndipo wina kumbuyo kwake .\n",
            "P-414\t-0.1176 -0.1346 -0.1301 -0.0617 -0.0725 -0.1287 -0.0495 -0.6785 -0.3515 -0.0695 -0.0547 -0.0889 -0.0545 -0.0592 -0.0761 -0.1157 -1.6853 -0.4277 -0.3916 -0.1138 -0.0863 -0.1055 -0.0882 -1.7032 -0.2553 -0.2019 -0.0985 -0.0798 -0.0981 -0.0958 -0.9974 -0.4063 -0.0678 -0.0658 -0.8593 -0.0443 -0.1543 -0.0913 -0.0957 -0.7726 -0.2359 -1.1458 -1.0276 -0.1433 -0.0930 -0.1359 -2.0449 -0.1450 -0.1001 -0.7149 -0.0670 -0.0748 -0.0577 -0.3102 -0.1555 -0.1354 -0.1394 -0.9553 -0.0959 -0.2385 -0.0887 -1.9010 -0.1061 -0.0634 -0.1945 -1.0913 -0.3522 -0.0945 -1.1113 -0.1035 -0.2765 -0.1825 -0.1127\n",
            "T-349\tMnyamata wakwera njonjo ya blue ndi yellow merry-go-round ndi dzanja la mwamuna wamkulu kutsogolo .\n",
            "H-349\t-0.3020235002040863\t▁ M n y a m a t a ▁ w o k w e r a ▁ n j o n j i ▁ y a ▁ b u l u u ▁ n d i ▁ y o y e r a ▁ n d i ▁ g o l o ▁ l a ▁ m w a m u n a ▁ w a m n g ' o n o ▁ k u t s o g o l o ▁ .\n",
            "D-349\t-0.3020235002040863\tMnyamata wokwera njonji ya buluu ndi yoyera ndi golo la mwamuna wamng'ono kutsogolo .\n",
            "P-349\t-0.1276 -0.1001 -0.0599 -0.0483 -0.1014 -0.0847 -0.1103 -0.0658 -0.1019 -0.1356 -0.6081 -0.1465 -0.0941 -0.4412 -0.1010 -0.0872 -0.0905 -0.1296 -0.0686 -0.0169 -0.4802 -0.1256 -1.0753 -0.2375 -0.1084 -0.0089 -0.1659 -0.4539 -0.4629 -0.6520 -0.0855 -0.1229 -0.0518 -0.0933 -0.1111 -0.1038 -0.1057 -0.0960 -0.7060 -0.8096 -0.8417 -0.0610 -0.0746 -0.0945 -0.1599 -3.5516 -0.2896 -0.0876 -0.0813 -1.5055 -0.3344 -0.1208 -0.3984 -0.3121 -0.8749 -0.1268 -0.2760 -0.1631 -1.6583 -0.1039 -0.3478 -0.0707 -0.1546 -0.0817 -0.1387 -0.4867 -0.2241 -0.2492 -0.9771 -0.0651 -0.2666 -0.1077 -0.1290 -0.0888 -0.1591 -0.6623 -0.0708 -0.6071 -0.0672 -0.0421 -0.0215 -0.0620 -0.0578 -0.0617 -0.2139 -0.8659 -0.1056\n",
            "T-34\tGalu wa bulauni ndi woyera waima pa trampoline lilime lake likulendewera panja .\n",
            "H-34\t-0.28448033332824707\t▁ G a l u ▁ w a b u l a u n i ▁ n d i ▁ w o y e r a ▁ w a i m a ▁ p a f u p i ▁ n d i ▁ m i y e n d e ▁ y a k u d a ▁ n d i ▁ p a n j i r a ▁ .\n",
            "D-34\t-0.28448033332824707\tGalu wabulauni ndi woyera waima pafupi ndi miyende yakuda ndi panjira .\n",
            "P-34\t-0.1266 -1.1154 -0.1139 -0.0717 -0.0687 -0.1164 -0.1392 -0.1416 -2.2310 -0.0846 -0.0372 -0.0968 -0.0523 -0.0626 -0.1610 -0.1243 -0.0449 -0.0847 -0.1472 -0.0836 -0.0170 -0.0638 -0.0540 -0.0675 -0.1437 -0.0816 -0.1582 -0.5806 -0.1390 -0.5289 -0.0472 -0.1411 -0.0773 -0.0473 -0.1400 -0.9792 -0.0843 -0.0425 -0.0928 -0.0776 -0.0742 -0.1632 -0.1254 -0.0958 -0.3176 -0.6862 -0.1553 -0.3001 -0.3983 -0.0914 -0.5703 -0.5849 -0.4014 -0.1485 -0.1238 -0.9758 -0.1068 -0.2224 -0.2150 -1.2599 -0.0688 -0.1480 -0.0826 -2.5722 -0.2082 -0.0752 -0.3223 -0.1588 -0.6630 -0.0902 -0.3747 -0.2313 -0.0880\n",
            "T-163\tZipaipi zikuseweredwa mukuyenda parade kapena chochitika mumsewu.\n",
            "H-163\t-0.4693288803100586\t▁ M z i p a y i ▁ a k u s e w e r e t s a ▁ m o t o ▁ w a y i n d a ▁ p a m e n e ▁ a k u c h o k e r a ▁ c h i t h u n z i ▁ m ' m i s e w u ▁ .\n",
            "D-163\t-0.4693288803100586\tMzipayi akuseweretsa moto wayinda pamene akuchokera chithunzi m'misewu .\n",
            "P-163\t-0.1237 -2.2086 -0.2730 -0.0998 -1.6232 -0.2942 -1.6786 -0.2429 -0.1598 -0.3985 -0.5622 -0.1045 -0.7903 -0.1567 -0.1746 -0.0953 -0.1249 -1.6330 -0.2682 -0.0455 -0.3306 -0.1373 -0.7017 -0.8392 -0.7518 -0.0846 -0.1465 -0.9686 -0.2165 -0.9403 -0.0723 -1.0212 -0.7416 -0.0997 -0.1725 -0.1045 -0.1280 -3.6306 -0.5844 -0.0949 -0.0537 -0.1065 -0.1483 -0.7352 -0.3643 -0.5632 -0.0602 -0.6698 -0.4997 -0.6526 -0.0503 -0.0789 -0.1248 -0.7829 -0.0967 -0.1429 -1.3771 -1.3835 -0.1338 -0.0390 -0.0439 -0.0867 -0.2059 -0.4157 -0.3286 -0.8760 -0.5214 -0.1512 -0.0678 -0.2246 -0.0629 -0.5290 -0.2200 -0.1091\n",
            "T-268\tGalu wotuwa amakhala pa kapinga atavala jekete lamanja lalitali la buluu wonyezimira .\n",
            "H-268\t-0.2461889088153839\t▁ G a l u ▁ w a k u d a ▁ a m a k h a l a ▁ p a ▁ k a p i n g a ▁ a t a v a l a ▁ m a ▁ j e k e t e ▁ a l i ▁ n d i ▁ a b u l u u ▁ w o n y e z i m i r a ▁ .\n",
            "D-268\t-0.2461889088153839\tGalu wakuda amakhala pa kapinga atavala ma jekete ali ndi abuluu wonyezimira .\n",
            "P-268\t-0.1247 -0.0654 -0.0995 -0.0657 -0.0954 -0.1426 -0.0266 -0.1963 -1.5658 -0.1056 -0.6859 -0.1186 -0.1922 -0.1441 -0.3389 -0.1049 -0.1065 -0.0568 -0.1072 -0.0617 -0.0942 -0.1108 -0.0230 -0.1138 -1.0587 -0.8938 -0.1076 -0.5084 -0.1912 -0.0370 -0.2594 -0.0851 -0.1197 -1.3388 -0.0156 -0.0948 -0.1138 -0.1035 -0.0736 -0.0993 -0.0861 -1.6397 -0.1402 -1.4115 -0.0176 -0.0757 -0.0554 -0.0805 -0.0325 -0.0974 -0.0795 -0.2399 -0.2176 -0.1060 -0.1240 -0.9512 -0.1782 -0.1272 -0.0671 -0.1124 -0.4113 -0.1373 -0.1044 -0.1255 -0.0776 -0.1833 -0.7694 -0.0417 -0.5157 -0.0486 -0.2084 -0.0270 -0.1213 -0.1895 -0.1044 -0.0907 -0.0970 -0.5984 -0.0498 -0.1074\n",
            "T-406\tMwamuna ali pampando akugwira mbiya yaikulu pagudumu loumba mbiya .\n",
            "H-406\t-0.30725541710853577\t▁ M w a m u n a ▁ a l i ▁ p a m p a n d o ▁ w a g w i r a ▁ m i y a l a ▁ y a i k u l u ▁ p a m u n d a ▁ w o b i r i w i r a ▁ .\n",
            "D-406\t-0.30725541710853577\tMwamuna ali pampando wagwira miyala yaikulu pamunda wobiriwira .\n",
            "P-406\t-0.1200 -0.0658 -0.0483 -0.1061 -0.1066 -0.0940 -0.0907 -0.1042 -0.1678 -0.4039 -0.0327 -0.0898 -0.1166 -0.0256 -0.1282 -0.4569 -2.7567 -0.1499 -0.0467 -0.0312 -0.0917 -0.0901 -0.1530 -0.1094 -1.6460 -0.0397 -0.1219 -0.1055 -0.0980 -0.1205 -1.5603 -1.1612 -0.6207 -0.2856 -0.1842 -0.2327 -0.1633 -0.0632 -0.1082 -0.2912 -0.0323 -0.0917 -0.0266 -0.0908 -0.1081 -0.2799 -0.1150 -1.8457 -0.1000 -0.4136 -0.3224 -0.1831 -0.1927 -0.2940 -0.0856 -2.2686 -0.1115 -0.0819 -0.0662 -0.1174 -0.1261 -0.0932 -0.0862 -0.5047 -0.1471 -0.1059\n",
            "T-5\tGalu woyera ndi wakuda watsala pang'ono kugwira chinthu ataima m'chipale chofewa .\n",
            "H-5\t-0.21281616389751434\t▁ G a l u ▁ w o y e r a ▁ n d i ▁ w a k u d a ▁ w a t s a l a ▁ p a m o d z i ▁ a k u g w i r a ▁ n t c h i t o ▁ m ' c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-5\t-0.21281616389751434\tGalu woyera ndi wakuda watsala pamodzi akugwira ntchito m'chipale chofewa .\n",
            "P-5\t-0.1188 -0.0704 -0.1107 -0.0742 -0.0751 -0.1497 -0.0896 -0.0790 -0.0461 -0.0829 -0.0906 -0.0880 -0.1428 -0.0391 -0.0954 -0.1207 -0.0969 -0.0174 -0.1070 -0.4163 -0.1061 -0.2686 -0.1204 -0.1358 -0.1969 -0.1175 -1.1764 -0.0273 -0.1135 -0.0897 -0.1262 -0.0962 -0.0447 -0.1014 -0.1767 -1.1197 -1.8264 -0.2503 -0.1340 -0.1202 -0.2532 -0.5647 -0.1102 -1.0741 -0.1146 -0.5530 -0.0534 -0.1654 -0.1116 -0.2469 -0.0482 -0.0498 -0.0832 -0.1054 -0.0249 -0.0483 -0.0946 -1.5024 -0.1445 -0.7735 -0.0768 -0.0968 -0.2914 -0.0976 -0.0296 -0.0828 -0.0894 -0.0330 -0.0815 -0.0412 -0.1257 -0.0993 -0.0729 -0.0928 -0.3662 -0.0421 -0.0873\n",
            "T-145\tGalu waima m'chipale chofewa chakuya atazunguliridwa ndi mitengo .\n",
            "H-145\t-0.23801568150520325\t▁ G a l u ▁ w o y e r a ▁ m ' c h i p e w a ▁ c h o f e w a ▁ a k u w u l i r a ▁ a t a z u n g u l i r i d w a ▁ n d i ▁ m i t e n g o ▁ .\n",
            "D-145\t-0.23801568150520325\tGalu woyera m'chipewa chofewa akuwulira atazunguliridwa ndi mitengo .\n",
            "P-145\t-0.1133 -0.0271 -0.1079 -0.0699 -0.0768 -0.1274 -0.0548 -0.1260 -0.0799 -0.0585 -0.7728 -0.1148 -0.1679 -0.5542 -0.2200 -0.1436 -0.1265 -0.0895 -0.0229 -0.5301 -0.2448 -0.1023 -0.1674 -0.0380 -0.0873 -0.0831 -0.2903 -0.2017 -0.0583 -0.1061 -0.2048 -0.7934 -0.4117 -0.0765 -1.3623 -0.6342 -0.1603 -0.1660 -0.0620 -0.1313 -0.1297 -1.7226 -0.0514 -0.1220 -0.1821 -0.0954 -0.1233 -0.0307 -0.0613 -0.0478 -0.0960 -0.1711 -0.0657 -0.0114 -0.0994 -0.1073 -0.0997 -0.4360 -0.0683 -0.1549 -0.1154 -0.2143 -1.7222 -0.1246 -0.5012 -0.1295 -0.5315 -0.0545 -0.4485 -0.1189 -0.0971\n",
            "T-56\tMunthu wovala malaya ofiira ndi ofiira akuyenda pa chipale chofewa pamwamba pa chipale chofewa .\n",
            "H-56\t-0.17272041738033295\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ o f i i r a ▁ a k u y e n d a ▁ c h i p a l e ▁ c h o f e w a ▁ p a m w a m b a ▁ p a ▁ c h i p a l e ▁ c h o f e w a .\n",
            "D-56\t-0.17272041738033295\tMunthu wovala malaya ofiira ndi ofiira akuyenda chipale chofewa pamwamba pa chipale chofewa.\n",
            "P-56\t-0.1198 -0.1294 -0.0449 -0.1081 -0.0829 -0.0781 -0.0903 -0.1470 -0.0636 -0.0963 -0.0705 -0.1272 -0.0728 -0.1231 -0.0989 -0.1125 -0.1264 -0.0359 -0.1041 -0.0624 -0.0965 -0.0943 -0.0669 -0.0758 -0.1005 -0.1005 -0.1081 -0.1254 -0.1526 -0.0774 -0.0749 -0.0852 -0.0959 -1.0882 -0.3190 -0.0982 -0.1912 -0.1430 -0.1520 -0.1669 -0.1249 -0.1248 -0.0754 -0.1240 -0.0871 -0.0961 -0.0747 -0.1114 -0.0860 -3.3337 -0.0804 -0.0915 -0.2241 -0.1337 -0.0495 -0.1278 -0.0683 -0.0146 -0.0854 -0.0858 -0.0389 -0.0810 -0.0640 -0.0957 -0.1581 -0.0356 -0.1553 -0.0946 -0.1130 -0.0763 -0.0616 -0.1099 -0.0918 -0.0997 -0.0210 -0.1249 -0.0831 -0.1035 -0.0711 -0.2878 -0.5858 -0.0886 -0.0467 -0.0744 -0.0965 -0.0916 -0.1137 -0.0780 -0.0170 -0.0767 -0.0573 -0.0965 -2.2408 -0.0999\n",
            "T-231\tGalu wamkulu wabulauni amayamba kunjenjemera ataima m'madzi .\n",
            "H-231\t-0.2562435269355774\t▁ G a l u ▁ w a m k u l u ▁ w a b u l a u n i ▁ a m a y a m b a ▁ k u j a m b u l a ▁ a t a i m a ▁ m ' m a d z i ▁ .\n",
            "D-231\t-0.2562435269355774\tGalu wamkulu wabulauni amayamba kujambula ataima m'madzi .\n",
            "P-231\t-0.1261 -0.0731 -0.1251 -0.0882 -0.0859 -0.1437 -0.0765 -0.1111 -0.5891 -0.1287 -0.0774 -0.0551 -0.0648 -0.1459 -0.0531 -0.1116 -0.0280 -0.0643 -0.0794 -0.0903 -0.0371 -0.0599 -0.0717 -0.1338 -0.0854 -0.3733 -0.1238 -0.2945 -0.1309 -0.6189 -0.5362 -0.1381 -0.1089 -0.8607 -0.1078 -0.7878 -0.2279 -0.0837 -0.0604 -0.0790 -0.0784 -0.1356 -0.1696 -1.3049 -0.0283 -0.1339 -2.5486 -0.0404 -0.1057 -0.1240 -0.7191 -0.1966 -0.0678 -0.1433 -1.0658 -0.1146 -0.0778 -0.7645 -0.2198 -0.0989\n",
            "T-306\tAtsikana awiri ovala malaya akhala moyang'anizana ndi zakumwa m'manja .\n",
            "H-306\t-0.2516215145587921\t▁ A t s i k a n a ▁ a w i r i ▁ a k u p a n g a ▁ m a l a y a ▁ a k h a l a ▁ m o y a n g ' a n i z a n a ▁ n d i ▁ z o m w e ▁ .\n",
            "D-306\t-0.2516215145587921\tAtsikana awiri akupanga malaya akhala moyang'anizana ndi zomwe .\n",
            "P-306\t-0.1217 -0.0989 -0.1098 -0.1250 -0.0900 -0.2328 -0.1215 -0.0874 -0.1003 -0.1588 -0.1299 -0.0934 -0.1111 -0.0519 -0.0859 -0.1699 -0.1904 -0.7509 -0.1479 -2.4094 -0.1294 -1.0014 -0.1318 -0.0752 -0.1817 -0.0700 -0.1171 -0.0504 -0.1425 -0.0250 -0.1105 -0.1139 -0.2427 -1.2941 -0.7810 -0.1196 -0.0781 -0.1125 -0.1495 -0.1433 -0.3281 -0.0556 -0.0574 -0.0490 -0.1776 -0.0507 -0.1021 -0.1293 -0.2648 -0.0640 -0.1871 -0.0544 -0.1223 -0.1136 -0.1553 -0.0469 -0.1072 -0.0949 -0.2944 -0.1612 -0.8374 -0.2317 -0.1116 -0.1445 -2.0952 -0.1140\n",
            "T-75\tAzimayi awiri, mmodzi atakhala pampando, wina ataima, akuwoneka kuti avulala.\n",
            "H-75\t-0.23772212862968445\t▁ A z i m a y i ▁ a w i r i ▁ a ▁ m ' m o d z i ▁ a t a k h a l a ▁ p a m p a n d o ▁ w i n a ▁ a t a i m a ▁ p a m e n e ▁ a k u w o n e k a ▁ .\n",
            "D-75\t-0.23772212862968445\tAzimayi awiri a m'modzi atakhala pampando wina ataima pamene akuwoneka .\n",
            "P-75\t-0.1225 -0.0378 -0.0919 -0.0901 -0.1183 -0.1134 -0.0293 -0.0762 -0.0972 -0.1384 -0.0595 -0.1265 -0.0513 -0.1039 -0.2703 -0.3341 -2.3846 -0.1721 -1.0444 -0.0869 -0.0493 -0.0398 -0.0460 -0.0950 -0.1380 -0.0676 -0.0917 -0.1051 -0.1013 -0.0321 -0.0985 -0.0549 -0.1042 -0.1181 -0.0213 -0.1077 -0.1541 -0.0886 -0.1682 -0.0523 -0.0126 -0.0471 -0.1019 -0.1244 -0.1298 -0.1626 -0.1009 -0.1545 -0.1063 -0.0408 -0.1169 -1.1989 -0.0690 -0.0950 -0.1195 -0.5801 -0.1471 -1.2969 -0.0775 -0.0414 -0.0673 -0.1129 -1.1155 -0.1371 -0.0956 -1.6352 -0.3104 -0.3875 -0.0400 -0.0534 -0.0819 -0.1903 -1.2685 -0.0901\n",
            "T-190\tKamnyamata ka jekete yochindikala kayimilira ndi dzanja lake pamwamba pamutu .\n",
            "H-190\t-0.34404873847961426\t▁ P a m n y a m a t a ▁ a t a k h a l a ▁ n d i ▁ c h i n t h u ▁ c h o k h a l a ▁ n d i ▁ z a n j a ▁ a t a k h a l a ▁ p a m w a m b a ▁ p a ▁ m u n t h u ▁ .\n",
            "D-190\t-0.34404873847961426\tPamnyamata atakhala ndi chinthu chokhala ndi zanja atakhala pamwamba pa munthu .\n",
            "P-190\t-0.1206 -1.1742 -0.1719 -0.2011 -1.0509 -0.0550 -0.0926 -0.0629 -0.0842 -0.0393 -0.0985 -0.1254 -0.5781 -0.1855 -0.1100 -0.3799 -0.0530 -0.0930 -0.0601 -0.0874 -0.1168 -2.2984 -0.1222 -0.1024 -0.0823 -1.0193 -0.1095 -0.1241 -1.3237 -0.8151 -0.2821 -0.0705 -0.1255 -0.9808 -0.1047 -0.2870 -2.4745 -0.1184 -0.1127 -0.0805 -0.1194 -0.1462 -0.0602 -0.1137 -0.1078 -0.0803 -0.2936 -0.1659 -0.1576 -0.0213 -0.1000 -0.1097 -0.3063 -1.0771 -0.1637 -0.7623 -0.8855 -0.1157 -0.0682 -0.1136 -0.1032 -0.0196 -0.1490 -0.2949 -2.9039 -0.0797 -0.0833 -0.5207 -0.1138 -0.1840 -0.0230 -0.1161 -0.2513 -0.1163 -0.2811 -1.3081 -0.2442 -0.0779 -0.1202 -0.3511 -0.2257 -0.1035\n",
            "T-266\tGulu la basketball la atsikana asanu ndi atatu likugwirana manja.\n",
            "H-266\t-0.32941073179244995\t▁ G u l u ▁ l a ▁ m b a s i ▁ l a ▁ b u l u u ▁ a t s i k a n a ▁ n d i ▁ a t a t u ▁ l i k u g w i r a ▁ m a n j a ▁ .\n",
            "D-266\t-0.32941073179244995\tGulu la mbasi la buluu atsikana ndi atatu likugwira manja .\n",
            "P-266\t-0.1117 -0.0592 -0.0740 -0.0539 -0.0985 -0.1143 -0.1517 -0.1171 -0.1026 -2.5051 -0.0434 -0.0971 -1.1141 -0.1898 -0.2765 -0.0436 -0.2041 -0.3657 -0.2033 -1.1138 -0.1612 -0.2441 -0.0550 -0.1819 -0.2043 -0.7933 -0.7412 -0.8423 -0.0565 -0.1221 -0.2604 -0.1068 -0.6781 -2.0562 -0.0804 -0.1307 -0.1635 -0.1348 -0.0926 -0.1655 -0.0284 -0.1118 -0.1225 -0.9155 -0.1455 -0.1674 -0.0838 -0.2013 -1.0912 -0.2081 -0.0888 -0.0913 -0.2177 -0.3264 -0.1303 -0.6457 -0.0397 -0.1289 -0.2322 -0.7032 -0.1037\n",
            "T-361\tGalu wabulauni wovala kolala walalanje akudumpha kuti agwire mpira wamitundu yowala .\n",
            "H-361\t-0.2531892955303192\t▁ G a l u ▁ w a b u l a u n i ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a k u d u m p h a ▁ k u t s o g o l o ▁ k w a ▁ m p i r a ▁ w a m t u n d u ▁ w a ▁ b u l u u ▁ .\n",
            "D-361\t-0.2531892955303192\tGalu wabulauni wovala malaya abulauni akudumpha kutsogolo kwa mpira wamtundu wa buluu .\n",
            "P-361\t-0.1114 -0.0953 -0.1075 -0.0664 -0.0877 -0.1238 -0.0459 -2.3139 -0.1355 -0.0912 -0.0681 -0.0958 -0.0750 -0.0730 -0.0800 -0.1363 -0.1308 -0.0964 -0.0641 -0.1111 -0.0749 -0.1222 -0.1003 -1.0744 -0.1661 -0.0422 -0.0973 -0.1354 -0.0985 -0.1035 -0.3747 -0.7528 -0.0814 -0.0938 -0.1168 -0.0829 -0.1321 -0.1248 -0.1131 -0.1083 -0.0362 -0.0782 -0.0641 -0.0860 -0.1257 -0.0886 -0.0562 -0.1021 -0.1512 -1.9212 -0.0385 -0.9804 -0.7137 -1.0384 -0.0722 -0.1411 -0.0619 -0.1486 -0.0805 -0.1552 -0.1023 -0.1362 -0.2256 -0.0606 -0.3060 -0.1130 -0.1070 -0.1013 -0.2179 -0.1254 -0.1822 -0.4781 -0.6414 -0.1465 -0.0749 -0.1240 -0.1594 -0.1577 -0.0516 -0.1584 -0.4492 -2.0794 -0.4420 -0.0738 -0.1340 -0.0830 -0.2772 -0.9830 -0.0986\n",
            "T-8\tOphunzira achichepere atatu atakhala pamatebulo m'laibulale akugwira ntchito ya kunyumba .\n",
            "H-8\t-0.3599523603916168\t▁ W o p h u n z i r a ▁ c h i c h e p e r e ▁ a t a t u ▁ a t a k h a l a ▁ p a m a t e b u l o ▁ .\n",
            "D-8\t-0.3599523603916168\tWophunzira chichepere atatu atakhala pamatebulo .\n",
            "P-8\t-0.1161 -1.2479 -0.0944 -2.1414 -0.5703 -0.0439 -0.0529 -0.1745 -0.1166 -0.8581 -0.0950 -0.1342 -0.2169 -0.1384 -0.1063 -1.3626 -0.1025 -1.4018 -0.2706 -0.0995 -0.1062 -0.6007 -0.1226 -0.0829 -0.0371 -0.1289 -1.5229 -0.0535 -0.2095 -0.1970 -0.0428 -0.1196 -0.9195 -0.0920 -0.1012 -0.0745 -0.1012 -0.0923 -0.1230 -0.1847 -1.5634 -0.1571 -0.1554 -0.2758 -0.0799 -0.1053 -0.1029 -0.0531 -0.1160 -1.3923 -0.1003\n",
            "T-167\tMnyamata pa skateboard ali pa khoma pafupi ndi madzi ndi pafupi ndi udzu.\n",
            "H-167\t-0.3148738145828247\t▁ M n y a m a t a ▁ w i n a ▁ p a ▁ s k a t e b o a r d ▁ a l i ▁ p a f u p i ▁ n d i ▁ m a p i r i ▁ m ' m a d z i ▁ p a f u p i ▁ n d i ▁ n j i n g a ▁ .\n",
            "D-167\t-0.3148738145828247\tMnyamata wina pa skateboard ali pafupi ndi mapiri m'madzi pafupi ndi njinga .\n",
            "P-167\t-0.1187 -0.3951 -0.0554 -0.0424 -0.1001 -0.0958 -0.0940 -0.0533 -0.0885 -0.1103 -2.0803 -0.8211 -0.1131 -0.1015 -0.1033 -0.5198 -0.1110 -0.2903 -0.0294 -0.1895 -0.1045 -0.0608 -0.0539 -0.0777 -0.0293 -0.0469 -0.0230 -0.0706 -0.5350 -0.2241 -0.0917 -0.0721 -0.0884 -0.1471 -0.1194 -2.7108 -0.0892 -0.0289 -0.0761 -0.1115 -0.0604 -0.0558 -0.0861 -0.0928 -0.0768 -0.1237 -1.6731 -1.3193 -0.4064 -0.0680 -0.1670 -0.9798 -0.4648 -0.1225 -0.1294 -1.7273 -0.0457 -0.0662 -0.1943 -1.3451 -0.1001 -0.0106 -0.0818 -0.0449 -0.0896 -0.1043 -0.0608 -0.0502 -0.0845 -0.0891 -1.2147 -1.3263 -0.1573 -0.0943 -0.1285 -0.1188 -0.3233 -1.2112 -0.1060\n",
            " 77% 10/13 [00:22<00:04,  1.64s/it, wps=1427]T-219\tGalu wakuda akudumpha mu mulu wa chipale chofewa chokhuthala .\n",
            "H-219\t-0.22629369795322418\t▁ G a l u ▁ w a k u d a ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-219\t-0.22629369795322418\tGalu wakuda akudumpha mumlengalenga pa chipale chofewa .\n",
            "P-219\t-0.1278 -0.0438 -0.1038 -0.0782 -0.0763 -0.1282 -0.1024 -0.1122 -0.0728 -0.1349 -0.0741 -0.1006 -0.1512 -0.1261 -0.0823 -0.0936 -0.4013 -0.0690 -0.1107 -0.0414 -0.0297 -0.1259 -0.1411 -0.5917 -0.2321 -2.2299 -0.2163 -0.2285 -0.2357 -0.0515 -0.0826 -0.0216 -0.0674 -0.0759 -0.0826 -0.0683 -0.2153 -0.5499 -0.1370 -0.5545 -0.0341 -0.0571 -0.1274 -0.9938 -0.1067 -0.0486 -0.0794 -0.0947 -0.0205 -0.0933 -0.0619 -1.0604 -0.0744 -0.1144 -0.1022 -0.3180 -1.4625 -0.1079\n",
            "T-69\tAmuna amene ali m'ngalawa akukonza zitsulo ndipo akuyang'ana m'mwamba .\n",
            "H-69\t-0.2648390829563141\t▁ A m u n a ▁ a m e n e ▁ a l i ▁ m ' m a k h a l a ▁ o v a l a ▁ z a z i k u l u ▁ n d i p o ▁ a k u y a n g ' a n a ▁ m w a m b a ▁ .\n",
            "D-69\t-0.2648390829563141\tAmuna amene ali m'makhala ovala zazikulu ndipo akuyang'ana mwamba .\n",
            "P-69\t-0.1225 -0.0510 -0.0879 -0.0953 -0.1011 -0.0869 -0.1394 -0.1776 -1.1568 -0.2211 -0.0912 -0.0672 -0.1640 -0.0748 -0.3658 -0.1045 -0.1185 -0.2587 -0.2445 -0.5109 -0.1160 -0.9537 -0.6531 -0.1112 -0.0568 -0.1184 -0.1239 -0.6912 -1.2635 -0.1234 -0.1024 -0.1067 -0.1292 -0.0410 -0.1423 -0.7701 -0.1247 -0.2328 -0.1480 -0.0715 -0.2083 -0.1546 -0.5517 -0.0723 -0.1191 -0.4165 -0.0837 -0.1096 -0.1110 -0.0416 -0.0797 -0.1143 -0.1254 -0.0859 -0.2084 -0.0609 -0.0898 -0.0777 -0.0978 -0.1271 -0.4002 -2.6565 -0.0857 -0.4054 -0.6882 -0.0892 -0.4151 -0.1762 -0.1026\n",
            "T-272\tGalu wakuda pabwalo la udzu akugwira mpira wabuluu ndi wofiira mkamwa mwake .\n",
            "H-272\t-0.2215721756219864\t▁ G a l u ▁ w a k u d a ▁ w a v a l a ▁ b u l u u ▁ a k u g w i r a ▁ m p i r a ▁ w a ▁ b u l u u ▁ n d i ▁ m k a m w a ▁ m w a k e ▁ .\n",
            "D-272\t-0.2215721756219864\tGalu wakuda wavala buluu akugwira mpira wa buluu ndi mkamwa mwake .\n",
            "P-272\t-0.1229 -0.0896 -0.1156 -0.0710 -0.1143 -0.1300 -0.0330 -0.1110 -0.0932 -0.0897 -0.0615 -0.1156 -0.1708 -0.5302 -0.1304 -1.5142 -0.1424 -0.0702 -0.1168 -0.1091 -1.0367 -0.0789 -0.0829 -0.2900 -0.0548 -0.1418 -0.8234 -0.2029 -0.0921 -0.4349 -0.1007 -0.1163 -0.0864 -0.1005 -0.1063 -0.4763 -0.0391 -0.1200 -0.0889 -0.1178 -0.1518 -0.3006 -0.1170 -0.9653 -0.0681 -0.0695 -0.0693 -0.1501 -0.0904 -0.1320 -0.1508 -0.0659 -0.1270 -0.0920 -1.4226 -0.3384 -0.0873 -0.1877 -0.1838 -0.0853 -0.1327 -0.2447 -0.2440 -0.1080 -0.3697 -0.1160 -0.2560 -0.3439 -0.0964\n",
            "T-381\tmnyamata wamng'ono wovala malaya abuluu ndi chisoti chofiira atakwera njinga m'mphepete mwa msewu\n",
            "H-381\t-0.14697779715061188\t▁ M n y a m a t a ▁ w a m n g ' o n o ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ c h i s o t i ▁ c h o f i i r a ▁ a t a k w e r a ▁ n j i n g a ▁ m ' m p h e p e t e ▁ m w a ▁ m s e w u ▁ .\n",
            "D-381\t-0.14697779715061188\tMnyamata wamng'ono wovala malaya abuluu ndi chisoti chofiira atakwera njinga m'mphepete mwa msewu .\n",
            "P-381\t-0.1265 -0.0617 -0.1054 -0.0786 -0.0917 -0.0809 -0.0984 -0.0619 -0.0943 -0.1249 -0.1480 -0.1225 -0.3534 -0.0769 -0.1251 -0.0763 -0.1290 -0.0724 -0.0823 -0.1379 -0.0609 -0.7775 -0.3620 -0.1164 -0.0961 -0.1136 -0.1009 -0.0731 -0.1328 -0.0640 -0.1206 -0.1178 -0.1064 -0.1091 -0.1617 -0.1395 -0.0635 -0.0801 -0.0600 -0.0425 -0.1098 -0.3555 -0.1168 -0.1489 -0.0930 -0.2055 -0.0716 -0.1607 -0.1854 -0.0644 -0.0736 -0.0781 -0.0984 -0.0688 -0.0831 -0.1098 -0.0182 -0.1058 -0.7952 -0.0635 -0.2274 -0.1715 -0.0837 -0.2154 -0.1063 -0.2946 -0.2147 -0.0770 -0.0936 -0.1040 -0.1111 -0.1577 -0.0117 -0.0950 -0.0789 -0.0261 -0.0924 -0.0944 -0.4055 -0.5752 -0.2151 -0.0117 -0.0232 -0.0973 -0.0285 -0.0707 -0.0394 -0.1101 -0.0928 -0.0370 -0.0281 -0.1070 -0.1132 -0.2853 -1.4069 -0.0800 -0.1162 -0.0490 -0.4148 -0.0219 -0.1076\n",
            "T-263\tMwamuna wa blond wovala malaya oyera waima kutsogolo kwa maikolofoni ndi gitala .\n",
            "H-263\t-0.19734542071819305\t▁ M w a m u n a ▁ w a ▁ b l o n d ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ w a i m a ▁ k u t s o g o l o ▁ k w a ▁ m a i k o l o f o n i ▁ n d i ▁ t a l a l a ▁ .\n",
            "D-263\t-0.19734542071819305\tMwamuna wa blond wovala malaya oyera waima kutsogolo kwa maikolofoni ndi talala .\n",
            "P-263\t-0.1155 -0.0671 -0.1087 -0.1140 -0.2449 -0.1096 -0.0985 -0.0998 -0.1234 -0.2058 -0.3051 -0.7364 -2.0066 -0.1757 -0.1242 -0.1071 -0.1782 -0.2381 -0.0272 -0.1214 -0.0406 -0.1160 -0.1051 -0.1181 -0.0988 -0.0648 -0.1230 -0.0799 -0.1065 -0.0830 -0.1041 -0.1111 -0.0510 -0.0976 -0.0667 -0.0941 -0.0989 -0.1605 -0.9966 -0.1536 -0.1395 -0.0434 -0.0881 -0.0720 -0.0891 -0.0966 -0.0257 -0.0407 -0.0589 -0.0307 -0.1196 -0.0543 -0.0708 -0.0744 -0.0221 -0.1094 -0.1107 -0.1486 -0.1140 -0.1070 -0.2389 -0.0395 -0.1738 -0.8120 -0.0542 -0.0123 -0.1028 -0.0506 -0.0622 -0.1180 -0.3249 -0.1015 -0.1322 -0.0810 -0.6387 -0.3045 -0.2852 -0.1658 -0.8024 -0.1231 -1.4081 -0.4517 -0.1038\n",
            "T-136\tMnyamata amachita zamatsenga pa skateboard yake pamalo omwe ali ndi zolemba zambiri.\n",
            "H-136\t-0.19476395845413208\t▁ M n y a m a t a ▁ a m a c h i t a ▁ z a m a s e n g a ▁ p a ▁ s k a t e b o a r d ▁ p a m a l o ▁ o m w e ▁ a l i ▁ n d i ▁ z o l e m b a ▁ z a m b i r i ▁ .\n",
            "D-136\t-0.19476395845413208\tMnyamata amachita zamasenga pa skateboard pamalo omwe ali ndi zolemba zambiri .\n",
            "P-136\t-0.1279 -0.0749 -0.0769 -0.0621 -0.0949 -0.0729 -0.0952 -0.0913 -0.0975 -0.1137 -0.4303 -0.9651 -0.1337 -0.5848 -0.0683 -0.0907 -0.0751 -0.0913 -0.1234 -0.1598 -0.1504 -0.1577 -0.1228 -1.3597 -0.0368 -0.5355 -0.1458 -0.0918 -0.1555 -0.0754 -0.1373 -0.1957 -0.1256 -0.1399 -0.1061 -0.0220 -0.0371 -0.1362 -0.0932 -0.0882 -0.0512 -0.0132 -0.4258 -2.0471 -0.1653 -0.3489 -0.1568 -0.0798 -0.0363 -0.0780 -0.0576 -0.1596 -0.1922 -0.0809 -0.1118 -0.1138 -0.0382 -0.1206 -0.0987 -0.0973 -0.2076 -0.1235 -0.0666 -0.0984 -0.1493 -0.0625 -0.0834 -0.1082 -0.0621 -0.1138 -0.3973 -0.2224 -0.1872 -0.3533 -0.1820 -0.1164 -0.0605 -0.0779 -0.9275 -0.0472 -0.1136\n",
            "T-288\tGalu wabulauni ndi wakuda akugona pa chipale chofewa atavala vest ya lalanje .\n",
            "H-288\t-0.28482189774513245\t▁ G u l u ▁ l a ▁ a m u n t h u ▁ l i k u j a m b u l a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ a t a v a l a ▁ j e r s i ▁ y o y e r a ▁ y a ▁ n j e r w a ▁ .\n",
            "D-288\t-0.28482189774513245\tGulu la amunthu likujambula pa chipale chofewa atavala jersi yoyera ya njerwa .\n",
            "P-288\t-0.0981 -1.8834 -0.3379 -0.0994 -0.0720 -0.1134 -0.0889 -0.1078 -0.0822 -0.5497 -0.2059 -0.2680 -0.1448 -0.9462 -0.1506 -0.1178 -0.1154 -1.0361 -2.4163 -0.4578 -0.0870 -0.8239 -0.0781 -0.7090 -0.0942 -0.0565 -0.0658 -0.1190 -0.1554 -0.4552 -0.1686 -0.4482 -0.1932 -0.1023 -0.0708 -0.1129 -0.1079 -0.0631 -0.0752 -0.0898 -0.0103 -0.0987 -0.0636 -0.0122 -0.0604 -0.0350 -0.1223 -0.2202 -0.1233 -0.1095 -0.1009 -0.0687 -0.1208 -0.1011 -0.1050 -0.1027 -1.7533 -0.0535 -0.8828 -0.2774 -0.1632 -0.1378 -0.0449 -0.5161 -0.3825 -0.0558 -0.2086 -0.1064 -0.1872 -0.9862 -0.5193 -0.3351 -0.3332 -0.0687 -0.1888 -0.0646 -0.3811 -0.0675 -0.2960 -0.1297 -0.1076\n",
            "T-298\tmayi wovala malaya apinki akuseweretsa galu wotuwa ndi woyera pagombe\n",
            "H-298\t-0.2270006239414215\t▁ M a y i ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a k u s e w e r e t s a ▁ g a l u ▁ w a n t h u ▁ w o y e r a ▁ p a g u l u ▁ .\n",
            "D-298\t-0.2270006239414215\tMayi wovala malaya apinki akuseweretsa galu wanthu woyera pagulu .\n",
            "P-298\t-0.1209 -0.0875 -0.0890 -0.0524 -0.1044 -0.1171 -0.1321 -0.1402 -0.1546 -0.1249 -0.0720 -0.1216 -0.1093 -0.0538 -0.1763 -0.0823 -0.1130 -0.0590 -0.1021 -0.0998 -0.2199 -0.5355 -0.1674 -0.0421 -0.0343 -0.1088 -0.1011 -0.1921 -0.0636 -0.0885 -0.1449 -0.0529 -0.4011 -0.0683 -0.1377 -0.8897 -0.0586 -0.0466 -0.1094 -0.1195 -1.3422 -0.1525 -0.0676 -0.1419 -0.0991 -0.0409 -0.5350 -0.5829 -0.1088 -0.0594 -0.1000 -0.1046 -0.5481 -0.0397 -0.0316 -0.1351 -0.3353 -0.1017 -0.1841 -0.0285 -0.1285 -2.5827 -0.3925 -1.1804 -0.1498 -0.1504 -0.3105 -0.1080\n",
            "T-416\tMunthu wovala zakuda ndi zoyera wanyamula chikwangwani chake cha tenisi kudikirira mpira.\n",
            "H-416\t-0.2524564564228058\t▁ M u n t h u ▁ w o v a l a ▁ z a k u d a ▁ n d i ▁ z o y e r a ▁ w a n y a m u l a ▁ c h i n g w a n i ▁ c h a ▁ t e n i s i ▁ k u m e n y e t s a ▁ m p i r a ▁ .\n",
            "D-416\t-0.2524564564228058\tMunthu wovala zakuda ndi zoyera wanyamula chingwani cha tenisi kumenyetsa mpira .\n",
            "P-416\t-0.1266 -0.0623 -0.0325 -0.0648 -0.0694 -0.0645 -0.0864 -0.1374 -0.0894 -0.2499 -0.0592 -0.1351 -0.0876 -0.1134 -0.1010 -0.0617 -0.1249 -0.2871 -0.0798 -0.7100 -0.1281 -0.1347 -0.1720 -0.2208 -0.0874 -0.0896 -0.1174 -0.1021 -0.1293 -0.1019 -0.0542 -0.0935 -0.1561 -0.1192 -0.1122 -0.0702 -0.0330 -0.0935 -0.1044 -0.0563 -0.0662 -0.0921 -0.0984 -0.0736 -0.0679 -0.0856 -0.1464 -0.6352 -0.0699 -0.6942 -0.0749 -0.0998 -0.1050 -0.0592 -0.1000 -0.1245 -0.1629 -2.8771 -0.0595 -0.1645 -0.1689 -0.1164 -0.3288 -0.1084 -0.3716 -0.0965 -1.8574 -1.0261 -0.2624 -0.6704 -0.0669 -0.8855 -0.1029 -1.0190 -0.1086 -0.5990 -0.3305 -0.7536 -0.0601 -0.1038 -0.4390 -0.5914 -0.1107\n",
            "T-73\twosewera mpira wachikazi ali pamzere kuti atenge swing ndi racquet yake.\n",
            "H-73\t-0.3088630139827728\t▁ W o s e w e r a ▁ m p i r a ▁ w a c h i k a z i ▁ a l i ▁ p a n s i ▁ a l i ▁ n d i ▁ c h i n a c h a k e ▁ n d i ▁ m i t e n g o ▁ y a k e ▁ y a ▁ m p i r a .\n",
            "D-73\t-0.3088630139827728\tWosewera mpira wachikazi ali pansi ali ndi chinachake ndi mitengo yake ya mpira.\n",
            "P-73\t-0.1170 -0.1318 -0.1068 -0.0609 -0.0665 -0.1055 -0.1079 -0.0611 -0.1281 -0.1363 -0.0717 -0.1227 -0.0951 -0.0645 -0.1035 -0.1602 -0.1621 -0.1236 -0.7877 -0.1938 -0.0999 -0.1058 -0.1439 -0.7533 -0.0824 -0.1297 -0.1446 -0.4588 -0.1078 -0.0928 -0.2254 -0.1199 -0.3747 -0.3912 -0.1224 -0.1251 -0.9670 -1.2033 -0.1304 -0.1257 -0.9392 -0.0840 -0.1170 -0.2076 -1.3360 -0.0878 -0.1680 -0.7346 -2.1918 -0.7002 -0.0830 -0.1247 -0.0464 -0.0959 -0.1215 -0.2543 -0.0665 -0.1335 -0.1064 -1.2533 -1.1235 -0.2384 -0.1298 -0.1444 -0.3704 -0.0761 -0.1426 -0.1328 -0.1732 -0.8734 -0.0414 -0.3050 -0.4946 -0.2022 -0.4121 -0.7627 -0.3797 -0.1169 -0.2544 -0.1390 -1.0480 -0.1034\n",
            "T-392\tAna ovala zovala zamitundumitundu akusewera pasiteji pafupi ndi nyumba yoyera .\n",
            "H-392\t-0.14943847060203552\t▁ A n a ▁ o v a l a ▁ z o v a l a ▁ z a m i t u n d u m i t u n d u ▁ a k u s e w e r a ▁ p a ▁ s i t e j i ▁ p a f u p i ▁ n d i ▁ m a i k o l o f o n i ▁ .\n",
            "D-392\t-0.14943847060203552\tAna ovala zovala zamitundumitundu akusewera pa siteji pafupi ndi maikolofoni .\n",
            "P-392\t-0.1198 -0.0622 -0.0726 -0.1735 -0.1446 -0.1067 -0.0912 -0.1396 -0.0853 -0.1305 -0.1157 -0.0206 -0.0914 -0.0329 -0.1188 -0.0704 -0.1132 -0.1054 -0.0137 -0.1663 -0.1087 -0.1202 -0.0121 -0.0690 -0.0737 -0.0261 -0.0642 -0.3487 -0.0600 -0.0527 -0.0624 -0.0572 -0.0245 -0.0698 -0.1594 -0.0685 -0.2251 -0.0805 -0.1923 -0.0474 -0.0959 -0.0876 -0.0767 -0.1304 -0.0935 -0.3014 -0.1640 -0.3367 -0.1911 -0.5598 -0.0539 -0.0499 -0.0268 -0.0775 -0.1302 -0.3947 -0.1217 -0.0960 -0.0848 -0.0723 -0.1171 -0.1189 -0.0778 -0.1045 -0.1249 -0.0965 -0.4903 -0.1260 -0.8592 -1.1757 -0.4224 -0.1003 -0.1128 -0.3011 -0.0567 -0.0684 -0.0714 -0.2187 -0.1739 -0.0967\n",
            "T-177\tAnthu awiriwa anayang'ana zithunzi zapadera zomwe zinali pakhoma .\n",
            "H-177\t-0.2951436936855316\t▁ A n t h u ▁ a w i r i ▁ a t a y i m a ▁ m ' n k h a l a n g o ▁ z a ▁ p e p a l a ▁ z o m w e ▁ z i n a w o n e k a ▁ .\n",
            "D-177\t-0.2951436936855316\tAnthu awiri atayima m'nkhalango za pepala zomwe zinawoneka .\n",
            "P-177\t-0.1121 -0.0319 -0.1236 -0.0357 -0.0803 -0.0950 -0.1299 -0.1391 -0.0872 -0.1140 -0.0541 -0.1008 -0.1775 -0.1072 -0.0221 -0.1194 -0.2680 -0.9896 -0.5867 -0.1179 -0.1103 -0.3609 -0.2939 -1.3165 -0.4191 -0.1411 -0.0820 -0.2200 -0.0974 -0.0704 -0.1540 -0.1366 -0.1754 -0.0454 -0.6204 -0.6542 -1.0441 -0.4346 -0.8549 -0.3103 -0.0288 -0.0961 -0.2036 -0.2547 -0.0641 -0.1309 -0.2748 -0.1275 -0.0931 -0.0210 -0.0745 -0.2760 -0.4191 -2.8778 -0.1036 -0.3716 -0.5344 -0.0851 -0.0910 -0.1675 -0.8682 -0.1021\n",
            "T-368\tMunthu wovala malaya achikasu amakhala m'mphepete mwa thanthwe akuyang'ana pansi\n",
            "H-368\t-0.16535049676895142\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ a m a k h a l a ▁ m ' m p h e p e t e ▁ m w a ▁ a k u y a n g ' a n a ▁ .\n",
            "D-368\t-0.16535049676895142\tMunthu wovala malaya achikasu amakhala m'mphepete mwa akuyang'ana .\n",
            "P-368\t-0.1139 -0.3040 -0.1678 -0.0714 -0.0654 -0.1242 -0.0912 -0.1414 -0.0975 -0.1547 -0.0870 -0.1356 -0.0769 -0.1154 -0.0950 -0.0656 -0.1347 -0.0635 -0.1117 -0.0759 -0.1019 -0.0838 -0.1550 -0.0203 -0.0939 -0.0936 -0.1344 -0.1006 -0.0741 -0.3316 -0.0994 -0.8793 -0.6448 -0.1303 -0.2032 -0.0247 -0.0915 -0.0794 -0.1121 -0.0900 -0.2885 -0.2401 -0.1244 -0.1367 -0.0182 -0.0642 -0.0661 -0.0470 -0.0099 -0.0753 -0.0850 -0.0293 -0.0345 -0.1018 -0.0961 -1.2396 -0.2580 -0.0975 -0.0449 -0.0846 -0.0680 -0.1454 -0.0582 -0.0840 -0.0932 -0.1094 -0.1213 -1.6494 -0.1017\n",
            "T-97\tBambo wina wokwera njinga yalalanje akudumphira mumlengalenga ndi mzere wa mzinda kumbuyo kwake .\n",
            "H-97\t-0.17435412108898163\t▁ B a m b o ▁ w i n a ▁ w o k w e r a ▁ n j i n g a ▁ y a l a l a n j e ▁ a k u d u m p h i r a ▁ m u m l e n g a l e n g a ▁ n d i ▁ m t s i n d a ▁ k u m b u y o ▁ k w a k e ▁ .\n",
            "D-97\t-0.17435412108898163\tBambo wina wokwera njinga yalalanje akudumphira mumlengalenga ndi mtsinda kumbuyo kwake .\n",
            "P-97\t-0.1206 -0.0654 -0.1082 -0.0810 -0.1082 -0.0903 -0.1186 -0.0679 -0.0990 -0.0883 -0.0986 -0.1094 -0.1009 -0.5932 -0.3537 -0.0828 -0.1376 -0.0805 -0.0956 -0.1254 -0.0558 -0.0258 -0.0874 -0.0428 -0.0440 -0.1047 -0.1415 -0.0288 -0.1248 -1.4894 -0.1048 -0.0934 -0.0880 -0.0812 -0.0412 -0.1553 -0.1255 -0.1099 -0.0514 -0.0873 -0.2842 -0.0748 -0.0454 -0.0163 -0.0381 -0.0755 -0.0613 -0.0841 -0.1097 -0.0811 -0.8647 -0.2678 -0.9711 -0.0809 -0.1270 -0.0784 -0.0958 -0.0432 -0.0966 -0.0948 -0.1713 -0.0806 -0.2398 -0.2913 -0.0828 -0.0773 -0.0867 -0.1417 -0.1355 -0.2057 -0.0909 -0.3329 -2.1482 -0.1313 -0.1413 -0.2172 -0.0704 -0.1022 -0.1561 -0.0549 -0.0412 -0.0594 -0.1751 -0.0808 -0.1175 -0.1062 -0.1343 -0.0893 -0.5549 -0.0583 -0.0924\n",
            "T-417\tAnthu angapo akuyang'ana bambo wina yemwe anavala sweti yofiira akusewera gofu .\n",
            "H-417\t-0.17878329753875732\t▁ A n t h u ▁ a n g a p o ▁ a k u y a n g ' a n a ▁ p a m b u y o ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ s w e t i ▁ y o f i i r a ▁ a k u s e w e r a ▁ .\n",
            "D-417\t-0.17878329753875732\tAnthu angapo akuyang'ana pambuyo wina yemwe wavala sweti yofiira akusewera .\n",
            "P-417\t-0.1250 -0.0738 -0.1928 -0.0530 -0.0957 -0.0768 -0.1000 -0.1154 -0.0761 -0.0432 -0.0887 -0.0135 -0.0685 -0.1129 -0.0672 -0.0932 -0.0812 -0.0507 -0.1199 -0.0785 -0.1290 -0.0766 -0.0877 -0.0600 -0.1005 -0.1126 -0.1975 -0.1211 -0.7511 -1.1444 -0.3838 -0.1266 -0.1138 -0.1180 -0.2945 -0.0807 -0.0977 -0.0996 -0.1595 -0.6187 -0.0181 -0.0756 -0.1678 -0.0903 -0.0790 -0.6513 -0.0995 -0.2151 -0.1005 -0.1015 -0.1257 -0.0983 -0.0697 -0.2794 -0.0724 -0.0505 -0.0840 -0.1153 -0.0346 -0.1455 -0.0519 -0.0955 -0.5012 -0.0636 -0.1432 -0.2257 -0.1000 -0.0656 -0.0936 -0.3090 -0.0653 -0.1804 -0.1239 -0.1107 -0.1074 -0.1772 -2.1591 -0.0982\n",
            "T-394\tMayi wina atavala diresi ya plaid ataima m'mphepete mwa msewu pafupi ndi galu woyera\n",
            "H-394\t-0.19506444036960602\t▁ M a y i ▁ w i n a ▁ a t a v a l a ▁ d i r e s i ▁ y a k u d a ▁ a i m a ▁ m ' m p h e p e t e ▁ m w a ▁ m s e w u ▁ p a f u p i ▁ n d i ▁ g a l u ▁ w o y e r a ▁ .\n",
            "D-394\t-0.19506444036960602\tMayi wina atavala diresi yakuda aima m'mphepete mwa msewu pafupi ndi galu woyera .\n",
            "P-394\t-0.1292 -0.1012 -0.1016 -0.0411 -0.0879 -0.1125 -0.0592 -0.1079 -0.0875 -0.1126 -0.1097 -0.0693 -0.0182 -0.1125 -0.0344 -0.1061 -0.0879 -0.1150 -0.1022 -0.9133 -0.0759 -0.0176 -0.0990 -0.0320 -0.0532 -0.0817 -0.5762 -0.1285 -3.3000 -0.2402 -0.3585 -0.0866 -0.1639 -0.2593 -2.2201 -0.2361 -0.1507 -0.0976 -0.8716 -0.0894 -0.1096 -0.0331 -0.0230 -0.0490 -0.0397 -0.0533 -0.0359 -0.0687 -0.0814 -0.0363 -0.0689 -0.0954 -0.1238 -0.0797 -0.0613 -0.0924 -0.0712 -0.0652 -0.1311 -0.0789 -0.1086 -0.0493 -0.1160 -0.0679 -0.0877 -0.0810 -0.0752 -0.0882 -0.1032 -0.0713 -0.2498 -0.1189 -0.0443 -0.0833 -0.1363 -0.1026 -0.2170 -0.1429 -0.1529 -0.1711 -0.0988 -0.7335 -0.0413 -0.0990\n",
            "T-171\tAnyamata anayi akusewera mpira kutsogolo kwa zitseko zazikulu zokongola .\n",
            "H-171\t-0.20727182924747467\t▁ A n y a m a t a ▁ a n a y i ▁ a k u s e w e r a ▁ m p i r a ▁ k u t s o g o l o ▁ k w a ▁ z e n e ▁ z a z i k u l u ▁ z o k o n g o l a ▁ .\n",
            "D-171\t-0.20727182924747467\tAnyamata anayi akusewera mpira kutsogolo kwa zene zazikulu zokongola .\n",
            "P-171\t-0.1262 -1.2055 -0.0784 -0.0433 -0.0888 -0.1146 -0.1015 -0.0418 -0.1075 -0.1085 -0.1513 -0.0490 -0.1277 -0.0345 -0.1142 -0.1370 -0.1067 -0.1044 -0.0991 -0.3477 -0.0385 -0.1757 -0.0898 -0.0698 -0.1360 -0.1204 -0.2931 -0.0415 -0.1513 -0.1193 -0.1108 -0.1403 -0.4660 -0.0682 -0.4665 -0.1539 -0.0448 -0.0236 -0.1081 -0.0522 -0.0643 -0.1037 -0.0580 -0.1637 -0.1342 -0.1190 -0.0695 -0.1974 -2.2951 -0.2257 -2.6480 -0.0559 -0.3056 -0.2373 -0.0840 -0.0699 -0.1777 -0.0361 -0.0984 -0.1760 -0.0681 -0.2797 -0.1120 -0.1319 -0.0770 -0.0125 -0.0555 -0.0587 -0.1171 -0.3386 -0.0837 -0.1119\n",
            "T-379\tBambo wina akumenya mpira wa tenesi pa mpikisano wa akatswiri .\n",
            "H-379\t-0.3087899386882782\t▁ B a m b o ▁ w i n a ▁ a k u m e n y a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ p a ▁ s k a t e b o a r d ▁ p a k a t i ▁ .\n",
            "D-379\t-0.3087899386882782\tBambo wina akumenya mpira wa tenisi pa skateboard pakati .\n",
            "P-379\t-0.1276 -0.0481 -0.1158 -0.0923 -0.0882 -0.0689 -0.1271 -0.0872 -0.1223 -0.0890 -0.1072 -0.1105 -0.8193 -0.1363 -0.1112 -0.2049 -0.2778 -0.2363 -0.1755 -0.1059 -0.1319 -0.7312 -0.1043 -0.1604 -0.1259 -0.2066 -0.1379 -0.0580 -0.1294 -0.1894 -0.2123 -0.3404 -0.1312 -0.4282 -0.0278 -0.4372 -0.0864 -0.0981 -0.1204 -0.4154 -0.8306 -3.0974 -0.1081 -0.0375 -0.1051 -0.2204 -0.0809 -0.1132 -0.0313 -0.0905 -0.3259 -3.0912 -0.1522 -0.8636 -0.1240 -0.0979 -0.1178 -0.2236 -1.1826 -0.1095\n",
            "T-332\tMayi wina wa ku Asia wakhala pansi pakati pa zinyalala zamatabwa atanyamula ndodo .\n",
            "H-332\t-0.1885526031255722\t▁ M a y i ▁ w i n a ▁ w a ▁ k u ▁ A s i a ▁ w a k h a l a ▁ p a n s i ▁ p a ▁ z i n y a l a l a ▁ z a m a t a b w a ▁ a t a n y a m u l a ▁ n d o d o ▁ .\n",
            "D-332\t-0.1885526031255722\tMayi wina wa ku Asia wakhala pansi pa zinyalala zamatabwa atanyamula ndodo .\n",
            "P-332\t-0.1214 -0.5810 -0.2564 -0.0693 -0.0810 -0.1344 -0.1087 -0.0992 -0.0980 -0.1081 -0.1088 -0.5446 -0.1487 -0.4010 -0.0557 -0.0540 -0.0160 -0.2454 -0.1051 -0.0992 -0.1091 -0.1419 -0.3055 -0.2325 -0.1416 -0.1408 -0.1036 -0.0524 -0.1122 -0.1093 -0.0289 -0.1223 -0.5879 -0.1598 -0.1205 -0.1388 -0.1743 -0.1235 -0.2207 -0.9768 -0.1083 -0.0518 -0.1513 -0.0960 -0.0652 -0.1329 -0.0467 -0.1170 -0.1431 -1.2315 -0.1391 -1.6727 -0.1617 -0.0619 -0.2347 -0.0334 -0.0244 -0.0977 -0.1598 -0.1075 -0.3919 -0.0972 -0.0762 -0.0189 -0.0868 -0.0836 -0.0985 -0.0770 -0.0975 -0.1260 -0.1701 -0.5310 -0.0512 -0.0032 -0.0549 -0.2119 -0.0580 -0.0978\n",
            "T-9\tGalu akupalasa chipika chomwe chagwa pafupi ndi mtsinje pamalo omwe pali udzu .\n",
            "H-9\t-0.2763623595237732\t▁ G a l u ▁ a k u k w e r a ▁ c h i p i k a ▁ c h o m w e ▁ c h i l i ▁ p a f u p i ▁ n d i ▁ n s i n j e ▁ p a m a l o ▁ o m w e ▁ a l i ▁ p a m o d z i ▁ .\n",
            "D-9\t-0.2763623595237732\tGalu akukwera chipika chomwe chili pafupi ndi nsinje pamalo omwe ali pamodzi .\n",
            "P-9\t-0.1187 -0.0787 -0.1069 -0.0661 -0.0821 -0.1284 -0.2216 -0.0686 -0.0792 -0.4015 -1.3228 -0.1659 -0.0665 -0.1183 -0.1467 -0.7664 -0.1587 -0.0809 -1.4096 -0.3139 -0.6863 -0.1445 -0.3878 -0.0716 -0.1137 -0.9370 -0.0557 -0.0387 -0.0818 -0.0884 -0.0246 -0.0675 -0.2551 -1.2041 -0.1131 -0.1143 -1.0701 -0.1316 -0.4822 -0.0509 -0.0662 -0.1114 -0.1001 -0.0448 -0.0684 -0.0934 -0.0998 -0.7261 -0.3044 -0.4410 -0.1927 -0.0347 -0.7560 -0.1595 -0.1240 -0.1551 -0.1623 -0.1469 -0.0390 -0.0446 -0.1163 -0.0973 -0.0756 -0.1544 -0.0971 -0.1195 -0.7206 -0.1759 -0.0881 -0.1099 -0.5692 -0.1590 -1.1211 -1.2998 -0.3690 -0.0710 -0.0873 -0.6219 -0.0648 -0.1005\n",
            "T-277\tMnyamata akukwera njinga pamwamba pa msewu wa mtawuni pafupi ndi njanji .\n",
            "H-277\t-0.19684788584709167\t▁ M n y a m a t a ▁ a k u k w e r a ▁ n j i n g a ▁ p a m w a m b a ▁ p a ▁ m u t u ▁ w a m i t u n d u ▁ p a f u p i ▁ n d i ▁ n j a n j i ▁ .\n",
            "D-277\t-0.19684788584709167\tMnyamata akukwera njinga pamwamba pa mutu wamitundu pafupi ndi njanji .\n",
            "P-277\t-0.1201 -0.3214 -0.0517 -0.0333 -0.0972 -0.0692 -0.0976 -0.0526 -0.1008 -0.1332 -0.1854 -0.0745 -0.0793 -0.1276 -0.1320 -0.0660 -0.0773 -0.1114 -0.1095 -0.0633 -0.0905 -0.0815 -0.0363 -0.0471 -0.0840 -0.1243 -0.7773 -0.2034 -0.6337 -0.0417 -0.0803 -0.0557 -0.0771 -0.0940 -0.1079 -0.0174 -0.1209 -0.0944 -0.2908 -0.1214 -0.9845 -0.1212 -0.0892 -0.5602 -0.1141 -1.5324 -0.3253 -0.0989 -0.7735 -0.1147 -0.0412 -0.0880 -0.1951 -0.4613 -0.1359 -0.2630 -0.0683 -0.0440 -0.0925 -0.1339 -0.0538 -0.0691 -0.0968 -0.0714 -1.4285 -0.0682 -0.0990 -0.0633 -0.0534 -0.0547 -0.5581 -0.1342 -0.0989\n",
            "T-45\tGalu wabulauni wokhala ndi kolala wakuda anyambita pakamwa pake .\n",
            "H-45\t-0.25441819429397583\t▁ G a l u ▁ w a b u l a u n i ▁ w o k h a l a ▁ n d i ▁ w o l a l a ▁ a k u j a m b u l i d w a ▁ a t a k h a l a ▁ p a m o d z i ▁ .\n",
            "D-45\t-0.25441819429397583\tGalu wabulauni wokhala ndi wolala akujambulidwa atakhala pamodzi .\n",
            "P-45\t-0.1231 -0.0867 -0.1058 -0.0829 -0.0630 -0.1349 -0.0572 -0.4430 -1.0296 -0.0662 -0.0447 -0.0812 -0.0557 -0.0591 -0.0740 -0.1194 -0.0687 -0.1829 -0.0641 -0.0196 -0.1081 -0.0603 -0.0985 -0.1051 -0.0541 -0.1370 -0.0855 -0.1279 -1.3744 -0.2226 -0.8405 -0.1185 -0.2006 -0.0970 -0.1778 -1.4112 -0.1528 -0.0826 -1.2718 -0.1016 -0.0781 -0.1173 -0.1181 -0.0840 -1.0000 -0.2463 -0.0827 -0.1134 -0.1211 -1.4189 -0.6240 -0.1254 -0.1546 -0.0416 -0.1157 -0.0979 -0.1045 -0.1061 -0.1138 -0.1283 -0.8681 -0.3399 -0.4857 -0.2019 -0.1062 -0.2492 -0.1647 -0.1030\n",
            "T-125\tMwamuna akuyendetsa moped ndi chisamaliro chakumbali ndi jeepney kumbuyo .\n",
            "H-125\t-0.30915144085884094\t▁ M w a m u n a ▁ a k u y e n d e t s a ▁ m p i r a ▁ n d i ▁ c h i s a n u ▁ c h a k u m b a l i ▁ m ' n y e n g o ▁ y o k o n g o l e t s e d w a ▁ .\n",
            "D-125\t-0.30915144085884094\tMwamuna akuyendetsa mpira ndi chisanu chakumbali m'nyengo yokongoletsedwa .\n",
            "P-125\t-0.1171 -0.0820 -0.0539 -0.0861 -0.0844 -0.0806 -0.1048 -0.0944 -0.1266 -0.5815 -0.0419 -0.0870 -0.4871 -0.0581 -0.6339 -0.0303 -0.0329 -0.0133 -0.0352 -0.1078 -0.0945 -1.6162 -1.4578 -0.3509 -0.3010 -0.1454 -0.1726 -1.0529 -0.1746 -0.1070 -0.1128 -0.0515 -0.0938 -0.1034 -0.2183 -0.1602 -1.4705 -0.2100 -0.0849 -0.3411 -0.1160 -0.1431 -1.5089 -0.1039 -0.0798 -0.1046 -0.1358 -0.2159 -0.1172 -0.1311 -0.7999 -0.3012 -1.0365 -0.0632 -0.1405 -0.0608 -0.3374 -0.0354 -0.1441 -0.4345 -0.8378 -0.5409 -1.1145 -0.0833 -0.0559 -0.0330 -0.1103 -0.2356 -0.9180 -0.2652 -0.3516 -1.0158 -0.1568 -0.0809 -0.4689 -0.1831 -0.0852\n",
            "T-160\tAzimayi awiri ali ndi ngolo m'nyumba yomwe ili pafupi ndi tebulo ndi mipando.\n",
            "H-160\t-0.23430411517620087\t▁ A t s i k a n a ▁ a w i r i ▁ a l i ▁ n d i ▁ n d o d o ▁ m ' n y u m b a ▁ y o m w e ▁ i l i ▁ p a f u p i ▁ n d i ▁ t e b u l o ▁ n d i ▁ p a n d o ▁ .\n",
            "D-160\t-0.23430411517620087\tAtsikana awiri ali ndi ndodo m'nyumba yomwe ili pafupi ndi tebulo ndi pando .\n",
            "P-160\t-0.1173 -0.6200 -0.4246 -0.1127 -0.0802 -0.2633 -0.0889 -0.1007 -0.0858 -0.5089 -0.2093 -0.0886 -0.1201 -0.0642 -0.0930 -0.1538 -0.1406 -0.1778 -0.0926 -0.1151 -0.1428 -0.0745 -0.0834 -0.0869 -0.6961 -0.2470 -0.9870 -0.6808 -0.0493 -0.1376 -0.4561 -0.2361 -1.1373 -0.0234 -0.2325 -0.1097 -0.0962 -0.0909 -0.1295 -0.1364 -0.1204 -0.1177 -0.0837 -0.0502 -0.0816 -0.1229 -0.0415 -0.0838 -0.0836 -0.1428 -0.1229 -0.0213 -0.0753 -0.1182 -0.0851 -0.1063 -0.0743 -0.0686 -0.0812 -0.1068 -0.9907 -0.2046 -0.9039 -0.0786 -0.1073 -0.0437 -0.1038 -0.5990 -0.0567 -0.0839 -0.3695 -1.6579 -0.2159 -0.3580 -0.5151 -0.0396 -0.5175 -0.2841 -0.1013\n",
            "T-192\tMwana akudumpha pa trampoline kutsogolo kwa khoma la njerwa ndi pansi pa mbendera zamitundu .\n",
            "H-192\t-0.3473605513572693\t▁ M w a n a ▁ a k u d u m p h a ▁ p a ▁ c h i n g w e ▁ c h o v a l a ▁ k o m a n s o ▁ m k a z i ▁ w a ▁ m k a z i ▁ p a m b e n d e r a ▁ z a m t u n d u ▁ .\n",
            "D-192\t-0.3473605513572693\tMwana akudumpha pa chingwe chovala komanso mkazi wa mkazi pambendera zamtundu .\n",
            "P-192\t-0.1292 -0.0696 -0.8313 -0.1457 -0.0555 -0.0997 -0.1540 -0.1629 -0.0850 -0.0909 -0.2742 -0.0508 -0.1325 -0.1542 -0.1250 -0.0725 -0.1852 -0.6105 -0.1209 -0.5643 -0.1034 -0.1115 -3.0732 -0.1478 -0.3087 -0.1699 -0.1075 -0.3092 -0.9550 -0.1420 -0.2889 -1.6201 -0.1038 -0.1000 -0.1002 -0.1232 -0.4721 -0.5221 -0.0573 -0.1055 -0.5389 -0.1626 -0.0844 -0.0833 -0.1876 -2.0488 -0.0992 -0.3234 -0.1042 -0.1361 -0.6472 -0.1398 -1.3041 -1.4365 -0.9438 -0.1318 -0.2749 -0.1109 -0.1326 -0.2189 -0.1252 -0.1519 -0.8062 -0.0834 -0.0473 -0.1424 -0.2452 -0.0324 -0.1175 -0.1658 -0.0395 -0.2857 -0.3188 -2.0942 -0.0605 -0.0955 -0.1818 -0.1268 -0.5548 -0.2115 -0.1053\n",
            "T-271\tGalu wakuda mkati mwa nyumba akuyang'ana chinthu chapamwamba.\n",
            "H-271\t-0.27819767594337463\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ k a b u d u l a ▁ a k u y a n g ' a n a ▁ c h i n t h u ▁ p a m w a m b a ▁ p a ▁ m w a m b a ▁ .\n",
            "D-271\t-0.27819767594337463\tGalu wakuda ndi kabudula akuyang'ana chinthu pamwamba pa mwamba .\n",
            "P-271\t-0.1223 -0.0755 -0.1107 -0.0740 -0.0641 -0.1233 -0.0471 -0.1058 -0.1128 -0.0916 -0.1453 -0.3235 -0.1319 -0.5771 -0.1403 -0.1069 -0.0587 -0.4110 -0.1927 -2.8465 -0.2270 -0.3615 -0.1197 -0.1037 -0.0826 -0.1250 -0.1943 -0.3863 -0.0899 -2.4701 -0.1173 -0.0941 -0.0602 -0.0863 -0.0932 -0.0788 -0.0942 -0.0745 -0.1200 -0.0989 -0.2129 -0.1781 -0.1000 -0.1039 -0.0959 -0.1626 -1.6634 -0.1457 -0.1624 -0.1291 -0.0979 -0.0753 -0.1021 -0.0912 -0.2387 -0.1697 -0.1442 -0.1763 -0.2814 -1.1907 -0.0916 -0.2085 -0.3315 -0.0919 -0.4736 -0.8729 -0.1092\n",
            "T-310\tBambo wina wachikulire akugulitsa chakudya pasitolo kwa mnyamata wina .\n",
            "H-310\t-0.20819982886314392\t▁ B a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ a k u g u l i t s a ▁ c h a k u d y a ▁ p a ▁ s i t o l o ▁ k w a ▁ m n y a m a t a ▁ w i n a .\n",
            "D-310\t-0.20819982886314392\tBambo wina wachikulire akugulitsa chakudya pa sitolo kwa mnyamata wina.\n",
            "P-310\t-0.1347 -0.0461 -0.1118 -0.0860 -0.0770 -0.0744 -0.1688 -0.0792 -0.1196 -0.1062 -0.1011 -0.1186 -0.0599 -0.1533 -0.0632 -0.0775 -0.0973 -0.1306 -0.0778 -0.1024 -0.0713 -0.0597 -0.0707 -0.1279 -0.0682 -0.1141 -0.1220 -0.0506 -0.1048 -0.1689 -0.0701 -0.0271 -0.0861 -0.1027 -0.0795 -0.0801 -0.0725 -0.4348 -0.5981 -0.0754 -0.1178 -0.5559 -0.1221 -0.1353 -0.0204 -0.1423 -1.9081 -0.9047 -0.2841 -0.0642 -0.0566 -0.0775 -0.0793 -0.1430 -0.3390 -0.0559 -0.1202 -0.2690 -0.2491 -0.1981 -0.0620 -0.1049 -0.0593 -0.0793 -0.0640 -0.1158 -0.2233 -0.1563 -0.0905 -0.0648 -0.1010 -3.5747 -0.0897\n",
            "T-322\tAwiri amipanda amachitira limodzi; wina amalumpha pamene wina agwada .\n",
            "H-322\t-0.35104861855506897\t▁ A n y a m a t a ▁ a w i r i ▁ a m a c h i t i r a ▁ m o z u n g u l i r a ▁ m a l u m p h a ▁ p a m e n e ▁ w i n a ▁ a t a g o n a ▁ .\n",
            "D-322\t-0.35104861855506897\tAnyamata awiri amachitira mozungulira malumpha pamene wina atagona .\n",
            "P-322\t-0.1224 -0.0534 -0.9261 -2.3764 -0.1027 -0.1277 -0.1929 -0.2647 -0.1073 -0.1561 -0.1647 -1.8431 -0.1066 -0.0711 -0.0856 -0.2233 -0.7944 -0.4396 -0.1281 -1.2553 -0.0466 -0.1371 -0.0947 -0.1148 -0.4680 -0.1202 -0.1458 -0.4475 -0.4521 -0.4710 -1.6166 -0.0429 -0.1195 -0.1038 -0.0643 -0.0841 -0.0923 -0.0903 -0.1675 -0.8635 -0.2199 -0.7192 -0.2124 -0.2729 -0.2377 -0.0799 -0.1128 -0.2418 -0.0203 -0.1500 -0.0716 -0.0969 -0.0843 -0.1046 -0.1146 -1.6324 -0.1356 -0.1037 -0.0931 -0.1355 -0.0720 -0.5845 -0.1088 -1.4223 -1.2235 -0.0484 -0.1087 -0.2226 -0.5618 -0.0977\n",
            "T-232\tGalu wamkulu wakuda ndi woyera amathamanga m'madzi a m'nyanja\n",
            "H-232\t-0.17973528802394867\t▁ G a l u ▁ w a m k u l u ▁ w a k u d a ▁ n d i ▁ w o y e r a ▁ a m a t h a m a n g a ▁ m ' m a n j a ▁ .\n",
            "D-232\t-0.17973528802394867\tGalu wamkulu wakuda ndi woyera amathamanga m'manja .\n",
            "P-232\t-0.1265 -0.1646 -0.1138 -0.0976 -0.0897 -0.1303 -0.0717 -0.1043 -0.5918 -0.0886 -0.0822 -0.0426 -0.0832 -0.1408 -0.0518 -0.1189 -0.1941 -0.1058 -0.1007 -0.0941 -0.1352 -0.0646 -0.0725 -0.1169 -0.0784 -0.0313 -0.0554 -0.0396 -0.0666 -0.1808 -0.0920 -0.2021 -0.0838 -0.2541 -0.1306 -0.1617 -0.0619 -0.1004 -0.0804 -0.1172 -0.0664 -0.1382 -0.1397 -0.1181 -0.0936 -0.0390 -1.9765 -0.1086 -0.5962 -0.0246 -0.0833 -0.2506 -1.2644 -0.0878\n",
            "T-337\tMnyamata wina amene ali ndi ma dreadlocks akuda atakhala pansi pamene wina akukonza .\n",
            "H-337\t-0.2563400864601135\t▁ M n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ a k u d a ▁ a t a k h a l a ▁ p a n s i ▁ p a m e n e ▁ w i n a ▁ a k u k o n z a ▁ .\n",
            "D-337\t-0.2563400864601135\tMnyamata wina wovala malaya abuluu ndi akuda atakhala pansi pamene wina akukonza .\n",
            "P-337\t-0.1261 -0.0582 -0.0749 -0.0768 -0.1063 -0.0876 -0.1114 -0.0416 -0.1028 -0.1351 -0.1140 -0.1087 -0.1296 -0.1057 -0.1105 -0.5495 -0.1475 -0.9999 -0.1514 -0.0766 -0.1049 -0.1031 -0.0418 -0.3640 -0.1268 -0.1166 -0.0867 -0.0871 -0.1161 -0.1808 -2.6892 -0.1396 -0.1166 -0.1144 -0.0405 -0.1267 -0.4933 -0.0697 -0.1237 -0.0761 -1.7779 -0.1349 -0.2501 -0.0341 -0.1046 -0.1503 -0.1024 -1.2044 -0.1203 -0.2150 -0.1029 -0.1035 -0.0587 -0.1151 -0.0986 -0.0176 -0.1244 -1.7465 -0.0344 -0.1319 -0.1621 -0.0155 -0.1336 -0.7171 -0.0865 -0.0879 -0.0718 -0.1082 -1.9038 -0.1219 -0.1152 -0.1035 -0.1706 -0.1047 -0.0416 -0.1137 -0.2590 -0.1386 -0.2174 -0.0141 -0.1071 -0.2778 -0.9981 -0.1032\n",
            "T-21\tMnyamata akupanga masewera otsetsereka pansi pa masitepe achitsulo .\n",
            "H-21\t-0.22718927264213562\t▁ M n y a m a t a ▁ a k u p a n g a ▁ m a s e w e r a ▁ o s e w e r e t s a ▁ p a n s i ▁ p a ▁ m a s i t e p e ▁ a ▁ c h i t s o l o ▁ .\n",
            "D-21\t-0.22718927264213562\tMnyamata akupanga masewera oseweretsa pansi pa masitepe a chitsolo .\n",
            "P-21\t-0.1299 -0.0537 -0.0758 -0.0385 -0.0900 -0.0774 -0.0939 -0.0579 -0.0933 -0.1061 -0.1573 -0.0750 -0.0880 -0.2172 -0.3031 -1.1027 -0.2997 -0.3270 -0.1269 -0.0816 -0.0613 -0.2724 -0.1295 -0.1144 -0.0786 -0.0856 -0.4888 -0.1344 -0.0258 -0.4689 -0.0499 -0.4744 -0.0676 -0.1069 -0.8546 -0.0323 -0.0326 -0.1527 -0.1146 -0.1780 -0.1475 -0.2364 -0.7316 -0.0861 -0.1149 -0.0299 -0.1709 -0.3799 -0.1041 -0.2956 -0.5162 -0.0637 -0.2522 -0.0336 -0.1059 -0.1479 -0.1320 -0.1411 -1.5079 -0.3630 -0.2537 -0.1021 -0.3839 -0.0752 -0.2904 -0.7623 -0.0526 -0.5292 -0.2818 -0.0936\n",
            "T-204\tAmuna anayi akudumphira mumlengalenga pamene wachisanu waima pansi kunja kwa nyumba.\n",
            "H-204\t-0.20183129608631134\t▁ A m u n a ▁ a n a y i ▁ a k u d u m p h i r a ▁ m l e n g a l e n g a ▁ p a m e n e ▁ w a c h i s a n u ▁ w a i m a ▁ k u n j a ▁ k w a ▁ n y u m b a ▁ .\n",
            "D-204\t-0.20183129608631134\tAmuna anayi akudumphira mlengalenga pamene wachisanu waima kunja kwa nyumba .\n",
            "P-204\t-0.1137 -0.0861 -0.0817 -0.0668 -0.1068 -0.0983 -0.1665 -0.1688 -0.1505 -0.1385 -0.0354 -0.0984 -0.1535 -0.1270 -0.1074 -0.0893 -0.0783 -0.0609 -0.0767 -0.0809 -0.0500 -0.0553 -0.0833 -0.0790 -0.1349 -0.0596 -3.3800 -0.0808 -0.0592 -0.1957 -0.1090 -0.0248 -0.1734 -0.0470 -0.1515 -0.0811 -0.1927 -0.1059 -0.1493 -0.4261 -0.0853 -0.1008 -0.0868 -0.1103 -0.1525 -0.1550 -0.3755 -0.0541 -0.0989 -1.0199 -0.0989 -0.2413 -0.0670 -0.1195 -1.1339 -0.1350 -0.2128 -0.0725 -0.0922 -0.0883 -1.0028 -0.0840 -0.1417 -0.0798 -0.0945 -0.1683 -0.0543 -0.0622 -0.1093 -0.1063 -0.0590 -0.0530 -0.0375 -0.0773 -0.0546 -0.0857 -0.5872 -0.7619 -0.1015\n",
            "T-386\tGalu wofiirira waubweya akuthamanga m'dera laudzu.\n",
            "H-386\t-0.20512406527996063\t▁ G a l u ▁ w o f i i r i r a ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ m ' d e r a ▁ l a u d z u ▁ .\n",
            "D-386\t-0.20512406527996063\tGalu wofiirira wabulauni akuthamanga m'dera laudzu .\n",
            "P-386\t-0.1097 -0.0708 -0.1187 -0.0744 -0.1141 -0.1168 -0.0455 -0.0846 -0.0554 -0.0810 -0.2497 -0.0824 -0.2851 -0.1746 -0.1140 -0.2195 -0.0846 -0.1240 -0.7463 -0.0759 -0.1091 -0.3501 -0.0506 -0.1891 -0.0954 -0.1268 -0.0705 -0.1558 -0.0880 -0.0404 -0.0366 -0.0984 -0.0629 -0.0734 -0.0754 -0.0491 -0.3660 -0.1105 -1.8029 -0.2674 -0.4954 -1.1959 -0.0768 -0.0985 -0.2742 -0.0232 -0.1703 -0.1722 -0.2148 -0.0554 -0.1048 -0.8380 -0.0325 -0.0792\n",
            "T-424\tAtsikana awiri akusewera ndi mipira yapulasitiki m'dzenje la mpira .\n",
            "H-424\t-0.26463404297828674\t▁ A t s i k a n a ▁ a w i r i ▁ a k u s e w e r a ▁ n d i ▁ m p i r a ▁ y a ▁ s i k u ▁ n d i ▁ z e n j e ▁ y a k e ▁ .\n",
            "D-424\t-0.26463404297828674\tAtsikana awiri akusewera ndi mpira ya siku ndi zenje yake .\n",
            "P-424\t-0.1183 -0.0498 -0.0912 -0.0745 -0.1134 -0.0882 -0.1388 -0.0854 -0.1113 -0.1608 -0.1307 -0.0775 -0.0957 -0.0770 -0.1010 -0.2096 -0.1131 -0.1021 -0.0937 -0.0586 -0.0725 -0.1274 -0.0948 -0.0847 -0.1042 -0.1248 -0.1240 -0.1831 -0.0957 -0.0876 -0.7852 -0.0707 -0.0917 -0.1530 -0.1012 -0.1210 -0.6745 -0.1082 -1.1052 -0.3231 -0.0820 -0.6717 -0.5011 -0.1251 -0.8195 -0.2303 -0.0814 -0.2714 -1.0768 -0.8365 -0.0633 -0.1312 -0.0575 -0.7507 -1.8876 -0.1899 -0.5801 -0.0959 -0.2881 -0.5715 -0.1077\n",
            "T-274\tWoyenda panyanja atavala suti yakuda wakwera mafunde oyera m'nyanja.\n",
            "H-274\t-0.22865872085094452\t▁ W o y e n d a ▁ p a n y a n j a ▁ a t a v a l a ▁ s u t i ▁ y a k u d a ▁ a k u y a n g ' a n a ▁ m a f u n d e ▁ o y e r a ▁ m ' n y a n j a ▁ .\n",
            "D-274\t-0.22865872085094452\tWoyenda panyanja atavala suti yakuda akuyang'ana mafunde oyera m'nyanja .\n",
            "P-274\t-0.1162 -3.7041 -0.3723 -0.0420 -0.1720 -0.0558 -0.0525 -0.1099 -0.1221 -0.0756 -0.1487 -0.0634 -0.1773 -0.0948 -0.0790 -0.0296 -0.1031 -0.1563 -0.0566 -0.0395 -0.1139 -0.0391 -0.1157 -0.0773 -0.1147 -0.1046 -0.4040 -0.0687 -0.0581 -0.0591 -0.0972 -0.0283 -0.1296 -0.1666 -0.1157 -0.0500 -0.0853 -0.1516 -0.8285 -0.0610 -0.1112 -0.1001 -0.2810 -0.8432 -0.1882 -0.1239 -0.1005 -0.1249 -0.0969 -0.0933 -1.0833 -0.0943 -0.0241 -0.2297 -0.0478 -0.0176 -0.0779 -0.1517 -0.0806 -0.1169 -0.0928 -0.0871 -0.1101 -0.2916 -2.3966 -0.1005 -0.0407 -0.0365 -0.0901 -0.0540 -0.0302 -0.0973 -0.9175 -0.0703 -0.1073\n",
            "T-294\tAmuna angapo ovala zovala zobiriwira ndi zakuda kutsogolo kwa chipilala .\n",
            "H-294\t-0.16693927347660065\t▁ A m u n a ▁ a n g a p o ▁ o v a l a ▁ z o v a l a ▁ z o b i r i w i r a ▁ n d i ▁ z a k u d a ▁ k u t s o g o l o ▁ k w a ▁ c h i p i l a l e ▁ .\n",
            "D-294\t-0.16693927347660065\tAmuna angapo ovala zovala zobiriwira ndi zakuda kutsogolo kwa chipilale .\n",
            "P-294\t-0.1229 -0.0591 -0.0847 -0.0838 -0.1000 -0.1056 -0.1291 -0.1370 -0.1462 -0.2050 -0.1052 -0.0092 -0.0540 -0.1964 -0.0520 -0.0342 -0.1204 -0.0924 -0.1112 -0.1090 -0.0225 -0.0885 -0.0454 -0.1037 -0.0823 -0.1121 -0.1055 -0.0205 -0.1402 -0.2376 -0.2488 -0.0768 -0.0996 -0.0513 -0.1227 -0.0934 -0.0962 -0.1588 -0.0603 -0.0749 -0.0834 -0.0815 -0.5367 -0.1533 -1.7159 -0.0625 -0.1835 -0.2391 -0.2201 -0.6559 -0.1598 -0.4115 -0.0979 -0.0998 -0.0265 -0.1306 -0.0688 -0.0841 -0.0922 -0.0361 -0.0771 -0.1397 -0.1485 -0.1345 -0.0620 -0.1150 -0.0325 -0.0868 -1.2973 -0.1843 -0.1116 -0.2779 -0.2132 -0.2994 -0.1030\n",
            "T-113\tMwamuna wovala suti akugwira mutu wake pamene wina akulankhula pa maikolofoni .\n",
            "H-113\t-0.1894838660955429\t▁ M w a m u n a ▁ w o v a l a ▁ s u t i ▁ y a k u d a ▁ n d i ▁ w a k e ▁ p a m e n e ▁ w i n a ▁ a k u l a n k h u l a ▁ p a ▁ m a i k o l o f o n i ▁ .\n",
            "D-113\t-0.1894838660955429\tMwamuna wovala suti yakuda ndi wake pamene wina akulankhula pa maikolofoni .\n",
            "P-113\t-0.1222 -0.0665 -0.0363 -0.0935 -0.1117 -0.1146 -0.0957 -0.0942 -0.1403 -0.1222 -0.1000 -0.0385 -0.1179 -0.0717 -0.1143 -0.1163 -0.0641 -0.0499 -0.0449 -0.0712 -0.0914 -0.1966 -0.1190 -0.2015 -0.0934 -0.1139 -0.0767 -0.1632 -2.2539 -0.2647 -0.2047 -0.1510 -0.3201 -0.1131 -1.7089 -0.1163 -0.1660 -1.1935 -0.1118 -0.0777 -0.0428 -0.0793 -0.1281 -0.1100 -0.2458 -0.1291 -0.1316 -0.1087 -0.1352 -0.0921 -0.0450 -0.1038 -0.2781 -0.2551 -0.3293 -0.0082 -0.0685 -0.0457 -0.0437 -0.1214 -0.1380 -0.3088 -0.1404 -0.3844 -0.0925 -0.0970 -0.3327 -0.3837 -0.0353 -0.1076 -0.0368 -0.0440 -0.0360 -0.0381 -0.0726 -0.3978 -0.0154 -0.0935\n",
            "T-93\tBambo wina akuyenda kutsogolo kwa galimoto yaikulu yabuluu yomwe inayima pakati pa nyumba .\n",
            "H-93\t-0.1957995742559433\t▁ B a m b o ▁ w i n a ▁ a k u y e n d a ▁ k u t s o g o l o ▁ k w a ▁ g a l i m o t o ▁ y a ▁ m u l u ▁ y o m w e ▁ i n a y o ▁ p a k a t i ▁ p a ▁ n y u m b a ▁ .\n",
            "D-93\t-0.1957995742559433\tBambo wina akuyenda kutsogolo kwa galimoto ya mulu yomwe inayo pakati pa nyumba .\n",
            "P-93\t-0.1283 -0.0701 -0.1157 -0.0967 -0.0991 -0.0678 -0.1430 -0.0812 -0.0960 -0.0987 -0.1093 -0.1101 -0.2152 -0.2121 -0.0942 -0.3408 -0.0624 -0.0654 -0.0974 -0.1256 -0.1107 -0.0820 -0.0491 -0.2580 -0.0964 -0.0729 -0.0381 -0.1196 -0.0730 -0.0662 -0.0877 -0.0740 -0.0630 -0.1048 -0.1086 -0.0466 -0.0894 -0.0488 -0.1131 -0.0408 -0.0669 -0.0623 -0.0323 -0.1862 -0.0204 -0.1313 -0.9585 -0.9086 -0.8569 -0.5648 -0.0516 -0.1629 -0.6423 -0.2820 -0.3008 -0.1044 -0.1058 -0.0998 -0.0775 -0.1641 -0.1117 -0.5915 -0.1131 -0.1232 -0.4371 -0.1154 -0.2580 -0.1749 -0.2244 -0.0513 -0.1178 -0.1894 -0.1257 -0.0914 -1.2457 -0.3200 -0.0834 -0.1281 -0.1197 -0.0882 -0.3485 -1.1435 -0.0984\n",
            "T-359\tMayi wina wa ku America waku Africa akutsamira uku atanyamula racket ya tennis .\n",
            "H-359\t-0.2789595127105713\t▁ M a y i ▁ w i n a ▁ w a ▁ k u ▁ A m e r i c a ▁ w a k u ▁ A s i a ▁ a k u s a m i r a ▁ a t a n y a m u l a ▁ t e n i s ▁ y a k e ▁ .\n",
            "D-359\t-0.2789595127105713\tMayi wina wa ku America waku Asia akusamira atanyamula tenis yake .\n",
            "P-359\t-0.1340 -0.0644 -0.0880 -0.0754 -0.0970 -0.1322 -0.0644 -0.1210 -0.0747 -0.1031 -0.1090 -0.1793 -0.3426 -0.6321 -0.0932 -0.4581 -0.0198 -0.1176 -0.1654 -0.0831 -0.0497 -0.1750 -0.0609 -0.0714 -0.1148 -0.1013 -0.1345 -2.8432 -0.8557 -0.0386 -0.0726 -0.8627 -0.1593 -0.1085 -0.1089 -0.1048 -0.0513 -0.0797 -0.0888 -0.0913 -1.3674 -0.3421 -0.0869 -0.0916 -0.1058 -1.3382 -0.1747 -0.1129 -0.1306 -0.0229 -0.0982 -0.0598 -0.0915 -0.0640 -0.0984 -0.1321 -0.5171 -0.1267 -0.7226 -0.4382 -0.0471 -0.9857 -1.4397 -0.1107 -0.4285 -0.0522 -0.1808 -0.4479 -0.1066\n",
            "T-425\tMunthu wovala zakuda ndi zoyera zosambira akugwera mumchenga m'mphepete mwa nyanja .\n",
            "H-425\t-0.16269710659980774\t▁ M u n t h u ▁ w o v a l a ▁ z a k u d a ▁ n d i ▁ z o y e r a ▁ z o s a m b i r a ▁ a k u g w e d e z a ▁ m ' m p h e p e t e ▁ m w a ▁ n y a n j a ▁ .\n",
            "D-425\t-0.16269710659980774\tMunthu wovala zakuda ndi zoyera zosambira akugwedeza m'mphepete mwa nyanja .\n",
            "P-425\t-0.1134 -0.0702 -0.0741 -0.0546 -0.0770 -0.0708 -0.0756 -0.1229 -0.0691 -0.0778 -0.0262 -0.1264 -0.0768 -0.1108 -0.0949 -0.0477 -0.2285 -0.2338 -0.0760 -0.2576 -0.1595 -0.1150 -0.3502 -0.1766 -0.1047 -0.0829 -0.0675 -0.0905 -0.1086 -0.1094 -0.0727 -0.1121 -0.1421 -0.2209 -0.1199 -0.0711 -0.1123 -0.2572 -0.0757 -0.0776 -0.0560 -0.0934 -0.1466 -0.0930 -0.0598 -0.0871 -0.0054 -0.0435 -0.2994 -0.3971 -0.2618 -0.7195 -0.4806 -0.1156 -0.1217 -2.6438 -0.3654 -0.0134 -0.0168 -0.0783 -0.0156 -0.0521 -0.0276 -0.0973 -0.0804 -0.0936 -0.0378 -0.1145 -0.1028 -0.1390 -0.0114 -0.0834 -0.0973 -0.0586 -0.0819 -0.5891 -0.0937 -0.1058\n",
            "T-144\tMunthu wovala chipewa amakhala pachinthu chachikasu pamene akuwedza pamwala.\n",
            "H-144\t-0.23544834554195404\t▁ M u n t h u ▁ w o v a l a ▁ c h i p e w a ▁ w a v a l a ▁ c h i n t h u ▁ c h a c h i k a s u ▁ p a m e n e ▁ a k u w e z a ▁ p a m w a l a ▁ .\n",
            "D-144\t-0.23544834554195404\tMunthu wovala chipewa wavala chinthu chachikasu pamene akuweza pamwala .\n",
            "P-144\t-0.1198 -0.1665 -0.0463 -0.0715 -0.0707 -0.1303 -0.0767 -0.1546 -0.0497 -0.1711 -0.0272 -0.1207 -0.0862 -0.1200 -0.1011 -0.0895 -0.0997 -0.0916 -0.0183 -0.1101 -0.0685 -0.0936 -0.1349 -2.2494 -0.1492 -1.0281 -0.0977 -0.0882 -0.0991 -0.0902 -0.5985 -0.1061 -0.1950 -1.5421 -0.9775 -0.1101 -0.0972 -0.1140 -0.0413 -0.0731 -0.1299 -0.2378 -0.0844 -0.0891 -0.0780 -0.1288 -0.2280 -0.0969 -0.1127 -0.2965 -0.1205 -0.0857 -0.0336 -0.0592 -0.1242 -0.0857 -0.0911 -0.1252 -0.1008 -0.8922 -0.1561 -0.1270 -0.0950 -0.0915 -1.5816 -0.1704 -0.2487 -0.0991 -0.0938 -0.9977 -0.2081 -0.2140 -0.1623 -0.1025\n",
            "T-180\tMnyamata wagwira ukonde wokhala ndi njoka pafupi ndi nthaka .\n",
            "H-180\t-0.2333686351776123\t▁ M n y a m a t a ▁ w a g w a d a ▁ w a g o n d e ▁ w o k h a l a ▁ n d i ▁ n j o v u ▁ p a f u p i ▁ n d i ▁ n t h a k a ▁ .\n",
            "D-180\t-0.2333686351776123\tMnyamata wagwada wagonde wokhala ndi njovu pafupi ndi nthaka .\n",
            "P-180\t-0.1162 -0.0723 -0.0576 -0.0567 -0.0905 -0.0755 -0.1131 -0.0413 -0.1008 -0.1266 -0.1034 -0.1141 -0.4878 -1.0234 -0.2221 -0.1006 -0.2015 -0.1795 -0.3321 -0.4425 -2.1090 -0.1156 -0.0386 -0.4476 -0.1426 -0.1075 -0.0570 -0.0876 -0.0477 -0.0338 -0.1303 -0.0522 -0.1014 -0.0999 -0.0640 -0.0945 -0.1041 -0.0735 -0.1387 -0.0603 -0.2191 -1.5418 -0.0873 -0.2237 -0.9506 -0.1105 -0.0279 -0.0935 -0.0897 -0.1077 -0.1309 -0.0664 -0.1351 -0.1132 -0.0811 -1.3531 -0.4179 -0.1084 -0.0896 -0.1091 -0.2172 -0.3600 -0.0496 -0.0885\n",
            "T-89\tMayi watsitsi lalifupi akuyang'ana maluwa omwe amamera m'munda .\n",
            "H-89\t-0.22986771166324615\t▁ M a y i ▁ w a t s i t s i ▁ l a l i f u p i ▁ a k u y a n g ' a n a ▁ m a l u w a ▁ a ▁ m e n e ▁ a m a m u n d a ▁ .\n",
            "D-89\t-0.22986771166324615\tMayi watsitsi lalifupi akuyang'ana maluwa a mene amamunda .\n",
            "P-89\t-0.1332 -0.0427 -0.0975 -0.2319 -0.0868 -0.1480 -0.0657 -0.1077 -0.1173 -0.0843 -0.0884 -0.0895 -0.0698 -0.0951 -0.0933 -0.1286 -0.1215 -0.0616 -0.1015 -0.0839 -0.0796 -0.0408 -0.0949 -0.1399 -1.0375 -0.0669 -0.1012 -0.1598 -0.1015 -0.0943 -0.0497 -0.0812 -0.0943 -0.0941 -0.1018 -0.0876 -0.1654 -0.3677 -0.2137 -0.5115 -0.0972 -0.0925 -0.1965 -0.3658 -1.7040 -0.0722 -0.6304 -0.0565 -0.1622 -0.1003 -0.1243 -0.3281 -0.1134 -0.5458 -1.1988 -0.3065 -0.9907 -0.0854 -0.5019 -0.5096 -0.1080\n",
            "T-285\tBambo wina amene ali ndi chakumwa cham'chitini waima pansi pa mathithi .\n",
            "H-285\t-0.29221129417419434\t▁ W i n a ▁ a l i ▁ n d i ▁ c h a k u m w a ▁ c h a ▁ m u n t h u ▁ w a i m i r i r a ▁ p a m a d z i ▁ .\n",
            "D-285\t-0.29221129417419434\tWina ali ndi chakumwa cha munthu waimirira pamadzi .\n",
            "P-285\t-0.1078 -0.9824 -0.2696 -0.0516 -0.2303 -0.3083 -0.1320 -0.0419 -0.1075 -0.0923 -1.0632 -0.1143 -0.1066 -0.0889 -0.6414 -0.1231 -1.6606 -0.1080 -0.0753 -0.1608 -0.0457 -0.1248 -0.0989 -0.0468 -0.1272 -0.5145 -0.2409 -0.0793 -0.6779 -0.7210 -0.0432 -0.1178 -0.3003 -0.1064 -0.4618 -0.4659 -1.2869 -0.1026 -0.2029 -0.0946 -0.0802 -0.0769 -0.1594 -0.1299 -0.0349 -0.1557 -0.5373 -0.4789 -0.3358 -0.1245 -0.0888 -0.3920 -0.7670 -0.0927\n",
            "T-179\tMnyamata akuchita chinyengo chapakhoma ndi njinga yake pakhoma lolembedwapo .\n",
            "H-179\t-0.20910939574241638\t▁ M n y a m a t a ▁ a k u c h i t a ▁ c h i n y e n g o ▁ c h a ▁ p a n j i n g a ▁ y a k e ▁ p a n j i n g a ▁ y a k u m a l e m b e d w a ▁ .\n",
            "D-179\t-0.20910939574241638\tMnyamata akuchita chinyengo cha panjinga yake panjinga yakumalembedwa .\n",
            "P-179\t-0.1130 -0.0912 -0.0562 -0.0402 -0.0924 -0.0703 -0.1013 -0.0615 -0.0933 -0.1076 -0.1733 -0.1333 -0.1044 -0.2110 -0.1023 -0.0675 -0.0206 -0.0790 -0.0926 -0.0260 -0.0931 -0.0898 -0.1342 -0.0409 -0.0488 -0.0402 -0.0668 -0.0650 -0.0926 -0.3238 -0.0914 -0.0972 -1.0972 -0.7214 -0.3137 -0.0915 -0.0761 -0.0832 -0.0359 -0.0993 -0.0815 -0.1168 -0.0541 -0.1295 -0.2252 -0.0883 -0.1174 -0.1332 -0.1353 -1.2956 -0.0324 -0.0823 -0.1616 -0.0514 -0.0861 -0.1490 -0.1201 -0.2393 -0.3799 -1.5185 -0.0717 -0.2855 -1.0538 -0.2946 -0.9569 -0.2156 -0.0472 -0.3687 -0.6409 -0.0858 -0.2476 -0.1703 -0.0898\n",
            "T-131\tMwana yemwe ali ndi malaya oyera ndi chisoti atakwera njinga m'nkhalango\n",
            "H-131\t-0.20286060869693756\t▁ M w a n a ▁ y e m w e ▁ a l i ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ c h i s o t i ▁ y a k u d a ▁ a k u y a n g ' a n a ▁ m ' n k h a l a n g o .\n",
            "D-131\t-0.20286060869693756\tMwana yemwe ali ndi malaya oyera ndi chisoti yakuda akuyang'ana m'nkhalango.\n",
            "P-131\t-0.1090 -0.0620 -0.0673 -0.1145 -0.1114 -0.0919 -0.3678 -0.2615 -0.0268 -0.0599 -0.0522 -0.1013 -0.0865 -0.1297 -0.0457 -0.0725 -0.1281 -0.0347 -0.1368 -0.1015 -0.0844 -0.0915 -0.1160 -0.0755 -0.1391 -0.0650 -0.1180 -0.0881 -0.1247 -0.1085 -0.0908 -0.0797 -0.1023 -0.1547 -0.6362 -0.0932 -0.1091 -0.0824 -1.5020 -0.0846 -0.0879 -0.2013 -0.0745 -0.0185 -0.0645 -0.1391 -0.9884 -0.0967 -0.2496 -0.1547 -0.1654 -0.1119 -0.1585 -0.2093 -0.2149 -0.0881 -0.6506 -0.1153 -0.2228 -0.7245 -0.1240 -0.0839 -0.0883 -0.1033 -0.1142 -1.0670 -0.7769 -0.2430 -0.4827 -0.1828 -0.1230 -0.0410 -0.1224 -0.0364 -0.0247 -0.0413 -1.2202 -0.1044\n",
            "T-374\tGulu la akavalo ndi okwera akusewera polo pa udzu .\n",
            "H-374\t-0.3473210334777832\t▁ G u l u ▁ l a ▁ a k h a l a ▁ p a b w a l o ▁ l o k w e r a ▁ a k u s e w e r a ▁ p a u d z u ▁ .\n",
            "D-374\t-0.3473210334777832\tGulu la akhala pabwalo lokwera akusewera paudzu .\n",
            "P-374\t-0.1102 -0.1105 -0.0460 -0.0509 -0.0761 -0.1135 -0.1888 -0.1202 -0.1365 -0.1428 -0.8244 -1.9665 -0.1192 -0.0587 -0.1300 -0.1258 -2.0948 -0.1247 -1.3753 -0.3752 -0.0911 -0.0407 -0.0791 -0.1368 -0.4479 -1.3941 -0.3564 -0.3358 -0.0757 -0.0794 -0.1148 -0.1860 -0.6261 -0.0892 -0.0761 -0.2888 -0.0566 -0.3490 -0.0940 -0.0752 -0.1172 -0.1607 -0.1919 -0.3222 -1.3380 -1.4878 -0.0261 -0.1303 -0.3193 -0.2374 -0.0993\n",
            "T-403\tAna atatu ovala zosanja aimirira panja pa kanyumba kaudzu .\n",
            "H-403\t-0.3353302478790283\t▁ A n a ▁ a t a t u ▁ o v a l a ▁ z o v a l a ▁ z o s a m b i r a ▁ a l i ▁ p a n j a ▁ p a f u p i ▁ n d i ▁ u d z u ▁ .\n",
            "D-403\t-0.3353302478790283\tAna atatu ovala zovala zosambira ali panja pafupi ndi udzu .\n",
            "P-403\t-0.1224 -0.0476 -0.0446 -0.2081 -0.1336 -0.1391 -0.0334 -0.0924 -0.0144 -0.0458 -0.1374 -0.2576 -0.0466 -0.1315 -0.0703 -0.1069 -0.1077 -0.0678 -0.0826 -1.0488 -0.1201 -0.0710 -0.1090 -0.1087 -0.0473 -0.5636 -0.0693 -0.0962 -2.4171 -0.9515 -0.0749 -0.1101 -0.0973 -0.1421 -1.5406 -0.5564 -0.0880 -0.0791 -0.0531 -0.1311 -0.0900 -0.0567 -0.1219 -0.1758 -0.1376 -0.1215 -1.4857 -0.1028 -2.1486 -0.1492 -0.1126 -0.5304 -0.7681 -0.1044 -0.0914 -2.7253 -0.7593 -0.0317 -0.0731 -0.5034 -0.0363 -0.0995\n",
            "T-323\tMunthu wovala malaya oyera , akuda ndi ofiira akuyenda motsetsereka .\n",
            "H-323\t-0.22735033929347992\t▁ M u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u j a m b u l a ▁ n d i ▁ o f i i r a ▁ a k u y e n d a ▁ m o s e w e r e k a ▁ .\n",
            "D-323\t-0.22735033929347992\tMunthu wovala malaya oyera akujambula ndi ofiira akuyenda mosewereka .\n",
            "P-323\t-0.1210 -0.1111 -0.0636 -0.0727 -0.0904 -0.1088 -0.0867 -0.1466 -0.1139 -0.0929 -0.0612 -0.1487 -0.0815 -0.1362 -0.1076 -0.0726 -0.1671 -0.0500 -0.1108 -0.0594 -0.1045 -0.1067 -0.0591 -0.0827 -0.0753 -0.1183 -0.0967 -0.1622 -0.2790 -0.1776 -0.1072 -0.4502 -0.1320 -0.6410 -0.1176 -0.1013 -0.1640 -0.1097 -0.1374 -1.6998 -0.1168 -0.1310 -0.1235 -0.0926 -0.0144 -0.1380 -0.1500 -0.0857 -0.1759 -0.2024 -1.0797 -0.0426 -0.0878 -0.4814 -0.0638 -1.2689 -0.1322 -0.1233 -0.1131 -0.0428 -0.1814 -1.4238 -0.0530 -0.6163 -0.0921 -0.0663 -0.1241 -1.6711 -0.1110 -0.3161 -0.0212 -0.1015\n",
            "T-344\tWosewera pa skateboarder akudumpha mumlengalenga kutsogolo kwa mtengo wa telegraph.\n",
            "H-344\t-0.19992677867412567\t▁ W o s e w e r a ▁ p a ▁ s k a t e b o a r d e r ▁ a k u d u m p h a ▁ m ' n y e n g o ▁ k u t s o g o l o ▁ k w a ▁ m p i r a ▁ .\n",
            "D-344\t-0.19992677867412567\tWosewera pa skateboarder akudumpha m'nyengo kutsogolo kwa mpira .\n",
            "P-344\t-0.1073 -0.2121 -0.1404 -0.0858 -0.0806 -0.0750 -0.0870 -0.0803 -0.1129 -0.1272 -1.8763 -0.1575 -0.0520 -0.0296 -0.0339 -0.2278 -0.0376 -0.0427 -0.0489 -0.0311 -0.0458 -0.0394 -0.0405 -0.6027 -0.1014 -0.1360 -0.1602 -0.0500 -0.0976 -0.1690 -0.0356 -0.0408 -0.0292 -0.0388 -0.0770 -0.1162 -0.0851 -1.3970 -0.6974 -0.0688 -0.1237 -0.0495 -0.4250 -0.0843 -0.1152 -0.2560 -0.0434 -0.0941 -0.1704 -0.0631 -0.0166 -0.1295 -0.0572 -0.0696 -0.0935 -0.2939 -0.0801 -0.1071 -0.2156 -0.6335 -0.4859 -0.1907 -0.1540 -0.1622 -0.3484 -1.1452 -0.1130\n",
            "T-13\tGalu akugudubuzika chagada pa udzu ndi kukamwa .\n",
            "H-13\t-0.37988364696502686\t▁ G a l u ▁ a k u t u l u k a ▁ c h i t h u n z i ▁ p a ▁ u d z u ▁ n d i ▁ m k a m w a ▁ .\n",
            "D-13\t-0.37988364696502686\tGalu akutuluka chithunzi pa udzu ndi mkamwa .\n",
            "P-13\t-0.1239 -0.1273 -0.1255 -0.0731 -0.0512 -0.1099 -0.5188 -0.0800 -0.0779 -1.7096 -0.6926 -0.0670 -0.0675 -0.1511 -0.0846 -0.1120 -0.5285 -0.1324 -0.0925 -1.5808 -0.0190 -0.0560 -0.0784 -0.0373 -0.0948 -0.1395 -0.8163 -0.1806 -1.1651 -1.5849 -0.5568 -0.1105 -0.0496 -0.1763 -0.2523 -0.0936 -0.0864 -0.6039 -0.7758 -1.8461 -0.2493 -0.2729 -0.1546 -0.1017 -0.1710 -1.5911 -0.0849\n",
            "T-279\tmayi akunyamula zipatso ndi ndiwo zamasamba kuti akagulitse patebulo\n",
            "H-279\t-0.38496360182762146\t▁ A n y a m a t a ▁ a m u n a ▁ a s a n u ▁ n d i ▁ n d i ▁ w o v a l a ▁ m a s a n g a l a ▁ a k u j a m b u l i t s a ▁ t e b u l o ▁ .\n",
            "D-279\t-0.38496360182762146\tAnyamata amuna asanu ndi ndi wovala masangala akujambulitsa tebulo .\n",
            "P-279\t-0.1100 -0.2575 -0.2246 -0.4283 -0.0878 -0.0793 -0.0759 -0.1618 -0.0939 -0.1222 -0.1952 -0.2896 -0.8005 -1.4503 -0.1370 -0.2159 -0.2871 -0.6868 -0.1627 -0.0806 -0.9388 -0.1430 -0.1423 -0.0565 -0.1178 -0.0883 -1.0863 -0.3105 -0.1118 -0.1843 -1.6331 -0.0937 -2.0567 -0.1099 -0.1166 -0.0942 -0.1022 -0.5936 -0.1254 -0.8836 -0.1965 -0.4274 -0.0735 -0.0957 -0.5975 -0.0646 -1.1992 -1.0638 -0.0930 -0.0814 -1.2725 -0.3182 -1.4284 -0.2064 -0.0486 -0.0698 -0.2306 -0.2383 -0.3230 -0.8857 -0.0998 -1.0621 -0.1147 -0.1075 -0.0989 -0.0758 -0.0906 -0.1734 -1.1833 -0.0913\n",
            "T-150\tMunthu wovala chisoti chakuda akukwera njinga yofiira kudutsa m'nkhalango .\n",
            "H-150\t-0.2152089625597\t▁ M u n t h u ▁ w o v a l a ▁ c h i s o t i ▁ c h a k u d a ▁ a k u k w e r a ▁ n j i n g a ▁ y a k u d a ▁ m ' n k h a l a n g o ▁ .\n",
            "D-150\t-0.2152089625597\tMunthu wovala chisoti chakuda akukwera njinga yakuda m'nkhalango .\n",
            "P-150\t-0.1110 -0.1790 -0.0312 -0.0730 -0.0674 -0.1190 -0.0757 -0.1536 -0.0601 -0.3690 -0.0348 -0.1360 -0.0737 -0.1153 -0.1008 -0.1212 -0.0989 -0.0983 -0.9085 -0.0754 -0.0266 -0.1176 -0.1543 -0.0319 -0.0788 -0.0899 -0.3825 -0.0962 -0.1295 -0.2244 -0.1207 -0.8960 -0.2294 -0.0936 -0.3678 -2.7360 -0.0823 -0.1189 -0.0985 -0.0859 -0.0571 -0.0313 -0.0892 -0.1774 -0.0637 -0.0890 -0.1298 -0.0262 -0.3423 -0.1934 -0.0953 -0.0186 -0.1233 -0.2071 -0.7051 -0.3055 -1.0988 -0.0813 -0.0331 -0.1274 -0.0363 -0.1233 -0.0336 -0.0511 -0.0230 -1.0786 -0.0327 -0.0977\n",
            "T-256\tKumbuyo kwa anthu atatu onse ovala malaya ofiira omwe amati kupewa pa iwo .\n",
            "H-256\t-0.30669406056404114\t▁ G u l u ▁ l a ▁ a n t h u ▁ a t a t u ▁ o v a l a ▁ z o v a l a ▁ m a l a y a ▁ o f i i r a ▁ k o m a n s o ▁ m n y a m a t a ▁ a i m i r i r a ▁ .\n",
            "D-256\t-0.30669406056404114\tGulu la anthu atatu ovala zovala malaya ofiira komanso mnyamata aimirira .\n",
            "P-256\t-0.1123 -0.8857 -0.1139 -0.1439 -0.1112 -0.1078 -0.1956 -0.1193 -0.1353 -0.4848 -0.1435 -0.0897 -0.0946 -0.0706 -0.1099 -0.6329 -0.0430 -0.1018 -0.1030 -0.0502 -0.1322 -0.2109 -0.2761 -0.1089 -0.0823 -0.1018 -0.1014 -2.2797 -0.2402 -0.0574 -0.1089 -0.0795 -0.1212 -0.1085 -1.5776 -0.1132 -0.0387 -0.1158 -0.0476 -0.0899 -0.1049 -0.1228 -0.0123 -0.1053 -0.1818 -0.0971 -0.1389 -0.2156 -1.8594 -0.2795 -0.0782 -0.2184 -0.1790 -0.9023 -0.0588 -0.0747 -0.2600 -1.9037 -0.0404 -0.1081 -0.0470 -0.0799 -0.0562 -0.0940 -0.2987 -2.1942 -0.2977 -0.4587 -1.4775 -0.3027 -0.0599 -0.2578 -0.1548 -0.4725 -0.1681 -0.1068\n",
            "T-0\tMwamuna wovala jekete loyera akuyang'ana kutali ndi zomwe wina aliyense akuyang'ana .\n",
            "H-0\t-0.25978946685791016\t▁ M w a m u n a ▁ w o v a l a ▁ j e k e t e ▁ l o y e r a ▁ a k u y a n g ' a n a ▁ g u l u ▁ l i z o m w e ▁ l i n a l i ▁ k u y a n g ' a n a ▁ .\n",
            "D-0\t-0.25978946685791016\tMwamuna wovala jekete loyera akuyang'ana gulu lizomwe linali kuyang'ana .\n",
            "P-0\t-0.1274 -0.0752 -0.0500 -0.1013 -0.1442 -0.0810 -0.1071 -0.0944 -0.1284 -0.1056 -0.1405 -0.1900 -0.1211 -0.0846 -0.1121 -0.1013 -0.5128 -0.0482 -0.2490 -0.0854 -0.0387 -0.1946 -0.0856 -0.8889 -0.1327 -0.0768 -0.1106 -0.0730 -0.0757 -0.1575 -0.3096 -0.0983 -0.0842 -0.0587 -0.6303 -0.0553 -0.1536 -0.0610 -0.0888 -0.1649 -0.1036 -0.0825 -1.1149 -1.0998 -0.1042 -0.0641 -0.1131 -0.0468 -0.3189 -1.6177 -0.5303 -0.4594 -1.1491 -0.1351 -0.0977 -0.1413 -0.1161 -1.0854 -0.0737 -0.5888 -0.0972 -0.1400 -1.0852 -0.3056 -0.1190 -0.5204 -0.0787 -0.1788 -0.1390 -0.0903 -0.0814 -0.1076 -0.1842 -1.0059 -0.1099\n",
            "T-260\tGalu woyera ndi wofiirira akuthamanga mumsewu wafumbi m'paki.\n",
            "H-260\t-0.15442943572998047\t▁ G a l u ▁ w o y e r a ▁ n d i ▁ w o f i i r i r a ▁ a k u t h a m a n g a ▁ m u m s e w u ▁ w a f u m b i ▁ .\n",
            "D-260\t-0.15442943572998047\tGalu woyera ndi wofiirira akuthamanga mumsewu wafumbi .\n",
            "P-260\t-0.1106 -0.0834 -0.1137 -0.0679 -0.0883 -0.1462 -0.1086 -0.0680 -0.0357 -0.0708 -0.1032 -0.1005 -0.1545 -0.0745 -0.0836 -0.1218 -0.0853 -0.0187 -0.2492 -0.0332 -0.0869 -0.2038 -0.1296 -0.3352 -0.2207 -0.0870 -0.1811 -0.0942 -0.1404 -0.1112 -0.1074 -0.0720 -0.0845 -0.0742 -0.0790 -0.0944 -0.0303 -0.0810 -0.1068 -0.1358 -0.7288 -0.1232 -0.0507 -0.0716 -0.0971 -0.0385 -0.1331 -0.0604 -0.1406 -1.5286 -0.0568 -0.7809 -0.1154 -0.1069 -0.2347 -0.0816 -0.0802\n",
            " 85% 11/13 [00:24<00:03,  1.69s/it, wps=1486]T-396\tmunthu wadazi wovala malaya abuluu akuwotcha ng'anjo yamoto .\n",
            "H-396\t-0.2489537000656128\t▁ M u n t h u ▁ w a d a z i ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u w o t c h a ▁ n j i n g a ▁ y o m w e ▁ .\n",
            "D-396\t-0.2489537000656128\tMunthu wadazi wovala malaya abuluu akuwotcha njinga yomwe .\n",
            "P-396\t-0.1185 -0.1132 -0.0523 -0.0743 -0.0894 -0.1002 -0.0803 -0.1224 -0.0453 -0.4969 -1.2387 -0.1154 -0.0754 -0.0610 -0.1889 -0.0526 -0.1435 -0.0355 -0.1083 -0.0896 -0.1160 -0.1056 -0.0646 -0.1241 -0.0646 -0.1089 -0.0561 -0.0987 -0.1039 -0.1501 -0.0545 -0.1318 -0.0976 -0.1308 -0.0533 -0.1033 -0.3369 -0.0535 -0.0998 -0.8747 -0.2788 -0.1564 -0.0384 -0.0748 -0.1049 -0.0868 -0.3074 -0.0713 -3.2293 -0.0919 -0.0436 -0.0845 -0.1499 -0.4881 -0.2041 -0.3388 -0.8696 -0.1085 -0.1258 -1.9095 -0.0932\n",
            "T-300\tBambo wina wachikulire atavala chovala chabuluu wakhala pansi pafupi ndi zikwama zake .\n",
            "H-300\t-0.20547407865524292\t▁ B a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ a t a v a l a ▁ c h o v a l a ▁ c h a b u l u u ▁ w a k h a l a ▁ p a f u p i ▁ n d i ▁ n y u m b a ▁ z a k e ▁ .\n",
            "D-300\t-0.20547407865524292\tBambo wina wachikulire atavala chovala chabuluu wakhala pafupi ndi nyumba zake .\n",
            "P-300\t-0.1114 -0.5332 -0.2974 -0.3481 -0.2099 -0.0578 -0.1228 -0.0388 -0.1660 -0.0875 -0.1037 -0.1297 -0.0488 -0.1008 -0.2317 -0.1285 -0.1085 -0.0999 -0.0591 -0.0996 -0.0680 -0.0754 -0.1317 -0.1311 -0.0854 -0.0154 -0.0970 -0.0306 -0.1069 -0.0868 -0.1137 -0.0953 -0.0279 -0.0847 -0.0703 -0.0256 -0.1007 -0.0719 -0.1100 -0.1076 -0.0703 -0.1193 -0.0976 -0.5764 -0.0927 -0.0742 -0.0808 -0.0457 -0.0891 -0.0713 -0.1292 -0.0916 -0.0176 -0.1037 -0.0447 -0.1263 -0.1014 -0.0338 -0.1234 -1.6055 -0.0658 -0.0557 -0.1075 -0.1041 -0.0546 -0.1088 -0.1154 -0.0622 -2.3882 -0.6598 -0.0989 -0.3069 -0.0896 -0.2161 -0.1455 -0.6736 -0.7760 -1.3011 -0.2443 -0.5177 -0.2350 -0.1086\n",
            "T-409\tGalu wakuda ndi woyera akusewera ndi mpira walalanje mu chipale chofewa .\n",
            "H-409\t-0.16776061058044434\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ w o y e r a ▁ a k u s e w e r a ▁ n d i ▁ m p i r a ▁ w a ▁ n y a n j a ▁ m ' c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-409\t-0.16776061058044434\tGalu wakuda ndi woyera akusewera ndi mpira wa nyanja m'chipale chofewa .\n",
            "P-409\t-0.1174 -0.1171 -0.1087 -0.0677 -0.0693 -0.1291 -0.0378 -0.1085 -0.0508 -0.0811 -0.0373 -0.1042 -0.1632 -0.1496 -0.0778 -0.0968 -0.0824 -0.0127 -0.0903 -0.0402 -0.0715 -0.1073 -0.0958 -0.1553 -0.0989 -0.0632 -0.0891 -0.1126 -0.0534 -0.0827 -0.0831 -0.0810 -0.0968 -0.1057 -0.1273 -0.0975 -0.1109 -0.0850 -0.1734 -0.0256 -0.0746 -0.1796 -0.1002 -0.1882 -0.0383 -0.1303 -0.1960 -0.5744 -0.5680 -2.2437 -0.2373 -0.0282 -0.1289 -0.2118 -0.7323 -1.0402 -0.1892 -0.0974 -0.1603 -0.1227 -0.0935 -0.0478 -0.1101 -0.0863 -0.0655 -0.0671 -0.0461 -0.0296 -0.0881 -0.0807 -0.0952 -0.5871 -0.0243 -0.0932\n",
            "T-269\tGalu wamkulu wabulauni akudumphira munthu wovala suti yodziteteza .\n",
            "H-269\t-0.20083217322826385\t▁ G a l u ▁ w a m k u l u ▁ w a b u l a u n i ▁ a k u d u m p h i r a ▁ m u n t h u ▁ w o v a l a ▁ s u t i ▁ y o t e t e z a ▁ .\n",
            "D-269\t-0.20083217322826385\tGalu wamkulu wabulauni akudumphira munthu wovala suti yoteteza .\n",
            "P-269\t-0.1301 -0.1552 -0.1275 -0.0727 -0.0720 -0.1301 -0.0498 -0.1246 -0.2433 -0.2644 -0.0912 -0.0531 -0.0732 -0.1283 -0.0487 -0.1474 -0.1460 -0.0807 -0.0575 -0.0943 -0.0582 -0.0644 -0.0958 -0.1337 -1.0302 -0.0563 -0.0850 -0.1374 -0.0665 -0.1024 -0.0444 -0.0457 -0.0776 -0.0932 -0.0823 -0.1267 -0.2005 -0.3362 -1.3592 -0.0309 -0.0626 -0.1299 -0.0994 -0.0898 -0.0956 -0.0667 -0.1121 -0.0899 -0.1071 -0.0923 -0.0996 -0.2516 -0.0296 -0.0388 -0.1234 -1.5667 -0.0556 -1.5940 -0.8296 -0.1316 -0.1875 -0.0295 -0.0977 -0.2149 -0.4390 -0.1032\n",
            "T-90\tChimbalangondo chachikazi ndi mwana wake akungolirana .\n",
            "H-90\t-0.3272646367549896\t▁ C h i n y a m a t a ▁ m ' n k h a l a n d o ▁ c h a c h i k a z i ▁ n d i ▁ m w a n a ▁ a k u m b u y o ▁ .\n",
            "D-90\t-0.3272646367549896\tChinyamata m'nkhalando chachikazi ndi mwana akumbuyo .\n",
            "P-90\t-0.1196 -1.6820 -0.0622 -0.1037 -0.7601 -1.1203 -0.1209 -0.1354 -0.3796 -0.2473 -0.0925 -0.1441 -2.4879 -0.1613 -0.3190 -1.3181 -0.0489 -0.1160 -0.2173 -0.1003 -0.0300 -1.2589 -0.0533 -0.1244 -0.3008 -0.0637 -0.1922 -0.7585 -0.0711 -0.0751 -0.1445 -0.1481 -0.1688 -0.0869 -0.1059 -0.1484 -0.0733 -0.1173 -0.0987 -0.0454 -0.0616 -0.0977 -0.5625 -0.1004 -0.1089 -0.4967 -0.1114 -0.4614 -0.5301 -0.5218 -0.1729 -0.1994 -0.1488 -0.2850 -0.5846 -0.0815\n",
            "T-128\tGulu la anthu lili kutsogolo kwa sitolo likuyenda pampitawu .\n",
            "H-128\t-0.25264865159988403\t▁ G u l u ▁ l a ▁ a n t h u ▁ l i k u s o g o l o ▁ k w a ▁ s i t o l o ▁ i k u y e n d a ▁ p a m p i k i s a n o ▁ .\n",
            "D-128\t-0.25264865159988403\tGulu la anthu likusogolo kwa sitolo ikuyenda pampikisano .\n",
            "P-128\t-0.1193 -0.0587 -0.0740 -0.0567 -0.1044 -0.1229 -0.1120 -0.1097 -0.0898 -0.1301 -0.0921 -0.0767 -0.1452 -0.0927 -0.1293 -0.5974 -0.1768 -0.2607 -0.0970 -1.3985 -0.1956 -0.9829 -0.1413 -0.0997 -0.1141 -0.1525 -0.0928 -0.0932 -0.1286 -0.1454 -0.7866 -0.0676 -0.1876 -0.0730 -0.0373 -0.0579 -0.1541 -0.7619 -0.0275 -0.0658 -0.3060 -0.0778 -0.0942 -0.1326 -0.1054 -0.1337 -0.0800 -0.1384 -0.1860 -0.1666 -2.0443 -0.6124 -0.1632 -1.1323 -0.1056 -0.2290 -0.0560 -0.4933 -0.3980 -0.0946\n",
            "T-203\tAgalu awiri apakati ndi galu wamng'ono akusewera m'madzi osaya.\n",
            "H-203\t-0.26102760434150696\t▁ A g a l u ▁ a w i r i ▁ a v a l a ▁ p a k a t i ▁ n d i ▁ g a l u ▁ w a m n g ' o n o ▁ a k u s e w e r a ▁ m a d z i ▁ .\n",
            "D-203\t-0.26102760434150696\tAgalu awiri avala pakati ndi galu wamng'ono akusewera madzi .\n",
            "P-203\t-0.1277 -0.0472 -0.3851 -0.1027 -0.0566 -0.0836 -0.1463 -0.1110 -0.0878 -0.1086 -0.0715 -0.0939 -0.1703 -0.1531 -1.3804 -0.1180 -0.0740 -0.1172 -0.1078 -1.9676 -0.2161 -0.6133 -0.1277 -0.0251 -0.0794 -0.1667 -0.4528 -0.0865 -0.1026 -0.1245 -0.2858 -0.2400 -0.0583 -0.0766 -0.1082 -1.0103 -0.0853 -0.2436 -0.1455 -0.2529 -0.0479 -0.0702 -0.0631 -0.0353 -0.1497 -0.3174 -0.0735 -0.0596 -0.1027 -0.0352 -0.1346 -0.0812 -0.0528 -0.1078 -0.1627 -0.5053 -0.1577 -0.4398 -0.0136 -0.3458 -0.4165 -2.9545 -0.1062\n",
            "T-413\tBambo wina wakhala pabenchi kutsogolo kwa nyumba ina imene inasiyidwa .\n",
            "H-413\t-0.20843006670475006\t▁ B a m b o ▁ w i n a ▁ w a k h a l a ▁ p a ▁ b e n c h i ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ i n a ▁ p a f u p i ▁ n a s i t o ▁ .\n",
            "D-413\t-0.20843006670475006\tBambo wina wakhala pa benchi kutsogolo kwa nyumba ina pafupi nasito .\n",
            "P-413\t-0.1359 -0.0342 -0.1024 -0.0756 -0.0852 -0.0731 -0.1301 -0.0994 -0.1201 -0.0824 -0.1083 -0.1106 -0.1249 -0.2377 -0.4906 -0.1335 -0.1021 -0.0430 -0.1153 -0.1090 -0.0656 -0.1164 -0.4040 -0.1437 -0.0532 -0.0824 -0.0677 -0.1635 -0.0869 -0.1531 -0.0331 -0.0671 -0.1251 -0.0812 -0.0668 -0.0381 -0.0941 -0.0566 -0.0668 -0.0828 -0.0342 -0.0482 -0.1297 -0.0906 -0.1329 -0.0639 -0.0560 -0.1232 -0.0381 -0.1031 -0.1601 -0.2120 -0.1718 -0.1060 -0.1220 -3.3081 -0.1629 -1.0095 -0.1096 -0.4106 -0.1131 -0.1395 -0.1829 -0.6271 -1.3047 -0.0791 -0.2297 -0.1129 -0.5931 -0.1612 -0.1011\n",
            "T-178\tmwamuna wavala chipewa chakuda ndi mpango wabulauni mumsewu wa mumzinda .\n",
            "H-178\t-0.21746483445167542\t▁ M w a m u n a ▁ w a v a l a ▁ c h i p e w a ▁ c h a k u d a ▁ n d i ▁ m p a n g o ▁ w a b u l a u n i ▁ m u m s e w u ▁ w a ▁ m z i n d a ▁ .\n",
            "D-178\t-0.21746483445167542\tMwamuna wavala chipewa chakuda ndi mpango wabulauni mumsewu wa mzinda .\n",
            "P-178\t-0.1266 -0.0517 -0.0521 -0.0874 -0.1312 -0.1024 -0.1329 -0.0892 -0.1258 -0.0874 -0.9926 -0.1201 -0.1157 -0.0837 -0.1033 -0.1125 -0.0808 -0.0785 -0.1101 -0.1279 -0.1024 -0.0698 -0.1083 -0.1127 -0.0218 -0.0740 -0.0834 -0.7760 -0.0949 -0.2748 -0.3136 -0.1427 -0.0662 -0.1329 -0.0973 -0.1236 -1.1779 -0.0254 -0.1892 -0.1548 -0.7824 -0.0760 -0.0932 -0.3849 -0.1106 -1.6599 -0.0725 -0.0432 -0.4502 -0.0695 -0.0953 -0.0962 -0.1346 -0.2469 -0.2828 -0.1033 -0.1486 -0.0766 -0.0789 -0.0452 -0.1619 -0.0893 -0.1553 -0.9138 -0.0604 -1.4696 -0.0938 -0.0375 -0.0621 -0.0908 -0.5174 -0.0191 -0.0989\n",
            "T-201\tGalu wokhala ndi ubweya wagolide amakhala pachifuwa m'madzi.\n",
            "H-201\t-0.2970004379749298\t▁ G a l u ▁ w o k h a l a ▁ n d i ▁ w a b u l a u n i ▁ w o y e r a ▁ a m a k h a l a ▁ p a ▁ c h i f u w a ▁ m ' m a d z i ▁ .\n",
            "D-201\t-0.2970004379749298\tGalu wokhala ndi wabulauni woyera amakhala pa chifuwa m'madzi .\n",
            "P-201\t-0.1204 -0.1124 -0.1135 -0.0719 -0.0655 -0.1149 -0.0341 -0.3137 -0.0481 -0.0825 -0.1164 -0.0605 -0.1012 -0.1312 -0.0616 -0.1413 -0.0983 -0.0677 -1.3820 -1.9553 -0.2968 -0.0925 -0.0626 -0.6149 -0.0645 -0.0710 -0.0846 -0.1214 -0.2924 -0.1367 -1.8027 -0.0737 -0.1603 -0.0858 -0.1600 -0.8735 -1.3598 -0.2293 -0.1979 -0.1755 -0.0954 -0.0754 -0.1074 -0.1036 -0.5027 -0.1081 -0.8794 -0.5203 -0.0909 -0.1278 -1.0105 -0.0430 -0.0524 -0.0876 -0.1713 -1.1989 -0.1977 -0.0896 -0.1139 -0.1034 -0.1096 -0.0773 -1.1043 -0.0930 -0.0931\n",
            "T-183\tBambo wina amene waika pensulo m'khutu akumeta thabwa .\n",
            "H-183\t-0.30721515417099\t▁ B a m b o ▁ w i n a ▁ a m e n e ▁ w a i m a ▁ p a n s i ▁ l o k h a l a ▁ a k u m e t a ▁ t a v a l a ▁ b w a l o ▁ .\n",
            "D-183\t-0.30721515417099\tBambo wina amene waima pansi lokhala akumeta tavala bwalo .\n",
            "P-183\t-0.1182 -0.1739 -0.1174 -0.0804 -0.0927 -0.0831 -0.1317 -0.0667 -0.1159 -0.0764 -0.1115 -0.1126 -0.9074 -0.2987 -0.0617 -0.0785 -0.1707 -0.1076 -0.0362 -0.1011 -0.3087 -0.4515 -0.2672 -0.0821 -1.1667 -0.2917 -0.3956 -0.0820 -0.1528 -0.0929 -1.2177 -0.6829 -0.7128 -0.4095 -0.1269 -0.2461 -0.0823 -0.1185 -0.5757 -0.1274 -0.1064 -1.0791 -0.3121 -0.1651 -0.0900 -0.2131 -1.3886 -0.4336 -0.5500 -0.1416 -0.1003 -0.1607 -0.1381 -0.1766 -0.4138 -0.6500 -0.5148 -0.4958 -0.4707 -0.4196 -0.0863\n",
            "T-339\tMunthu waima pansanjika ya njerwa akujambula chinthu chapatali .\n",
            "H-339\t-0.20962579548358917\t▁ M u n t h u ▁ w a i m a ▁ p a n s a n j i ▁ y a ▁ n j e r w a ▁ y a ▁ n j e r w a ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ .\n",
            "D-339\t-0.20962579548358917\tMunthu waima pansanji ya njerwa ya njerwa akujambula chithunzi .\n",
            "P-339\t-0.1189 -0.0986 -0.0609 -0.0631 -0.0664 -0.0929 -0.0894 -0.1496 -0.0632 -0.2518 -0.5601 -0.0501 -0.1277 -0.1040 -0.0372 -0.1390 -0.8811 -0.0338 -0.5609 -0.1196 -0.0295 -0.1044 -0.4425 -0.2229 -0.1170 -0.3446 -0.4404 -0.5124 -0.4601 -0.3865 -0.1479 -0.1038 -0.1466 -0.1225 -0.1387 -0.2438 -0.1655 -0.0659 -0.0691 -0.0626 -0.0925 -0.0792 -0.1345 -0.2862 -0.1004 -0.1048 -0.3249 -0.0953 -0.3396 -0.1058 -0.0797 -0.0800 -0.1039 -0.1564 -0.0313 -0.1099 -0.1543 -0.3174 -0.8431 -1.4768 -0.0657 -0.0402 -0.0814 -0.3403 -0.1972 -0.0998\n",
            "T-68\tAtsikana awiri aang'ono amavina pansi pamatabwa olimba m'nyumba.\n",
            "H-68\t-0.2626769542694092\t▁ A t s i k a n a ▁ a w i r i ▁ a n g ' o n o a n g ' o n o ▁ a t a k h a l a ▁ p a n j i n g a ▁ w a b u l u u ▁ .\n",
            "D-68\t-0.2626769542694092\tAtsikana awiri ang'onoang'ono atakhala panjinga wabuluu .\n",
            "P-68\t-0.1203 -0.0423 -0.0540 -0.0696 -0.1765 -0.1281 -0.0976 -0.0706 -0.1033 -0.1534 -0.1195 -0.0670 -0.1046 -0.0618 -0.0907 -0.1718 -0.1772 -1.6951 -0.1254 -0.0596 -0.0859 -0.0655 -0.1049 -0.4299 -0.0810 -0.0502 -0.0697 -0.1232 -0.0461 -0.1056 -0.1028 -0.0963 -1.5533 -0.1185 -0.6353 -0.0117 -0.1163 -0.0485 -0.0917 -0.0964 -0.2054 -0.1214 -1.1860 -0.1162 -0.0933 -0.1133 -0.0295 -0.0990 -0.1184 -0.8591 -1.4805 -1.7089 -0.2620 -0.0637 -0.1846 -0.0688 -0.2231 -0.7232 -0.1204\n",
            "T-399\tAnthu awiri, ovala malaya ndi masiketi, atakhala ndikumwetulira.\n",
            "H-399\t-0.199193075299263\t▁ A n t h u ▁ a w i r i ▁ o v a l a ▁ m a l a y a ▁ o v a l a ▁ s i k e t i ▁ a t a k h a l a ▁ k u m e t u l i r a ▁ .\n",
            "D-399\t-0.199193075299263\tAnthu awiri ovala malaya ovala siketi atakhala kumetulira .\n",
            "P-399\t-0.1182 -0.0258 -0.1167 -0.0448 -0.1150 -0.0872 -0.1184 -0.1255 -0.0848 -0.1301 -0.0779 -0.1021 -0.1700 -0.0990 -0.1015 -0.1192 -0.0886 -0.1239 -0.1048 -0.0984 -0.1889 -0.0582 -0.1125 -0.0558 -0.0984 -0.1090 -0.7281 -2.1511 -0.1393 -0.0961 -0.1063 -0.1141 -0.3199 -0.1212 -0.0281 -0.0443 -0.0179 -0.0733 -0.1183 -1.2784 -0.1912 -0.1126 -0.0395 -0.0496 -0.0935 -0.0709 -0.1115 -0.0974 -1.0482 -0.1167 -0.0551 -0.1047 -0.2883 -0.0557 -0.5341 -0.1348 -0.0967 -0.0746 -0.2925 -0.4586 -0.1134\n",
            "T-365\tMnyamatayo wavala malaya abuluu, ndipo mtsikanayo wavala zakuda.\n",
            "H-365\t-0.19580122828483582\t▁ M n y a m a t a ▁ y e m w e ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m t s i k a n a ▁ w o v a l a ▁ z a k u d a ▁ .\n",
            "D-365\t-0.19580122828483582\tMnyamata yemwe wavala malaya abuluu ndi mtsikana wovala zakuda .\n",
            "P-365\t-0.1237 -0.0900 -0.1225 -0.0537 -0.1009 -0.0941 -0.1166 -0.0456 -0.1115 -0.2244 -3.2623 -0.8068 -0.2418 -0.1893 -0.1023 -0.0989 -0.0384 -0.1448 -0.0171 -0.1323 -0.0613 -0.1280 -0.1030 -0.0625 -0.1215 -0.0466 -0.1139 -0.0540 -0.1032 -0.1102 -0.1404 -0.1013 -0.1330 -0.0512 -0.0952 -0.0471 -0.1243 -0.0619 -0.0834 -0.1051 -0.1006 -0.9439 -0.1700 -0.0617 -0.0871 -0.0287 -0.0936 -0.0951 -0.1038 -0.3860 -0.4828 -0.1014 -0.0290 -0.1126 -0.0825 -0.1232 -0.1154 -0.0770 -0.1394 -0.1782 -0.0890 -0.1441 -0.0825 -0.3891 -0.6382 -0.1036\n",
            "T-86\takazi awiri akumwetulira atayima moyandikana\n",
            "H-86\t-0.21020054817199707\t▁ A t s i k a n a ▁ a w i r i ▁ a k u m w e t u l i r a ▁ a k u m w e t u l i r a ▁ m o y a n d i k a n a .\n",
            "D-86\t-0.21020054817199707\tAtsikana awiri akumwetulira akumwetulira moyandikana.\n",
            "P-86\t-0.1309 -0.0539 -0.8411 -0.2974 -0.1033 -0.1505 -0.1487 -0.0868 -0.0947 -0.1627 -0.1221 -0.2414 -0.1254 -0.0769 -0.1115 -0.1518 -0.1422 -0.7259 -0.1405 -0.0632 -0.1657 -0.0865 -0.0199 -0.0414 -0.0543 -0.0852 -0.1060 -0.0926 -0.1536 -0.6722 -0.7035 -0.0958 -0.1328 -0.4002 -0.1189 -0.0776 -0.0575 -0.0551 -0.0779 -0.0651 -0.0830 -0.2088 -0.4799 -0.4487 -0.1634 -0.0487 -0.0444 -0.6727 -0.0713 -0.0372 -0.1063 -0.0546 -0.0719 -1.7451 -0.0927\n",
            "T-31\tKamnyamata kakugwedezeka m'mphepete mwa mitengo ndi mtsinje.\n",
            "H-31\t-0.21228070557117462\t▁ K a m n y a m a t a ▁ k a k u g w e d e z e k a ▁ m ' m p h e p e t e ▁ m w a ▁ m s e w u ▁ m ' n j i n g a ▁ .\n",
            "D-31\t-0.21228070557117462\tKamnyamata kakugwedezeka m'mphepete mwa msewu m'njinga .\n",
            "P-31\t-0.1149 -0.5381 -0.1696 -0.1403 -0.0686 -0.0478 -0.1111 -0.0561 -0.1026 -0.0278 -0.0984 -0.1083 -0.0459 -0.1249 -0.1436 -0.0880 -0.4653 -0.0580 -0.0888 -0.1258 -0.0758 -0.0114 -0.1014 -0.0648 -0.1334 -0.1030 -0.0642 -0.5334 -0.4557 -0.2337 -0.0250 -0.0778 -0.0719 -0.0815 -0.0401 -0.0488 -0.0940 -0.1924 -0.0193 -0.0915 -0.1142 -0.2393 -1.4633 -0.0509 -0.2107 -0.0647 -0.2043 -0.8388 -0.4960 -0.6616 -1.2469 -0.0489 -0.1746 -0.0700 -0.1026 -0.2923 -0.6858 -0.1039\n",
            "T-120\tGalu wabulauni ndi woyera amathamanga m'madzi ndi mitengo ndi nthambi zozungulira .\n",
            "H-120\t-0.1989644318819046\t▁ G a l u ▁ w a b u l a u n i ▁ n d i ▁ w o y e r a ▁ a t a v a l a ▁ m a l a y a ▁ a m t e n g o ▁ n d i ▁ z o z u n g u l i r a ▁ .\n",
            "D-120\t-0.1989644318819046\tGalu wabulauni ndi woyera atavala malaya amtengo ndi zozungulira .\n",
            "P-120\t-0.1055 -0.8243 -0.1332 -0.0752 -0.0688 -0.1245 -0.0691 -0.4848 -0.0547 -0.1306 -0.0580 -0.1037 -0.0880 -0.0712 -0.2806 -0.1178 -0.0623 -0.1837 -0.1204 -0.0840 -0.0256 -0.0435 -0.0273 -0.0751 -0.0890 -0.1012 -0.1762 -0.1320 -0.5812 -0.1297 -0.4860 -0.1035 -0.1292 -0.1017 -0.0918 -0.1115 -0.1228 -2.3352 -0.0971 -0.2146 -0.0722 -0.1058 -0.1805 -0.4018 -0.4868 -0.2014 -0.0503 -0.0211 -0.0520 -0.0863 -0.2726 -0.0856 -0.1141 -0.1262 -0.3469 -0.3078 -0.8701 -0.0449 -0.1851 -0.0186 -0.0439 -0.0571 -0.0783 -0.0666 -0.1679 -0.5209 -0.0487 -0.1013\n",
            "T-291\tBambo wina wovala chisoti chabuluu akudumpha kuchokera paphiri panjinga yadothi .\n",
            "H-291\t-0.25063249468803406\t▁ B a m b o ▁ w i n a ▁ w o v a l a ▁ c h i s o t i ▁ c h a ▁ b u l u u ▁ a k u d u m p h a ▁ m ' n j i r a ▁ y a p a n j i n g a ▁ y a k e ▁ .\n",
            "D-291\t-0.25063249468803406\tBambo wina wovala chisoti cha buluu akudumpha m'njira yapanjinga yake .\n",
            "P-291\t-0.1215 -0.7685 -0.1184 -0.5730 -0.0685 -0.0482 -0.1246 -0.0724 -0.1229 -0.1044 -0.0951 -0.1103 -0.0620 -0.0897 -0.0871 -0.1072 -0.0780 -0.1138 -0.0995 -0.1752 -0.1466 -0.1012 -0.5426 -0.1872 -0.0401 -0.0863 -0.1329 -0.0635 -0.1235 -0.0831 -0.6032 -0.1307 -0.2872 -0.1248 -0.1032 -0.0359 -0.1146 -0.0814 -0.0334 -0.0793 -0.8323 -0.0670 -0.7775 -0.0225 -0.0567 -0.1253 -0.1300 -0.4595 -1.2344 -1.0718 -1.0623 -0.1191 -0.0896 -0.0871 -0.1079 -0.0544 -0.1754 -1.6983 -0.1332 -0.1001 -0.0235 -0.0936 -0.7053 -0.1337 -0.0886 -0.1183 -0.1544 -0.2003 -1.2329 -0.1170 -0.1907 -0.4880 -0.1046\n",
            "T-135\tWadazi wa masharubu oyera wavala khutu la bluetooth .\n",
            "H-135\t-0.398796409368515\t▁ W o t h a z i r a ▁ w a ▁ m a s h a r u b u ▁ o y e r a ▁ w o v a l a ▁ t - s h i r t ▁ y a k u d a ▁ .\n",
            "D-135\t-0.398796409368515\tWothazira wa masharubu oyera wovala t-shirt yakuda .\n",
            "P-135\t-0.1055 -0.3507 -0.1543 -2.2514 -0.0844 -0.1118 -0.7894 -0.1356 -0.7352 -0.1820 -0.1359 -2.4147 -0.1133 -0.5664 -0.4120 -0.0921 -0.5480 -0.2074 -0.1160 -0.3244 -0.0379 -0.0954 -0.1091 -0.1150 -0.4841 -0.0835 -0.0849 -0.1056 -0.0957 -0.1508 -0.8455 -1.0508 -0.0715 -0.1201 -0.1265 -0.1064 -0.1066 -2.2407 -1.3492 -0.0664 -0.1065 -1.1262 -0.0056 -0.0116 -0.1106 -0.1050 -0.1029 -1.1976 -0.1058 -0.1412 -0.1029 -0.6603 -0.3997 -0.0826\n",
            "T-50\tMbalame yaikulu yotuwa ndi yoyera imayamba kuuluka .\n",
            "H-50\t-0.31295067071914673\t▁ M b a l a m e ▁ y a i k u l u ▁ y o t u w a ▁ n d i ▁ w a n y a m u l a ▁ m a l a y a ▁ a b u l u u ▁ .\n",
            "D-50\t-0.31295067071914673\tMbalame yaikulu yotuwa ndi wanyamula malaya abuluu .\n",
            "P-50\t-0.1049 -1.9494 -1.3795 -0.1206 -0.0627 -0.1160 -0.0611 -0.0679 -0.0884 -0.0667 -0.1945 -0.3366 -0.6924 -0.0661 -0.0473 -0.0718 -0.1224 -0.0610 -0.1037 -0.0573 -2.7064 -0.0819 -0.1417 -0.1413 -0.1301 -0.0847 -0.1014 -0.1097 -0.6040 -0.1501 -0.3323 -0.1303 -0.2091 -0.0846 -0.2616 -0.0518 -0.0915 -0.1209 -2.0779 -0.5635 -1.0163 -0.2500 -0.1005 -0.0939 -0.1181 -0.2193 -0.3637 -0.0748 -0.0485 -0.0793 -0.0413 -0.2473 -0.2171 -0.0839\n",
            "T-363\tParade of cheerleaders ovala yunifolomu yakuda, pinki ndi yoyera.\n",
            "H-363\t-0.3328227698802948\t▁ A l e n d o ▁ o s e w e r a ▁ z o v a l a ▁ z o v a l a ▁ y u n i f o l o m u ▁ y a k u d a ▁ n d i ▁ y o y e r a ▁ .\n",
            "D-363\t-0.3328227698802948\tAlendo osewera zovala zovala yunifolomu yakuda ndi yoyera .\n",
            "P-363\t-0.1188 -1.8202 -0.6380 -0.2968 -0.2301 -0.7676 -0.5672 -0.1311 -0.6070 -2.0131 -0.2688 -0.1718 -0.0837 -0.0461 -0.1088 -0.1593 -1.7687 -0.1677 -0.2397 -0.1177 -0.0709 -0.1050 -0.1066 -0.0178 -0.1122 -1.0068 -0.0954 -0.0831 -0.0984 -0.1144 -1.9896 -0.1654 -0.0584 -0.0503 -0.0761 -0.1062 -0.1488 -0.0586 -0.0227 -0.0659 -0.1099 -0.0628 -0.1240 -0.6412 -0.3323 -0.1377 -0.1056 -0.1412 -0.3451 -0.0795 -0.1001 -0.0802 -2.0696 -0.0726 -0.1027 -0.0931 -0.0682 -0.0894 -0.5063 -0.0478 -0.1183\n",
            "T-217\tMunthu wovala malaya akuda akuliza gitala lamagetsi .\n",
            "H-217\t-0.25381195545196533\t▁ M n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u l i z a ▁ g i t a l a ▁ l a k e ▁ m ' m a d z i ▁ .\n",
            "D-217\t-0.25381195545196533\tMnyamata wovala malaya akuda akuliza gitala lake m'madzi .\n",
            "P-217\t-0.0993 -0.8099 -0.3840 -0.0685 -0.1018 -0.1355 -0.1257 -0.0297 -0.1198 -0.1405 -0.1114 -0.0826 -0.0611 -0.1076 -0.0844 -0.1119 -0.1078 -0.0685 -0.1050 -0.0622 -0.1089 -0.0440 -0.1007 -0.1233 -0.1281 -0.4662 -0.1116 -0.1000 -0.1033 -0.1182 -0.1358 -0.5595 -0.1209 -1.0795 -0.3180 -0.2799 -0.1113 -0.0982 -2.2807 -0.1496 -0.0471 -0.0963 -0.0339 -0.1170 -0.1270 -0.5100 -0.1086 -2.0900 -0.2247 -0.1220 -0.6574 -0.2320 -0.1548 -0.1079 -0.0571 -0.1092 -0.0811 -0.5347 -0.2596 -0.1033\n",
            "T-384\tAmuna angapo akusewera mpira wa basketball ku paki usiku.\n",
            "H-384\t-0.23013851046562195\t▁ A m u n a ▁ a n g a p o ▁ a k u s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ .\n",
            "D-384\t-0.23013851046562195\tAmuna angapo akusewera mpira wa basketball .\n",
            "P-384\t-0.1101 -1.8316 -0.1269 -0.0725 -0.1047 -0.1065 -0.1307 -0.1615 -0.0432 -0.0849 -0.0908 -0.0249 -0.0501 -0.1558 -0.1379 -0.0861 -0.0776 -0.1164 -0.0478 -0.2219 -0.0857 -0.0784 -0.1117 -0.1260 -0.3941 -0.2713 -0.0901 -0.1664 -0.1086 -0.1408 -0.1977 -0.2977 -0.3442 -0.5070 -0.0625 -0.0177 -0.3404 -0.1315 -0.0165 -0.1599 -0.0830 -0.0389 -0.3112 -0.3534 -2.2610 -0.1090\n",
            "T-7\tMtsikana wamkulu akuseka ndikumugwira mtsikanayo panja\n",
            "H-7\t-0.24352645874023438\t▁ M t s i k a n a ▁ w a m k u l u ▁ a k u s e k a ▁ n d i ▁ k u g w i r a ▁ m t s i k a n a ▁ y e k h a ▁ .\n",
            "D-7\t-0.24352645874023438\tMtsikana wamkulu akuseka ndi kugwira mtsikana yekha .\n",
            "P-7\t-0.1225 -0.5217 -0.0847 -0.1206 -0.0997 -0.0473 -0.1157 -0.0787 -0.1137 -0.1490 -0.2429 -0.5122 -0.0415 -0.2306 -0.1461 -0.0355 -0.0451 -0.1370 -0.0939 -0.0840 -0.0680 -0.1598 -0.0501 -0.4706 -0.0812 -0.0866 -0.0631 -0.0879 -0.1240 -0.2295 -0.8299 -0.5276 -0.3930 -0.6417 -0.1834 -0.1067 -0.0957 -0.1073 -0.1182 -1.1844 -0.0929 -0.0916 -0.0714 -0.1004 -0.0711 -0.0979 -0.6067 -0.4701 -1.5191 -0.3751 -0.0193 -0.1288 -0.7940 -0.2296 -0.0948\n",
            "T-355\tGalu amabisala muudzu wautali m'mphepete mwa nyanja\n",
            "H-355\t-0.2713638246059418\t▁ G a l u ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ w a u z u ▁ m ' m p h e p e t e ▁ m w a ▁ n y a n j a ▁ .\n",
            "D-355\t-0.2713638246059418\tGalu wovala malaya abuluu wauzu m'mphepete mwa nyanja .\n",
            "P-355\t-0.1190 -0.0888 -0.0949 -0.0738 -0.0558 -0.1167 -1.0465 -1.1863 -1.9283 -0.2211 -0.0836 -0.0985 -0.1130 -0.1137 -0.1184 -1.4088 -0.1155 -0.1416 -0.0918 -0.1033 -0.1152 -1.1923 -0.0680 -0.0733 -0.1030 -0.0550 -0.1366 -0.7217 -0.3813 -0.2978 -0.7134 -0.0841 -0.2820 -1.6799 -0.1490 -0.1278 -0.0098 -0.0401 -0.0789 -0.0169 -0.0701 -0.0619 -0.0970 -0.0909 -0.0320 -0.0747 -0.1258 -0.0873 -0.0743 -0.0161 -0.0909 -0.0632 -0.1374 -0.0755 -0.4812 -0.1474 -0.0966\n",
            "T-352\tMa raft awiri amtundu wa buluu akuwombana pamadzi oyera.\n",
            "H-352\t-0.2582106292247772\t▁ M a y i ▁ a k u g w i r a ▁ m u t u ▁ w a b u l u u ▁ w a b u l u u ▁ a k u m b a n a ▁ p a m a d z i ▁ o d y e r a ▁ .\n",
            "D-352\t-0.2582106292247772\tMayi akugwira mutu wabuluu wabuluu akumbana pamadzi odyera .\n",
            "P-352\t-0.1278 -0.0731 -0.1222 -0.3039 -0.0818 -0.1165 -0.1665 -0.7080 -0.2179 -0.0786 -0.0442 -0.1187 -0.0646 -0.1106 -0.1342 -0.2118 -0.1350 -1.0629 -0.0977 -0.1434 -0.2196 -0.1103 -0.7078 -0.1386 -0.0439 -0.1570 -0.0488 -0.1347 -1.4802 -0.2651 -0.2731 -0.0923 -0.0525 -0.1036 -0.0782 -0.1424 -0.4737 -0.1321 -0.0770 -0.3897 -1.4857 -0.1080 -0.7324 -0.1715 -0.1554 -0.5348 -0.1248 -0.1933 -0.0815 -0.3799 -0.0185 -0.0872 -0.2231 -0.0497 -0.6707 -0.2366 -0.0810 -0.2443 -0.0842 -0.9608 -0.0447 -0.1008\n",
            "T-420\tAmuna awiri ndi mkazi akuombera limodzi .\n",
            "H-420\t-0.23692142963409424\t▁ A m e n e ▁ a w i r i ▁ n d i ▁ m k a z i ▁ a k u m w e t u l i r a ▁ .\n",
            "D-420\t-0.23692142963409424\tAmene awiri ndi mkazi akumwetulira .\n",
            "P-420\t-0.1180 -0.5213 -0.0831 -0.2371 -0.9720 -0.2493 -0.1449 -0.1058 -0.0838 -0.1419 -0.0871 -0.1329 -0.2243 -0.3642 -0.0545 -0.1005 -0.0727 -0.1275 -0.1002 -0.1192 -0.0111 -0.1018 -0.0932 -0.5211 -0.0664 -0.0669 -0.7300 -1.1002 -0.1234 -0.3060 -0.1345 -0.0394 -0.1188 -0.0763 -0.0878 -0.1537 -1.1510 -0.0813\n",
            "T-74\tAmuna ndi akazi amasonkhana kuti apeze chakudya pamalo otsika .\n",
            "H-74\t-0.28244444727897644\t▁ A m u n a ▁ n d i ▁ a k a z i ▁ a m a s o n k h a n a ▁ k u t i ▁ a g w i r e ▁ c h a k u d y a ▁ p a m a l o ▁ o s i k a ▁ .\n",
            "D-74\t-0.28244444727897644\tAmuna ndi akazi amasonkhana kuti agwire chakudya pamalo osika .\n",
            "P-74\t-0.1090 -0.0490 -0.0857 -0.0670 -0.1080 -0.2519 -0.1272 -0.1295 -0.0454 -0.1906 -0.0876 -0.0455 -1.8306 -0.4155 -0.0884 -0.0689 -0.1564 -0.0680 -1.6818 -0.1100 -0.0702 -0.1403 -0.2404 -0.0787 -0.0342 -0.0947 -0.0404 -0.0894 -0.1182 -0.6051 -0.0970 -0.5455 -0.2139 -0.0754 -0.0668 -1.7064 -0.1584 -0.1422 -0.0813 -0.0791 -0.1047 -0.0885 -0.1103 -0.1274 -0.9633 -0.0628 -1.0306 -0.3714 -0.1107 -0.2289 -0.2475 -0.1559 -0.1408 -0.0973 -0.0463 -0.0551 -0.1588 -0.2296 -0.3209 -0.5166 -0.7981 -0.5015 -0.9982 -0.3829 -0.1170\n",
            "T-380\tMunthu amene wanyamula chiwalo cha tenisi akumenya mpira wachikaso .\n",
            "H-380\t-0.26670342683792114\t▁ M u n t h u ▁ w a m e n e ▁ w a n y a m u l a ▁ c h i n g w e ▁ c h a ▁ t e n i s i ▁ a k u m e n y a ▁ m p i r a ▁ w a c h i k a s u .\n",
            "D-380\t-0.26670342683792114\tMunthu wamene wanyamula chingwe cha tenisi akumenya mpira wachikasu.\n",
            "P-380\t-0.1119 -0.1151 -0.0785 -0.0892 -0.0914 -0.1325 -0.0920 -0.1476 -0.6486 -1.0400 -0.4394 -0.3243 -0.0847 -0.2745 -0.1293 -0.0893 -0.1224 -1.5364 -0.0322 -0.1026 -0.1056 -0.0527 -0.0563 -0.1113 -0.1176 -0.0360 -0.0836 -0.0893 -1.5019 -0.4437 -0.0591 -0.9629 -0.1327 -0.0486 -0.0873 -0.1318 -0.7178 -0.6028 -0.0481 -0.1341 -0.1665 -0.0384 -0.3600 -0.1002 -0.1639 -0.0280 -0.0987 -0.1440 -0.2758 -0.1294 -0.0259 -0.1067 -0.1330 -0.0756 -0.0297 -0.0840 -0.0962 -0.1125 -0.2107 -0.5972 -0.1246 -0.9485 -0.1514 -0.1195 -0.0225 -0.1361 -0.0278 -0.0934 -2.7706 -0.0932\n",
            "T-46\tGalu wakuda ndi wabulauni amasewera ndi ndodo yayitali .\n",
            "H-46\t-0.18951107561588287\t▁ G a l u ▁ w a k u d a ▁ n d i ▁ w a b u l a u n i ▁ a m a s e w e r a ▁ n d i ▁ n d o d o ▁ y a i k u l u ▁ .\n",
            "D-46\t-0.18951107561588287\tGalu wakuda ndi wabulauni amasewera ndi ndodo yaikulu .\n",
            "P-46\t-0.1174 -0.0791 -0.1154 -0.0687 -0.0647 -0.1295 -0.0568 -0.1001 -0.1882 -0.0754 -0.2998 -0.1590 -0.1636 -0.0708 -0.0994 -0.1067 -0.1012 -0.0189 -2.4536 -0.3720 -0.2188 -0.0732 -0.0838 -0.0449 -0.0750 -0.0606 -0.1255 -0.1076 -0.1264 -0.0937 -0.1812 -0.0762 -0.0690 -0.0736 -0.0690 -0.0997 -0.1193 -0.1277 -0.0488 -0.2139 -0.0731 -0.3661 -0.1631 -0.0341 -0.0417 -0.0225 -0.1445 -0.0565 -0.2156 -0.3448 -0.8809 -0.1777 -0.0901 -0.0511 -0.3302 -0.7852 -0.0964\n",
            "T-362\tMwana wamng'ono wanyamula mpira wa pinki wa ulusi .\n",
            "H-362\t-0.23303210735321045\t▁ M w a n a ▁ w a m n g ' o n o ▁ w a n y a m u l a ▁ m u n t h u ▁ w a k e ▁ w a u d z u ▁ .\n",
            "D-362\t-0.23303210735321045\tMwana wamng'ono wanyamula munthu wake waudzu .\n",
            "P-362\t-0.1089 -0.1081 -0.0937 -0.1242 -0.0726 -0.0938 -0.1626 -0.0797 -0.1203 -0.1356 -0.0857 -0.0964 -0.0548 -0.0883 -0.0507 -0.0567 -0.1380 -0.0484 -0.7681 -0.3783 -0.0342 -0.1030 -0.1297 -0.0654 -0.0410 -0.1147 -0.1013 -0.2668 -0.3217 -1.3551 -0.0685 -0.0561 -0.0817 -0.1216 -0.0636 -0.1291 -0.8410 -0.1072 -0.0966 -0.3848 -0.1421 -1.1319 -0.2589 -0.8085 -0.1091 -0.2211 -1.0469 -0.1190\n",
            "T-305\tGalu akuthamanga m'madzi ambiri ndikupangitsa kuti agwetse .\n",
            "H-305\t-0.29100900888442993\t▁ G a l u ▁ a k u t h a m a n g a ▁ m ' m a d z i ▁ n d i ▁ a n t h u ▁ a m b i r i ▁ z a k u d y a ▁ .\n",
            "D-305\t-0.29100900888442993\tGalu akuthamanga m'madzi ndi anthu ambiri zakudya .\n",
            "P-305\t-0.1241 -0.6766 -0.1203 -0.0731 -0.0728 -0.1088 -0.5119 -0.1125 -0.0701 -0.1052 -0.0856 -0.0893 -0.0987 -0.0841 -0.0785 -0.0746 -0.0843 -0.1335 -0.0410 -0.2678 -0.1701 -0.1089 -0.3626 -0.1500 -0.1030 -0.1472 -0.3357 -0.0784 -0.1077 -0.1523 -0.7427 -0.5626 -0.5162 -0.2705 -0.0707 -0.1231 -0.4214 -1.6529 -0.3239 -0.0725 -0.1123 -0.1068 -0.2460 -2.9755 -0.1661 -0.6176 -0.0770 -0.2833 -0.3759 -0.1052 -0.4165 -0.3681 -0.0877\n",
            "T-206\tMunthu yemwe ali ndi suti ya buluu ndi yakuda akusefukira.\n",
            "H-206\t-0.27304691076278687\t▁ M u n t h u ▁ y e m w e ▁ a l i ▁ n d i ▁ s u t i ▁ y a ▁ b u l u u ▁ n d i ▁ y a k u d a ▁ a k u j a m b u l a ▁ .\n",
            "D-206\t-0.27304691076278687\tMunthu yemwe ali ndi suti ya buluu ndi yakuda akujambula .\n",
            "P-206\t-0.1261 -0.0997 -0.0309 -0.0888 -0.0366 -0.0842 -0.1100 -0.2120 -0.1216 -0.0600 -0.0516 -0.0724 -0.1320 -0.0964 -0.1506 -0.0318 -0.0833 -0.1090 -0.0342 -0.1196 -0.1148 -0.0762 -0.3180 -0.3404 -0.0392 -0.3833 -0.1193 -0.0295 -0.1458 -0.3534 -0.0529 -1.1232 -0.0813 -0.1657 -0.0663 -0.1077 -0.0599 -0.1235 -0.1077 -0.0773 -0.9659 -0.1300 -0.3432 -0.0845 -0.3013 -0.1524 -0.1441 -0.0903 -0.7286 -0.1164 -1.5295 -0.1054 -1.3973 -0.2431 -0.1667 -0.1443 -0.1191 -0.2860 -3.4892 -0.1091\n",
            "T-308\tKamwana akuyang'ana nkhunda kutsidya lina la msewu .\n",
            "H-308\t-0.27423009276390076\t▁ A m u n a ▁ a k u y a n g ' a n a ▁ k u t s o g o l o ▁ k w a ▁ g u l u ▁ l i n a ▁ n d i ▁ m s e w u ▁ .\n",
            "D-308\t-0.27423009276390076\tAmuna akuyang'ana kutsogolo kwa gulu lina ndi msewu .\n",
            "P-308\t-0.1156 -0.3756 -0.1498 -0.1861 -0.0926 -0.0969 -0.1191 -0.1160 -0.7172 -0.0768 -0.0985 -0.1557 -0.0483 -0.1710 -0.1886 -0.1036 -0.0867 -0.1011 -0.0988 -0.3202 -0.8173 -1.5694 -0.3869 -0.1677 -0.0405 -0.0899 -0.0569 -0.0838 -0.1077 -0.0647 -0.1054 -0.1187 -0.1292 -1.7523 -0.5810 -0.4173 -0.4360 -0.1899 -0.0698 -0.5499 -0.1111 -0.0651 -0.2045 -0.7398 -0.1458 -0.1117 -0.0855 -0.2250 -1.4179 -0.0742 -0.1215 -0.0474 -0.3989 -0.0818 -0.1000\n",
            "T-371\tMnyamata akumenya mpira wa tenisi ndi racket yakuda ndi yachikasu .\n",
            "H-371\t-0.24158617854118347\t▁ M n y a m a t a ▁ a k u m e n y a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ n d i ▁ j e k e t e ▁ y a k u d a ▁ y a c h i k a s u ▁ .\n",
            "D-371\t-0.24158617854118347\tMnyamata akumenya mpira wa tenisi ndi jekete yakuda yachikasu .\n",
            "P-371\t-0.1212 -0.0811 -0.0558 -0.0490 -0.0894 -0.0592 -0.1042 -0.0424 -0.0969 -0.1325 -0.0565 -0.0875 -0.0933 -0.2959 -0.2664 -0.0899 -0.0560 -0.1044 -0.1208 -0.0888 -0.0246 -0.2582 -0.1205 -0.1107 -0.1335 -0.0769 -0.1093 -0.3740 -0.1926 -0.1051 -0.1260 -0.6690 -0.1829 -1.1092 -0.0994 -0.8499 -0.0474 -0.1272 -0.1661 -1.5231 -0.0839 -0.5838 -0.0573 -0.0591 -0.1383 -0.1324 -0.1012 -0.1144 -1.5888 -0.0702 -0.1875 -0.1516 -0.2204 -1.0933 -0.2366 -0.8305 -0.1322 -0.0952 -0.1937 -0.1179 -0.0266 -0.0832 -0.6218 -0.1832 -0.1034\n",
            "T-63\tMwana wovala malaya a baseball amakwawa ndi chubu .\n",
            "H-63\t-0.28160133957862854\t▁ M w a n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u s e w e r a ▁ m ' c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-63\t-0.28160133957862854\tMwana wovala malaya abuluu akusewera m'chipale chofewa .\n",
            "P-63\t-0.1160 -0.0782 -0.1638 -0.1325 -0.1168 -0.1027 -0.1701 -0.0757 -0.0753 -0.1236 -0.1143 -0.0779 -0.1155 -0.1073 -0.0814 -0.1393 -0.0608 -0.1100 -0.0606 -0.1017 -0.1027 -0.1382 -0.8187 -0.1008 -0.1103 -1.1187 -0.0410 -0.1178 -0.8518 -1.8406 -0.0770 -0.7205 -0.1410 -0.2989 -0.2717 -0.0771 -0.0858 -0.1180 -0.2696 -0.2991 -1.2487 -0.1561 -0.1038 -1.2800 -0.5192 -0.0682 -0.1042 -0.1473 -1.2841 -0.1734 -0.1331 -0.1775 -0.0931 -0.1243 -0.1219 -0.6051 -0.1673 -0.1026\n",
            "T-385\tGulu la anthu akuyang'ana nyumba yokongola kwambiri .\n",
            "H-385\t-0.15111203491687775\t▁ G u l u ▁ l a ▁ a n t h u ▁ a k u y a n g ' a n a ▁ n y u m b a ▁ y o k o n g o l a ▁ k w a m b i r i ▁ .\n",
            "D-385\t-0.15111203491687775\tGulu la anthu akuyang'ana nyumba yokongola kwambiri .\n",
            "P-385\t-0.1133 -0.0552 -0.0680 -0.0560 -0.0694 -0.1104 -0.2911 -0.1145 -0.0977 -0.1089 -0.0515 -0.0288 -0.0972 -0.0926 -0.1136 -0.5406 -0.0950 -0.0986 -0.0762 -0.1202 -0.0568 -0.0674 -0.0908 -0.0964 -0.0668 -0.0983 -0.1032 -0.8805 -0.0974 -0.0490 -0.1796 -0.0818 -0.0999 -0.0939 -0.0711 -0.1060 -0.0980 -0.4562 -0.2616 -0.0529 -0.0431 -0.0547 -0.1035 -0.1804 -0.3308 -0.5041 -0.1103 -0.4624 -0.0322 -0.0887 -0.0601 -0.1068 -0.6075 -0.0345 -0.0855\n",
            "T-57\tMunthu wovala jekete lakuda akudumpha mumlengalenga panjinga .\n",
            "H-57\t-0.20697034895420074\t▁ M u n t h u ▁ w o v a l a ▁ j e k e t e ▁ y a k u d a ▁ a k u j a m b u l a ▁ y e m w e ▁ a l i ▁ n d i ▁ n j i n g a ▁ .\n",
            "D-57\t-0.20697034895420074\tMunthu wovala jekete yakuda akujambula yemwe ali ndi njinga .\n",
            "P-57\t-0.1151 -0.1695 -0.1041 -0.0852 -0.1047 -0.0807 -0.0796 -0.1381 -0.0771 -0.0672 -0.0360 -0.1116 -0.0793 -0.1067 -0.0861 -0.5739 -0.0719 -0.0796 -0.0924 -0.0340 -0.1841 -0.0896 -0.2400 -0.1127 -0.2795 -0.0951 -0.1918 -0.0811 -0.1352 -0.2745 -0.0780 -0.1087 -1.4771 -0.0860 -0.2013 -0.1479 -0.1097 -0.1041 -0.1692 -0.1335 -2.2362 -0.2027 -0.2310 -0.0930 -0.1094 -0.1279 -0.1943 -0.3311 -0.0710 -0.1090 -0.2448 -0.2908 -0.0912 -0.0705 -0.2109 -0.6472 -0.3677 -0.0937 -0.0369 -0.0789 -0.2196 -0.2950 -0.0946\n",
            "T-212\tAzimayi awiri atakumbatirana akumwetulira mu kamera .\n",
            "H-212\t-0.3077118396759033\t▁ A c h i n y a m a t a ▁ a w i r i ▁ a t a k h a l a ▁ n d i ▁ k u m w e t u l i r a ▁ m u ▁ k a m e r a .\n",
            "D-212\t-0.3077118396759033\tAchinyamata awiri atakhala ndi kumwetulira mu kamera.\n",
            "P-212\t-0.1094 -0.0513 -1.3432 -0.1378 -0.0886 -0.4428 -0.0380 -0.1177 -0.6347 -0.1194 -0.1835 -0.1151 -0.1701 -0.1700 -0.0493 -0.1314 -0.0641 -0.0917 -0.1288 -0.1055 -0.4171 -0.1150 -0.2261 -1.0705 -0.2656 -0.0382 -0.0894 -0.1199 -2.4772 -0.1078 -0.1116 -0.1396 -2.2762 -0.2355 -1.1022 -0.1517 -0.0668 -0.0172 -0.0348 -0.0498 -0.0658 -0.1849 -0.0829 -0.1515 -0.3474 -0.8205 -0.0814 -0.5439 -0.0745 -0.0636 -0.1582 -0.0228 -0.0851 -0.7585 -0.0789\n",
            "T-314\tKamnyamata ka shati lakuda ndi jinzi ya buluu akuyenda m'njira .\n",
            "H-314\t-0.2771613597869873\t▁ K a m n y a m a t a ▁ k a ▁ t s i t s i ▁ l a k u d a ▁ n d i ▁ j e a n s ▁ y a b u l u u ▁ a k u y e n d a ▁ m ' d a n j a ▁ .\n",
            "D-314\t-0.2771613597869873\tKamnyamata ka tsitsi lakuda ndi jeans yabuluu akuyenda m'danja .\n",
            "P-314\t-0.1184 -0.0889 -0.1197 -0.1271 -0.0843 -0.0367 -0.1052 -0.0640 -0.1018 -0.0364 -0.0971 -0.1158 -0.0472 -0.1399 -0.7525 -2.3945 -0.3393 -0.2414 -0.9015 -0.1716 -0.1576 -0.0781 -0.0933 -0.1164 -0.3930 -0.0754 -0.4663 -0.5125 -0.1363 -0.1907 -0.0916 -0.1126 -0.0773 -0.0438 -1.1904 -0.2329 -0.0551 -0.1193 -0.1157 -0.1353 -0.1191 -1.5472 -0.1204 -0.0540 -0.0936 -0.0334 -0.1489 -0.3808 -0.0565 -0.0655 -0.2909 -0.1308 -0.0945 -0.0403 -0.1134 -0.1710 -0.2110 -0.2758 -1.0537 -0.3223 -0.8090 -0.1869 -0.4233 -0.5729 -0.3943 -0.1064\n",
            "T-353\tGalu wa bulauni akudumpha panjira yotchinga m'chipinda .\n",
            "H-353\t-0.22096244990825653\t▁ G a l u ▁ w a b u l a u n i ▁ a k u d u m p h a ▁ p a n j i r a ▁ y o d z a z a ▁ n d i ▁ n j i n g a ▁ .\n",
            "D-353\t-0.22096244990825653\tGalu wabulauni akudumpha panjira yodzaza ndi njinga .\n",
            "P-353\t-0.1147 -0.1513 -0.1063 -0.0801 -0.0901 -0.1384 -0.0560 -0.4695 -0.0470 -0.0865 -0.0544 -0.0836 -0.0476 -0.0629 -0.0543 -0.1293 -0.0930 -0.0906 -0.0831 -0.0572 -0.0542 -0.0529 -0.0987 -0.1354 -0.0935 -0.1262 -0.3256 -0.1184 -0.2004 -0.0244 -0.0960 -0.1387 -0.0900 -0.1117 -0.0313 -0.6265 -0.8248 -1.0930 -0.1333 -0.1787 -0.0971 -0.1389 -1.3394 -0.2520 -0.1251 -0.0759 -1.5790 -0.7410 -0.2042 -0.3073 -0.0804 -0.1087 -0.2471 -0.1195 -0.0877\n",
            "T-345\tAmuna awiri ali mkati akuphika pamoto .\n",
            "H-345\t-0.3206768333911896\t▁ A m u n a ▁ a w i r i ▁ a l i ▁ m ' k a z i ▁ a k u p h i k a ▁ p a m o t o ▁ .\n",
            "D-345\t-0.3206768333911896\tAmuna awiri ali m'kazi akuphika pamoto .\n",
            "P-345\t-0.1160 -0.0373 -0.1150 -0.0802 -0.0887 -0.1143 -0.1400 -0.1259 -0.0977 -0.1291 -0.0589 -0.1176 -0.1372 -0.1097 -0.1584 -0.0917 -0.1351 -0.0958 -0.6605 -0.4366 -0.1049 -1.4344 -0.1664 -0.1142 -0.1193 -0.2920 -0.0796 -1.4953 -1.6541 -0.0686 -0.0638 -0.0821 -0.0913 -0.4646 -0.1169 -0.3399 -0.7167 -1.5765 -0.0725 -0.3090 -0.9785 -0.0821\n",
            "T-227\tGulu la anthu laima pa chipale chofewa m'phiri .\n",
            "H-227\t-0.21639342606067657\t▁ G u l u ▁ l a ▁ a n t h u ▁ l a i m a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-227\t-0.21639342606067657\tGulu la anthu laima pa chipale chofewa .\n",
            "P-227\t-0.1076 -0.0398 -0.0946 -0.0735 -0.1053 -0.1107 -0.1028 -0.1919 -0.1240 -0.1024 -0.1795 -0.0423 -0.1056 -0.0756 -0.1241 -0.7016 -0.2293 -0.4288 -0.1085 -0.1553 -0.1006 -1.3231 -0.1423 -0.4393 -0.1051 -0.0533 -0.0824 -0.0862 -0.1108 -0.1105 -0.0947 -0.0909 -0.0234 -0.0605 -0.0509 -0.0545 -0.0902 -0.0957 -0.0914 -0.2489 -2.3110 -0.1196\n",
            "T-287\tGalu woyera akusambira m'nyanja pamene mbalame ikuuluka .\n",
            "H-287\t-0.28507548570632935\t▁ G u l u ▁ l a ▁ a k u s a m b i r a ▁ m ' m a n j a ▁ p a m e n e ▁ a l i ▁ p a m e n e ▁ g u l u ▁ l a ▁ a n t h u ▁ .\n",
            "D-287\t-0.28507548570632935\tGulu la akusambira m'manja pamene ali pamene gulu la anthu .\n",
            "P-287\t-0.1190 -0.6335 -0.1331 -0.1350 -0.0926 -0.1303 -0.2013 -1.0077 -0.6710 -1.2704 -1.2371 -0.1630 -0.1833 -0.1127 -0.0792 -0.0646 -0.0915 -0.0795 -0.0714 -0.1365 -0.2363 -0.0600 -0.1063 -0.1847 -0.2634 -0.0287 -0.0955 -0.1127 -0.3794 -0.1116 -0.3536 -0.6500 -0.0530 -0.0836 -0.0990 -0.2090 -0.3594 -0.1732 -0.0973 -0.5455 -0.1371 -0.7152 -0.1491 -0.0570 -0.0747 -0.1200 -1.6463 -0.0923 -0.0547 -0.0708 -0.2331 -0.0539 -0.6583 -0.3471 -0.1750 -0.1788 -0.7668 -0.0829 -0.0711 -0.3482 -0.7248 -0.1020\n",
            "T-264\tWoyimba wachimuna wovala zoyera akuimba gitala .\n",
            "H-264\t-0.19885334372520447\t▁ W o y i m b a ▁ w a c h i m w a m u n a ▁ w o v a l a ▁ z o y e r a ▁ a k u i m b a ▁ g i t a l a ▁ .\n",
            "D-264\t-0.19885334372520447\tWoyimba wachimwamuna wovala zoyera akuimba gitala .\n",
            "P-264\t-0.1109 -0.5436 -0.2980 -0.3304 -0.2893 -0.2034 -0.0488 -0.0992 -0.1103 -0.0806 -0.1110 -0.2050 -0.0725 -0.0813 -0.4652 -2.2510 -0.2958 -0.4166 -0.1027 -0.0853 -0.1018 -0.1155 -0.0487 -0.0950 -0.0367 -0.1034 -0.1268 -0.1140 -0.1200 -0.0409 -0.0944 -0.2571 -0.0860 -0.1096 -0.0990 -0.1422 -0.1663 -0.0702 -0.0938 -0.7097 -0.1010 -0.0683 -0.1020 -0.1101 -0.2426 -0.0784 -0.0178 -0.0992 -0.0675 -0.1316 -0.3412 -0.1512 -0.0961\n",
            "T-307\tMwamuna ndi mkazi akupsompsonana pachibowo choyang'ana padoko ladzuwa.\n",
            "H-307\t-0.30358585715293884\t▁ M w a m u n a ▁ n d i ▁ m k a z i ▁ a k u t s o g o l o ▁ k w a ▁ n y a n j a ▁ .\n",
            "D-307\t-0.30358585715293884\tMwamuna ndi mkazi akutsogolo kwa nyanja .\n",
            "P-307\t-0.1119 -1.3175 -0.1280 -0.1000 -0.6950 -0.0508 -0.1039 -0.1152 -0.1844 -0.0669 -0.0850 -0.0908 -0.0790 -0.1167 -0.7463 -0.0941 -0.0198 -0.0911 -0.1340 -0.0891 -0.1053 -0.0626 -2.5150 -1.2451 -0.2736 -0.0657 -0.0827 -0.1119 -0.1469 -0.1256 -1.7283 -0.0868 -0.1444 -0.0992 -0.1894 -0.1176 -0.4262 -0.1478 -0.3147 -0.1142 -0.3256 -0.1190 -0.0869\n",
            "T-229\tGalu wabulauniyu akukumba dzenje pomwe pali mbewu pafupi ndi .\n",
            "H-229\t-0.269514262676239\t▁ G a l u ▁ w a b u l a u n i ▁ a k u k u m b a ▁ n j i n g a ▁ y o m w e ▁ i l i ▁ p a f u p i ▁ n d i ▁ n j i n g a ▁ .\n",
            "D-229\t-0.269514262676239\tGalu wabulauni akukumba njinga yomwe ili pafupi ndi njinga .\n",
            "P-229\t-0.1021 -0.8611 -0.5564 -0.0812 -0.1415 -0.1396 -0.0578 -0.1130 -0.1695 -0.1141 -0.0443 -0.0806 -0.0680 -0.0555 -0.0877 -0.1227 -0.0611 -0.0459 -0.1191 -1.8754 -0.4931 -0.0506 -0.0879 -0.1018 -0.1101 -1.3937 -0.2172 -0.3028 -0.4405 -0.1600 -0.0809 -0.1113 -0.7281 -1.4916 -0.1586 -0.1137 -0.0900 -0.0788 -0.4070 -0.0234 -0.0835 -0.0830 -0.4970 -0.1226 -0.2546 -0.0741 -0.1108 -0.0724 -0.0934 -0.1116 -0.1081 -0.0912 -0.0898 -0.9482 -0.9520 -0.1388 -0.3481 -0.0540 -0.1173 -0.4978 -0.2347 -0.0894\n",
            "T-153\tMunthu wachikulire akuyendetsa ngolo ndi kamnyamata .\n",
            "H-153\t-0.17717362940311432\t▁ M u n t h u ▁ w a c h i k u l i r e ▁ a k u y e n d e t s a ▁ n g o l o ▁ n d i ▁ k a m n y a m a t a ▁ .\n",
            "D-153\t-0.17717362940311432\tMunthu wachikulire akuyendetsa ngolo ndi kamnyamata .\n",
            "P-153\t-0.1224 -0.1049 -0.0310 -0.0716 -0.0577 -0.1032 -0.0918 -0.1442 -0.2112 -0.1111 -0.4205 -0.0912 -0.0739 -0.0745 -0.0591 -0.0624 -0.0681 -0.0747 -0.0790 -0.1295 -0.1230 -0.0699 -0.1020 -0.1952 -0.0793 -0.1519 -0.0382 -0.0992 -0.1313 -0.1013 -0.1114 -0.0902 -0.2508 -0.2436 -0.1162 -0.0393 -0.0579 -0.0986 -1.5686 -0.0894 -0.0997 -0.6869 -0.4033 -0.3161 -0.1104 -0.1392 -0.0186 -0.0994 -0.0467 -0.0948 -0.0680 -0.0828 -0.1844 -1.3655 -0.0895\n",
            "T-402\tMnyamata akupeza mpweya wambiri pa skateboard pa skatepark\n",
            "H-402\t-0.2632576525211334\t▁ M n y a m a t a ▁ a k u g w e d e z a ▁ m p i r a ▁ w a ▁ m p i r a ▁ p a ▁ s k a t e b o a r d ▁ .\n",
            "D-402\t-0.2632576525211334\tMnyamata akugwedeza mpira wa mpira pa skateboard .\n",
            "P-402\t-0.1258 -0.1315 -0.0377 -0.0486 -0.1032 -0.0646 -0.1113 -0.0490 -0.0962 -0.1232 -0.0694 -0.0731 -0.1164 -2.4323 -0.2591 -0.0884 -0.2562 -0.1158 -0.0338 -0.0981 -0.1441 -0.4226 -0.3501 -0.2524 -0.0920 -0.1448 -0.2016 -0.1732 -0.1773 -0.0780 -1.1420 -2.0874 -0.5325 -0.1617 -0.1057 -0.1671 -0.2166 -0.1302 -0.7488 -0.0326 -0.2188 -0.1318 -0.0163 -0.0282 -0.1383 -0.1946 -0.0754 -0.0229 -0.1514 -0.7236 -0.1112 -0.0824\n",
            "T-401\tBambo akugona pansi galu akugona pachifuwa chake .\n",
            "H-401\t-0.30479931831359863\t▁ B a m b o ▁ a k u g o n a ▁ p a ▁ d z i d a ▁ l a k u g w a ▁ p a ▁ c h i f u w a ▁ c h a k e ▁ .\n",
            "D-401\t-0.30479931831359863\tBambo akugona pa dzida lakugwa pa chifuwa chake .\n",
            "P-401\t-0.1105 -0.1177 -0.1111 -0.0851 -0.0909 -0.0933 -0.1180 -0.0673 -0.0719 -0.0775 -0.0715 -0.7075 -0.0379 -0.0910 -0.0983 -0.0102 -0.1501 -0.8630 -2.7373 -0.0932 -0.0746 -0.3157 -0.1505 -0.1123 -0.2882 -0.1293 -0.2650 -0.1094 -0.2277 -0.5796 -0.1499 -0.2096 -0.4060 -0.1519 -0.5338 -0.1900 -0.1107 -0.0939 -1.3010 -0.0364 -0.2601 -0.3774 -0.1658 -0.5679 -0.0721 -0.1203 -2.1104 -0.2483 -0.2432 -0.0364 -0.1044\n",
            "T-418\tKayaker wachimuna akuyenda m'madzi ovuta.\n",
            "H-418\t-0.3557778298854828\t▁ G a l u ▁ w a k u d a ▁ w a c h i m u n a ▁ a k u y e n d a ▁ m ' m a d z i ▁ o u m a ▁ .\n",
            "D-418\t-0.3557778298854828\tGalu wakuda wachimuna akuyenda m'madzi ouma .\n",
            "P-418\t-0.1204 -3.6653 -0.1355 -0.1186 -0.0925 -0.1125 -1.2831 -0.2224 -0.4929 -0.2396 -0.9259 -0.1203 -0.1505 -0.6124 -0.4764 -0.1187 -0.1041 -0.0839 -1.2491 -0.0412 -0.1185 -0.3355 -0.1304 -0.0903 -0.0751 -0.0878 -0.2344 -0.0598 -0.0720 -0.0869 -0.1099 -0.1032 -0.0500 -0.1329 -0.0849 -0.0870 -0.1385 -0.0295 -0.1168 -0.2783 -0.4195 -0.6255 -1.2657 -0.7841 -0.6862 -0.0773 -0.0762\n",
            "T-303\tPali galu wamtundu wapakati pa chipale chofewa.\n",
            "H-303\t-0.21160267293453217\t▁ G a l u ▁ w a b u l a u n i ▁ n d i ▁ w a p a k a t i ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ .\n",
            "D-303\t-0.21160267293453217\tGalu wabulauni ndi wapakati pa chipale chofewa .\n",
            "P-303\t-0.1153 -0.1279 -0.1100 -0.0731 -0.0601 -0.1165 -0.0693 -0.4781 -2.0095 -0.0916 -0.0866 -0.2779 -0.0838 -0.0974 -0.1228 -0.1220 -0.5751 -0.1176 -0.4476 -0.0844 -0.2932 -0.3085 -1.6721 -0.1729 -0.1560 -0.1536 -0.1871 -0.0736 -0.1457 -0.0561 -0.1378 -0.1548 -0.0533 -0.0738 -0.1137 -0.2199 -0.0842 -0.0384 -0.1304 -0.0823 -0.0581 -0.0961 -0.0802 -0.0165 -0.0856 -0.0666 -0.1097 -0.3854 -0.0203 -0.0874\n",
            "T-187\tMnyamata ndi mtsikana akuyenda panja pa msika .\n",
            "H-187\t-0.13585734367370605\t▁ M n y a m a t a ▁ n d i ▁ m t s i k a n a ▁ a k u y e n d a ▁ p a n j a ▁ p a n s i ▁ .\n",
            "D-187\t-0.13585734367370605\tMnyamata ndi mtsikana akuyenda panja pansi .\n",
            "P-187\t-0.1167 -0.0883 -0.1046 -0.0450 -0.1051 -0.0765 -0.1212 -0.0435 -0.1019 -0.1202 -0.1433 -0.1339 -0.0960 -0.0737 -0.0321 -0.0867 -0.0505 -0.0901 -0.0606 -0.1083 -0.0523 -0.0977 -0.1428 -0.1267 -0.1178 -0.0526 -0.1515 -0.0706 -0.0541 -0.1441 -0.1205 -0.1332 -0.0429 -0.1282 -0.0914 -0.1780 -0.1329 -0.1566 -0.2188 -0.1303 -1.0417 -0.2856 -0.0855 -0.2637 -0.3457 -0.0863\n",
            "T-79\tAmuna awiri akupereka nsapato panja.\n",
            "H-79\t-0.3258017301559448\t▁ A m u n a ▁ a w i r i ▁ a k u ▁ A s i a ▁ a k u k h a l a ▁ p a n s i ▁ .\n",
            "D-79\t-0.3258017301559448\tAmuna awiri aku Asia akukhala pansi .\n",
            "P-79\t-0.1096 -0.0559 -0.1429 -0.0537 -0.1325 -0.0836 -0.1301 -0.1457 -0.1303 -0.1280 -0.0694 -0.1250 -0.1408 -0.1228 -0.1752 -0.0927 -3.8571 -0.3096 -0.2498 -0.1374 -0.1086 -0.1404 -0.1272 -0.0756 -0.0923 -1.2686 -0.7806 -0.0817 -0.1721 -0.1022 -0.1145 -0.8097 -0.1099 -0.1176 -0.1653 -0.3818 -0.2140 -1.3480 -0.1043\n",
            "T-105\tGalu wabulauni akudumpha m'nkhalango.\n",
            "H-105\t-0.23500956594944\t▁ G a l u ▁ w a b u l a u n i ▁ a k u d u m p h a ▁ m ' n g o l a n g o ▁ .\n",
            "D-105\t-0.23500956594944\tGalu wabulauni akudumpha m'ngolango .\n",
            "P-105\t-0.1235 -0.1890 -0.1233 -0.0749 -0.0827 -0.1316 -0.0650 -1.3908 -0.0582 -0.1044 -0.0775 -0.0936 -0.0552 -0.0811 -0.1071 -0.1323 -0.2657 -0.0759 -0.0938 -0.1062 -0.0771 -0.0676 -0.0375 -0.0930 -0.1297 -0.1314 -0.2387 -0.3804 -0.3283 -0.6482 -0.1889 -0.0976 -2.0265 -0.2405 -0.0593 -0.3543 -0.1667 -0.3779 -0.0899\n",
            " 92% 12/13 [00:26<00:01,  1.70s/it, wps=1513]T-17\tGalu wamng'ono wabulauni akudumpha m'madzi.\n",
            "H-17\t-0.22512051463127136\t▁ G a l u ▁ w a b u l a u n i ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ m ' m a d z i ▁ .\n",
            "D-17\t-0.22512051463127136\tGalu wabulauni wabulauni akuthamanga m'madzi .\n",
            "P-17\t-0.1166 -0.1916 -0.1371 -0.0786 -0.0900 -0.1357 -0.0655 -0.1130 -0.2280 -0.1027 -0.0365 -0.0976 -0.0451 -0.0512 -0.0762 -0.1354 -0.5361 -1.0102 -2.6580 -0.0566 -0.0589 -0.1004 -0.0345 -0.0790 -0.0902 -0.1303 -0.6649 -0.2028 -0.0796 -0.2810 -0.5068 -0.3034 -0.0564 -0.0728 -0.1373 -0.0577 -0.2640 -0.1261 -0.1709 -0.0810 -0.1194 -0.1107 -0.1393 -0.0466 -0.0819 -0.5231 -0.2448 -0.0803\n",
            "T-39\tMunthu akuchita zanzeru panjinga pa skatepark.\n",
            "H-39\t-0.36902251839637756\t▁ M u n t h u ▁ w o k w e r a ▁ n j i n g a ▁ z a z i l i ▁ p a n j i n g a ▁ .\n",
            "D-39\t-0.36902251839637756\tMunthu wokwera njinga zazili panjinga .\n",
            "P-39\t-0.1042 -0.1876 -0.1560 -0.1049 -0.0373 -0.1177 -0.0662 -0.1535 -1.8010 -1.4255 -0.5569 -0.1617 -0.0750 -0.2775 -0.0959 -0.1293 -0.8389 -0.1173 -0.0713 -0.0771 -0.2276 -0.0754 -0.1046 -0.0340 -0.1262 -1.8521 -0.0476 -1.0553 -1.0064 -0.1530 -0.4795 -0.1072 -0.4155 -0.0468 -0.0695 -0.5390 -0.0344 -0.0714 -0.1343 -1.8755 -0.1197\n",
            "T-106\tgalu wakuda akuthamanga m'munda waudzu\n",
            "H-106\t-0.22742950916290283\t▁ G a l u ▁ w a k u d a ▁ a k u t h a m a n g a ▁ m ' n y u m b a ▁ w a u d z u ▁ .\n",
            "D-106\t-0.22742950916290283\tGalu wakuda akuthamanga m'nyumba waudzu .\n",
            "P-106\t-0.1214 -0.1481 -0.1205 -0.0573 -0.0674 -0.1250 -0.0830 -0.1229 -0.0979 -0.0797 -0.2231 -0.1606 -0.1680 -0.6299 -0.2865 -0.0815 -0.2390 -0.0277 -0.0921 -0.0593 -0.0940 -0.1027 -0.0512 -0.0909 -0.1322 -0.0823 -0.7004 -1.5580 -0.4670 -0.1054 -0.4237 -0.2574 -0.1018 -0.1924 -1.1504 -0.1018 -0.3049 -0.0597 -0.1538 -0.0642 -0.4277 -0.0818 -0.0846\n",
            "T-138\tWosewera mpira wachikazi yemwe wavala chipewa choyera ndi malaya abuluu akuseweretsa okonzeka kumenyanso mpira kwa mdani wake .\n",
            "H-138\t-0.4743044078350067\t▁ M t s i k a n a ▁ w o v a l a ▁ c h i p e w a ▁ c h o f e w a ▁ a t a k h a l a ▁ p a ▁ s k a t e b o a r d ▁ .\n",
            "D-138\t-0.4743044078350067\tMtsikana wovala chipewa chofewa atakhala pa skateboard .\n",
            "P-138\t-0.1002 -1.0836 -2.3147 -0.2135 -0.1346 -0.2232 -0.0613 -0.0832 -0.0742 -0.1340 -0.3513 -0.8789 -0.4511 -0.1369 -0.1055 -0.0869 -0.1000 -3.0004 -0.2484 -0.5600 -0.3137 -0.0387 -0.1186 -0.0824 -0.1294 -0.3430 -0.1276 -1.0857 -1.7040 -0.1773 -0.2054 -0.0940 -0.1796 -0.6134 -1.8493 -0.0992 -0.8314 -0.2395 -0.1115 -0.0719 -0.0646 -0.1317 -0.2228 -0.0975 -0.5544 -2.7757 -1.4851 -0.0842 -0.0565 -0.0393 -0.6342 -0.2818 -0.0631 -0.0488 -0.0875 -0.3114 -1.6936 -0.1196\n",
            "2023-02-06 19:46:49 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2023-02-06 19:46:49 | INFO | fairseq_cli.generate | Translated 428 sentences (39,600 tokens) in 23.5s (18.19 sentences/s, 1682.70 tokens/s)\n",
            "Generate test_asr_nya with beam=5: WER: 54.13\n"
          ]
        }
      ],
      "source": [
        "# Evaluation using BEST CHECKPOINT MODEL\n",
        "!fairseq-generate /content/zambezi-voice/nyanja/nya \\\n",
        "  --config-yaml config_asr_nya.yaml \\\n",
        "  --gen-subset test_asr_nya \\\n",
        "  --task speech_to_text \\\n",
        "  --path /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints/checkpoint_best.pt \\\n",
        "  --max-tokens 50000 \\\n",
        "  --beam 5 \\\n",
        "  --scoring wer \\\n",
        "  --wer-tokenizer 13a \\\n",
        "  --wer-lowercase \\\n",
        "  --wer-remove-punct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVE THE MODEL TO GOOGLE DRIVE FOR LATER USE"
      ],
      "metadata": {
        "id": "a4ceNk6FQp6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCpwj9TpAxif",
        "outputId": "24a1ba20-0763-4bfb-9c22-f24e849b81db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2c2pN6n_ZP3"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/zambezi-voice/nyanja/nya/nya_asr_checkpoints <PATH TO SAVE DIRECTORY>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "115DZQnHLrpP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}