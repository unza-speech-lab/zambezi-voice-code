{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "6IP7rUdhs-S5",
        "outputId": "33f9b1fd-af93-467c-dc9a-316e569431ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.14.0\n",
            "  Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 32.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.14.0) (1.15.0)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "proto-plus 1.22.1 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 3.14.0 which is incompatible.\n",
            "googleapis-common-protos 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-datastore 2.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.14.0 which is incompatible.\n",
            "google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.14.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install protobuf==3.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nmRbzqfsK9r",
        "outputId": "dd6a8746-8aa2-414f-f1de-ea4a6f021bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34294, done.\u001b[K\n",
            "remote: Counting objects: 100% (877/877), done.\u001b[K\n",
            "remote: Compressing objects: 100% (408/408), done.\u001b[K\n",
            "remote: Total 34294 (delta 480), reused 794 (delta 457), pack-reused 33417\u001b[K\n",
            "Receiving objects: 100% (34294/34294), 23.90 MiB | 18.22 MiB/s, done.\n",
            "Resolving deltas: 100% (24896/24896), done.\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.21.6)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 89.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (4.64.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.29.32)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.0.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.13.0+cu116)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (21.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (2022.6.2)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.13.0+cu116)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 87.9 MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 87.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (5.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (3.11.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fairseq==0.12.2) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fairseq==0.12.2) (3.1.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=9d3729ed4771ebe7d5cc0798e7a26b7a493b9cbe734b22afd678e6f491ff434d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.1 colorama-0.4.6 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.6.0 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!python -m pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-iyf7IUhfhK",
        "outputId": "338d2bf5-4172-400f-9185-4b46cb72a8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 29.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.14.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fairseq\n",
            "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.0.6)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.21.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq) (2022.6.2)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.3.1)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.13.0+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq) (4.64.1)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.13.0+cu116)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.29.32)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (4.4.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.11.0)\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-0.12.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchaudio) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchaudio) (4.4.0)\n",
            "Installing collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/train.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/generate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/hydra_train.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/score.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/validate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq_cli/hydra_validate.py -> build/lib.linux-x86_64-3.8/fairseq_cli\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/binarizer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_io.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/ngram_repeat_block.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/version.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/registry.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/speech_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/incremental_decoding_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/nan_detector.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/pdb.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/token_generation_constraints.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/hub_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/file_chunker_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/search.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/quantization_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-3.8/fairseq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction_adapters.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/wav2vec_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/speech_to_speech_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/ctc.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/model_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/tacotron2_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_ctc.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/hubert_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/speech_ulm_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/fastspeech2_loss.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_rdrop.py -> build/lib.linux-x86_64-3.8/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/benchmark_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_lm.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_mt.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_model.py -> build/lib.linux-x86_64-3.8/fairseq/benchmark\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "copying fairseq/examples/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/megatron_trainer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/span_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction_adapters.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_ulm_task.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_denoising.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/simultaneous_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/text_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/nlu_finetuning.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/online_backtranslation.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_text.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/audio_finetuning.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_language_modeling.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/hubert_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_bart.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/frm_text_to_speech.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "copying fairseq/tasks/translation_multi_simple_epoch.py -> build/lib.linux-x86_64-3.8/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/configs.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/constants.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/initialize.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "copying fairseq/dataclass/utils.py -> build/lib.linux-x86_64-3.8/fairseq/dataclass\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config\n",
            "copying fairseq/config/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/config\n",
            "copying fairseq/data/add_class_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/padding_mask_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/codedataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_concat_langpair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/add_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/bucket_pad_length_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/noising.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/fasta_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/text_compressor.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/span_mask_tokens_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/shorten_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/multi_corpus_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-3.8/fairseq/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/metrics.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/meters.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "copying fairseq/logging/progress_bar.py -> build/lib.linux-x86_64-3.8/fairseq/logging\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/dynamic_loss_scaler.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fused_lamb.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/composite.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/cpu_adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/amp_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fused_adam.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/shard.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-3.8/fairseq/optim\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/distributed_timeout_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/tpu_distributed_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/module_proxy_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/utils.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/fully_sharded_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "copying fairseq/distributed/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-3.8/fairseq/distributed\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/bleu.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/meteor.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/bertscore.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/wer.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "copying fairseq/scoring/chrf.py -> build/lib.linux-x86_64-3.8/fairseq/scoring\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/layer_drop.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/rotary_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/ema_module.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fairseq_dropout.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/gumbel_vector_quantizer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/kmeans_vector_quantizer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/dynamic_crf_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/conformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/espnet_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/same_pad.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/checkpoint_activations.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transpose_last.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_group_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/lstm_cell_with_zoneout.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/kmeans_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_instance_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/fp32_batch_norm.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/base_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/positional_encoding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer_aug.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/location_attention.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/quant_noise.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_ulm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_align.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/lstm_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-3.8/fairseq/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "copying fairseq/examples/simultaneous_translation/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_featurize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/libri_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "copying fairseq/examples/rxf/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/fb_convert_beit_cp.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/generate_waveform_from_code.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/infer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/generate_waveform.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "copying fairseq/examples/speech_text_joint_to_text/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/monotonic_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/functions.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/w2vu_generate.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf/rxf_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_pretraining.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/audio_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/multimodal.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/add_class_target_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_finetuning_image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/path_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/modality.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/image_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec2.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_vision.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/audio_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_image_classification.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/base.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/images.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/modules.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/models/modalities\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_output_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/preprocessing\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator_multi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/unity\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/infer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder_config.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/base_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/decoders\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_asr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_sp.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/evaluation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_compound.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_denoise_pretrain.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/pair_denoising.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/joint_speech_text_pretrain_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputwavtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/criterions\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/multihead_attention.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer_lm.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/model.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/lib.linux-x86_64-3.8/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/characters.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_byte_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/bytes.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/encoders\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/legacy\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/data_cfg.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/hubert_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_joint_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/multi_modality_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/audio_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/frm_text_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "copying fairseq/data/audio/text_to_speech_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_data_manager.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_utils.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampling_method.py -> build/lib.linux-x86_64-3.8/fairseq/data/multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_coder.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_mmap_indexed_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/data/huffman\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/noiseaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/waveform_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/global_cmvn.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/specaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/delta_deltas.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/feature_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/concataugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/noisyoverlapaugment.py -> build/lib.linux-x86_64-3.8/fairseq/data/audio/dataset_transforms\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/pass_through.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/step_lr_scheduler.py -> build/lib.linux-x86_64-3.8/fairseq/optim/lr_scheduler\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-3.8/fairseq/modules/lightconv_layer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/quantization_options.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-3.8/fairseq/modules/dynamicconv_layer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/ops.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/utils.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/pq.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/utils.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/em.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qconv.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qemb.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qact.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qlinear.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/scalar/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qconv.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qemb.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qlinear.py -> build/lib.linux-x86_64-3.8/fairseq/modules/quantization/pq/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/berard.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_wav_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_conformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/multi_modality_model.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer_unity.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/convtransformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/transformer_layer_xmod.py -> build/lib.linux-x86_64-3.8/fairseq/models/xmod\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/enc_dec.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_xlmr.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_gottbert.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_camembert.py -> build/lib.linux-x86_64-3.8/fairseq/models/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_legacy.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_config.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_base.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder_aug.py -> build/lib.linux-x86_64-3.8/fairseq/models/transformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_asr.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec.py -> build/lib.linux-x86_64-3.8/fairseq/models/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/insertion_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_utils.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/nat_crf_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/fairseq_nat_model.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "copying fairseq/models/nat/cmlm_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/nat\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_unity.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_translatotron2.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-3.8/fairseq/models/bart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hub_interface.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tts_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/codehifigan.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/vocoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tacotron2.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hifigan.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/fastspeech2.py -> build/lib.linux-x86_64-3.8/fairseq/models/text_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "copying fairseq/models/ema/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "copying fairseq/models/ema/ema.py -> build/lib.linux-x86_64-3.8/fairseq/models/ema\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert_asr.py -> build/lib.linux-x86_64-3.8/fairseq/models/hubert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/hf_gpt2.py -> build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/huggingface\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/convolution.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/augmented_memory_attention.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/emformer.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_text/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/stacked_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/ctc_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_decoder_aug.py -> build/lib.linux-x86_64-3.8/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/examples/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples\n",
            "copying fairseq/examples/simultaneous_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/ende-mma.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/enja-waitk.md -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_text_models.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_alignment_train.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/tests\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval/agents\n",
            "copying fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py -> build/lib.linux-x86_64-3.8/fairseq/examples/simultaneous_translation/eval/agents\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/seg_mustc_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mustc_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_covost_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/covost_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mustc_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_text/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/preprocess_nli.py -> build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xmod\n",
            "copying fairseq/examples/adaptive_span/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/camembert\n",
            "copying fairseq/examples/camembert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/camembert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/data_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/model_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/moe_lm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/tok.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/install_dependecies.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "copying fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/dedup_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/m2m_100/process_data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/layerdrop/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/layerdrop\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pay_less_attention_paper\n",
            "copying fairseq/examples/pay_less_attention_paper/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pay_less_attention_paper\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/fast_noisy_channel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.race.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.glue.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.custom_classification.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/commonsense_qa\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/fb_multilingual\n",
            "copying fairseq/examples/roberta/fb_multilingual/README.multilingual.pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/fb_multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sst_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qqp.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/cola.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mrpc.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sts_b.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/rte.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining\n",
            "copying fairseq/examples/roberta/config/pretraining/base.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/config/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_criterion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/roberta/wsc\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xformers\n",
            "copying fairseq/examples/xformers/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xformers\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/scripts.md -> build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/wav2vec/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/unsupervised/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio_v2.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/pca.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/vads.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws_v100.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_8.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_old.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_16.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/config/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr\n",
            "copying fairseq/examples/wav2vec/xlsr/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/config\n",
            "copying fairseq/examples/wav2vec/xlsr/config/finetune.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/eval_speaker_clf_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/gen_audio_embedding.py -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/xlsr/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/scripts/binarize_manifest.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wav2vec/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/save_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine_example.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/mining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/sentence_retrieval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/criss/unsupervised_mt\n",
            "copying fairseq/examples/criss/unsupervised_mt/eval.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/criss/unsupervised_mt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/extract_bt_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/sacrebleu.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/deduplicate_lines.py -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/tokenized_bleu.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/rxf/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/postprocess.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/preprocess.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.xsum.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/gottbert\n",
            "copying fairseq/examples/gottbert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/gottbert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/normalize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/tok.py -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/constrained_decoding\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt14.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2de.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/translation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/fully_sharded_data_parallel\n",
            "copying fairseq/examples/fully_sharded_data_parallel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/fully_sharded_data_parallel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt20\n",
            "copying fairseq/examples/wmt20/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt20\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/data2vec/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task_pgrp_1M.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_audio_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_text_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images14_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_images_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_audio_only_task.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sst_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qqp.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/cola.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mrpc.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sts_b.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mnli.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/rte.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/base.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification\n",
            "copying fairseq/examples/data2vec/config/audio/classification/base_classification.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/audioset.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_huge_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_large_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_clean.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet_d2v1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_mae_imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts\n",
            "copying fairseq/examples/data2vec/scripts/convert_audioset_labels.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/multi\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/valids.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/unprocess_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue_lr.py -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_sst2_qnli_sweep_fair_nodep.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr_nopos.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_char_fair_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/data2vec/scripts/text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/flores_logo.png -> build/lib.linux-x86_64-3.8/fairseq/examples/flores101\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer\n",
            "copying fairseq/examples/linformer/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src\n",
            "copying fairseq/examples/linformer/linformer_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/lib.linux-x86_64-3.8/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/config\n",
            "copying fairseq/examples/discriminative_reranking_nmt/config/deen.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "copying fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "copying fairseq/examples/noisychannel/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/scaling_nmt\n",
            "copying fairseq/examples/scaling_nmt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/scaling_nmt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/stories\n",
            "copying fairseq/examples/stories/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/stories\n",
            "copying fairseq/examples/speech_to_speech/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/textless_s2st_real_data.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/data_augmentation.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/direct_s2st_discrete_units.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/enhanced_direct_s2st_discrete_units.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/core.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/get_metrics.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/utils.h -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.cpp -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.h -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cpu.cpp -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_kernel.cu -> build/lib.linux-x86_64-3.8/fairseq/examples/operators\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth\n",
            "copying fairseq/examples/latent_depth/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/speech_recognition/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/datasets\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/utils/wer_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/new/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf\n",
            "copying fairseq/examples/speech_recognition/new/conf/infer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax_sil.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_2g.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi/config\n",
            "copying fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_recognition/kaldi/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/summarize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.glue.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.summarization.md -> build/lib.linux-x86_64-3.8/fairseq/examples/bart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/DATASET.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/.gitignore -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/videoclip.png -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/pretraining.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/vlm.png -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/CONFIG.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/locallaunch.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/setup.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/endtask.md -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/localjob.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/predict.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt_cli\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects\n",
            "copying fairseq/examples/MMPT/projects/mfmmlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/ft.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/default.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/task\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoretri.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt\n",
            "copying fairseq/examples/MMPT/mmpt/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/metric.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/evaluator.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/evaluators\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/retritask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/vlmtask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/milncetask.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/tasks\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/mmdataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/datasets\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2processor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/processor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dsprocessor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors/models\n",
            "copying fairseq/examples/MMPT/mmpt/processors/models/s3dg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/processors/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/loss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/nce.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/losses\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/retri.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/mm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/vectorpool.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusion.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/transformermodel.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/load_config.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/shardedtensor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/MMPT/mmpt/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xlmr\n",
            "copying fairseq/examples/xlmr/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xlmr\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/eval.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/normalize-punctuation.perl -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt21/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/synthesize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/requirements.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/emotion_models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/fairseq_models\n",
            "copying fairseq/examples/emotion_conversion/fairseq_models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/fairseq_models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/extract_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/process_km.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_translation_manifests.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_hifigan_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km_tsv.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/create_core_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_emov_km_tsv_by_uttid.py -> build/lib.linux-x86_64-3.8/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/speech_synthesis/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/vctk_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/ljspeech_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/common_voice_example.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_synthesis/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/mbart\n",
            "copying fairseq/examples/mbart/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/mbart\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/wmt19\n",
            "copying fairseq/examples/wmt19/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/wmt19\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection\n",
            "copying fairseq/examples/attention_head_selection/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/loss\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_functional.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/modules\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/attention_head_selection/src/models\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/update_ckpt.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/measure_teacher_quality.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_kenlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_viterbi.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_fsqlm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune\n",
            "copying fairseq/examples/hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/run\n",
            "copying fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/lm\n",
            "copying fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/lm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/ckpt\n",
            "copying fairseq/examples/hubert/config/finetune/ckpt/it1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/finetune/ckpt\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter2.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter1.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/run\n",
            "copying fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/config/pretrain/run\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_finetuned_asr.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.hypo.word -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.npy -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_feature_and_unit.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/6313-76958-0021.flac -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.hypo.word -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.km500.km -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.len -> build/lib.linux-x86_64-3.8/fairseq/examples/hubert/tests\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/laser\n",
            "copying fairseq/examples/laser/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/laser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_lstm.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_task.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/laser/laser_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/ML50_langs.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/train_multilingual_model.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/requirement.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/binarize.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/lib.linux-x86_64-3.8/fairseq/examples/multilingual/data_scripts/utils\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/query_occupations_from_wikidata.py -> build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/womens_bios\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/model_card.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/xglm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/data_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/truncated_laplace.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/preprocess_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/generate_waveform.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/prepare_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/naive_decoder.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/inference_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/quantize_f0.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/sample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/sample\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/pgslm/eval\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm\n",
            "copying fairseq/examples/textless_nlp/gslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/glow.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/sample.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/ulm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/tools\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/img/fig.png -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/textless_nlp/dgslm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/create_dict_stop.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/generate_manifests.py -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu/configs\n",
            "copying fairseq/examples/audio_nlp/nlu/configs/nlu_finetuning.yaml -> build/lib.linux-x86_64-3.8/fairseq/examples/audio_nlp/nlu/configs\n",
            "copying fairseq/examples/speech_text_joint_to_text/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/pre-training.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/docs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/data\n",
            "copying fairseq/examples/speech_text_joint_to_text/data/pair_denoising_dataset.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/data\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/convert_model.py -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/configs\n",
            "copying fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list -> build/lib.linux-x86_64-3.8/fairseq/examples/speech_text_joint_to_text/configs\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/lib.linux-x86_64-3.8/fairseq/examples/unsupervised_quality_estimation\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/score.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/lib.linux-x86_64-3.8/fairseq/examples/translation_moe/translation_moe_src\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.finetuning.md -> build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/shuffled_word_order\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/paraphrase.py -> build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/paraphraser\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/cross_lingual_language_model\n",
            "copying fairseq/examples/cross_lingual_language_model/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/cross_lingual_language_model\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_bitext.py -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_data.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/gru_transformer.py -> build/lib.linux-x86_64-3.8/fairseq/examples/byte_level_bpe\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/conv_seq2seq\n",
            "copying fairseq/examples/conv_seq2seq/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/conv_seq2seq\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/train_lm.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/normformer\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/detok.py -> build/lib.linux-x86_64-3.8/fairseq/examples/megatron_11b\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.conv.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/prepare-wikitext-103.sh -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.adaptive_inputs.md -> build/lib.linux-x86_64-3.8/fairseq/examples/language_model\n",
            "copying fairseq/examples/truncated_bptt/README.md -> build/lib.linux-x86_64-3.8/fairseq/examples/truncated_bptt\n",
            "copying fairseq/config/config.yaml -> build/lib.linux-x86_64-3.8/fairseq/config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/fb_run_config\n",
            "copying fairseq/config/fb_run_config/slurm.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/fb_run_config\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec\n",
            "copying fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/transformer_lm\n",
            "creating build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/lib.linux-x86_64-3.8/fairseq/config/model/wav2vec2\n",
            "running build_ext\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "skipping 'fairseq/data/data_utils_fast.cpp' Cython extension (up-to-date)\n",
            "skipping 'fairseq/data/token_block_utils_fast.cpp' Cython extension (up-to-date)\n",
            "running develop\n",
            "running egg_info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing entry points to fairseq.egg-info/entry_points.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbleu.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/data_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/data/token_block_utils_fast.cpython-38-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libbase.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/fairseq/libnat.cpython-38-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-3.8/alignment_train_cpu_binding.cpython-38-x86_64-linux-gnu.so -> \n",
            "Creating /usr/local/lib/python3.8/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.12.2 to easy-install.pth file\n",
            "Installing fairseq-eval-lm script to /usr/local/bin\n",
            "Installing fairseq-generate script to /usr/local/bin\n",
            "Installing fairseq-hydra-train script to /usr/local/bin\n",
            "Installing fairseq-interactive script to /usr/local/bin\n",
            "Installing fairseq-preprocess script to /usr/local/bin\n",
            "Installing fairseq-score script to /usr/local/bin\n",
            "Installing fairseq-train script to /usr/local/bin\n",
            "Installing fairseq-validate script to /usr/local/bin\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.12.2\n",
            "Searching for packaging==21.3\n",
            "Best match: packaging 21.3\n",
            "Adding packaging 21.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scikit-learn==1.0.2\n",
            "Best match: scikit-learn 1.0.2\n",
            "Adding scikit-learn 1.0.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torchaudio==0.13.0+cu116\n",
            "Best match: torchaudio 0.13.0+cu116\n",
            "Adding torchaudio 0.13.0+cu116 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for bitarray==2.6.1\n",
            "Best match: bitarray 2.6.1\n",
            "Adding bitarray 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tqdm==4.64.1\n",
            "Best match: tqdm 4.64.1\n",
            "Adding tqdm 4.64.1 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for torch==1.13.0+cu116\n",
            "Best match: torch 1.13.0+cu116\n",
            "Adding torch 1.13.0+cu116 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for sacrebleu==2.3.1\n",
            "Best match: sacrebleu 2.3.1\n",
            "Adding sacrebleu 2.3.1 to easy-install.pth file\n",
            "Installing sacrebleu script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for regex==2022.6.2\n",
            "Best match: regex 2022.6.2\n",
            "Adding regex 2022.6.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for omegaconf==2.0.6\n",
            "Best match: omegaconf 2.0.6\n",
            "Adding omegaconf 2.0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for hydra-core==1.0.7\n",
            "Best match: hydra-core 1.0.7\n",
            "Adding hydra-core 1.0.7 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for Cython==0.29.32\n",
            "Best match: Cython 0.29.32\n",
            "Adding Cython 0.29.32 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for cffi==1.15.1\n",
            "Best match: cffi 1.15.1\n",
            "Adding cffi 1.15.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pyparsing==3.0.9\n",
            "Best match: pyparsing 3.0.9\n",
            "Adding pyparsing 3.0.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for joblib==1.2.0\n",
            "Best match: joblib 1.2.0\n",
            "Adding joblib 1.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for threadpoolctl==3.1.0\n",
            "Best match: threadpoolctl 3.1.0\n",
            "Adding threadpoolctl 3.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for scipy==1.7.3\n",
            "Best match: scipy 1.7.3\n",
            "Adding scipy 1.7.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for typing-extensions==4.4.0\n",
            "Best match: typing-extensions 4.4.0\n",
            "Adding typing-extensions 4.4.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for portalocker==2.6.0\n",
            "Best match: portalocker 2.6.0\n",
            "Adding portalocker 2.6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for colorama==0.4.6\n",
            "Best match: colorama 0.4.6\n",
            "Adding colorama 0.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for tabulate==0.8.10\n",
            "Best match: tabulate 0.8.10\n",
            "Adding tabulate 0.8.10 to easy-install.pth file\n",
            "Installing tabulate script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for lxml==4.9.2\n",
            "Best match: lxml 4.9.2\n",
            "Adding lxml 4.9.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for PyYAML==6.0\n",
            "Best match: PyYAML 6.0\n",
            "Adding PyYAML 6.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for importlib-resources==5.10.1\n",
            "Best match: importlib-resources 5.10.1\n",
            "Adding importlib-resources 5.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for antlr4-python3-runtime==4.8\n",
            "Best match: antlr4-python3-runtime 4.8\n",
            "Adding antlr4-python3-runtime 4.8 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for pycparser==2.21\n",
            "Best match: pycparser 2.21\n",
            "Adding pycparser 2.21 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Searching for zipp==3.11.0\n",
            "Best match: zipp 3.11.0\n",
            "Adding zipp 3.11.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.8/dist-packages\n",
            "Finished processing dependencies for fairseq==0.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install fairseq\n",
        "!pip install pandas torchaudio sentencepiece\n",
        "!python setup.py build develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ynvbDVURyoV",
        "outputId": "d92b8c8b-14dd-4eb9-ca13-27380acab342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'zambezi-voice'...\n",
            "remote: Enumerating objects: 37086, done.\u001b[K\n",
            "remote: Counting objects: 100% (6968/6968), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6293/6293), done.\u001b[K\n",
            "remote: Total 37086 (delta 701), reused 6924 (delta 665), pack-reused 30118\u001b[K\n",
            "Receiving objects: 100% (37086/37086), 5.18 GiB | 17.50 MiB/s, done.\n",
            "Resolving deltas: 100% (15372/15372), done.\n",
            "Checking out files: 100% (18666/18666), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/unza-speech-lab/zambezi-voice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ie0969IeaYe",
        "outputId": "b0fc74f8-921b-476e-f703-c870b1ec6b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq\n",
            "Fetching split train...\n",
            "Extracting log mel filter bank features...\n",
            "100% 8117/8117 [00:46<00:00, 175.02it/s]\n",
            "Fetching split dev...\n",
            "Extracting log mel filter bank features...\n",
            "100% 622/622 [00:04<00:00, 149.19it/s]\n",
            "Fetching split test...\n",
            "Extracting log mel filter bank features...\n",
            "100% 428/428 [00:02<00:00, 155.13it/s]\n",
            "ZIPing features...\n",
            "100% 9167/9167 [00:07<00:00, 1155.49it/s]\n",
            "Fetching ZIP manifest...\n",
            "100% 9167/9167 [00:04<00:00, 2249.86it/s]\n",
            "Generating manifest...\n",
            "100% 8117/8117 [00:11<00:00, 689.94it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, long speech (>3000 frames): 12, total 12 filtered, 8105 remained.\n",
            "100% 622/622 [00:01<00:00, 553.06it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 622 remained.\n",
            "100% 428/428 [00:00<00:00, 612.62it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 428 remained.\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/tmp/tmp3rslx12_ --model_prefix=/content/zambezi-voice/nyanja/nya/spm_char_asr_nya --model_type=char --vocab_size=1000 --character_coverage=1.0 --num_threads=12 --unk_id=3 --bos_id=0 --eos_id=2 --pad_id=1\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /tmp/tmp3rslx12_\n",
            "  input_format: \n",
            "  model_prefix: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya\n",
            "  model_type: CHAR\n",
            "  vocab_size: 1000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 12\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 3\n",
            "  bos_id: 0\n",
            "  eos_id: 2\n",
            "  pad_id: 1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: /tmp/tmp3rslx12_\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 8090 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(536) LOG(INFO) all chars count=781185\n",
            "trainer_interface.cc(557) LOG(INFO) Alphabet size=27\n",
            "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 8090 sentences.\n",
            "trainer_interface.cc(685) LOG(INFO) Saving model: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model\n",
            "trainer_interface.cc(697) LOG(INFO) Saving vocabs: /content/zambezi-voice/nyanja/nya/spm_char_asr_nya.vocab\n"
          ]
        }
      ],
      "source": [
        "# Nyanja (nya) ASR\n",
        "%cd /content/fairseq\n",
        "!python examples/speech_to_text/prep_zambezivoice_data.py \\\n",
        "  --data-root /content/zambezi-voice/nyanja \\\n",
        "  --vocab-type char \\\n",
        "  --src-lang nya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK94Fqm9YWGg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ASR_SAVE_DIR = \"/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints\"\n",
        "\n",
        "if not os.path.exists(ASR_SAVE_DIR):\n",
        "  os.mkdir(ASR_SAVE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1EssspYaYOtT"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/fairseq/ASR_SAVE_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ph9CSRp4nl",
        "outputId": "e4524be4-2c0e-4742-8e52-e49135f43394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "2022-12-24 21:34:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint357.pt\n",
            "2022-12-24 21:34:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint357.pt\n",
            "2022-12-24 21:34:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint357.pt (epoch 357 @ 7847 updates, score 1.834) (writing took 10.006773370998417 seconds)\n",
            "2022-12-24 21:34:27 | INFO | fairseq_cli.train | end of epoch 357 (average epoch stats below)\n",
            "2022-12-24 21:34:27 | INFO | train | epoch 357 | loss 1.788 | nll_loss 1.082 | total 35852.4 | n_correct 28534.9 | ppl 2.12 | accuracy 79.59 | wps 27799.3 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 7847 | lr 2.3541e-05 | gnorm 1.183 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.5 | wall 11240\n",
            "2022-12-24 21:34:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 358:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:34:27 | INFO | fairseq.trainer | begin training epoch 358\n",
            "2022-12-24 21:34:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 358:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 21:34:44 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.46it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.99it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.83it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.59it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.25it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.76it/s]\u001b[A\n",
            "epoch 358 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.62it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:34:45 | INFO | dev_asr_nya | epoch 358 | valid on 'dev_asr_nya' subset | loss 1.832 | nll_loss 1.047 | total 3156.42 | n_correct 2492.47 | ppl 2.07 | accuracy 78.965 | wps 84742.6 | wpb 3156.4 | bsz 32.7 | num_updates 7869 | best_loss 1.832\n",
            "2022-12-24 21:34:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 358 @ 7869 updates\n",
            "2022-12-24 21:34:45 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint358.pt\n",
            "2022-12-24 21:34:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint358.pt\n",
            "2022-12-24 21:35:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint358.pt (epoch 358 @ 7869 updates, score 1.832) (writing took 16.05185353900015 seconds)\n",
            "2022-12-24 21:35:01 | INFO | fairseq_cli.train | end of epoch 358 (average epoch stats below)\n",
            "2022-12-24 21:35:01 | INFO | train | epoch 358 | loss 1.786 | nll_loss 1.08 | total 35852.4 | n_correct 28534.7 | ppl 2.11 | accuracy 79.59 | wps 22692 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 7869 | lr 2.3607e-05 | gnorm 1.598 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.8 | wall 11275\n",
            "2022-12-24 21:35:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 359:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:35:01 | INFO | fairseq.trainer | begin training epoch 359\n",
            "2022-12-24 21:35:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 359:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:35:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.13it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.99it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.38it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.97it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.03it/s]\u001b[A\n",
            "epoch 359 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.25it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:35:20 | INFO | dev_asr_nya | epoch 359 | valid on 'dev_asr_nya' subset | loss 1.823 | nll_loss 1.035 | total 3156.42 | n_correct 2497.11 | ppl 2.05 | accuracy 79.112 | wps 89720.1 | wpb 3156.4 | bsz 32.7 | num_updates 7891 | best_loss 1.823\n",
            "2022-12-24 21:35:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 359 @ 7891 updates\n",
            "2022-12-24 21:35:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint359.pt\n",
            "2022-12-24 21:35:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint359.pt\n",
            "2022-12-24 21:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint359.pt (epoch 359 @ 7891 updates, score 1.823) (writing took 14.500005413003237 seconds)\n",
            "2022-12-24 21:35:34 | INFO | fairseq_cli.train | end of epoch 359 (average epoch stats below)\n",
            "2022-12-24 21:35:34 | INFO | train | epoch 359 | loss 1.781 | nll_loss 1.074 | total 35852.4 | n_correct 28601.9 | ppl 2.11 | accuracy 79.777 | wps 23839.3 | ups 0.66 | wpb 35852.4 | bsz 368.4 | num_updates 7891 | lr 2.3673e-05 | gnorm 1.302 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.5 | wall 11308\n",
            "2022-12-24 21:35:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 360:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:35:35 | INFO | fairseq.trainer | begin training epoch 360\n",
            "2022-12-24 21:35:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 360:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.787, nll_loss=1.081, total=35840.3, n_correct=28523.6, ppl=2.12, accuracy=79.585, wps=25390.6, ups=0.71, wpb=35840.3, bsz=367.2, num_updates=7900, lr=2.37e-05, gnorm=1.345, clip=0, loss_scale=8, train_wall=78, gb_free=31.2, wall=11316]2022-12-24 21:35:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.60it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.70it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.97it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.10it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.92it/s]\u001b[A\n",
            "epoch 360 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:35:53 | INFO | dev_asr_nya | epoch 360 | valid on 'dev_asr_nya' subset | loss 1.824 | nll_loss 1.035 | total 3156.42 | n_correct 2497.42 | ppl 2.05 | accuracy 79.122 | wps 85819.9 | wpb 3156.4 | bsz 32.7 | num_updates 7913 | best_loss 1.823\n",
            "2022-12-24 21:35:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 360 @ 7913 updates\n",
            "2022-12-24 21:35:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint360.pt\n",
            "2022-12-24 21:35:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint360.pt\n",
            "2022-12-24 21:36:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint360.pt (epoch 360 @ 7913 updates, score 1.824) (writing took 10.162944668998534 seconds)\n",
            "2022-12-24 21:36:03 | INFO | fairseq_cli.train | end of epoch 360 (average epoch stats below)\n",
            "2022-12-24 21:36:03 | INFO | train | epoch 360 | loss 1.778 | nll_loss 1.071 | total 35852.4 | n_correct 28596.7 | ppl 2.1 | accuracy 79.762 | wps 27677.5 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 7913 | lr 2.3739e-05 | gnorm 1.41 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 11337\n",
            "2022-12-24 21:36:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 361:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:36:03 | INFO | fairseq.trainer | begin training epoch 361\n",
            "2022-12-24 21:36:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 361:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:36:21 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.18it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.24it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.84it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 23.09it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.19it/s]\u001b[A\n",
            "epoch 361 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.35it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:36:21 | INFO | dev_asr_nya | epoch 361 | valid on 'dev_asr_nya' subset | loss 1.819 | nll_loss 1.029 | total 3156.42 | n_correct 2499.79 | ppl 2.04 | accuracy 79.197 | wps 91602 | wpb 3156.4 | bsz 32.7 | num_updates 7935 | best_loss 1.819\n",
            "2022-12-24 21:36:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 361 @ 7935 updates\n",
            "2022-12-24 21:36:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint361.pt\n",
            "2022-12-24 21:36:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint361.pt\n",
            "2022-12-24 21:36:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint361.pt (epoch 361 @ 7935 updates, score 1.819) (writing took 12.727540078001766 seconds)\n",
            "2022-12-24 21:36:34 | INFO | fairseq_cli.train | end of epoch 361 (average epoch stats below)\n",
            "2022-12-24 21:36:34 | INFO | train | epoch 361 | loss 1.778 | nll_loss 1.07 | total 35852.4 | n_correct 28603.2 | ppl 2.1 | accuracy 79.781 | wps 25262.3 | ups 0.7 | wpb 35852.4 | bsz 368.4 | num_updates 7935 | lr 2.3805e-05 | gnorm 1.684 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.5 | wall 11368\n",
            "2022-12-24 21:36:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 362:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:36:34 | INFO | fairseq.trainer | begin training epoch 362\n",
            "2022-12-24 21:36:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 362:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 21:36:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.71it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.39it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.84it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.68it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.87it/s]\u001b[A\n",
            "epoch 362 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.51it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:36:53 | INFO | dev_asr_nya | epoch 362 | valid on 'dev_asr_nya' subset | loss 1.82 | nll_loss 1.035 | total 3156.42 | n_correct 2499.79 | ppl 2.05 | accuracy 79.197 | wps 88566.7 | wpb 3156.4 | bsz 32.7 | num_updates 7957 | best_loss 1.819\n",
            "2022-12-24 21:36:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 362 @ 7957 updates\n",
            "2022-12-24 21:36:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint362.pt\n",
            "2022-12-24 21:36:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint362.pt\n",
            "2022-12-24 21:37:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint362.pt (epoch 362 @ 7957 updates, score 1.82) (writing took 7.652808483999252 seconds)\n",
            "2022-12-24 21:37:01 | INFO | fairseq_cli.train | end of epoch 362 (average epoch stats below)\n",
            "2022-12-24 21:37:01 | INFO | train | epoch 362 | loss 1.776 | nll_loss 1.068 | total 35852.4 | n_correct 28621.3 | ppl 2.1 | accuracy 79.831 | wps 29834.1 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 7957 | lr 2.3871e-05 | gnorm 1.936 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 11394\n",
            "2022-12-24 21:37:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 363:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:37:01 | INFO | fairseq.trainer | begin training epoch 363\n",
            "2022-12-24 21:37:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 363:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 21:37:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.52it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.20it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.56it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.52it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.46it/s]\u001b[A\n",
            "epoch 363 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.37it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:37:19 | INFO | dev_asr_nya | epoch 363 | valid on 'dev_asr_nya' subset | loss 1.813 | nll_loss 1.022 | total 3156.42 | n_correct 2506.32 | ppl 2.03 | accuracy 79.404 | wps 88130.8 | wpb 3156.4 | bsz 32.7 | num_updates 7979 | best_loss 1.813\n",
            "2022-12-24 21:37:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 363 @ 7979 updates\n",
            "2022-12-24 21:37:19 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint363.pt\n",
            "2022-12-24 21:37:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint363.pt\n",
            "2022-12-24 21:37:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint363.pt (epoch 363 @ 7979 updates, score 1.813) (writing took 15.141419649000454 seconds)\n",
            "2022-12-24 21:37:34 | INFO | fairseq_cli.train | end of epoch 363 (average epoch stats below)\n",
            "2022-12-24 21:37:34 | INFO | train | epoch 363 | loss 1.772 | nll_loss 1.063 | total 35852.4 | n_correct 28672.3 | ppl 2.09 | accuracy 79.973 | wps 23323.4 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 7979 | lr 2.3937e-05 | gnorm 1.624 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 11428\n",
            "2022-12-24 21:37:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 364:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:37:35 | INFO | fairseq.trainer | begin training epoch 364\n",
            "2022-12-24 21:37:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 364:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.773, nll_loss=1.064, total=35851.4, n_correct=28652.9, ppl=2.09, accuracy=79.921, wps=27687.7, ups=0.77, wpb=35851.4, bsz=369.2, num_updates=8000, lr=2.4e-05, gnorm=1.611, clip=0, loss_scale=8, train_wall=79, gb_free=30.7, wall=11445]2022-12-24 21:37:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.51it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.67it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.05it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.19it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.88it/s]\u001b[A\n",
            "epoch 364 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.37it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:37:53 | INFO | dev_asr_nya | epoch 364 | valid on 'dev_asr_nya' subset | loss 1.825 | nll_loss 1.037 | total 3156.42 | n_correct 2495.79 | ppl 2.05 | accuracy 79.07 | wps 91392 | wpb 3156.4 | bsz 32.7 | num_updates 8001 | best_loss 1.813\n",
            "2022-12-24 21:37:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 364 @ 8001 updates\n",
            "2022-12-24 21:37:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint364.pt\n",
            "2022-12-24 21:37:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint364.pt\n",
            "2022-12-24 21:38:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint364.pt (epoch 364 @ 8001 updates, score 1.825) (writing took 7.873818669002503 seconds)\n",
            "2022-12-24 21:38:01 | INFO | fairseq_cli.train | end of epoch 364 (average epoch stats below)\n",
            "2022-12-24 21:38:01 | INFO | train | epoch 364 | loss 1.765 | nll_loss 1.055 | total 35852.4 | n_correct 28742.5 | ppl 2.08 | accuracy 80.169 | wps 29963.6 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 8001 | lr 2.4003e-05 | gnorm 1.196 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 11454\n",
            "2022-12-24 21:38:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 365:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:38:01 | INFO | fairseq.trainer | begin training epoch 365\n",
            "2022-12-24 21:38:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 365:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 21:38:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.68it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.50it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.60it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.28it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.22it/s]\u001b[A\n",
            "epoch 365 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:38:20 | INFO | dev_asr_nya | epoch 365 | valid on 'dev_asr_nya' subset | loss 1.812 | nll_loss 1.02 | total 3156.42 | n_correct 2506.16 | ppl 2.03 | accuracy 79.399 | wps 88203.1 | wpb 3156.4 | bsz 32.7 | num_updates 8023 | best_loss 1.812\n",
            "2022-12-24 21:38:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 365 @ 8023 updates\n",
            "2022-12-24 21:38:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint365.pt\n",
            "2022-12-24 21:38:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint365.pt\n",
            "2022-12-24 21:38:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint365.pt (epoch 365 @ 8023 updates, score 1.812) (writing took 15.5813539280025 seconds)\n",
            "2022-12-24 21:38:35 | INFO | fairseq_cli.train | end of epoch 365 (average epoch stats below)\n",
            "2022-12-24 21:38:35 | INFO | train | epoch 365 | loss 1.767 | nll_loss 1.057 | total 35852.4 | n_correct 28721 | ppl 2.08 | accuracy 80.109 | wps 22724.9 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 8023 | lr 2.4069e-05 | gnorm 1.917 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 28.8 | wall 11489\n",
            "2022-12-24 21:38:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 366:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:38:36 | INFO | fairseq.trainer | begin training epoch 366\n",
            "2022-12-24 21:38:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 366:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 21:38:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.39it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.56it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.82it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.85it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.66it/s]\u001b[A\n",
            "epoch 366 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.86it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:38:54 | INFO | dev_asr_nya | epoch 366 | valid on 'dev_asr_nya' subset | loss 1.809 | nll_loss 1.018 | total 3156.42 | n_correct 2507.89 | ppl 2.02 | accuracy 79.454 | wps 89251.7 | wpb 3156.4 | bsz 32.7 | num_updates 8045 | best_loss 1.809\n",
            "2022-12-24 21:38:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 366 @ 8045 updates\n",
            "2022-12-24 21:38:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint366.pt\n",
            "2022-12-24 21:38:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint366.pt\n",
            "2022-12-24 21:39:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint366.pt (epoch 366 @ 8045 updates, score 1.809) (writing took 12.311860220001108 seconds)\n",
            "2022-12-24 21:39:06 | INFO | fairseq_cli.train | end of epoch 366 (average epoch stats below)\n",
            "2022-12-24 21:39:06 | INFO | train | epoch 366 | loss 1.763 | nll_loss 1.053 | total 35852.4 | n_correct 28753.6 | ppl 2.07 | accuracy 80.2 | wps 25699.6 | ups 0.72 | wpb 35852.4 | bsz 368.4 | num_updates 8045 | lr 2.4135e-05 | gnorm 1.657 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 11520\n",
            "2022-12-24 21:39:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 367:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:39:06 | INFO | fairseq.trainer | begin training epoch 367\n",
            "2022-12-24 21:39:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 367:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 21:39:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.93it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.70it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.36it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.51it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.86it/s]\u001b[A\n",
            "epoch 367 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.72it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:39:24 | INFO | dev_asr_nya | epoch 367 | valid on 'dev_asr_nya' subset | loss 1.806 | nll_loss 1.015 | total 3156.42 | n_correct 2508.84 | ppl 2.02 | accuracy 79.484 | wps 91192.7 | wpb 3156.4 | bsz 32.7 | num_updates 8067 | best_loss 1.806\n",
            "2022-12-24 21:39:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 367 @ 8067 updates\n",
            "2022-12-24 21:39:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint367.pt\n",
            "2022-12-24 21:39:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint367.pt\n",
            "2022-12-24 21:39:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint367.pt (epoch 367 @ 8067 updates, score 1.806) (writing took 11.92557433100228 seconds)\n",
            "2022-12-24 21:39:36 | INFO | fairseq_cli.train | end of epoch 367 (average epoch stats below)\n",
            "2022-12-24 21:39:36 | INFO | train | epoch 367 | loss 1.757 | nll_loss 1.045 | total 35852.4 | n_correct 28817.6 | ppl 2.06 | accuracy 80.378 | wps 26188.8 | ups 0.73 | wpb 35852.4 | bsz 368.4 | num_updates 8067 | lr 2.4201e-05 | gnorm 1.212 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 11550\n",
            "2022-12-24 21:39:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 368:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:39:36 | INFO | fairseq.trainer | begin training epoch 368\n",
            "2022-12-24 21:39:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 368:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 21:39:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.39it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.91it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:01, 13.93it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 17.97it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 22.72it/s]\u001b[A\n",
            "epoch 368 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:39:55 | INFO | dev_asr_nya | epoch 368 | valid on 'dev_asr_nya' subset | loss 1.81 | nll_loss 1.02 | total 3156.42 | n_correct 2508.74 | ppl 2.03 | accuracy 79.48 | wps 81111 | wpb 3156.4 | bsz 32.7 | num_updates 8089 | best_loss 1.806\n",
            "2022-12-24 21:39:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 368 @ 8089 updates\n",
            "2022-12-24 21:39:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint368.pt\n",
            "2022-12-24 21:39:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint368.pt\n",
            "2022-12-24 21:40:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint368.pt (epoch 368 @ 8089 updates, score 1.81) (writing took 8.238756901002489 seconds)\n",
            "2022-12-24 21:40:03 | INFO | fairseq_cli.train | end of epoch 368 (average epoch stats below)\n",
            "2022-12-24 21:40:03 | INFO | train | epoch 368 | loss 1.753 | nll_loss 1.04 | total 35852.4 | n_correct 28840.8 | ppl 2.06 | accuracy 80.443 | wps 29190.7 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 8089 | lr 2.4267e-05 | gnorm 1.518 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 11577\n",
            "2022-12-24 21:40:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 369:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:40:03 | INFO | fairseq.trainer | begin training epoch 369\n",
            "2022-12-24 21:40:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 369:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.76, nll_loss=1.049, total=35792.7, n_correct=28737, ppl=2.07, accuracy=80.287, wps=25311.2, ups=0.71, wpb=35792.7, bsz=367.6, num_updates=8100, lr=2.43e-05, gnorm=1.614, clip=0, loss_scale=8, train_wall=79, gb_free=31, wall=11587]2022-12-24 21:40:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.71it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.64it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.64it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.22it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.32it/s]\u001b[A\n",
            "epoch 369 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.66it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:40:22 | INFO | dev_asr_nya | epoch 369 | valid on 'dev_asr_nya' subset | loss 1.805 | nll_loss 1.016 | total 3156.42 | n_correct 2513.26 | ppl 2.02 | accuracy 79.624 | wps 86932 | wpb 3156.4 | bsz 32.7 | num_updates 8111 | best_loss 1.805\n",
            "2022-12-24 21:40:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 369 @ 8111 updates\n",
            "2022-12-24 21:40:22 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint369.pt\n",
            "2022-12-24 21:40:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint369.pt\n",
            "2022-12-24 21:40:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint369.pt (epoch 369 @ 8111 updates, score 1.805) (writing took 12.562612223999167 seconds)\n",
            "2022-12-24 21:40:35 | INFO | fairseq_cli.train | end of epoch 369 (average epoch stats below)\n",
            "2022-12-24 21:40:35 | INFO | train | epoch 369 | loss 1.753 | nll_loss 1.04 | total 35852.4 | n_correct 28857.6 | ppl 2.06 | accuracy 80.49 | wps 24965 | ups 0.7 | wpb 35852.4 | bsz 368.4 | num_updates 8111 | lr 2.4333e-05 | gnorm 1.88 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 30.9 | wall 11609\n",
            "2022-12-24 21:40:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 370:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:40:35 | INFO | fairseq.trainer | begin training epoch 370\n",
            "2022-12-24 21:40:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 370:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 21:40:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.48it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.71it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.76it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.42it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.70it/s]\u001b[A\n",
            "epoch 370 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:40:54 | INFO | dev_asr_nya | epoch 370 | valid on 'dev_asr_nya' subset | loss 1.809 | nll_loss 1.018 | total 3156.42 | n_correct 2512.26 | ppl 2.03 | accuracy 79.592 | wps 91652.6 | wpb 3156.4 | bsz 32.7 | num_updates 8133 | best_loss 1.805\n",
            "2022-12-24 21:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 370 @ 8133 updates\n",
            "2022-12-24 21:40:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint370.pt\n",
            "2022-12-24 21:40:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint370.pt\n",
            "2022-12-24 21:41:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint370.pt (epoch 370 @ 8133 updates, score 1.809) (writing took 7.874340660000598 seconds)\n",
            "2022-12-24 21:41:01 | INFO | fairseq_cli.train | end of epoch 370 (average epoch stats below)\n",
            "2022-12-24 21:41:01 | INFO | train | epoch 370 | loss 1.744 | nll_loss 1.03 | total 35852.4 | n_correct 28941.1 | ppl 2.04 | accuracy 80.723 | wps 29801.2 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8133 | lr 2.4399e-05 | gnorm 0.985 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 11635\n",
            "2022-12-24 21:41:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 371:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:41:01 | INFO | fairseq.trainer | begin training epoch 371\n",
            "2022-12-24 21:41:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 371:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 21:41:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.37it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 11.68it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.17it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.25it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.29it/s]\u001b[A\n",
            "epoch 371 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.85it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:41:20 | INFO | dev_asr_nya | epoch 371 | valid on 'dev_asr_nya' subset | loss 1.805 | nll_loss 1.015 | total 3156.42 | n_correct 2513 | ppl 2.02 | accuracy 79.615 | wps 90066 | wpb 3156.4 | bsz 32.7 | num_updates 8155 | best_loss 1.805\n",
            "2022-12-24 21:41:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 371 @ 8155 updates\n",
            "2022-12-24 21:41:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint371.pt\n",
            "2022-12-24 21:41:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint371.pt\n",
            "2022-12-24 21:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint371.pt (epoch 371 @ 8155 updates, score 1.805) (writing took 12.388677585997357 seconds)\n",
            "2022-12-24 21:41:33 | INFO | fairseq_cli.train | end of epoch 371 (average epoch stats below)\n",
            "2022-12-24 21:41:33 | INFO | train | epoch 371 | loss 1.746 | nll_loss 1.033 | total 35852.4 | n_correct 28913.8 | ppl 2.05 | accuracy 80.647 | wps 25203.6 | ups 0.7 | wpb 35852.4 | bsz 368.4 | num_updates 8155 | lr 2.4465e-05 | gnorm 1.85 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 31.4 | wall 11666\n",
            "2022-12-24 21:41:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 372:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:41:33 | INFO | fairseq.trainer | begin training epoch 372\n",
            "2022-12-24 21:41:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 372:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 21:41:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.43it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.29it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.73it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.81it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.71it/s]\u001b[A\n",
            "epoch 372 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.16it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:41:51 | INFO | dev_asr_nya | epoch 372 | valid on 'dev_asr_nya' subset | loss 1.816 | nll_loss 1.031 | total 3156.42 | n_correct 2498.89 | ppl 2.04 | accuracy 79.169 | wps 89655.6 | wpb 3156.4 | bsz 32.7 | num_updates 8177 | best_loss 1.805\n",
            "2022-12-24 21:41:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 372 @ 8177 updates\n",
            "2022-12-24 21:41:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint372.pt\n",
            "2022-12-24 21:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint372.pt\n",
            "2022-12-24 21:42:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint372.pt (epoch 372 @ 8177 updates, score 1.816) (writing took 9.30527025900301 seconds)\n",
            "2022-12-24 21:42:00 | INFO | fairseq_cli.train | end of epoch 372 (average epoch stats below)\n",
            "2022-12-24 21:42:00 | INFO | train | epoch 372 | loss 1.742 | nll_loss 1.027 | total 35852.4 | n_correct 28936.3 | ppl 2.04 | accuracy 80.71 | wps 28487.8 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 8177 | lr 2.4531e-05 | gnorm 1.731 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.6 | wall 11694\n",
            "2022-12-24 21:42:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 373:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:42:00 | INFO | fairseq.trainer | begin training epoch 373\n",
            "2022-12-24 21:42:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 373:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 21:42:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.83it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.16it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.43it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.97it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.84it/s]\u001b[A\n",
            "epoch 373 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:42:19 | INFO | dev_asr_nya | epoch 373 | valid on 'dev_asr_nya' subset | loss 1.797 | nll_loss 1.007 | total 3156.42 | n_correct 2518.26 | ppl 2.01 | accuracy 79.782 | wps 91227.2 | wpb 3156.4 | bsz 32.7 | num_updates 8199 | best_loss 1.797\n",
            "2022-12-24 21:42:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 373 @ 8199 updates\n",
            "2022-12-24 21:42:19 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint373.pt\n",
            "2022-12-24 21:42:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint373.pt\n",
            "2022-12-24 21:42:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint373.pt (epoch 373 @ 8199 updates, score 1.797) (writing took 16.47929318399838 seconds)\n",
            "2022-12-24 21:42:35 | INFO | fairseq_cli.train | end of epoch 373 (average epoch stats below)\n",
            "2022-12-24 21:42:35 | INFO | train | epoch 373 | loss 1.746 | nll_loss 1.033 | total 35852.4 | n_correct 28889 | ppl 2.05 | accuracy 80.578 | wps 22466.7 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 8199 | lr 2.4597e-05 | gnorm 2.248 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 11729\n",
            "2022-12-24 21:42:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 374:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:42:36 | INFO | fairseq.trainer | begin training epoch 374\n",
            "2022-12-24 21:42:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 374:  95% 21/22 [00:17<00:00,  1.28it/s, loss=1.746, nll_loss=1.032, total=35841.5, n_correct=28903.2, ppl=2.05, accuracy=80.642, wps=24929.5, ups=0.7, wpb=35841.5, bsz=368.1, num_updates=8200, lr=2.46e-05, gnorm=1.707, clip=0, loss_scale=8, train_wall=79, gb_free=30.9, wall=11730]2022-12-24 21:42:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.67it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.43it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.92it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.40it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.43it/s]\u001b[A\n",
            "epoch 374 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:42:54 | INFO | dev_asr_nya | epoch 374 | valid on 'dev_asr_nya' subset | loss 1.816 | nll_loss 1.025 | total 3156.42 | n_correct 2504.42 | ppl 2.04 | accuracy 79.344 | wps 86804.7 | wpb 3156.4 | bsz 32.7 | num_updates 8221 | best_loss 1.797\n",
            "2022-12-24 21:42:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 374 @ 8221 updates\n",
            "2022-12-24 21:42:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint374.pt\n",
            "2022-12-24 21:42:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint374.pt\n",
            "2022-12-24 21:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint374.pt (epoch 374 @ 8221 updates, score 1.816) (writing took 7.929313442997227 seconds)\n",
            "2022-12-24 21:43:02 | INFO | fairseq_cli.train | end of epoch 374 (average epoch stats below)\n",
            "2022-12-24 21:43:02 | INFO | train | epoch 374 | loss 1.744 | nll_loss 1.031 | total 35852.4 | n_correct 28926.6 | ppl 2.04 | accuracy 80.683 | wps 29744 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8221 | lr 2.4663e-05 | gnorm 2.032 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 11756\n",
            "2022-12-24 21:43:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 375:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:43:02 | INFO | fairseq.trainer | begin training epoch 375\n",
            "2022-12-24 21:43:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 375:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 21:43:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:03,  5.98it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:01, 14.66it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.54it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.84it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.73it/s]\u001b[A\n",
            "epoch 375 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.40it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:43:21 | INFO | dev_asr_nya | epoch 375 | valid on 'dev_asr_nya' subset | loss 1.806 | nll_loss 1.015 | total 3156.42 | n_correct 2511.42 | ppl 2.02 | accuracy 79.565 | wps 90419.1 | wpb 3156.4 | bsz 32.7 | num_updates 8243 | best_loss 1.797\n",
            "2022-12-24 21:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 375 @ 8243 updates\n",
            "2022-12-24 21:43:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint375.pt\n",
            "2022-12-24 21:43:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint375.pt\n",
            "2022-12-24 21:43:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint375.pt (epoch 375 @ 8243 updates, score 1.806) (writing took 7.881733468002494 seconds)\n",
            "2022-12-24 21:43:29 | INFO | fairseq_cli.train | end of epoch 375 (average epoch stats below)\n",
            "2022-12-24 21:43:29 | INFO | train | epoch 375 | loss 1.743 | nll_loss 1.03 | total 35852.4 | n_correct 28924.6 | ppl 2.04 | accuracy 80.677 | wps 29276.6 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 8243 | lr 2.4729e-05 | gnorm 2.347 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 30.6 | wall 11783\n",
            "2022-12-24 21:43:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 376:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:43:29 | INFO | fairseq.trainer | begin training epoch 376\n",
            "2022-12-24 21:43:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 376:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 21:43:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.10it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.37it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.76it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.14it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.61it/s]\u001b[A\n",
            "epoch 376 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:43:47 | INFO | dev_asr_nya | epoch 376 | valid on 'dev_asr_nya' subset | loss 1.791 | nll_loss 0.998 | total 3156.42 | n_correct 2523.05 | ppl 2 | accuracy 79.934 | wps 87947.1 | wpb 3156.4 | bsz 32.7 | num_updates 8265 | best_loss 1.791\n",
            "2022-12-24 21:43:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 376 @ 8265 updates\n",
            "2022-12-24 21:43:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint376.pt\n",
            "2022-12-24 21:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint376.pt\n",
            "2022-12-24 21:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint376.pt (epoch 376 @ 8265 updates, score 1.791) (writing took 17.417839255998842 seconds)\n",
            "2022-12-24 21:44:05 | INFO | fairseq_cli.train | end of epoch 376 (average epoch stats below)\n",
            "2022-12-24 21:44:05 | INFO | train | epoch 376 | loss 1.74 | nll_loss 1.026 | total 35852.4 | n_correct 28955.1 | ppl 2.04 | accuracy 80.762 | wps 21917.2 | ups 0.61 | wpb 35852.4 | bsz 368.4 | num_updates 8265 | lr 2.4795e-05 | gnorm 2.319 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.8 | wall 11819\n",
            "2022-12-24 21:44:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 377:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:44:05 | INFO | fairseq.trainer | begin training epoch 377\n",
            "2022-12-24 21:44:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 377:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 21:44:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.47it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.71it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.86it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.34it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.15it/s]\u001b[A\n",
            "epoch 377 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:44:23 | INFO | dev_asr_nya | epoch 377 | valid on 'dev_asr_nya' subset | loss 1.794 | nll_loss 1.002 | total 3156.42 | n_correct 2522.21 | ppl 2 | accuracy 79.907 | wps 88051.7 | wpb 3156.4 | bsz 32.7 | num_updates 8287 | best_loss 1.791\n",
            "2022-12-24 21:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 377 @ 8287 updates\n",
            "2022-12-24 21:44:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint377.pt\n",
            "2022-12-24 21:44:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint377.pt\n",
            "2022-12-24 21:44:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint377.pt (epoch 377 @ 8287 updates, score 1.794) (writing took 7.8753894520014 seconds)\n",
            "2022-12-24 21:44:31 | INFO | fairseq_cli.train | end of epoch 377 (average epoch stats below)\n",
            "2022-12-24 21:44:31 | INFO | train | epoch 377 | loss 1.728 | nll_loss 1.012 | total 35852.4 | n_correct 29083.7 | ppl 2.02 | accuracy 81.121 | wps 29815.6 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8287 | lr 2.4861e-05 | gnorm 1.525 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.5 | wall 11845\n",
            "2022-12-24 21:44:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 378:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:44:31 | INFO | fairseq.trainer | begin training epoch 378\n",
            "2022-12-24 21:44:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 378:  95% 21/22 [00:17<00:00,  1.22it/s, loss=1.736, nll_loss=1.021, total=35899, n_correct=29041, ppl=2.03, accuracy=80.896, wps=28516.4, ups=0.79, wpb=35899, bsz=368.6, num_updates=8300, lr=2.49e-05, gnorm=1.951, clip=0, loss_scale=8, train_wall=79, gb_free=30.7, wall=11856]2022-12-24 21:44:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.46it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.43it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.83it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.80it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.67it/s]\u001b[A\n",
            "epoch 378 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:44:51 | INFO | dev_asr_nya | epoch 378 | valid on 'dev_asr_nya' subset | loss 1.803 | nll_loss 1.016 | total 3156.42 | n_correct 2511.79 | ppl 2.02 | accuracy 79.577 | wps 91757.1 | wpb 3156.4 | bsz 32.7 | num_updates 8309 | best_loss 1.791\n",
            "2022-12-24 21:44:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 378 @ 8309 updates\n",
            "2022-12-24 21:44:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint378.pt\n",
            "2022-12-24 21:44:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint378.pt\n",
            "2022-12-24 21:44:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint378.pt (epoch 378 @ 8309 updates, score 1.803) (writing took 8.594878076000896 seconds)\n",
            "2022-12-24 21:44:59 | INFO | fairseq_cli.train | end of epoch 378 (average epoch stats below)\n",
            "2022-12-24 21:44:59 | INFO | train | epoch 378 | loss 1.723 | nll_loss 1.006 | total 35852.4 | n_correct 29121.9 | ppl 2.01 | accuracy 81.227 | wps 28447.3 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 8309 | lr 2.4927e-05 | gnorm 1.186 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 31.4 | wall 11873\n",
            "2022-12-24 21:44:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 379:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:44:59 | INFO | fairseq.trainer | begin training epoch 379\n",
            "2022-12-24 21:44:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 379:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:45:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.47it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.95it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.99it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.11it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.34it/s]\u001b[A\n",
            "epoch 379 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.69it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:45:17 | INFO | dev_asr_nya | epoch 379 | valid on 'dev_asr_nya' subset | loss 1.786 | nll_loss 0.996 | total 3156.42 | n_correct 2527.89 | ppl 1.99 | accuracy 80.087 | wps 92478.2 | wpb 3156.4 | bsz 32.7 | num_updates 8331 | best_loss 1.786\n",
            "2022-12-24 21:45:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 379 @ 8331 updates\n",
            "2022-12-24 21:45:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint379.pt\n",
            "2022-12-24 21:45:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint379.pt\n",
            "2022-12-24 21:45:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint379.pt (epoch 379 @ 8331 updates, score 1.786) (writing took 14.916123641000013 seconds)\n",
            "2022-12-24 21:45:32 | INFO | fairseq_cli.train | end of epoch 379 (average epoch stats below)\n",
            "2022-12-24 21:45:32 | INFO | train | epoch 379 | loss 1.718 | nll_loss 1 | total 35852.4 | n_correct 29174.3 | ppl 2 | accuracy 81.373 | wps 23683.8 | ups 0.66 | wpb 35852.4 | bsz 368.4 | num_updates 8331 | lr 2.4993e-05 | gnorm 1.12 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 11906\n",
            "2022-12-24 21:45:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 380:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:45:32 | INFO | fairseq.trainer | begin training epoch 380\n",
            "2022-12-24 21:45:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 380:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 21:45:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.78it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.87it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.96it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.25it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.49it/s]\u001b[A\n",
            "epoch 380 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.84it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:45:51 | INFO | dev_asr_nya | epoch 380 | valid on 'dev_asr_nya' subset | loss 1.787 | nll_loss 0.994 | total 3156.42 | n_correct 2525.21 | ppl 1.99 | accuracy 80.002 | wps 85448.3 | wpb 3156.4 | bsz 32.7 | num_updates 8353 | best_loss 1.786\n",
            "2022-12-24 21:45:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 380 @ 8353 updates\n",
            "2022-12-24 21:45:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint380.pt\n",
            "2022-12-24 21:45:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint380.pt\n",
            "2022-12-24 21:45:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint380.pt (epoch 380 @ 8353 updates, score 1.787) (writing took 7.846494924000581 seconds)\n",
            "2022-12-24 21:45:59 | INFO | fairseq_cli.train | end of epoch 380 (average epoch stats below)\n",
            "2022-12-24 21:45:59 | INFO | train | epoch 380 | loss 1.716 | nll_loss 0.997 | total 35852.4 | n_correct 29207.5 | ppl 2 | accuracy 81.466 | wps 29822.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8353 | lr 2.5059e-05 | gnorm 0.992 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.8 | wall 11933\n",
            "2022-12-24 21:45:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 381:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:45:59 | INFO | fairseq.trainer | begin training epoch 381\n",
            "2022-12-24 21:45:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 381:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 21:46:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.96it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.22it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.55it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 21.24it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 25.09it/s]\u001b[A\n",
            "epoch 381 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.72it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:46:18 | INFO | dev_asr_nya | epoch 381 | valid on 'dev_asr_nya' subset | loss 1.801 | nll_loss 1.01 | total 3156.42 | n_correct 2511 | ppl 2.01 | accuracy 79.552 | wps 90199 | wpb 3156.4 | bsz 32.7 | num_updates 8375 | best_loss 1.786\n",
            "2022-12-24 21:46:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 381 @ 8375 updates\n",
            "2022-12-24 21:46:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint381.pt\n",
            "2022-12-24 21:46:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint381.pt\n",
            "2022-12-24 21:46:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint381.pt (epoch 381 @ 8375 updates, score 1.801) (writing took 10.53044363799927 seconds)\n",
            "2022-12-24 21:46:28 | INFO | fairseq_cli.train | end of epoch 381 (average epoch stats below)\n",
            "2022-12-24 21:46:28 | INFO | train | epoch 381 | loss 1.718 | nll_loss 0.999 | total 35852.4 | n_correct 29173.2 | ppl 2 | accuracy 81.37 | wps 26828.9 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 8375 | lr 2.5125e-05 | gnorm 2.011 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 29.5 | wall 11962\n",
            "2022-12-24 21:46:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 382:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:46:28 | INFO | fairseq.trainer | begin training epoch 382\n",
            "2022-12-24 21:46:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 382:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:46:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.98it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.19it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.81it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.23it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.94it/s]\u001b[A\n",
            "epoch 382 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:46:47 | INFO | dev_asr_nya | epoch 382 | valid on 'dev_asr_nya' subset | loss 1.79 | nll_loss 0.998 | total 3156.42 | n_correct 2523.26 | ppl 2 | accuracy 79.941 | wps 92069.2 | wpb 3156.4 | bsz 32.7 | num_updates 8397 | best_loss 1.786\n",
            "2022-12-24 21:46:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 382 @ 8397 updates\n",
            "2022-12-24 21:46:47 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint382.pt\n",
            "2022-12-24 21:46:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint382.pt\n",
            "2022-12-24 21:46:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint382.pt (epoch 382 @ 8397 updates, score 1.79) (writing took 9.441257736998523 seconds)\n",
            "2022-12-24 21:46:56 | INFO | fairseq_cli.train | end of epoch 382 (average epoch stats below)\n",
            "2022-12-24 21:46:56 | INFO | train | epoch 382 | loss 1.712 | nll_loss 0.993 | total 35852.4 | n_correct 29236.8 | ppl 1.99 | accuracy 81.548 | wps 28237.1 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 8397 | lr 2.5191e-05 | gnorm 1.315 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 11990\n",
            "2022-12-24 21:46:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 383:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:46:56 | INFO | fairseq.trainer | begin training epoch 383\n",
            "2022-12-24 21:46:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 383:  95% 21/22 [00:17<00:00,  1.29it/s, loss=1.717, nll_loss=0.998, total=35851.7, n_correct=29186.2, ppl=2, accuracy=81.408, wps=26276.7, ups=0.73, wpb=35851.7, bsz=369, num_updates=8400, lr=2.52e-05, gnorm=1.332, clip=0, loss_scale=8, train_wall=79, gb_free=28.9, wall=11993]2022-12-24 21:47:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.54it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.66it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.55it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.48it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.91it/s]\u001b[A\n",
            "epoch 383 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:47:15 | INFO | dev_asr_nya | epoch 383 | valid on 'dev_asr_nya' subset | loss 1.786 | nll_loss 0.992 | total 3156.42 | n_correct 2531.63 | ppl 1.99 | accuracy 80.206 | wps 87298.5 | wpb 3156.4 | bsz 32.7 | num_updates 8419 | best_loss 1.786\n",
            "2022-12-24 21:47:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 383 @ 8419 updates\n",
            "2022-12-24 21:47:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint383.pt\n",
            "2022-12-24 21:47:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint383.pt\n",
            "2022-12-24 21:47:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint383.pt (epoch 383 @ 8419 updates, score 1.786) (writing took 14.555303818000539 seconds)\n",
            "2022-12-24 21:47:29 | INFO | fairseq_cli.train | end of epoch 383 (average epoch stats below)\n",
            "2022-12-24 21:47:29 | INFO | train | epoch 383 | loss 1.708 | nll_loss 0.988 | total 35852.4 | n_correct 29276.1 | ppl 1.98 | accuracy 81.657 | wps 23798.3 | ups 0.66 | wpb 35852.4 | bsz 368.4 | num_updates 8419 | lr 2.5257e-05 | gnorm 0.935 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 12023\n",
            "2022-12-24 21:47:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 384:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:47:29 | INFO | fairseq.trainer | begin training epoch 384\n",
            "2022-12-24 21:47:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 384:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 21:47:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.56it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.30it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.16it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.73it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.01it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.47it/s]\u001b[A\n",
            "epoch 384 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 26.25it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:47:48 | INFO | dev_asr_nya | epoch 384 | valid on 'dev_asr_nya' subset | loss 1.788 | nll_loss 0.994 | total 3156.42 | n_correct 2525 | ppl 1.99 | accuracy 79.996 | wps 83937.2 | wpb 3156.4 | bsz 32.7 | num_updates 8441 | best_loss 1.786\n",
            "2022-12-24 21:47:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 384 @ 8441 updates\n",
            "2022-12-24 21:47:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint384.pt\n",
            "2022-12-24 21:47:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint384.pt\n",
            "2022-12-24 21:47:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint384.pt (epoch 384 @ 8441 updates, score 1.788) (writing took 9.63375841800007 seconds)\n",
            "2022-12-24 21:47:58 | INFO | fairseq_cli.train | end of epoch 384 (average epoch stats below)\n",
            "2022-12-24 21:47:58 | INFO | train | epoch 384 | loss 1.709 | nll_loss 0.988 | total 35852.4 | n_correct 29241.9 | ppl 1.98 | accuracy 81.562 | wps 27888.1 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 8441 | lr 2.5323e-05 | gnorm 1.704 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 12051\n",
            "2022-12-24 21:47:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 385:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:47:58 | INFO | fairseq.trainer | begin training epoch 385\n",
            "2022-12-24 21:47:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 385:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 21:48:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.84it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.05it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.46it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.15it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.45it/s]\u001b[A\n",
            "epoch 385 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.10it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:48:16 | INFO | dev_asr_nya | epoch 385 | valid on 'dev_asr_nya' subset | loss 1.777 | nll_loss 0.984 | total 3156.42 | n_correct 2533.68 | ppl 1.98 | accuracy 80.271 | wps 88915.4 | wpb 3156.4 | bsz 32.7 | num_updates 8463 | best_loss 1.777\n",
            "2022-12-24 21:48:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 385 @ 8463 updates\n",
            "2022-12-24 21:48:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint385.pt\n",
            "2022-12-24 21:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint385.pt\n",
            "2022-12-24 21:48:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint385.pt (epoch 385 @ 8463 updates, score 1.777) (writing took 14.617398481001146 seconds)\n",
            "2022-12-24 21:48:31 | INFO | fairseq_cli.train | end of epoch 385 (average epoch stats below)\n",
            "2022-12-24 21:48:31 | INFO | train | epoch 385 | loss 1.707 | nll_loss 0.986 | total 35852.4 | n_correct 29282.7 | ppl 1.98 | accuracy 81.676 | wps 23563.9 | ups 0.66 | wpb 35852.4 | bsz 368.4 | num_updates 8463 | lr 2.5389e-05 | gnorm 1.833 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 31.3 | wall 12085\n",
            "2022-12-24 21:48:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 386:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:48:31 | INFO | fairseq.trainer | begin training epoch 386\n",
            "2022-12-24 21:48:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 386:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 21:48:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.23it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.15it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.10it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.16it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.12it/s]\u001b[A\n",
            "epoch 386 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:48:50 | INFO | dev_asr_nya | epoch 386 | valid on 'dev_asr_nya' subset | loss 1.777 | nll_loss 0.983 | total 3156.42 | n_correct 2532.37 | ppl 1.98 | accuracy 80.229 | wps 87895.5 | wpb 3156.4 | bsz 32.7 | num_updates 8485 | best_loss 1.777\n",
            "2022-12-24 21:48:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 386 @ 8485 updates\n",
            "2022-12-24 21:48:50 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint386.pt\n",
            "2022-12-24 21:48:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint386.pt\n",
            "2022-12-24 21:49:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint386.pt (epoch 386 @ 8485 updates, score 1.777) (writing took 16.30379200599782 seconds)\n",
            "2022-12-24 21:49:06 | INFO | fairseq_cli.train | end of epoch 386 (average epoch stats below)\n",
            "2022-12-24 21:49:06 | INFO | train | epoch 386 | loss 1.703 | nll_loss 0.982 | total 35852.4 | n_correct 29313.8 | ppl 1.97 | accuracy 81.763 | wps 22661.8 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 8485 | lr 2.5455e-05 | gnorm 1.484 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.3 | wall 12120\n",
            "2022-12-24 21:49:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 387:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:49:06 | INFO | fairseq.trainer | begin training epoch 387\n",
            "2022-12-24 21:49:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 387:  95% 21/22 [00:17<00:00,  1.28it/s, loss=1.704, nll_loss=0.983, total=35914.4, n_correct=29354.9, ppl=1.98, accuracy=81.736, wps=25750.5, ups=0.72, wpb=35914.4, bsz=369.8, num_updates=8500, lr=2.55e-05, gnorm=1.49, clip=0, loss_scale=8, train_wall=79, gb_free=31.3, wall=12132]2022-12-24 21:49:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.54it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.63it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.24it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.40it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.03it/s]\u001b[A\n",
            "epoch 387 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.69it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:49:25 | INFO | dev_asr_nya | epoch 387 | valid on 'dev_asr_nya' subset | loss 1.781 | nll_loss 0.984 | total 3156.42 | n_correct 2529.68 | ppl 1.98 | accuracy 80.144 | wps 88926.3 | wpb 3156.4 | bsz 32.7 | num_updates 8507 | best_loss 1.777\n",
            "2022-12-24 21:49:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 387 @ 8507 updates\n",
            "2022-12-24 21:49:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint387.pt\n",
            "2022-12-24 21:49:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint387.pt\n",
            "2022-12-24 21:49:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint387.pt (epoch 387 @ 8507 updates, score 1.781) (writing took 9.903001198999846 seconds)\n",
            "2022-12-24 21:49:35 | INFO | fairseq_cli.train | end of epoch 387 (average epoch stats below)\n",
            "2022-12-24 21:49:35 | INFO | train | epoch 387 | loss 1.697 | nll_loss 0.975 | total 35852.4 | n_correct 29378.9 | ppl 1.97 | accuracy 81.944 | wps 27500.6 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 8507 | lr 2.5521e-05 | gnorm 1.322 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.6 | wall 12148\n",
            "2022-12-24 21:49:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 388:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:49:35 | INFO | fairseq.trainer | begin training epoch 388\n",
            "2022-12-24 21:49:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 388:  55% 12/22 [00:09<00:08,  1.22it/s]2022-12-24 21:49:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "epoch 388:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 21:49:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.36it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.44it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.11it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.61it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.04it/s]\u001b[A\n",
            "epoch 388 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:49:53 | INFO | dev_asr_nya | epoch 388 | valid on 'dev_asr_nya' subset | loss 1.788 | nll_loss 0.997 | total 3156.42 | n_correct 2523.84 | ppl 2 | accuracy 79.959 | wps 88616.2 | wpb 3156.4 | bsz 32.7 | num_updates 8528 | best_loss 1.777\n",
            "2022-12-24 21:49:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 388 @ 8528 updates\n",
            "2022-12-24 21:49:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint388.pt\n",
            "2022-12-24 21:49:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint388.pt\n",
            "2022-12-24 21:50:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint388.pt (epoch 388 @ 8528 updates, score 1.788) (writing took 8.10622599600174 seconds)\n",
            "2022-12-24 21:50:01 | INFO | fairseq_cli.train | end of epoch 388 (average epoch stats below)\n",
            "2022-12-24 21:50:01 | INFO | train | epoch 388 | loss 1.73 | nll_loss 1.014 | total 35866 | n_correct 29032 | ppl 2.02 | accuracy 80.946 | wps 28150.7 | ups 0.78 | wpb 35866 | bsz 369.6 | num_updates 8528 | lr 2.5584e-05 | gnorm 3.643 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 12175\n",
            "2022-12-24 21:50:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 389:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:50:01 | INFO | fairseq.trainer | begin training epoch 389\n",
            "2022-12-24 21:50:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 389:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 21:50:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.34it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.20it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.54it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.89it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.58it/s]\u001b[A\n",
            "epoch 389 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.48it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:50:20 | INFO | dev_asr_nya | epoch 389 | valid on 'dev_asr_nya' subset | loss 1.781 | nll_loss 0.984 | total 3156.42 | n_correct 2532.95 | ppl 1.98 | accuracy 80.247 | wps 87916.6 | wpb 3156.4 | bsz 32.7 | num_updates 8550 | best_loss 1.777\n",
            "2022-12-24 21:50:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 389 @ 8550 updates\n",
            "2022-12-24 21:50:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint389.pt\n",
            "2022-12-24 21:50:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint389.pt\n",
            "2022-12-24 21:50:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint389.pt (epoch 389 @ 8550 updates, score 1.781) (writing took 8.163719894000678 seconds)\n",
            "2022-12-24 21:50:28 | INFO | fairseq_cli.train | end of epoch 389 (average epoch stats below)\n",
            "2022-12-24 21:50:28 | INFO | train | epoch 389 | loss 1.713 | nll_loss 0.996 | total 35852.4 | n_correct 29195.6 | ppl 1.99 | accuracy 81.433 | wps 29420.2 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 8550 | lr 2.565e-05 | gnorm 2.043 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 12202\n",
            "2022-12-24 21:50:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 390:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:50:28 | INFO | fairseq.trainer | begin training epoch 390\n",
            "2022-12-24 21:50:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 390:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 21:50:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.10it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.39it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.42it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.86it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.64it/s]\u001b[A\n",
            "epoch 390 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:50:46 | INFO | dev_asr_nya | epoch 390 | valid on 'dev_asr_nya' subset | loss 1.78 | nll_loss 0.986 | total 3156.42 | n_correct 2533.79 | ppl 1.98 | accuracy 80.274 | wps 90725.9 | wpb 3156.4 | bsz 32.7 | num_updates 8572 | best_loss 1.777\n",
            "2022-12-24 21:50:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 390 @ 8572 updates\n",
            "2022-12-24 21:50:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint390.pt\n",
            "2022-12-24 21:50:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint390.pt\n",
            "2022-12-24 21:50:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint390.pt (epoch 390 @ 8572 updates, score 1.78) (writing took 9.808612827000616 seconds)\n",
            "2022-12-24 21:50:56 | INFO | fairseq_cli.train | end of epoch 390 (average epoch stats below)\n",
            "2022-12-24 21:50:56 | INFO | train | epoch 390 | loss 1.694 | nll_loss 0.972 | total 35852.4 | n_correct 29380.8 | ppl 1.96 | accuracy 81.949 | wps 28091.4 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 8572 | lr 2.5716e-05 | gnorm 1.154 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 12230\n",
            "2022-12-24 21:50:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 391:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:50:56 | INFO | fairseq.trainer | begin training epoch 391\n",
            "2022-12-24 21:50:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 391:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 21:51:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.91it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.99it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.62it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.42it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.23it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.03it/s]\u001b[A\n",
            "epoch 391 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.74it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:51:15 | INFO | dev_asr_nya | epoch 391 | valid on 'dev_asr_nya' subset | loss 1.775 | nll_loss 0.979 | total 3156.42 | n_correct 2535.79 | ppl 1.97 | accuracy 80.337 | wps 86828.5 | wpb 3156.4 | bsz 32.7 | num_updates 8594 | best_loss 1.775\n",
            "2022-12-24 21:51:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 391 @ 8594 updates\n",
            "2022-12-24 21:51:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint391.pt\n",
            "2022-12-24 21:51:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint391.pt\n",
            "2022-12-24 21:51:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint391.pt (epoch 391 @ 8594 updates, score 1.775) (writing took 13.581131422000908 seconds)\n",
            "2022-12-24 21:51:28 | INFO | fairseq_cli.train | end of epoch 391 (average epoch stats below)\n",
            "2022-12-24 21:51:28 | INFO | train | epoch 391 | loss 1.689 | nll_loss 0.965 | total 35852.4 | n_correct 29452.7 | ppl 1.95 | accuracy 82.15 | wps 24702 | ups 0.69 | wpb 35852.4 | bsz 368.4 | num_updates 8594 | lr 2.5782e-05 | gnorm 1.133 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 12262\n",
            "2022-12-24 21:51:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 392:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:51:28 | INFO | fairseq.trainer | begin training epoch 392\n",
            "2022-12-24 21:51:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 392:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.705, nll_loss=0.984, total=35776.2, n_correct=29218.4, ppl=1.98, accuracy=81.67, wps=26544.1, ups=0.74, wpb=35776.2, bsz=368.3, num_updates=8600, lr=2.58e-05, gnorm=1.857, clip=0, loss_scale=4, train_wall=79, gb_free=29.9, wall=12267]2022-12-24 21:51:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.83it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.35it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.39it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.27it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.42it/s]\u001b[A\n",
            "epoch 392 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:51:46 | INFO | dev_asr_nya | epoch 392 | valid on 'dev_asr_nya' subset | loss 1.763 | nll_loss 0.967 | total 3156.42 | n_correct 2542.47 | ppl 1.96 | accuracy 80.549 | wps 88843.8 | wpb 3156.4 | bsz 32.7 | num_updates 8616 | best_loss 1.763\n",
            "2022-12-24 21:51:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 392 @ 8616 updates\n",
            "2022-12-24 21:51:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint392.pt\n",
            "2022-12-24 21:51:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint392.pt\n",
            "2022-12-24 21:52:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint392.pt (epoch 392 @ 8616 updates, score 1.763) (writing took 15.325379398000223 seconds)\n",
            "2022-12-24 21:52:02 | INFO | fairseq_cli.train | end of epoch 392 (average epoch stats below)\n",
            "2022-12-24 21:52:02 | INFO | train | epoch 392 | loss 1.686 | nll_loss 0.961 | total 35852.4 | n_correct 29479.8 | ppl 1.95 | accuracy 82.226 | wps 23459.9 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 8616 | lr 2.5848e-05 | gnorm 1.37 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 12295\n",
            "2022-12-24 21:52:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 393:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:52:02 | INFO | fairseq.trainer | begin training epoch 393\n",
            "2022-12-24 21:52:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 393:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 21:52:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.97it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.52it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.81it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.21it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.31it/s]\u001b[A\n",
            "epoch 393 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.84it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:52:20 | INFO | dev_asr_nya | epoch 393 | valid on 'dev_asr_nya' subset | loss 1.766 | nll_loss 0.969 | total 3156.42 | n_correct 2543.95 | ppl 1.96 | accuracy 80.596 | wps 88006.9 | wpb 3156.4 | bsz 32.7 | num_updates 8638 | best_loss 1.763\n",
            "2022-12-24 21:52:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 393 @ 8638 updates\n",
            "2022-12-24 21:52:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint393.pt\n",
            "2022-12-24 21:52:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint393.pt\n",
            "2022-12-24 21:52:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint393.pt (epoch 393 @ 8638 updates, score 1.766) (writing took 7.892515386000014 seconds)\n",
            "2022-12-24 21:52:28 | INFO | fairseq_cli.train | end of epoch 393 (average epoch stats below)\n",
            "2022-12-24 21:52:28 | INFO | train | epoch 393 | loss 1.68 | nll_loss 0.954 | total 35852.4 | n_correct 29534.2 | ppl 1.94 | accuracy 82.377 | wps 29690.6 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8638 | lr 2.5914e-05 | gnorm 1.122 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 12322\n",
            "2022-12-24 21:52:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 394:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:52:28 | INFO | fairseq.trainer | begin training epoch 394\n",
            "2022-12-24 21:52:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 394:  95% 21/22 [00:17<00:00,  1.23it/s]2022-12-24 21:52:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.63it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.64it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.98it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.99it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.78it/s]\u001b[A\n",
            "epoch 394 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:52:48 | INFO | dev_asr_nya | epoch 394 | valid on 'dev_asr_nya' subset | loss 1.768 | nll_loss 0.972 | total 3156.42 | n_correct 2542.26 | ppl 1.96 | accuracy 80.543 | wps 86010.2 | wpb 3156.4 | bsz 32.7 | num_updates 8660 | best_loss 1.763\n",
            "2022-12-24 21:52:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 394 @ 8660 updates\n",
            "2022-12-24 21:52:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint394.pt\n",
            "2022-12-24 21:52:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint394.pt\n",
            "2022-12-24 21:52:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint394.pt (epoch 394 @ 8660 updates, score 1.768) (writing took 10.338751939001668 seconds)\n",
            "2022-12-24 21:52:58 | INFO | fairseq_cli.train | end of epoch 394 (average epoch stats below)\n",
            "2022-12-24 21:52:58 | INFO | train | epoch 394 | loss 1.676 | nll_loss 0.949 | total 35852.4 | n_correct 29583.5 | ppl 1.93 | accuracy 82.515 | wps 26582.4 | ups 0.74 | wpb 35852.4 | bsz 368.4 | num_updates 8660 | lr 2.598e-05 | gnorm 0.989 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.7 | wall 12352\n",
            "2022-12-24 21:52:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 395:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:52:58 | INFO | fairseq.trainer | begin training epoch 395\n",
            "2022-12-24 21:52:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 395:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 21:53:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.04it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.38it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.17it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.95it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.96it/s]\u001b[A\n",
            "epoch 395 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:53:17 | INFO | dev_asr_nya | epoch 395 | valid on 'dev_asr_nya' subset | loss 1.776 | nll_loss 0.981 | total 3156.42 | n_correct 2534.05 | ppl 1.97 | accuracy 80.282 | wps 87993.3 | wpb 3156.4 | bsz 32.7 | num_updates 8682 | best_loss 1.763\n",
            "2022-12-24 21:53:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 395 @ 8682 updates\n",
            "2022-12-24 21:53:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint395.pt\n",
            "2022-12-24 21:53:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint395.pt\n",
            "2022-12-24 21:53:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint395.pt (epoch 395 @ 8682 updates, score 1.776) (writing took 8.823184771998058 seconds)\n",
            "2022-12-24 21:53:26 | INFO | fairseq_cli.train | end of epoch 395 (average epoch stats below)\n",
            "2022-12-24 21:53:26 | INFO | train | epoch 395 | loss 1.689 | nll_loss 0.965 | total 35852.4 | n_correct 29420.8 | ppl 1.95 | accuracy 82.061 | wps 28556.3 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 8682 | lr 2.6046e-05 | gnorm 2.441 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 12379\n",
            "2022-12-24 21:53:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 396:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:53:26 | INFO | fairseq.trainer | begin training epoch 396\n",
            "2022-12-24 21:53:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 396:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.682, nll_loss=0.958, total=35861.3, n_correct=29509.6, ppl=1.94, accuracy=82.288, wps=28269, ups=0.79, wpb=35861.3, bsz=367, num_updates=8700, lr=2.61e-05, gnorm=1.653, clip=0, loss_scale=4, train_wall=79, gb_free=31, wall=12394]2022-12-24 21:53:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.10it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.49it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.91it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.92it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.78it/s]\u001b[A\n",
            "epoch 396 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.42it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:53:44 | INFO | dev_asr_nya | epoch 396 | valid on 'dev_asr_nya' subset | loss 1.763 | nll_loss 0.965 | total 3156.42 | n_correct 2545.32 | ppl 1.95 | accuracy 80.639 | wps 90876.4 | wpb 3156.4 | bsz 32.7 | num_updates 8704 | best_loss 1.763\n",
            "2022-12-24 21:53:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 396 @ 8704 updates\n",
            "2022-12-24 21:53:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint396.pt\n",
            "2022-12-24 21:53:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint396.pt\n",
            "2022-12-24 21:53:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint396.pt (epoch 396 @ 8704 updates, score 1.763) (writing took 14.179127478000737 seconds)\n",
            "2022-12-24 21:53:58 | INFO | fairseq_cli.train | end of epoch 396 (average epoch stats below)\n",
            "2022-12-24 21:53:58 | INFO | train | epoch 396 | loss 1.683 | nll_loss 0.959 | total 35852.4 | n_correct 29484.9 | ppl 1.94 | accuracy 82.24 | wps 24321 | ups 0.68 | wpb 35852.4 | bsz 368.4 | num_updates 8704 | lr 2.6112e-05 | gnorm 2.178 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 12412\n",
            "2022-12-24 21:53:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 397:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:53:58 | INFO | fairseq.trainer | begin training epoch 397\n",
            "2022-12-24 21:53:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 397:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:54:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.07it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.49it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.87it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.06it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.32it/s]\u001b[A\n",
            "epoch 397 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.46it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:54:17 | INFO | dev_asr_nya | epoch 397 | valid on 'dev_asr_nya' subset | loss 1.766 | nll_loss 0.971 | total 3156.42 | n_correct 2541.05 | ppl 1.96 | accuracy 80.504 | wps 91420.9 | wpb 3156.4 | bsz 32.7 | num_updates 8726 | best_loss 1.763\n",
            "2022-12-24 21:54:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 397 @ 8726 updates\n",
            "2022-12-24 21:54:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint397.pt\n",
            "2022-12-24 21:54:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint397.pt\n",
            "2022-12-24 21:54:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint397.pt (epoch 397 @ 8726 updates, score 1.766) (writing took 11.093256935000682 seconds)\n",
            "2022-12-24 21:54:28 | INFO | fairseq_cli.train | end of epoch 397 (average epoch stats below)\n",
            "2022-12-24 21:54:28 | INFO | train | epoch 397 | loss 1.672 | nll_loss 0.945 | total 35852.4 | n_correct 29618.7 | ppl 1.93 | accuracy 82.613 | wps 26598.8 | ups 0.74 | wpb 35852.4 | bsz 368.4 | num_updates 8726 | lr 2.6178e-05 | gnorm 1.087 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 12441\n",
            "2022-12-24 21:54:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 398:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:54:28 | INFO | fairseq.trainer | begin training epoch 398\n",
            "2022-12-24 21:54:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 398:  95% 21/22 [00:17<00:00,  1.19it/s]2022-12-24 21:54:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.95it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.27it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.00it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.01it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.44it/s]\u001b[A\n",
            "epoch 398 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:54:47 | INFO | dev_asr_nya | epoch 398 | valid on 'dev_asr_nya' subset | loss 1.775 | nll_loss 0.981 | total 3156.42 | n_correct 2538.32 | ppl 1.97 | accuracy 80.418 | wps 87277.8 | wpb 3156.4 | bsz 32.7 | num_updates 8748 | best_loss 1.763\n",
            "2022-12-24 21:54:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 398 @ 8748 updates\n",
            "2022-12-24 21:54:47 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint398.pt\n",
            "2022-12-24 21:54:50 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint398.pt\n",
            "2022-12-24 21:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint398.pt (epoch 398 @ 8748 updates, score 1.775) (writing took 9.83389195899872 seconds)\n",
            "2022-12-24 21:54:57 | INFO | fairseq_cli.train | end of epoch 398 (average epoch stats below)\n",
            "2022-12-24 21:54:57 | INFO | train | epoch 398 | loss 1.669 | nll_loss 0.942 | total 35852.4 | n_correct 29636.2 | ppl 1.92 | accuracy 82.662 | wps 27298.2 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 8748 | lr 2.6244e-05 | gnorm 1.445 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.9 | wall 12470\n",
            "2022-12-24 21:54:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 399:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:54:57 | INFO | fairseq.trainer | begin training epoch 399\n",
            "2022-12-24 21:54:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 399:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:55:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.82it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.55it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.88it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.66it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.59it/s]\u001b[A\n",
            "epoch 399 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.07it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:55:15 | INFO | dev_asr_nya | epoch 399 | valid on 'dev_asr_nya' subset | loss 1.793 | nll_loss 1.003 | total 3156.42 | n_correct 2520.47 | ppl 2 | accuracy 79.852 | wps 90552.9 | wpb 3156.4 | bsz 32.7 | num_updates 8770 | best_loss 1.763\n",
            "2022-12-24 21:55:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 399 @ 8770 updates\n",
            "2022-12-24 21:55:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint399.pt\n",
            "2022-12-24 21:55:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint399.pt\n",
            "2022-12-24 21:55:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint399.pt (epoch 399 @ 8770 updates, score 1.793) (writing took 10.30564065499857 seconds)\n",
            "2022-12-24 21:55:25 | INFO | fairseq_cli.train | end of epoch 399 (average epoch stats below)\n",
            "2022-12-24 21:55:25 | INFO | train | epoch 399 | loss 1.678 | nll_loss 0.953 | total 35852.4 | n_correct 29546.5 | ppl 1.94 | accuracy 82.411 | wps 27611.9 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 8770 | lr 2.631e-05 | gnorm 2.352 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 12499\n",
            "2022-12-24 21:55:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 400:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:55:25 | INFO | fairseq.trainer | begin training epoch 400\n",
            "2022-12-24 21:55:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 400:  95% 21/22 [00:16<00:00,  1.25it/s]2022-12-24 21:55:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.48it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.66it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.62it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.94it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.68it/s]\u001b[A\n",
            "epoch 400 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:55:44 | INFO | dev_asr_nya | epoch 400 | valid on 'dev_asr_nya' subset | loss 1.754 | nll_loss 0.958 | total 3156.42 | n_correct 2553.79 | ppl 1.94 | accuracy 80.908 | wps 90842 | wpb 3156.4 | bsz 32.7 | num_updates 8792 | best_loss 1.754\n",
            "2022-12-24 21:55:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 400 @ 8792 updates\n",
            "2022-12-24 21:55:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint400.pt\n",
            "2022-12-24 21:55:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint400.pt\n",
            "2022-12-24 21:55:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint400.pt (epoch 400 @ 8792 updates, score 1.754) (writing took 13.198952530998213 seconds)\n",
            "2022-12-24 21:55:57 | INFO | fairseq_cli.train | end of epoch 400 (average epoch stats below)\n",
            "2022-12-24 21:55:57 | INFO | train | epoch 400 | loss 1.672 | nll_loss 0.946 | total 35852.4 | n_correct 29598 | ppl 1.93 | accuracy 82.555 | wps 24848.3 | ups 0.69 | wpb 35852.4 | bsz 368.4 | num_updates 8792 | lr 2.6376e-05 | gnorm 1.871 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 12531\n",
            "2022-12-24 21:55:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 401:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:55:57 | INFO | fairseq.trainer | begin training epoch 401\n",
            "2022-12-24 21:55:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 401:  95% 21/22 [00:17<00:00,  1.24it/s, loss=1.674, nll_loss=0.948, total=35835.9, n_correct=29575, ppl=1.93, accuracy=82.529, wps=24950.2, ups=0.7, wpb=35835.9, bsz=367.4, num_updates=8800, lr=2.64e-05, gnorm=1.674, clip=0, loss_scale=4, train_wall=79, gb_free=30.7, wall=12537]2022-12-24 21:56:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.71it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.06it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.20it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.92it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.55it/s]\u001b[A\n",
            "epoch 401 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.63it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:56:16 | INFO | dev_asr_nya | epoch 401 | valid on 'dev_asr_nya' subset | loss 1.753 | nll_loss 0.956 | total 3156.42 | n_correct 2553.32 | ppl 1.94 | accuracy 80.893 | wps 91275.9 | wpb 3156.4 | bsz 32.7 | num_updates 8814 | best_loss 1.753\n",
            "2022-12-24 21:56:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 401 @ 8814 updates\n",
            "2022-12-24 21:56:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint401.pt\n",
            "2022-12-24 21:56:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint401.pt\n",
            "2022-12-24 21:56:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint401.pt (epoch 401 @ 8814 updates, score 1.753) (writing took 15.562437452001177 seconds)\n",
            "2022-12-24 21:56:31 | INFO | fairseq_cli.train | end of epoch 401 (average epoch stats below)\n",
            "2022-12-24 21:56:31 | INFO | train | epoch 401 | loss 1.662 | nll_loss 0.933 | total 35852.4 | n_correct 29701.2 | ppl 1.91 | accuracy 82.843 | wps 23055.1 | ups 0.64 | wpb 35852.4 | bsz 368.4 | num_updates 8814 | lr 2.6442e-05 | gnorm 1.168 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 12565\n",
            "2022-12-24 21:56:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 402:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:56:31 | INFO | fairseq.trainer | begin training epoch 402\n",
            "2022-12-24 21:56:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 402:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:56:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.30it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.59it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.27it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.35it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.01it/s]\u001b[A\n",
            "epoch 402 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.04it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:56:50 | INFO | dev_asr_nya | epoch 402 | valid on 'dev_asr_nya' subset | loss 1.754 | nll_loss 0.957 | total 3156.42 | n_correct 2553.79 | ppl 1.94 | accuracy 80.908 | wps 90816.3 | wpb 3156.4 | bsz 32.7 | num_updates 8836 | best_loss 1.753\n",
            "2022-12-24 21:56:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 402 @ 8836 updates\n",
            "2022-12-24 21:56:50 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint402.pt\n",
            "2022-12-24 21:56:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint402.pt\n",
            "2022-12-24 21:57:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint402.pt (epoch 402 @ 8836 updates, score 1.754) (writing took 10.159865752997575 seconds)\n",
            "2022-12-24 21:57:00 | INFO | fairseq_cli.train | end of epoch 402 (average epoch stats below)\n",
            "2022-12-24 21:57:00 | INFO | train | epoch 402 | loss 1.658 | nll_loss 0.929 | total 35852.4 | n_correct 29744.3 | ppl 1.9 | accuracy 82.963 | wps 27631.9 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 8836 | lr 2.6508e-05 | gnorm 1.209 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 12593\n",
            "2022-12-24 21:57:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 403:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:57:00 | INFO | fairseq.trainer | begin training epoch 403\n",
            "2022-12-24 21:57:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 403:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 21:57:18 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.96it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.90it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.80it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.21it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.83it/s]\u001b[A\n",
            "epoch 403 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.85it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:57:19 | INFO | dev_asr_nya | epoch 403 | valid on 'dev_asr_nya' subset | loss 1.758 | nll_loss 0.96 | total 3156.42 | n_correct 2549.89 | ppl 1.95 | accuracy 80.784 | wps 85976.1 | wpb 3156.4 | bsz 32.7 | num_updates 8858 | best_loss 1.753\n",
            "2022-12-24 21:57:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 403 @ 8858 updates\n",
            "2022-12-24 21:57:19 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint403.pt\n",
            "2022-12-24 21:57:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint403.pt\n",
            "2022-12-24 21:57:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint403.pt (epoch 403 @ 8858 updates, score 1.758) (writing took 7.812814271001116 seconds)\n",
            "2022-12-24 21:57:27 | INFO | fairseq_cli.train | end of epoch 403 (average epoch stats below)\n",
            "2022-12-24 21:57:27 | INFO | train | epoch 403 | loss 1.653 | nll_loss 0.923 | total 35852.4 | n_correct 29782.2 | ppl 1.9 | accuracy 83.069 | wps 29152.1 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 8858 | lr 2.6574e-05 | gnorm 0.959 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.7 | wall 12620\n",
            "2022-12-24 21:57:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 404:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:57:27 | INFO | fairseq.trainer | begin training epoch 404\n",
            "2022-12-24 21:57:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 404:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 21:57:44 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.76it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.50it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.30it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 23.04it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 25.35it/s]\u001b[A\n",
            "epoch 404 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 28.11it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:57:45 | INFO | dev_asr_nya | epoch 404 | valid on 'dev_asr_nya' subset | loss 1.755 | nll_loss 0.958 | total 3156.42 | n_correct 2555.79 | ppl 1.94 | accuracy 80.971 | wps 91667 | wpb 3156.4 | bsz 32.7 | num_updates 8880 | best_loss 1.753\n",
            "2022-12-24 21:57:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 404 @ 8880 updates\n",
            "2022-12-24 21:57:45 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint404.pt\n",
            "2022-12-24 21:57:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint404.pt\n",
            "2022-12-24 21:57:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint404.pt (epoch 404 @ 8880 updates, score 1.755) (writing took 9.314460483998118 seconds)\n",
            "2022-12-24 21:57:54 | INFO | fairseq_cli.train | end of epoch 404 (average epoch stats below)\n",
            "2022-12-24 21:57:54 | INFO | train | epoch 404 | loss 1.659 | nll_loss 0.93 | total 35852.4 | n_correct 29721.4 | ppl 1.91 | accuracy 82.899 | wps 28422.5 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 8880 | lr 2.664e-05 | gnorm 2.078 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.6 | wall 12648\n",
            "2022-12-24 21:57:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 405:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:57:55 | INFO | fairseq.trainer | begin training epoch 405\n",
            "2022-12-24 21:57:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 405:  95% 21/22 [00:17<00:00,  1.29it/s, loss=1.657, nll_loss=0.927, total=35864.7, n_correct=29760.9, ppl=1.9, accuracy=82.981, wps=28195.6, ups=0.79, wpb=35864.7, bsz=368.5, num_updates=8900, lr=2.67e-05, gnorm=1.35, clip=0, loss_scale=4, train_wall=79, gb_free=28.8, wall=12665]2022-12-24 21:58:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.22it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.54it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.83it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.99it/s]\u001b[A\n",
            "epoch 405 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.54it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:58:13 | INFO | dev_asr_nya | epoch 405 | valid on 'dev_asr_nya' subset | loss 1.755 | nll_loss 0.957 | total 3156.42 | n_correct 2554.42 | ppl 1.94 | accuracy 80.928 | wps 90404.9 | wpb 3156.4 | bsz 32.7 | num_updates 8902 | best_loss 1.753\n",
            "2022-12-24 21:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 405 @ 8902 updates\n",
            "2022-12-24 21:58:13 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint405.pt\n",
            "2022-12-24 21:58:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint405.pt\n",
            "2022-12-24 21:58:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint405.pt (epoch 405 @ 8902 updates, score 1.755) (writing took 7.885331945999496 seconds)\n",
            "2022-12-24 21:58:21 | INFO | fairseq_cli.train | end of epoch 405 (average epoch stats below)\n",
            "2022-12-24 21:58:21 | INFO | train | epoch 405 | loss 1.653 | nll_loss 0.923 | total 35852.4 | n_correct 29781.5 | ppl 1.9 | accuracy 83.067 | wps 29772.8 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 8902 | lr 2.6706e-05 | gnorm 1.408 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 12675\n",
            "2022-12-24 21:58:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 406:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:58:21 | INFO | fairseq.trainer | begin training epoch 406\n",
            "2022-12-24 21:58:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 406:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 21:58:38 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.34it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.26it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.66it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.71it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.07it/s]\u001b[A\n",
            "epoch 406 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 26.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:58:39 | INFO | dev_asr_nya | epoch 406 | valid on 'dev_asr_nya' subset | loss 1.75 | nll_loss 0.951 | total 3156.42 | n_correct 2556.05 | ppl 1.93 | accuracy 80.979 | wps 89339.9 | wpb 3156.4 | bsz 32.7 | num_updates 8924 | best_loss 1.75\n",
            "2022-12-24 21:58:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 406 @ 8924 updates\n",
            "2022-12-24 21:58:39 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint406.pt\n",
            "2022-12-24 21:58:43 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint406.pt\n",
            "2022-12-24 21:58:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint406.pt (epoch 406 @ 8924 updates, score 1.75) (writing took 12.847392019000836 seconds)\n",
            "2022-12-24 21:58:52 | INFO | fairseq_cli.train | end of epoch 406 (average epoch stats below)\n",
            "2022-12-24 21:58:52 | INFO | train | epoch 406 | loss 1.647 | nll_loss 0.917 | total 35852.4 | n_correct 29832.6 | ppl 1.89 | accuracy 83.21 | wps 25310.8 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 8924 | lr 2.6772e-05 | gnorm 1.076 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 12706\n",
            "2022-12-24 21:58:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 407:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:58:52 | INFO | fairseq.trainer | begin training epoch 407\n",
            "2022-12-24 21:58:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 407:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 21:59:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.04it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.33it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.56it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.83it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.19it/s]\u001b[A\n",
            "epoch 407 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.87it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:59:11 | INFO | dev_asr_nya | epoch 407 | valid on 'dev_asr_nya' subset | loss 1.757 | nll_loss 0.961 | total 3156.42 | n_correct 2550 | ppl 1.95 | accuracy 80.788 | wps 87095.3 | wpb 3156.4 | bsz 32.7 | num_updates 8946 | best_loss 1.75\n",
            "2022-12-24 21:59:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 407 @ 8946 updates\n",
            "2022-12-24 21:59:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint407.pt\n",
            "2022-12-24 21:59:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint407.pt\n",
            "2022-12-24 21:59:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint407.pt (epoch 407 @ 8946 updates, score 1.757) (writing took 7.737853321999864 seconds)\n",
            "2022-12-24 21:59:18 | INFO | fairseq_cli.train | end of epoch 407 (average epoch stats below)\n",
            "2022-12-24 21:59:18 | INFO | train | epoch 407 | loss 1.645 | nll_loss 0.914 | total 35852.4 | n_correct 29829 | ppl 1.88 | accuracy 83.2 | wps 30029.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 8946 | lr 2.6838e-05 | gnorm 1.147 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.6 | wall 12732\n",
            "2022-12-24 21:59:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 408:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:59:18 | INFO | fairseq.trainer | begin training epoch 408\n",
            "2022-12-24 21:59:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 408:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 21:59:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.24it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.96it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.85it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.00it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.65it/s]\u001b[A\n",
            "epoch 408 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.32it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 21:59:37 | INFO | dev_asr_nya | epoch 408 | valid on 'dev_asr_nya' subset | loss 1.775 | nll_loss 0.982 | total 3156.42 | n_correct 2540.16 | ppl 1.98 | accuracy 80.476 | wps 89127.5 | wpb 3156.4 | bsz 32.7 | num_updates 8968 | best_loss 1.75\n",
            "2022-12-24 21:59:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 408 @ 8968 updates\n",
            "2022-12-24 21:59:37 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint408.pt\n",
            "2022-12-24 21:59:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint408.pt\n",
            "2022-12-24 21:59:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint408.pt (epoch 408 @ 8968 updates, score 1.775) (writing took 8.592903721997573 seconds)\n",
            "2022-12-24 21:59:45 | INFO | fairseq_cli.train | end of epoch 408 (average epoch stats below)\n",
            "2022-12-24 21:59:45 | INFO | train | epoch 408 | loss 1.648 | nll_loss 0.918 | total 35852.4 | n_correct 29820.2 | ppl 1.89 | accuracy 83.175 | wps 29136.5 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 8968 | lr 2.6904e-05 | gnorm 1.856 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 12759\n",
            "2022-12-24 21:59:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 409:   0% 0/22 [00:00<?, ?it/s]2022-12-24 21:59:46 | INFO | fairseq.trainer | begin training epoch 409\n",
            "2022-12-24 21:59:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 409:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 22:00:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.17it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.74it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.64it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.97it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.93it/s]\u001b[A\n",
            "epoch 409 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:00:04 | INFO | dev_asr_nya | epoch 409 | valid on 'dev_asr_nya' subset | loss 1.74 | nll_loss 0.938 | total 3156.42 | n_correct 2565.42 | ppl 1.92 | accuracy 81.276 | wps 92393.2 | wpb 3156.4 | bsz 32.7 | num_updates 8990 | best_loss 1.74\n",
            "2022-12-24 22:00:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 409 @ 8990 updates\n",
            "2022-12-24 22:00:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint409.pt\n",
            "2022-12-24 22:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint409.pt\n",
            "2022-12-24 22:00:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint409.pt (epoch 409 @ 8990 updates, score 1.74) (writing took 12.545768476000376 seconds)\n",
            "2022-12-24 22:00:17 | INFO | fairseq_cli.train | end of epoch 409 (average epoch stats below)\n",
            "2022-12-24 22:00:17 | INFO | train | epoch 409 | loss 1.665 | nll_loss 0.937 | total 35852.4 | n_correct 29644.7 | ppl 1.91 | accuracy 82.686 | wps 25300.9 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 8990 | lr 2.697e-05 | gnorm 3.203 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 12790\n",
            "2022-12-24 22:00:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 410:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:00:17 | INFO | fairseq.trainer | begin training epoch 410\n",
            "2022-12-24 22:00:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 410:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.65, nll_loss=0.92, total=35895.8, n_correct=29828.1, ppl=1.89, accuracy=83.096, wps=26760.1, ups=0.75, wpb=35895.8, bsz=369.8, num_updates=9000, lr=2.7e-05, gnorm=1.803, clip=0, loss_scale=4, train_wall=78, gb_free=31.3, wall=12799]2022-12-24 22:00:34 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.70it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.72it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.02it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.23it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.69it/s]\u001b[A\n",
            "epoch 410 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.06it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:00:35 | INFO | dev_asr_nya | epoch 410 | valid on 'dev_asr_nya' subset | loss 1.742 | nll_loss 0.942 | total 3156.42 | n_correct 2562.37 | ppl 1.92 | accuracy 81.18 | wps 86076.9 | wpb 3156.4 | bsz 32.7 | num_updates 9012 | best_loss 1.74\n",
            "2022-12-24 22:00:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 410 @ 9012 updates\n",
            "2022-12-24 22:00:35 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint410.pt\n",
            "2022-12-24 22:00:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint410.pt\n",
            "2022-12-24 22:00:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint410.pt (epoch 410 @ 9012 updates, score 1.742) (writing took 7.766140430998348 seconds)\n",
            "2022-12-24 22:00:43 | INFO | fairseq_cli.train | end of epoch 410 (average epoch stats below)\n",
            "2022-12-24 22:00:43 | INFO | train | epoch 410 | loss 1.644 | nll_loss 0.913 | total 35852.4 | n_correct 29855.9 | ppl 1.88 | accuracy 83.275 | wps 30213 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9012 | lr 2.7036e-05 | gnorm 1.671 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 12816\n",
            "2022-12-24 22:00:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 411:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:00:43 | INFO | fairseq.trainer | begin training epoch 411\n",
            "2022-12-24 22:00:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 411:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:01:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.38it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.59it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.98it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.37it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.37it/s]\u001b[A\n",
            "epoch 411 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:01:01 | INFO | dev_asr_nya | epoch 411 | valid on 'dev_asr_nya' subset | loss 1.76 | nll_loss 0.963 | total 3156.42 | n_correct 2547.95 | ppl 1.95 | accuracy 80.723 | wps 89229.1 | wpb 3156.4 | bsz 32.7 | num_updates 9034 | best_loss 1.74\n",
            "2022-12-24 22:01:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 411 @ 9034 updates\n",
            "2022-12-24 22:01:01 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint411.pt\n",
            "2022-12-24 22:01:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint411.pt\n",
            "2022-12-24 22:01:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint411.pt (epoch 411 @ 9034 updates, score 1.76) (writing took 7.7886172979997355 seconds)\n",
            "2022-12-24 22:01:09 | INFO | fairseq_cli.train | end of epoch 411 (average epoch stats below)\n",
            "2022-12-24 22:01:09 | INFO | train | epoch 411 | loss 1.637 | nll_loss 0.904 | total 35852.4 | n_correct 29931.1 | ppl 1.87 | accuracy 83.484 | wps 30162.3 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9034 | lr 2.7102e-05 | gnorm 1.35 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 12843\n",
            "2022-12-24 22:01:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 412:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:01:09 | INFO | fairseq.trainer | begin training epoch 412\n",
            "2022-12-24 22:01:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 412:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 22:01:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.44it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.61it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.24it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.38it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.65it/s]\u001b[A\n",
            "epoch 412 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.63it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:01:28 | INFO | dev_asr_nya | epoch 412 | valid on 'dev_asr_nya' subset | loss 1.739 | nll_loss 0.94 | total 3156.42 | n_correct 2568.32 | ppl 1.92 | accuracy 81.368 | wps 89640.1 | wpb 3156.4 | bsz 32.7 | num_updates 9056 | best_loss 1.739\n",
            "2022-12-24 22:01:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 412 @ 9056 updates\n",
            "2022-12-24 22:01:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint412.pt\n",
            "2022-12-24 22:01:31 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint412.pt\n",
            "2022-12-24 22:01:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint412.pt (epoch 412 @ 9056 updates, score 1.739) (writing took 12.309138357999473 seconds)\n",
            "2022-12-24 22:01:40 | INFO | fairseq_cli.train | end of epoch 412 (average epoch stats below)\n",
            "2022-12-24 22:01:40 | INFO | train | epoch 412 | loss 1.634 | nll_loss 0.9 | total 35852.4 | n_correct 29969.7 | ppl 1.87 | accuracy 83.592 | wps 25507.4 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 9056 | lr 2.7168e-05 | gnorm 1.26 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 12874\n",
            "2022-12-24 22:01:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 413:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:01:40 | INFO | fairseq.trainer | begin training epoch 413\n",
            "2022-12-24 22:01:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 413:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 22:01:58 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.94it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.50it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.91it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.96it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.56it/s]\u001b[A\n",
            "epoch 413 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 25.60it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:01:59 | INFO | dev_asr_nya | epoch 413 | valid on 'dev_asr_nya' subset | loss 1.75 | nll_loss 0.95 | total 3156.42 | n_correct 2558.68 | ppl 1.93 | accuracy 81.063 | wps 84107.1 | wpb 3156.4 | bsz 32.7 | num_updates 9078 | best_loss 1.739\n",
            "2022-12-24 22:01:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 413 @ 9078 updates\n",
            "2022-12-24 22:01:59 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint413.pt\n",
            "2022-12-24 22:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint413.pt\n",
            "2022-12-24 22:02:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint413.pt (epoch 413 @ 9078 updates, score 1.75) (writing took 7.6327607610001 seconds)\n",
            "2022-12-24 22:02:06 | INFO | fairseq_cli.train | end of epoch 413 (average epoch stats below)\n",
            "2022-12-24 22:02:06 | INFO | train | epoch 413 | loss 1.642 | nll_loss 0.91 | total 35852.4 | n_correct 29866.5 | ppl 1.88 | accuracy 83.304 | wps 29965.4 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9078 | lr 2.7234e-05 | gnorm 2.329 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.1 | wall 12900\n",
            "2022-12-24 22:02:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 414:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:02:06 | INFO | fairseq.trainer | begin training epoch 414\n",
            "2022-12-24 22:02:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 414:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:02:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.42it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.71it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.21it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.24it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.39it/s]\u001b[A\n",
            "epoch 414 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.81it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:02:25 | INFO | dev_asr_nya | epoch 414 | valid on 'dev_asr_nya' subset | loss 1.747 | nll_loss 0.949 | total 3156.42 | n_correct 2560.32 | ppl 1.93 | accuracy 81.115 | wps 89126.4 | wpb 3156.4 | bsz 32.7 | num_updates 9100 | best_loss 1.739\n",
            "2022-12-24 22:02:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 414 @ 9100 updates\n",
            "2022-12-24 22:02:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint414.pt\n",
            "2022-12-24 22:02:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint414.pt\n",
            "2022-12-24 22:02:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint414.pt (epoch 414 @ 9100 updates, score 1.747) (writing took 8.038429844000348 seconds)\n",
            "2022-12-24 22:02:33 | INFO | fairseq_cli.train | end of epoch 414 (average epoch stats below)\n",
            "2022-12-24 22:02:33 | INFO | train | epoch 414 | loss 1.633 | nll_loss 0.9 | total 35852.4 | n_correct 29960.4 | ppl 1.87 | accuracy 83.566 | wps 29268.4 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 9100 | lr 2.73e-05 | gnorm 1.68 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.8 | wall 12927\n",
            "2022-12-24 22:02:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 415:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:02:33 | INFO | fairseq.trainer | begin training epoch 415\n",
            "2022-12-24 22:02:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 415:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:02:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.72it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.76it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.91it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.08it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.75it/s]\u001b[A\n",
            "epoch 415 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.58it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:02:52 | INFO | dev_asr_nya | epoch 415 | valid on 'dev_asr_nya' subset | loss 1.736 | nll_loss 0.935 | total 3156.42 | n_correct 2568.53 | ppl 1.91 | accuracy 81.375 | wps 88994.7 | wpb 3156.4 | bsz 32.7 | num_updates 9122 | best_loss 1.736\n",
            "2022-12-24 22:02:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 415 @ 9122 updates\n",
            "2022-12-24 22:02:52 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint415.pt\n",
            "2022-12-24 22:02:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint415.pt\n",
            "2022-12-24 22:03:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint415.pt (epoch 415 @ 9122 updates, score 1.736) (writing took 13.532055698997283 seconds)\n",
            "2022-12-24 22:03:05 | INFO | fairseq_cli.train | end of epoch 415 (average epoch stats below)\n",
            "2022-12-24 22:03:05 | INFO | train | epoch 415 | loss 1.627 | nll_loss 0.893 | total 35852.4 | n_correct 30023.5 | ppl 1.86 | accuracy 83.742 | wps 24651.9 | ups 0.69 | wpb 35852.4 | bsz 368.4 | num_updates 9122 | lr 2.7366e-05 | gnorm 1.607 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.4 | wall 12959\n",
            "2022-12-24 22:03:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 416:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:03:05 | INFO | fairseq.trainer | begin training epoch 416\n",
            "2022-12-24 22:03:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 416:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 22:03:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.03it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.44it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.47it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.60it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.86it/s]\u001b[A\n",
            "epoch 416 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.62it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:03:24 | INFO | dev_asr_nya | epoch 416 | valid on 'dev_asr_nya' subset | loss 1.739 | nll_loss 0.937 | total 3156.42 | n_correct 2568 | ppl 1.91 | accuracy 81.358 | wps 88201.2 | wpb 3156.4 | bsz 32.7 | num_updates 9144 | best_loss 1.736\n",
            "2022-12-24 22:03:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 416 @ 9144 updates\n",
            "2022-12-24 22:03:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint416.pt\n",
            "2022-12-24 22:03:30 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint416.pt\n",
            "2022-12-24 22:03:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint416.pt (epoch 416 @ 9144 updates, score 1.739) (writing took 10.282565222998528 seconds)\n",
            "2022-12-24 22:03:34 | INFO | fairseq_cli.train | end of epoch 416 (average epoch stats below)\n",
            "2022-12-24 22:03:34 | INFO | train | epoch 416 | loss 1.627 | nll_loss 0.893 | total 35852.4 | n_correct 30022.9 | ppl 1.86 | accuracy 83.74 | wps 27149.7 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 9144 | lr 2.7432e-05 | gnorm 1.641 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 12988\n",
            "2022-12-24 22:03:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 417:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:03:34 | INFO | fairseq.trainer | begin training epoch 417\n",
            "2022-12-24 22:03:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 417:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:03:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.11it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.22it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.71it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.65it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.94it/s]\u001b[A\n",
            "epoch 417 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:03:53 | INFO | dev_asr_nya | epoch 417 | valid on 'dev_asr_nya' subset | loss 1.735 | nll_loss 0.932 | total 3156.42 | n_correct 2574.79 | ppl 1.91 | accuracy 81.573 | wps 87932.9 | wpb 3156.4 | bsz 32.7 | num_updates 9166 | best_loss 1.735\n",
            "2022-12-24 22:03:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 417 @ 9166 updates\n",
            "2022-12-24 22:03:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint417.pt\n",
            "2022-12-24 22:03:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint417.pt\n",
            "2022-12-24 22:04:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint417.pt (epoch 417 @ 9166 updates, score 1.735) (writing took 12.375223847000598 seconds)\n",
            "2022-12-24 22:04:05 | INFO | fairseq_cli.train | end of epoch 417 (average epoch stats below)\n",
            "2022-12-24 22:04:05 | INFO | train | epoch 417 | loss 1.622 | nll_loss 0.887 | total 35852.4 | n_correct 30074 | ppl 1.85 | accuracy 83.883 | wps 25496.9 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 9166 | lr 2.7498e-05 | gnorm 1.153 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 13019\n",
            "2022-12-24 22:04:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 418:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:04:05 | INFO | fairseq.trainer | begin training epoch 418\n",
            "2022-12-24 22:04:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 418:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:04:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.66it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.59it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.22it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.79it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.97it/s]\u001b[A\n",
            "epoch 418 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.54it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:04:23 | INFO | dev_asr_nya | epoch 418 | valid on 'dev_asr_nya' subset | loss 1.738 | nll_loss 0.937 | total 3156.42 | n_correct 2569 | ppl 1.92 | accuracy 81.39 | wps 90616.5 | wpb 3156.4 | bsz 32.7 | num_updates 9188 | best_loss 1.735\n",
            "2022-12-24 22:04:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 418 @ 9188 updates\n",
            "2022-12-24 22:04:23 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint418.pt\n",
            "2022-12-24 22:04:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint418.pt\n",
            "2022-12-24 22:04:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint418.pt (epoch 418 @ 9188 updates, score 1.738) (writing took 7.775891572000546 seconds)\n",
            "2022-12-24 22:04:31 | INFO | fairseq_cli.train | end of epoch 418 (average epoch stats below)\n",
            "2022-12-24 22:04:31 | INFO | train | epoch 418 | loss 1.618 | nll_loss 0.882 | total 35852.4 | n_correct 30111.3 | ppl 1.84 | accuracy 83.987 | wps 30375.1 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 9188 | lr 2.7564e-05 | gnorm 1.231 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 13045\n",
            "2022-12-24 22:04:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 419:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:04:31 | INFO | fairseq.trainer | begin training epoch 419\n",
            "2022-12-24 22:04:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 419:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.623, nll_loss=0.888, total=35905.6, n_correct=30108.2, ppl=1.85, accuracy=83.854, wps=26237.8, ups=0.73, wpb=35905.6, bsz=368.3, num_updates=9200, lr=2.76e-05, gnorm=1.369, clip=0, loss_scale=4, train_wall=78, gb_free=30.3, wall=13055]2022-12-24 22:04:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.44it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.59it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.22it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.86it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.62it/s]\u001b[A\n",
            "epoch 419 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:04:50 | INFO | dev_asr_nya | epoch 419 | valid on 'dev_asr_nya' subset | loss 1.729 | nll_loss 0.928 | total 3156.42 | n_correct 2579.89 | ppl 1.9 | accuracy 81.735 | wps 90551.2 | wpb 3156.4 | bsz 32.7 | num_updates 9210 | best_loss 1.729\n",
            "2022-12-24 22:04:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 419 @ 9210 updates\n",
            "2022-12-24 22:04:50 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint419.pt\n",
            "2022-12-24 22:04:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint419.pt\n",
            "2022-12-24 22:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint419.pt (epoch 419 @ 9210 updates, score 1.729) (writing took 14.218912593998539 seconds)\n",
            "2022-12-24 22:05:04 | INFO | fairseq_cli.train | end of epoch 419 (average epoch stats below)\n",
            "2022-12-24 22:05:04 | INFO | train | epoch 419 | loss 1.619 | nll_loss 0.884 | total 35852.4 | n_correct 30107.8 | ppl 1.84 | accuracy 83.977 | wps 23888.8 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 9210 | lr 2.763e-05 | gnorm 1.53 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31 | wall 13078\n",
            "2022-12-24 22:05:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 420:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:05:04 | INFO | fairseq.trainer | begin training epoch 420\n",
            "2022-12-24 22:05:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 420:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:05:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.25it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.91it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.10it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.23it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "epoch 420 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.28it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:05:23 | INFO | dev_asr_nya | epoch 420 | valid on 'dev_asr_nya' subset | loss 1.737 | nll_loss 0.935 | total 3156.42 | n_correct 2569.63 | ppl 1.91 | accuracy 81.41 | wps 92257.8 | wpb 3156.4 | bsz 32.7 | num_updates 9232 | best_loss 1.729\n",
            "2022-12-24 22:05:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 420 @ 9232 updates\n",
            "2022-12-24 22:05:23 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint420.pt\n",
            "2022-12-24 22:05:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint420.pt\n",
            "2022-12-24 22:05:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint420.pt (epoch 420 @ 9232 updates, score 1.737) (writing took 7.6320758830006525 seconds)\n",
            "2022-12-24 22:05:30 | INFO | fairseq_cli.train | end of epoch 420 (average epoch stats below)\n",
            "2022-12-24 22:05:30 | INFO | train | epoch 420 | loss 1.623 | nll_loss 0.888 | total 35852.4 | n_correct 30053.8 | ppl 1.85 | accuracy 83.826 | wps 30136.4 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9232 | lr 2.7696e-05 | gnorm 2.341 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 13104\n",
            "2022-12-24 22:05:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 421:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:05:30 | INFO | fairseq.trainer | begin training epoch 421\n",
            "2022-12-24 22:05:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 421:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:05:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.53it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.58it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.32it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.14it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.03it/s]\u001b[A\n",
            "epoch 421 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:05:49 | INFO | dev_asr_nya | epoch 421 | valid on 'dev_asr_nya' subset | loss 1.724 | nll_loss 0.921 | total 3156.42 | n_correct 2580.32 | ppl 1.89 | accuracy 81.748 | wps 86745.4 | wpb 3156.4 | bsz 32.7 | num_updates 9254 | best_loss 1.724\n",
            "2022-12-24 22:05:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 421 @ 9254 updates\n",
            "2022-12-24 22:05:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint421.pt\n",
            "2022-12-24 22:05:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint421.pt\n",
            "2022-12-24 22:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint421.pt (epoch 421 @ 9254 updates, score 1.724) (writing took 14.926287566999235 seconds)\n",
            "2022-12-24 22:06:04 | INFO | fairseq_cli.train | end of epoch 421 (average epoch stats below)\n",
            "2022-12-24 22:06:04 | INFO | train | epoch 421 | loss 1.629 | nll_loss 0.896 | total 35852.4 | n_correct 29976.7 | ppl 1.86 | accuracy 83.611 | wps 23417.9 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 9254 | lr 2.7762e-05 | gnorm 2.83 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 13138\n",
            "2022-12-24 22:06:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 422:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:06:04 | INFO | fairseq.trainer | begin training epoch 422\n",
            "2022-12-24 22:06:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 422:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:06:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.46it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.35it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.73it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.37it/s]\u001b[A\n",
            "epoch 422 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.05it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:06:23 | INFO | dev_asr_nya | epoch 422 | valid on 'dev_asr_nya' subset | loss 1.727 | nll_loss 0.927 | total 3156.42 | n_correct 2577.63 | ppl 1.9 | accuracy 81.663 | wps 90341.8 | wpb 3156.4 | bsz 32.7 | num_updates 9276 | best_loss 1.724\n",
            "2022-12-24 22:06:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 422 @ 9276 updates\n",
            "2022-12-24 22:06:23 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint422.pt\n",
            "2022-12-24 22:06:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint422.pt\n",
            "2022-12-24 22:06:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint422.pt (epoch 422 @ 9276 updates, score 1.727) (writing took 7.976868153000396 seconds)\n",
            "2022-12-24 22:06:31 | INFO | fairseq_cli.train | end of epoch 422 (average epoch stats below)\n",
            "2022-12-24 22:06:31 | INFO | train | epoch 422 | loss 1.615 | nll_loss 0.879 | total 35852.4 | n_correct 30133.4 | ppl 1.84 | accuracy 84.048 | wps 29586.4 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 9276 | lr 2.7828e-05 | gnorm 1.661 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 13164\n",
            "2022-12-24 22:06:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 423:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:06:31 | INFO | fairseq.trainer | begin training epoch 423\n",
            "2022-12-24 22:06:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 423:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 22:06:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.92it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.91it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.70it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.94it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.50it/s]\u001b[A\n",
            "epoch 423 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 27.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:06:49 | INFO | dev_asr_nya | epoch 423 | valid on 'dev_asr_nya' subset | loss 1.728 | nll_loss 0.927 | total 3156.42 | n_correct 2574.89 | ppl 1.9 | accuracy 81.576 | wps 85314.7 | wpb 3156.4 | bsz 32.7 | num_updates 9298 | best_loss 1.724\n",
            "2022-12-24 22:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 423 @ 9298 updates\n",
            "2022-12-24 22:06:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint423.pt\n",
            "2022-12-24 22:06:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint423.pt\n",
            "2022-12-24 22:06:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint423.pt (epoch 423 @ 9298 updates, score 1.728) (writing took 10.101809674000833 seconds)\n",
            "2022-12-24 22:06:59 | INFO | fairseq_cli.train | end of epoch 423 (average epoch stats below)\n",
            "2022-12-24 22:06:59 | INFO | train | epoch 423 | loss 1.619 | nll_loss 0.885 | total 35852.4 | n_correct 30066.5 | ppl 1.85 | accuracy 83.862 | wps 27329.5 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 9298 | lr 2.7894e-05 | gnorm 2.166 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 13193\n",
            "2022-12-24 22:07:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 424:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:07:00 | INFO | fairseq.trainer | begin training epoch 424\n",
            "2022-12-24 22:07:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 424:  95% 21/22 [00:16<00:00,  1.30it/s, loss=1.621, nll_loss=0.887, total=35808.2, n_correct=30026.4, ppl=1.85, accuracy=83.853, wps=25522.1, ups=0.71, wpb=35808.2, bsz=368, num_updates=9300, lr=2.79e-05, gnorm=2.205, clip=0, loss_scale=4, train_wall=79, gb_free=31.5, wall=13195]2022-12-24 22:07:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.82it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.76it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.92it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.29it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.19it/s]\u001b[A\n",
            "epoch 424 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.67it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:07:18 | INFO | dev_asr_nya | epoch 424 | valid on 'dev_asr_nya' subset | loss 1.741 | nll_loss 0.945 | total 3156.42 | n_correct 2565 | ppl 1.92 | accuracy 81.263 | wps 93223.5 | wpb 3156.4 | bsz 32.7 | num_updates 9320 | best_loss 1.724\n",
            "2022-12-24 22:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 424 @ 9320 updates\n",
            "2022-12-24 22:07:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint424.pt\n",
            "2022-12-24 22:07:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint424.pt\n",
            "2022-12-24 22:07:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint424.pt (epoch 424 @ 9320 updates, score 1.741) (writing took 10.203318559000763 seconds)\n",
            "2022-12-24 22:07:28 | INFO | fairseq_cli.train | end of epoch 424 (average epoch stats below)\n",
            "2022-12-24 22:07:28 | INFO | train | epoch 424 | loss 1.61 | nll_loss 0.873 | total 35852.4 | n_correct 30171 | ppl 1.83 | accuracy 84.153 | wps 27719.9 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 9320 | lr 2.796e-05 | gnorm 1.294 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 13222\n",
            "2022-12-24 22:07:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 425:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:07:28 | INFO | fairseq.trainer | begin training epoch 425\n",
            "2022-12-24 22:07:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 425:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:07:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.92it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.36it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.91it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.01it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.18it/s]\u001b[A\n",
            "epoch 425 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.55it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:07:46 | INFO | dev_asr_nya | epoch 425 | valid on 'dev_asr_nya' subset | loss 1.716 | nll_loss 0.911 | total 3156.42 | n_correct 2588.42 | ppl 1.88 | accuracy 82.005 | wps 91573.5 | wpb 3156.4 | bsz 32.7 | num_updates 9342 | best_loss 1.716\n",
            "2022-12-24 22:07:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 425 @ 9342 updates\n",
            "2022-12-24 22:07:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint425.pt\n",
            "2022-12-24 22:07:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint425.pt\n",
            "2022-12-24 22:08:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint425.pt (epoch 425 @ 9342 updates, score 1.716) (writing took 15.437269419999211 seconds)\n",
            "2022-12-24 22:08:02 | INFO | fairseq_cli.train | end of epoch 425 (average epoch stats below)\n",
            "2022-12-24 22:08:02 | INFO | train | epoch 425 | loss 1.612 | nll_loss 0.876 | total 35852.4 | n_correct 30151.1 | ppl 1.83 | accuracy 84.098 | wps 23284.3 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 9342 | lr 2.8026e-05 | gnorm 2.168 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 13255\n",
            "2022-12-24 22:08:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 426:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:08:02 | INFO | fairseq.trainer | begin training epoch 426\n",
            "2022-12-24 22:08:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 426:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:08:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.44it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.40it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.62it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 17.70it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.19it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.98it/s]\u001b[A\n",
            "epoch 426 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.91it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:08:20 | INFO | dev_asr_nya | epoch 426 | valid on 'dev_asr_nya' subset | loss 1.723 | nll_loss 0.921 | total 3156.42 | n_correct 2580.63 | ppl 1.89 | accuracy 81.758 | wps 83782.4 | wpb 3156.4 | bsz 32.7 | num_updates 9364 | best_loss 1.716\n",
            "2022-12-24 22:08:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 426 @ 9364 updates\n",
            "2022-12-24 22:08:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint426.pt\n",
            "2022-12-24 22:08:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint426.pt\n",
            "2022-12-24 22:08:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint426.pt (epoch 426 @ 9364 updates, score 1.723) (writing took 8.796075828002358 seconds)\n",
            "2022-12-24 22:08:29 | INFO | fairseq_cli.train | end of epoch 426 (average epoch stats below)\n",
            "2022-12-24 22:08:29 | INFO | train | epoch 426 | loss 1.603 | nll_loss 0.864 | total 35852.4 | n_correct 30246.2 | ppl 1.82 | accuracy 84.363 | wps 28799.1 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 9364 | lr 2.8092e-05 | gnorm 1.052 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 13283\n",
            "2022-12-24 22:08:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 427:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:08:29 | INFO | fairseq.trainer | begin training epoch 427\n",
            "2022-12-24 22:08:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 427:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 22:08:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.97it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.10it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.87it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.94it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.57it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.12it/s]\u001b[A\n",
            "epoch 427 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 25.02it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:08:48 | INFO | dev_asr_nya | epoch 427 | valid on 'dev_asr_nya' subset | loss 1.725 | nll_loss 0.925 | total 3156.42 | n_correct 2580.26 | ppl 1.9 | accuracy 81.746 | wps 80732.5 | wpb 3156.4 | bsz 32.7 | num_updates 9386 | best_loss 1.716\n",
            "2022-12-24 22:08:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 427 @ 9386 updates\n",
            "2022-12-24 22:08:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint427.pt\n",
            "2022-12-24 22:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint427.pt\n",
            "2022-12-24 22:08:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint427.pt (epoch 427 @ 9386 updates, score 1.725) (writing took 9.389498950000416 seconds)\n",
            "2022-12-24 22:08:58 | INFO | fairseq_cli.train | end of epoch 427 (average epoch stats below)\n",
            "2022-12-24 22:08:58 | INFO | train | epoch 427 | loss 1.598 | nll_loss 0.86 | total 35852.4 | n_correct 30284.3 | ppl 1.81 | accuracy 84.469 | wps 27813.9 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 9386 | lr 2.8158e-05 | gnorm 1.099 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.7 | wall 13311\n",
            "2022-12-24 22:08:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 428:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:08:58 | INFO | fairseq.trainer | begin training epoch 428\n",
            "2022-12-24 22:08:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 428:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.604, nll_loss=0.866, total=35824.6, n_correct=30205.7, ppl=1.82, accuracy=84.315, wps=28080.5, ups=0.78, wpb=35824.6, bsz=368.7, num_updates=9400, lr=2.82e-05, gnorm=1.353, clip=0, loss_scale=4, train_wall=78, gb_free=30.7, wall=13323]2022-12-24 22:09:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.62it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.16it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.90it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.46it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.78it/s]\u001b[A\n",
            "epoch 428 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.81it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:09:16 | INFO | dev_asr_nya | epoch 428 | valid on 'dev_asr_nya' subset | loss 1.724 | nll_loss 0.921 | total 3156.42 | n_correct 2583.63 | ppl 1.89 | accuracy 81.853 | wps 85089.5 | wpb 3156.4 | bsz 32.7 | num_updates 9408 | best_loss 1.716\n",
            "2022-12-24 22:09:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 428 @ 9408 updates\n",
            "2022-12-24 22:09:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint428.pt\n",
            "2022-12-24 22:09:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint428.pt\n",
            "2022-12-24 22:09:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint428.pt (epoch 428 @ 9408 updates, score 1.724) (writing took 10.058925240002281 seconds)\n",
            "2022-12-24 22:09:26 | INFO | fairseq_cli.train | end of epoch 428 (average epoch stats below)\n",
            "2022-12-24 22:09:26 | INFO | train | epoch 428 | loss 1.596 | nll_loss 0.856 | total 35852.4 | n_correct 30310 | ppl 1.81 | accuracy 84.541 | wps 27659.3 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 9408 | lr 2.8224e-05 | gnorm 1.271 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 13340\n",
            "2022-12-24 22:09:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 429:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:09:26 | INFO | fairseq.trainer | begin training epoch 429\n",
            "2022-12-24 22:09:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 429:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 22:09:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.63it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.76it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.54it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.69it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.43it/s]\u001b[A\n",
            "epoch 429 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.06it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:09:44 | INFO | dev_asr_nya | epoch 429 | valid on 'dev_asr_nya' subset | loss 1.726 | nll_loss 0.926 | total 3156.42 | n_correct 2580.79 | ppl 1.9 | accuracy 81.763 | wps 92451 | wpb 3156.4 | bsz 32.7 | num_updates 9430 | best_loss 1.716\n",
            "2022-12-24 22:09:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 429 @ 9430 updates\n",
            "2022-12-24 22:09:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint429.pt\n",
            "2022-12-24 22:09:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint429.pt\n",
            "2022-12-24 22:09:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint429.pt (epoch 429 @ 9430 updates, score 1.726) (writing took 8.000509516998136 seconds)\n",
            "2022-12-24 22:09:52 | INFO | fairseq_cli.train | end of epoch 429 (average epoch stats below)\n",
            "2022-12-24 22:09:52 | INFO | train | epoch 429 | loss 1.595 | nll_loss 0.855 | total 35852.4 | n_correct 30326.9 | ppl 1.81 | accuracy 84.588 | wps 30033.9 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9430 | lr 2.829e-05 | gnorm 1.397 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 13366\n",
            "2022-12-24 22:09:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 430:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:09:52 | INFO | fairseq.trainer | begin training epoch 430\n",
            "2022-12-24 22:09:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 430:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:10:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.70it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:01, 14.99it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.47it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.18it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 23.03it/s]\u001b[A\n",
            "epoch 430 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.17it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:10:11 | INFO | dev_asr_nya | epoch 430 | valid on 'dev_asr_nya' subset | loss 1.723 | nll_loss 0.92 | total 3156.42 | n_correct 2583.42 | ppl 1.89 | accuracy 81.847 | wps 84653.8 | wpb 3156.4 | bsz 32.7 | num_updates 9452 | best_loss 1.716\n",
            "2022-12-24 22:10:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 430 @ 9452 updates\n",
            "2022-12-24 22:10:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint430.pt\n",
            "2022-12-24 22:10:15 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint430.pt\n",
            "2022-12-24 22:10:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint430.pt (epoch 430 @ 9452 updates, score 1.723) (writing took 7.81752095399861 seconds)\n",
            "2022-12-24 22:10:19 | INFO | fairseq_cli.train | end of epoch 430 (average epoch stats below)\n",
            "2022-12-24 22:10:19 | INFO | train | epoch 430 | loss 1.59 | nll_loss 0.849 | total 35852.4 | n_correct 30371.2 | ppl 1.8 | accuracy 84.712 | wps 29583.5 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 9452 | lr 2.8356e-05 | gnorm 1.136 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.2 | wall 13393\n",
            "2022-12-24 22:10:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 431:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:10:19 | INFO | fairseq.trainer | begin training epoch 431\n",
            "2022-12-24 22:10:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 431:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:10:37 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.40it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.33it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.52it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.99it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.92it/s]\u001b[A\n",
            "epoch 431 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:10:37 | INFO | dev_asr_nya | epoch 431 | valid on 'dev_asr_nya' subset | loss 1.772 | nll_loss 0.979 | total 3156.42 | n_correct 2543.37 | ppl 1.97 | accuracy 80.578 | wps 92677.1 | wpb 3156.4 | bsz 32.7 | num_updates 9474 | best_loss 1.716\n",
            "2022-12-24 22:10:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 431 @ 9474 updates\n",
            "2022-12-24 22:10:37 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint431.pt\n",
            "2022-12-24 22:10:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint431.pt\n",
            "2022-12-24 22:10:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint431.pt (epoch 431 @ 9474 updates, score 1.772) (writing took 7.9441434319996915 seconds)\n",
            "2022-12-24 22:10:45 | INFO | fairseq_cli.train | end of epoch 431 (average epoch stats below)\n",
            "2022-12-24 22:10:45 | INFO | train | epoch 431 | loss 1.59 | nll_loss 0.85 | total 35852.4 | n_correct 30354.3 | ppl 1.8 | accuracy 84.665 | wps 29876.1 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 9474 | lr 2.8422e-05 | gnorm 1.34 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 13419\n",
            "2022-12-24 22:10:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 432:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:10:45 | INFO | fairseq.trainer | begin training epoch 432\n",
            "2022-12-24 22:10:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 432:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:11:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.51it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.56it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.73it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.10it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.23it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.55it/s]\u001b[A\n",
            "epoch 432 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:11:04 | INFO | dev_asr_nya | epoch 432 | valid on 'dev_asr_nya' subset | loss 1.768 | nll_loss 0.976 | total 3156.42 | n_correct 2546.63 | ppl 1.97 | accuracy 80.681 | wps 86353.6 | wpb 3156.4 | bsz 32.7 | num_updates 9496 | best_loss 1.716\n",
            "2022-12-24 22:11:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 432 @ 9496 updates\n",
            "2022-12-24 22:11:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint432.pt\n",
            "2022-12-24 22:11:08 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint432.pt\n",
            "2022-12-24 22:11:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint432.pt (epoch 432 @ 9496 updates, score 1.768) (writing took 8.497355333001906 seconds)\n",
            "2022-12-24 22:11:12 | INFO | fairseq_cli.train | end of epoch 432 (average epoch stats below)\n",
            "2022-12-24 22:11:12 | INFO | train | epoch 432 | loss 1.606 | nll_loss 0.869 | total 35852.4 | n_correct 30199.8 | ppl 1.83 | accuracy 84.234 | wps 29214.6 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 9496 | lr 2.8488e-05 | gnorm 3.283 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32 | wall 13446\n",
            "2022-12-24 22:11:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 433:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:11:12 | INFO | fairseq.trainer | begin training epoch 433\n",
            "2022-12-24 22:11:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 433:  95% 21/22 [00:17<00:00,  1.29it/s, loss=1.596, nll_loss=0.857, total=35888.9, n_correct=30331.9, ppl=1.81, accuracy=84.516, wps=28258.8, ups=0.79, wpb=35888.9, bsz=368.1, num_updates=9500, lr=2.85e-05, gnorm=1.854, clip=0, loss_scale=4, train_wall=78, gb_free=30.8, wall=13450]2022-12-24 22:11:30 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.99it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.29it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.31it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.43it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.95it/s]\u001b[A\n",
            "epoch 433 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.05it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:11:31 | INFO | dev_asr_nya | epoch 433 | valid on 'dev_asr_nya' subset | loss 1.724 | nll_loss 0.924 | total 3156.42 | n_correct 2580.63 | ppl 1.9 | accuracy 81.758 | wps 88442 | wpb 3156.4 | bsz 32.7 | num_updates 9518 | best_loss 1.716\n",
            "2022-12-24 22:11:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 433 @ 9518 updates\n",
            "2022-12-24 22:11:31 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint433.pt\n",
            "2022-12-24 22:11:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint433.pt\n",
            "2022-12-24 22:11:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint433.pt (epoch 433 @ 9518 updates, score 1.724) (writing took 8.874448880000273 seconds)\n",
            "2022-12-24 22:11:40 | INFO | fairseq_cli.train | end of epoch 433 (average epoch stats below)\n",
            "2022-12-24 22:11:40 | INFO | train | epoch 433 | loss 1.601 | nll_loss 0.863 | total 35852.4 | n_correct 30240.8 | ppl 1.82 | accuracy 84.348 | wps 28735.1 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 9518 | lr 2.8554e-05 | gnorm 2.134 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.1 | wall 13474\n",
            "2022-12-24 22:11:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 434:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:11:40 | INFO | fairseq.trainer | begin training epoch 434\n",
            "2022-12-24 22:11:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 434:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:11:58 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.41it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.88it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.12it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.89it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.85it/s]\u001b[A\n",
            "epoch 434 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.42it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:11:58 | INFO | dev_asr_nya | epoch 434 | valid on 'dev_asr_nya' subset | loss 1.72 | nll_loss 0.917 | total 3156.42 | n_correct 2585.53 | ppl 1.89 | accuracy 81.913 | wps 92595.8 | wpb 3156.4 | bsz 32.7 | num_updates 9540 | best_loss 1.716\n",
            "2022-12-24 22:11:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 434 @ 9540 updates\n",
            "2022-12-24 22:11:58 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint434.pt\n",
            "2022-12-24 22:12:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint434.pt\n",
            "2022-12-24 22:12:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint434.pt (epoch 434 @ 9540 updates, score 1.72) (writing took 9.198582683002314 seconds)\n",
            "2022-12-24 22:12:08 | INFO | fairseq_cli.train | end of epoch 434 (average epoch stats below)\n",
            "2022-12-24 22:12:08 | INFO | train | epoch 434 | loss 1.587 | nll_loss 0.847 | total 35852.4 | n_correct 30375.6 | ppl 1.8 | accuracy 84.724 | wps 28404.8 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 9540 | lr 2.862e-05 | gnorm 1.554 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 13501\n",
            "2022-12-24 22:12:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 435:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:12:08 | INFO | fairseq.trainer | begin training epoch 435\n",
            "2022-12-24 22:12:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 435:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:12:25 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.01it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.66it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.18it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.16it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.74it/s]\u001b[A\n",
            "epoch 435 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.94it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:12:26 | INFO | dev_asr_nya | epoch 435 | valid on 'dev_asr_nya' subset | loss 1.716 | nll_loss 0.915 | total 3156.42 | n_correct 2589.21 | ppl 1.89 | accuracy 82.03 | wps 93736.3 | wpb 3156.4 | bsz 32.7 | num_updates 9562 | best_loss 1.716\n",
            "2022-12-24 22:12:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 435 @ 9562 updates\n",
            "2022-12-24 22:12:26 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint435.pt\n",
            "2022-12-24 22:12:29 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint435.pt\n",
            "2022-12-24 22:12:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint435.pt (epoch 435 @ 9562 updates, score 1.716) (writing took 12.071224161001737 seconds)\n",
            "2022-12-24 22:12:38 | INFO | fairseq_cli.train | end of epoch 435 (average epoch stats below)\n",
            "2022-12-24 22:12:38 | INFO | train | epoch 435 | loss 1.582 | nll_loss 0.84 | total 35852.4 | n_correct 30441.7 | ppl 1.79 | accuracy 84.909 | wps 25840.8 | ups 0.72 | wpb 35852.4 | bsz 368.4 | num_updates 9562 | lr 2.8686e-05 | gnorm 1.17 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 28.9 | wall 13532\n",
            "2022-12-24 22:12:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 436:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:12:38 | INFO | fairseq.trainer | begin training epoch 436\n",
            "2022-12-24 22:12:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 436:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:12:56 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.56it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.96it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.95it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.26it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.97it/s]\u001b[A\n",
            "epoch 436 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.13it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:12:56 | INFO | dev_asr_nya | epoch 436 | valid on 'dev_asr_nya' subset | loss 1.741 | nll_loss 0.946 | total 3156.42 | n_correct 2567.21 | ppl 1.93 | accuracy 81.333 | wps 91220.5 | wpb 3156.4 | bsz 32.7 | num_updates 9584 | best_loss 1.716\n",
            "2022-12-24 22:12:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 436 @ 9584 updates\n",
            "2022-12-24 22:12:56 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint436.pt\n",
            "2022-12-24 22:13:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint436.pt\n",
            "2022-12-24 22:13:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint436.pt (epoch 436 @ 9584 updates, score 1.741) (writing took 7.746671933997277 seconds)\n",
            "2022-12-24 22:13:04 | INFO | fairseq_cli.train | end of epoch 436 (average epoch stats below)\n",
            "2022-12-24 22:13:04 | INFO | train | epoch 436 | loss 1.583 | nll_loss 0.841 | total 35852.4 | n_correct 30426.2 | ppl 1.79 | accuracy 84.865 | wps 30198.4 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 9584 | lr 2.8752e-05 | gnorm 1.742 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.9 | wall 13558\n",
            "2022-12-24 22:13:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 437:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:13:04 | INFO | fairseq.trainer | begin training epoch 437\n",
            "2022-12-24 22:13:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 437:  95% 21/22 [00:17<00:00,  1.28it/s, loss=1.586, nll_loss=0.846, total=35826.5, n_correct=30370.2, ppl=1.8, accuracy=84.77, wps=29456.9, ups=0.82, wpb=35826.5, bsz=367.8, num_updates=9600, lr=2.88e-05, gnorm=1.594, clip=0, loss_scale=4, train_wall=79, gb_free=31.5, wall=13571]2022-12-24 22:13:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.12it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.26it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.36it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.36it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.15it/s]\u001b[A\n",
            "epoch 437 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:13:23 | INFO | dev_asr_nya | epoch 437 | valid on 'dev_asr_nya' subset | loss 1.724 | nll_loss 0.925 | total 3156.42 | n_correct 2581.32 | ppl 1.9 | accuracy 81.78 | wps 87203.8 | wpb 3156.4 | bsz 32.7 | num_updates 9606 | best_loss 1.716\n",
            "2022-12-24 22:13:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 437 @ 9606 updates\n",
            "2022-12-24 22:13:23 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint437.pt\n",
            "2022-12-24 22:13:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint437.pt\n",
            "2022-12-24 22:13:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint437.pt (epoch 437 @ 9606 updates, score 1.724) (writing took 8.79656364100083 seconds)\n",
            "2022-12-24 22:13:32 | INFO | fairseq_cli.train | end of epoch 437 (average epoch stats below)\n",
            "2022-12-24 22:13:32 | INFO | train | epoch 437 | loss 1.581 | nll_loss 0.84 | total 35852.4 | n_correct 30447.5 | ppl 1.79 | accuracy 84.925 | wps 28666.2 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 9606 | lr 2.8818e-05 | gnorm 1.564 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 13585\n",
            "2022-12-24 22:13:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 438:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:13:32 | INFO | fairseq.trainer | begin training epoch 438\n",
            "2022-12-24 22:13:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 438:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:13:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.45it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.36it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.70it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.43it/s]\u001b[A\n",
            "epoch 438 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.03it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:13:50 | INFO | dev_asr_nya | epoch 438 | valid on 'dev_asr_nya' subset | loss 1.719 | nll_loss 0.918 | total 3156.42 | n_correct 2586.53 | ppl 1.89 | accuracy 81.945 | wps 90254.1 | wpb 3156.4 | bsz 32.7 | num_updates 9628 | best_loss 1.716\n",
            "2022-12-24 22:13:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 438 @ 9628 updates\n",
            "2022-12-24 22:13:50 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint438.pt\n",
            "2022-12-24 22:13:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint438.pt\n",
            "2022-12-24 22:13:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint438.pt (epoch 438 @ 9628 updates, score 1.719) (writing took 9.456651510001393 seconds)\n",
            "2022-12-24 22:13:59 | INFO | fairseq_cli.train | end of epoch 438 (average epoch stats below)\n",
            "2022-12-24 22:13:59 | INFO | train | epoch 438 | loss 1.576 | nll_loss 0.834 | total 35852.4 | n_correct 30483 | ppl 1.78 | accuracy 85.024 | wps 28479.2 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 9628 | lr 2.8884e-05 | gnorm 1.475 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 13613\n",
            "2022-12-24 22:14:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 439:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:14:00 | INFO | fairseq.trainer | begin training epoch 439\n",
            "2022-12-24 22:14:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 439:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:14:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.65it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.34it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.96it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.72it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.02it/s]\u001b[A\n",
            "epoch 439 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:14:18 | INFO | dev_asr_nya | epoch 439 | valid on 'dev_asr_nya' subset | loss 1.711 | nll_loss 0.912 | total 3156.42 | n_correct 2596.16 | ppl 1.88 | accuracy 82.25 | wps 89050.2 | wpb 3156.4 | bsz 32.7 | num_updates 9650 | best_loss 1.711\n",
            "2022-12-24 22:14:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 439 @ 9650 updates\n",
            "2022-12-24 22:14:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint439.pt\n",
            "2022-12-24 22:14:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint439.pt\n",
            "2022-12-24 22:14:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint439.pt (epoch 439 @ 9650 updates, score 1.711) (writing took 16.468187495996972 seconds)\n",
            "2022-12-24 22:14:34 | INFO | fairseq_cli.train | end of epoch 439 (average epoch stats below)\n",
            "2022-12-24 22:14:34 | INFO | train | epoch 439 | loss 1.574 | nll_loss 0.831 | total 35852.4 | n_correct 30507.8 | ppl 1.78 | accuracy 85.093 | wps 22614.9 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 9650 | lr 2.895e-05 | gnorm 1.665 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 13648\n",
            "2022-12-24 22:14:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 440:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:14:34 | INFO | fairseq.trainer | begin training epoch 440\n",
            "2022-12-24 22:14:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 440:  95% 21/22 [00:16<00:00,  1.25it/s]2022-12-24 22:14:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.24it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.40it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.20it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.17it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 23.58it/s]\u001b[A\n",
            "epoch 440 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.53it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:14:53 | INFO | dev_asr_nya | epoch 440 | valid on 'dev_asr_nya' subset | loss 1.705 | nll_loss 0.902 | total 3156.42 | n_correct 2596.63 | ppl 1.87 | accuracy 82.265 | wps 85713.6 | wpb 3156.4 | bsz 32.7 | num_updates 9672 | best_loss 1.705\n",
            "2022-12-24 22:14:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 440 @ 9672 updates\n",
            "2022-12-24 22:14:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint440.pt\n",
            "2022-12-24 22:14:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint440.pt\n",
            "2022-12-24 22:15:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint440.pt (epoch 440 @ 9672 updates, score 1.705) (writing took 12.294742234000296 seconds)\n",
            "2022-12-24 22:15:05 | INFO | fairseq_cli.train | end of epoch 440 (average epoch stats below)\n",
            "2022-12-24 22:15:05 | INFO | train | epoch 440 | loss 1.575 | nll_loss 0.832 | total 35852.4 | n_correct 30504.3 | ppl 1.78 | accuracy 85.083 | wps 25593.4 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 9672 | lr 2.9016e-05 | gnorm 1.852 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.8 | wall 13679\n",
            "2022-12-24 22:15:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 441:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:15:05 | INFO | fairseq.trainer | begin training epoch 441\n",
            "2022-12-24 22:15:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 441:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:15:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.68it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 18.08it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.16it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.28it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.89it/s]\u001b[A\n",
            "epoch 441 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:15:24 | INFO | dev_asr_nya | epoch 441 | valid on 'dev_asr_nya' subset | loss 1.766 | nll_loss 0.974 | total 3156.42 | n_correct 2547.37 | ppl 1.96 | accuracy 80.704 | wps 91454.5 | wpb 3156.4 | bsz 32.7 | num_updates 9694 | best_loss 1.705\n",
            "2022-12-24 22:15:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 441 @ 9694 updates\n",
            "2022-12-24 22:15:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint441.pt\n",
            "2022-12-24 22:15:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint441.pt\n",
            "2022-12-24 22:15:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint441.pt (epoch 441 @ 9694 updates, score 1.766) (writing took 7.966479169001104 seconds)\n",
            "2022-12-24 22:15:32 | INFO | fairseq_cli.train | end of epoch 441 (average epoch stats below)\n",
            "2022-12-24 22:15:32 | INFO | train | epoch 441 | loss 1.613 | nll_loss 0.879 | total 35852.4 | n_correct 30103.9 | ppl 1.84 | accuracy 83.966 | wps 29805.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 9694 | lr 2.9082e-05 | gnorm 3.452 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.9 | wall 13705\n",
            "2022-12-24 22:15:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 442:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:15:32 | INFO | fairseq.trainer | begin training epoch 442\n",
            "2022-12-24 22:15:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 442:  95% 21/22 [00:17<00:00,  1.25it/s, loss=1.585, nll_loss=0.845, total=35911.3, n_correct=30442.1, ppl=1.8, accuracy=84.77, wps=25800.4, ups=0.72, wpb=35911.3, bsz=370.7, num_updates=9700, lr=2.91e-05, gnorm=2.078, clip=0, loss_scale=4, train_wall=78, gb_free=30.9, wall=13710]2022-12-24 22:15:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.55it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.50it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.74it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.52it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.46it/s]\u001b[A\n",
            "epoch 442 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.63it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:15:51 | INFO | dev_asr_nya | epoch 442 | valid on 'dev_asr_nya' subset | loss 1.713 | nll_loss 0.915 | total 3156.42 | n_correct 2582 | ppl 1.89 | accuracy 81.802 | wps 86247.2 | wpb 3156.4 | bsz 32.7 | num_updates 9716 | best_loss 1.705\n",
            "2022-12-24 22:15:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 442 @ 9716 updates\n",
            "2022-12-24 22:15:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint442.pt\n",
            "2022-12-24 22:15:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint442.pt\n",
            "2022-12-24 22:15:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint442.pt (epoch 442 @ 9716 updates, score 1.713) (writing took 8.230483448001905 seconds)\n",
            "2022-12-24 22:15:59 | INFO | fairseq_cli.train | end of epoch 442 (average epoch stats below)\n",
            "2022-12-24 22:15:59 | INFO | train | epoch 442 | loss 1.592 | nll_loss 0.854 | total 35852.4 | n_correct 30305.9 | ppl 1.81 | accuracy 84.53 | wps 28880.1 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 9716 | lr 2.9148e-05 | gnorm 1.859 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 29.9 | wall 13733\n",
            "2022-12-24 22:15:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 443:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:15:59 | INFO | fairseq.trainer | begin training epoch 443\n",
            "2022-12-24 22:15:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 443:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 22:16:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.52it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.44it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.02it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.17it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.16it/s]\u001b[A\n",
            "epoch 443 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.85it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:16:17 | INFO | dev_asr_nya | epoch 443 | valid on 'dev_asr_nya' subset | loss 1.71 | nll_loss 0.908 | total 3156.42 | n_correct 2592 | ppl 1.88 | accuracy 82.118 | wps 88025 | wpb 3156.4 | bsz 32.7 | num_updates 9738 | best_loss 1.705\n",
            "2022-12-24 22:16:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 443 @ 9738 updates\n",
            "2022-12-24 22:16:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint443.pt\n",
            "2022-12-24 22:16:20 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint443.pt\n",
            "2022-12-24 22:16:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint443.pt (epoch 443 @ 9738 updates, score 1.71) (writing took 9.713217902000906 seconds)\n",
            "2022-12-24 22:16:27 | INFO | fairseq_cli.train | end of epoch 443 (average epoch stats below)\n",
            "2022-12-24 22:16:27 | INFO | train | epoch 443 | loss 1.573 | nll_loss 0.831 | total 35852.4 | n_correct 30519.6 | ppl 1.78 | accuracy 85.126 | wps 28169 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 9738 | lr 2.9214e-05 | gnorm 1.795 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 13761\n",
            "2022-12-24 22:16:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 444:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:16:27 | INFO | fairseq.trainer | begin training epoch 444\n",
            "2022-12-24 22:16:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 444:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:16:44 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.45it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.30it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.83it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.54it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.12it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.24it/s]\u001b[A\n",
            "epoch 444 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 27.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:16:45 | INFO | dev_asr_nya | epoch 444 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.899 | total 3156.42 | n_correct 2599.26 | ppl 1.86 | accuracy 82.348 | wps 84896.7 | wpb 3156.4 | bsz 32.7 | num_updates 9760 | best_loss 1.702\n",
            "2022-12-24 22:16:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 444 @ 9760 updates\n",
            "2022-12-24 22:16:45 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint444.pt\n",
            "2022-12-24 22:16:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint444.pt\n",
            "2022-12-24 22:16:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint444.pt (epoch 444 @ 9760 updates, score 1.702) (writing took 13.477049974000693 seconds)\n",
            "2022-12-24 22:16:59 | INFO | fairseq_cli.train | end of epoch 444 (average epoch stats below)\n",
            "2022-12-24 22:16:59 | INFO | train | epoch 444 | loss 1.569 | nll_loss 0.826 | total 35852.4 | n_correct 30555.2 | ppl 1.77 | accuracy 85.225 | wps 24750.5 | ups 0.69 | wpb 35852.4 | bsz 368.4 | num_updates 9760 | lr 2.928e-05 | gnorm 1.797 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 13792\n",
            "2022-12-24 22:16:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 445:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:16:59 | INFO | fairseq.trainer | begin training epoch 445\n",
            "2022-12-24 22:16:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 445:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 22:17:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.57it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.16it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.69it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.78it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.78it/s]\u001b[A\n",
            "epoch 445 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:17:17 | INFO | dev_asr_nya | epoch 445 | valid on 'dev_asr_nya' subset | loss 1.707 | nll_loss 0.906 | total 3156.42 | n_correct 2597.53 | ppl 1.87 | accuracy 82.293 | wps 92854.8 | wpb 3156.4 | bsz 32.7 | num_updates 9782 | best_loss 1.702\n",
            "2022-12-24 22:17:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 445 @ 9782 updates\n",
            "2022-12-24 22:17:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint445.pt\n",
            "2022-12-24 22:17:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint445.pt\n",
            "2022-12-24 22:17:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint445.pt (epoch 445 @ 9782 updates, score 1.707) (writing took 9.99343681600294 seconds)\n",
            "2022-12-24 22:17:27 | INFO | fairseq_cli.train | end of epoch 445 (average epoch stats below)\n",
            "2022-12-24 22:17:27 | INFO | train | epoch 445 | loss 1.564 | nll_loss 0.819 | total 35852.4 | n_correct 30602.7 | ppl 1.76 | accuracy 85.358 | wps 27611.4 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 9782 | lr 2.9346e-05 | gnorm 1.576 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 13821\n",
            "2022-12-24 22:17:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 446:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:17:27 | INFO | fairseq.trainer | begin training epoch 446\n",
            "2022-12-24 22:17:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 446:  95% 21/22 [00:17<00:00,  1.25it/s, loss=1.57, nll_loss=0.827, total=35852.8, n_correct=30542.9, ppl=1.77, accuracy=85.19, wps=28575.9, ups=0.8, wpb=35852.8, bsz=369.1, num_updates=9800, lr=2.94e-05, gnorm=1.654, clip=0, loss_scale=4, train_wall=79, gb_free=31.4, wall=13836]2022-12-24 22:17:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.36it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.87it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.12it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.20it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.54it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.88it/s]\u001b[A\n",
            "epoch 446 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 26.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:17:46 | INFO | dev_asr_nya | epoch 446 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.899 | total 3156.42 | n_correct 2599.84 | ppl 1.87 | accuracy 82.367 | wps 83279.8 | wpb 3156.4 | bsz 32.7 | num_updates 9804 | best_loss 1.702\n",
            "2022-12-24 22:17:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 446 @ 9804 updates\n",
            "2022-12-24 22:17:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint446.pt\n",
            "2022-12-24 22:17:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint446.pt\n",
            "2022-12-24 22:18:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint446.pt (epoch 446 @ 9804 updates, score 1.702) (writing took 14.907114955996803 seconds)\n",
            "2022-12-24 22:18:01 | INFO | fairseq_cli.train | end of epoch 446 (average epoch stats below)\n",
            "2022-12-24 22:18:01 | INFO | train | epoch 446 | loss 1.563 | nll_loss 0.82 | total 35852.4 | n_correct 30610.4 | ppl 1.77 | accuracy 85.379 | wps 23356 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 9804 | lr 2.9412e-05 | gnorm 1.506 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.3 | wall 13855\n",
            "2022-12-24 22:18:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 447:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:18:01 | INFO | fairseq.trainer | begin training epoch 447\n",
            "2022-12-24 22:18:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 447:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 22:18:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.32it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.04it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.02it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.78it/s]\u001b[A\n",
            "epoch 447 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.69it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:18:20 | INFO | dev_asr_nya | epoch 447 | valid on 'dev_asr_nya' subset | loss 1.701 | nll_loss 0.898 | total 3156.42 | n_correct 2603 | ppl 1.86 | accuracy 82.467 | wps 87759.5 | wpb 3156.4 | bsz 32.7 | num_updates 9826 | best_loss 1.701\n",
            "2022-12-24 22:18:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 447 @ 9826 updates\n",
            "2022-12-24 22:18:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint447.pt\n",
            "2022-12-24 22:18:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint447.pt\n",
            "2022-12-24 22:18:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint447.pt (epoch 447 @ 9826 updates, score 1.701) (writing took 15.86252624700137 seconds)\n",
            "2022-12-24 22:18:35 | INFO | fairseq_cli.train | end of epoch 447 (average epoch stats below)\n",
            "2022-12-24 22:18:35 | INFO | train | epoch 447 | loss 1.569 | nll_loss 0.826 | total 35852.4 | n_correct 30536.1 | ppl 1.77 | accuracy 85.172 | wps 23004.9 | ups 0.64 | wpb 35852.4 | bsz 368.4 | num_updates 9826 | lr 2.9478e-05 | gnorm 2.446 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 13889\n",
            "2022-12-24 22:18:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 448:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:18:35 | INFO | fairseq.trainer | begin training epoch 448\n",
            "2022-12-24 22:18:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 448:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 22:18:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.92it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.99it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.88it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.34it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.87it/s]\u001b[A\n",
            "epoch 448 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.56it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:18:54 | INFO | dev_asr_nya | epoch 448 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.899 | total 3156.42 | n_correct 2597.68 | ppl 1.86 | accuracy 82.298 | wps 90948.9 | wpb 3156.4 | bsz 32.7 | num_updates 9848 | best_loss 1.701\n",
            "2022-12-24 22:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 448 @ 9848 updates\n",
            "2022-12-24 22:18:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint448.pt\n",
            "2022-12-24 22:18:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint448.pt\n",
            "2022-12-24 22:19:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint448.pt (epoch 448 @ 9848 updates, score 1.702) (writing took 7.632244853000884 seconds)\n",
            "2022-12-24 22:19:01 | INFO | fairseq_cli.train | end of epoch 448 (average epoch stats below)\n",
            "2022-12-24 22:19:01 | INFO | train | epoch 448 | loss 1.57 | nll_loss 0.827 | total 35852.4 | n_correct 30511.4 | ppl 1.77 | accuracy 85.103 | wps 30422 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 9848 | lr 2.9544e-05 | gnorm 2.271 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 13915\n",
            "2022-12-24 22:19:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 449:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:19:01 | INFO | fairseq.trainer | begin training epoch 449\n",
            "2022-12-24 22:19:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 449:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:19:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.48it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.54it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.01it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.03it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.91it/s]\u001b[A\n",
            "epoch 449 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.02it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:19:20 | INFO | dev_asr_nya | epoch 449 | valid on 'dev_asr_nya' subset | loss 1.709 | nll_loss 0.907 | total 3156.42 | n_correct 2595.79 | ppl 1.88 | accuracy 82.238 | wps 86258.7 | wpb 3156.4 | bsz 32.7 | num_updates 9870 | best_loss 1.701\n",
            "2022-12-24 22:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 449 @ 9870 updates\n",
            "2022-12-24 22:19:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint449.pt\n",
            "2022-12-24 22:19:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint449.pt\n",
            "2022-12-24 22:19:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint449.pt (epoch 449 @ 9870 updates, score 1.709) (writing took 10.680720804000885 seconds)\n",
            "2022-12-24 22:19:30 | INFO | fairseq_cli.train | end of epoch 449 (average epoch stats below)\n",
            "2022-12-24 22:19:30 | INFO | train | epoch 449 | loss 1.552 | nll_loss 0.806 | total 35852.4 | n_correct 30727.7 | ppl 1.75 | accuracy 85.706 | wps 27120.4 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 9870 | lr 2.961e-05 | gnorm 0.967 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 13944\n",
            "2022-12-24 22:19:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 450:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:19:31 | INFO | fairseq.trainer | begin training epoch 450\n",
            "2022-12-24 22:19:31 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 450:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:19:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.93it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.79it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.75it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.23it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.18it/s]\u001b[A\n",
            "epoch 450 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.14it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:19:49 | INFO | dev_asr_nya | epoch 450 | valid on 'dev_asr_nya' subset | loss 1.705 | nll_loss 0.903 | total 3156.42 | n_correct 2599.79 | ppl 1.87 | accuracy 82.365 | wps 87160.2 | wpb 3156.4 | bsz 32.7 | num_updates 9892 | best_loss 1.701\n",
            "2022-12-24 22:19:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 450 @ 9892 updates\n",
            "2022-12-24 22:19:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint450.pt\n",
            "2022-12-24 22:19:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint450.pt\n",
            "2022-12-24 22:19:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint450.pt (epoch 450 @ 9892 updates, score 1.705) (writing took 8.633551334001822 seconds)\n",
            "2022-12-24 22:19:58 | INFO | fairseq_cli.train | end of epoch 450 (average epoch stats below)\n",
            "2022-12-24 22:19:58 | INFO | train | epoch 450 | loss 1.549 | nll_loss 0.802 | total 35852.4 | n_correct 30744 | ppl 1.74 | accuracy 85.752 | wps 29083.5 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 9892 | lr 2.9676e-05 | gnorm 1.154 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 13971\n",
            "2022-12-24 22:19:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 451:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:19:58 | INFO | fairseq.trainer | begin training epoch 451\n",
            "2022-12-24 22:19:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 451:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.559, nll_loss=0.814, total=35869.2, n_correct=30657.7, ppl=1.76, accuracy=85.471, wps=25250, ups=0.7, wpb=35869.2, bsz=368.4, num_updates=9900, lr=2.97e-05, gnorm=1.663, clip=0, loss_scale=4, train_wall=78, gb_free=28.8, wall=13978]2022-12-24 22:20:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.65it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.15it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.75it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.85it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.49it/s]\u001b[A\n",
            "epoch 451 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.31it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:20:16 | INFO | dev_asr_nya | epoch 451 | valid on 'dev_asr_nya' subset | loss 1.698 | nll_loss 0.894 | total 3156.42 | n_correct 2606.68 | ppl 1.86 | accuracy 82.584 | wps 89431.6 | wpb 3156.4 | bsz 32.7 | num_updates 9914 | best_loss 1.698\n",
            "2022-12-24 22:20:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 451 @ 9914 updates\n",
            "2022-12-24 22:20:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint451.pt\n",
            "2022-12-24 22:20:22 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint451.pt\n",
            "2022-12-24 22:20:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint451.pt (epoch 451 @ 9914 updates, score 1.698) (writing took 15.992709892001585 seconds)\n",
            "2022-12-24 22:20:32 | INFO | fairseq_cli.train | end of epoch 451 (average epoch stats below)\n",
            "2022-12-24 22:20:32 | INFO | train | epoch 451 | loss 1.549 | nll_loss 0.802 | total 35852.4 | n_correct 30751.8 | ppl 1.74 | accuracy 85.773 | wps 22745.7 | ups 0.63 | wpb 35852.4 | bsz 368.4 | num_updates 9914 | lr 2.9742e-05 | gnorm 1.32 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 14006\n",
            "2022-12-24 22:20:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 452:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:20:32 | INFO | fairseq.trainer | begin training epoch 452\n",
            "2022-12-24 22:20:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 452:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 22:20:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.64it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.36it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.55it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.33it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.22it/s]\u001b[A\n",
            "epoch 452 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.05it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:20:51 | INFO | dev_asr_nya | epoch 452 | valid on 'dev_asr_nya' subset | loss 1.763 | nll_loss 0.972 | total 3156.42 | n_correct 2555.05 | ppl 1.96 | accuracy 80.948 | wps 88578.3 | wpb 3156.4 | bsz 32.7 | num_updates 9936 | best_loss 1.698\n",
            "2022-12-24 22:20:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 452 @ 9936 updates\n",
            "2022-12-24 22:20:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint452.pt\n",
            "2022-12-24 22:20:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint452.pt\n",
            "2022-12-24 22:21:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint452.pt (epoch 452 @ 9936 updates, score 1.763) (writing took 9.351735627999005 seconds)\n",
            "2022-12-24 22:21:00 | INFO | fairseq_cli.train | end of epoch 452 (average epoch stats below)\n",
            "2022-12-24 22:21:00 | INFO | train | epoch 452 | loss 1.549 | nll_loss 0.802 | total 35852.4 | n_correct 30733.8 | ppl 1.74 | accuracy 85.723 | wps 28145.9 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 9936 | lr 2.9808e-05 | gnorm 1.481 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14034\n",
            "2022-12-24 22:21:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 453:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:21:00 | INFO | fairseq.trainer | begin training epoch 453\n",
            "2022-12-24 22:21:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 453:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 22:21:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.51it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.80it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.05it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.88it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.08it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.37it/s]\u001b[A\n",
            "epoch 453 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 25.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:21:19 | INFO | dev_asr_nya | epoch 453 | valid on 'dev_asr_nya' subset | loss 1.716 | nll_loss 0.916 | total 3156.42 | n_correct 2586.58 | ppl 1.89 | accuracy 81.947 | wps 82493.2 | wpb 3156.4 | bsz 32.7 | num_updates 9958 | best_loss 1.698\n",
            "2022-12-24 22:21:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 453 @ 9958 updates\n",
            "2022-12-24 22:21:19 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint453.pt\n",
            "2022-12-24 22:21:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint453.pt\n",
            "2022-12-24 22:21:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint453.pt (epoch 453 @ 9958 updates, score 1.716) (writing took 9.389344425999298 seconds)\n",
            "2022-12-24 22:21:29 | INFO | fairseq_cli.train | end of epoch 453 (average epoch stats below)\n",
            "2022-12-24 22:21:29 | INFO | train | epoch 453 | loss 1.546 | nll_loss 0.798 | total 35852.4 | n_correct 30769.9 | ppl 1.74 | accuracy 85.824 | wps 27645.9 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 9958 | lr 2.9874e-05 | gnorm 1.651 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.7 | wall 14062\n",
            "2022-12-24 22:21:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 454:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:21:29 | INFO | fairseq.trainer | begin training epoch 454\n",
            "2022-12-24 22:21:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 454:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:21:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.13it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.33it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.35it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.74it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.89it/s]\u001b[A\n",
            "epoch 454 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.03it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:21:47 | INFO | dev_asr_nya | epoch 454 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.899 | total 3156.42 | n_correct 2602.74 | ppl 1.86 | accuracy 82.458 | wps 86339.1 | wpb 3156.4 | bsz 32.7 | num_updates 9980 | best_loss 1.698\n",
            "2022-12-24 22:21:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 454 @ 9980 updates\n",
            "2022-12-24 22:21:47 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint454.pt\n",
            "2022-12-24 22:21:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint454.pt\n",
            "2022-12-24 22:21:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint454.pt (epoch 454 @ 9980 updates, score 1.702) (writing took 9.682047064998187 seconds)\n",
            "2022-12-24 22:21:57 | INFO | fairseq_cli.train | end of epoch 454 (average epoch stats below)\n",
            "2022-12-24 22:21:57 | INFO | train | epoch 454 | loss 1.54 | nll_loss 0.792 | total 35852.4 | n_correct 30823.1 | ppl 1.73 | accuracy 85.972 | wps 27971.6 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 9980 | lr 2.994e-05 | gnorm 1.031 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 14091\n",
            "2022-12-24 22:21:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 455:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:21:57 | INFO | fairseq.trainer | begin training epoch 455\n",
            "2022-12-24 22:21:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 455:  95% 21/22 [00:17<00:00,  1.27it/s, loss=1.546, nll_loss=0.799, total=35816.3, n_correct=30733.3, ppl=1.74, accuracy=85.808, wps=27763.4, ups=0.78, wpb=35816.3, bsz=366.8, num_updates=10000, lr=3e-05, gnorm=1.391, clip=0, loss_scale=4, train_wall=79, gb_free=30.3, wall=14107]2022-12-24 22:22:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.99it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.69it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.99it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.27it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.73it/s]\u001b[A\n",
            "epoch 455 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.58it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:22:16 | INFO | dev_asr_nya | epoch 455 | valid on 'dev_asr_nya' subset | loss 1.735 | nll_loss 0.94 | total 3156.42 | n_correct 2573.63 | ppl 1.92 | accuracy 81.536 | wps 87511.4 | wpb 3156.4 | bsz 32.7 | num_updates 10002 | best_loss 1.698\n",
            "2022-12-24 22:22:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 455 @ 10002 updates\n",
            "2022-12-24 22:22:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint455.pt\n",
            "2022-12-24 22:22:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint455.pt\n",
            "2022-12-24 22:22:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint455.pt (epoch 455 @ 10002 updates, score 1.735) (writing took 9.692728070000157 seconds)\n",
            "2022-12-24 22:22:25 | INFO | fairseq_cli.train | end of epoch 455 (average epoch stats below)\n",
            "2022-12-24 22:22:25 | INFO | train | epoch 455 | loss 1.541 | nll_loss 0.793 | total 35852.4 | n_correct 30798.2 | ppl 1.73 | accuracy 85.903 | wps 27850.5 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 10002 | lr 2.9997e-05 | gnorm 1.448 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 14119\n",
            "2022-12-24 22:22:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 456:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:22:25 | INFO | fairseq.trainer | begin training epoch 456\n",
            "2022-12-24 22:22:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 456:  95% 21/22 [00:17<00:00,  1.22it/s]2022-12-24 22:22:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.79it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.91it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.12it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.23it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.79it/s]\u001b[A\n",
            "epoch 456 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.05it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:22:44 | INFO | dev_asr_nya | epoch 456 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.903 | total 3156.42 | n_correct 2598.16 | ppl 1.87 | accuracy 82.313 | wps 90074.8 | wpb 3156.4 | bsz 32.7 | num_updates 10024 | best_loss 1.698\n",
            "2022-12-24 22:22:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 456 @ 10024 updates\n",
            "2022-12-24 22:22:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint456.pt\n",
            "2022-12-24 22:22:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint456.pt\n",
            "2022-12-24 22:22:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint456.pt (epoch 456 @ 10024 updates, score 1.702) (writing took 8.313175498002238 seconds)\n",
            "2022-12-24 22:22:52 | INFO | fairseq_cli.train | end of epoch 456 (average epoch stats below)\n",
            "2022-12-24 22:22:52 | INFO | train | epoch 456 | loss 1.556 | nll_loss 0.811 | total 35852.4 | n_correct 30653.7 | ppl 1.75 | accuracy 85.5 | wps 29257.4 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10024 | lr 2.99641e-05 | gnorm 2.937 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 14146\n",
            "2022-12-24 22:22:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 457:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:22:52 | INFO | fairseq.trainer | begin training epoch 457\n",
            "2022-12-24 22:22:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 457:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:23:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.79it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.99it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.88it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.02it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
            "epoch 457 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.87it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:23:11 | INFO | dev_asr_nya | epoch 457 | valid on 'dev_asr_nya' subset | loss 1.692 | nll_loss 0.891 | total 3156.42 | n_correct 2606.11 | ppl 1.85 | accuracy 82.565 | wps 93577.1 | wpb 3156.4 | bsz 32.7 | num_updates 10046 | best_loss 1.692\n",
            "2022-12-24 22:23:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 457 @ 10046 updates\n",
            "2022-12-24 22:23:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint457.pt\n",
            "2022-12-24 22:23:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint457.pt\n",
            "2022-12-24 22:23:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint457.pt (epoch 457 @ 10046 updates, score 1.692) (writing took 12.57447771200168 seconds)\n",
            "2022-12-24 22:23:23 | INFO | fairseq_cli.train | end of epoch 457 (average epoch stats below)\n",
            "2022-12-24 22:23:23 | INFO | train | epoch 457 | loss 1.566 | nll_loss 0.824 | total 35852.4 | n_correct 30537.5 | ppl 1.77 | accuracy 85.176 | wps 25523.2 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 10046 | lr 2.99312e-05 | gnorm 3.271 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 14177\n",
            "2022-12-24 22:23:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 458:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:23:23 | INFO | fairseq.trainer | begin training epoch 458\n",
            "2022-12-24 22:23:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 458:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 22:23:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.45it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.75it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.60it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.97it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.75it/s]\u001b[A\n",
            "epoch 458 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.78it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:23:42 | INFO | dev_asr_nya | epoch 458 | valid on 'dev_asr_nya' subset | loss 1.684 | nll_loss 0.881 | total 3156.42 | n_correct 2615.21 | ppl 1.84 | accuracy 82.854 | wps 85224.1 | wpb 3156.4 | bsz 32.7 | num_updates 10068 | best_loss 1.684\n",
            "2022-12-24 22:23:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 458 @ 10068 updates\n",
            "2022-12-24 22:23:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint458.pt\n",
            "2022-12-24 22:23:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint458.pt\n",
            "2022-12-24 22:23:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint458.pt (epoch 458 @ 10068 updates, score 1.684) (writing took 14.11463551700217 seconds)\n",
            "2022-12-24 22:23:56 | INFO | fairseq_cli.train | end of epoch 458 (average epoch stats below)\n",
            "2022-12-24 22:23:56 | INFO | train | epoch 458 | loss 1.543 | nll_loss 0.797 | total 35852.4 | n_correct 30782.4 | ppl 1.74 | accuracy 85.859 | wps 23994.8 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 10068 | lr 2.98985e-05 | gnorm 1.572 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 14210\n",
            "2022-12-24 22:23:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 459:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:23:56 | INFO | fairseq.trainer | begin training epoch 459\n",
            "2022-12-24 22:23:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 459:  95% 21/22 [00:16<00:00,  1.26it/s]2022-12-24 22:24:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.58it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.64it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.72it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.19it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.55it/s]\u001b[A\n",
            "epoch 459 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:24:15 | INFO | dev_asr_nya | epoch 459 | valid on 'dev_asr_nya' subset | loss 1.687 | nll_loss 0.883 | total 3156.42 | n_correct 2611.95 | ppl 1.84 | accuracy 82.75 | wps 88605.3 | wpb 3156.4 | bsz 32.7 | num_updates 10090 | best_loss 1.684\n",
            "2022-12-24 22:24:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 459 @ 10090 updates\n",
            "2022-12-24 22:24:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint459.pt\n",
            "2022-12-24 22:24:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint459.pt\n",
            "2022-12-24 22:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint459.pt (epoch 459 @ 10090 updates, score 1.687) (writing took 7.953423218001262 seconds)\n",
            "2022-12-24 22:24:23 | INFO | fairseq_cli.train | end of epoch 459 (average epoch stats below)\n",
            "2022-12-24 22:24:23 | INFO | train | epoch 459 | loss 1.535 | nll_loss 0.786 | total 35852.4 | n_correct 30852.8 | ppl 1.72 | accuracy 86.055 | wps 29761.3 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 10090 | lr 2.98659e-05 | gnorm 1.626 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14236\n",
            "2022-12-24 22:24:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 460:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:24:23 | INFO | fairseq.trainer | begin training epoch 460\n",
            "2022-12-24 22:24:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 460:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.547, nll_loss=0.801, total=35857.2, n_correct=30740.2, ppl=1.74, accuracy=85.73, wps=26015.8, ups=0.73, wpb=35857.2, bsz=368.9, num_updates=10100, lr=2.98511e-05, gnorm=2.28, clip=0, loss_scale=4, train_wall=79, gb_free=31.7, wall=14245]2022-12-24 22:24:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.16it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.77it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.33it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 22.01it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 23.09it/s]\u001b[A\n",
            "epoch 460 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 24.82it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:24:42 | INFO | dev_asr_nya | epoch 460 | valid on 'dev_asr_nya' subset | loss 1.704 | nll_loss 0.906 | total 3156.42 | n_correct 2593.84 | ppl 1.87 | accuracy 82.177 | wps 78692.7 | wpb 3156.4 | bsz 32.7 | num_updates 10112 | best_loss 1.684\n",
            "2022-12-24 22:24:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 460 @ 10112 updates\n",
            "2022-12-24 22:24:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint460.pt\n",
            "2022-12-24 22:24:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint460.pt\n",
            "2022-12-24 22:24:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint460.pt (epoch 460 @ 10112 updates, score 1.704) (writing took 7.699247819000448 seconds)\n",
            "2022-12-24 22:24:49 | INFO | fairseq_cli.train | end of epoch 460 (average epoch stats below)\n",
            "2022-12-24 22:24:49 | INFO | train | epoch 460 | loss 1.534 | nll_loss 0.785 | total 35852.4 | n_correct 30874.5 | ppl 1.72 | accuracy 86.116 | wps 29296.9 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10112 | lr 2.98334e-05 | gnorm 1.418 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.4 | wall 14263\n",
            "2022-12-24 22:24:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 461:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:24:50 | INFO | fairseq.trainer | begin training epoch 461\n",
            "2022-12-24 22:24:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 461:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:25:07 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.01it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.70it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.19it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.09it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.71it/s]\u001b[A\n",
            "epoch 461 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:25:08 | INFO | dev_asr_nya | epoch 461 | valid on 'dev_asr_nya' subset | loss 1.694 | nll_loss 0.891 | total 3156.42 | n_correct 2607.16 | ppl 1.85 | accuracy 82.599 | wps 90998.8 | wpb 3156.4 | bsz 32.7 | num_updates 10134 | best_loss 1.684\n",
            "2022-12-24 22:25:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 461 @ 10134 updates\n",
            "2022-12-24 22:25:08 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint461.pt\n",
            "2022-12-24 22:25:11 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint461.pt\n",
            "2022-12-24 22:25:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint461.pt (epoch 461 @ 10134 updates, score 1.694) (writing took 7.87168555199969 seconds)\n",
            "2022-12-24 22:25:16 | INFO | fairseq_cli.train | end of epoch 461 (average epoch stats below)\n",
            "2022-12-24 22:25:16 | INFO | train | epoch 461 | loss 1.539 | nll_loss 0.791 | total 35852.4 | n_correct 30804.7 | ppl 1.73 | accuracy 85.921 | wps 30227.1 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10134 | lr 2.9801e-05 | gnorm 2.112 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 14289\n",
            "2022-12-24 22:25:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 462:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:25:16 | INFO | fairseq.trainer | begin training epoch 462\n",
            "2022-12-24 22:25:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 462:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 22:25:33 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.98it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.18it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.44it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.95it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.99it/s]\u001b[A\n",
            "epoch 462 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.09it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:25:34 | INFO | dev_asr_nya | epoch 462 | valid on 'dev_asr_nya' subset | loss 1.692 | nll_loss 0.89 | total 3156.42 | n_correct 2608.37 | ppl 1.85 | accuracy 82.637 | wps 89910.4 | wpb 3156.4 | bsz 32.7 | num_updates 10156 | best_loss 1.684\n",
            "2022-12-24 22:25:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 462 @ 10156 updates\n",
            "2022-12-24 22:25:34 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint462.pt\n",
            "2022-12-24 22:25:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint462.pt\n",
            "2022-12-24 22:25:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint462.pt (epoch 462 @ 10156 updates, score 1.692) (writing took 10.739928954000789 seconds)\n",
            "2022-12-24 22:25:45 | INFO | fairseq_cli.train | end of epoch 462 (average epoch stats below)\n",
            "2022-12-24 22:25:45 | INFO | train | epoch 462 | loss 1.535 | nll_loss 0.787 | total 35852.4 | n_correct 30857.9 | ppl 1.73 | accuracy 86.069 | wps 26793.2 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 10156 | lr 2.97687e-05 | gnorm 1.925 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 14319\n",
            "2022-12-24 22:25:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 463:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:25:45 | INFO | fairseq.trainer | begin training epoch 463\n",
            "2022-12-24 22:25:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 463:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 22:26:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.54it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.05it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.16it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.28it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 22.91it/s]\u001b[A\n",
            "epoch 463 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 25.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:26:04 | INFO | dev_asr_nya | epoch 463 | valid on 'dev_asr_nya' subset | loss 1.681 | nll_loss 0.875 | total 3156.42 | n_correct 2619.74 | ppl 1.83 | accuracy 82.997 | wps 84710.3 | wpb 3156.4 | bsz 32.7 | num_updates 10178 | best_loss 1.681\n",
            "2022-12-24 22:26:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 463 @ 10178 updates\n",
            "2022-12-24 22:26:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint463.pt\n",
            "2022-12-24 22:26:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint463.pt\n",
            "2022-12-24 22:26:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint463.pt (epoch 463 @ 10178 updates, score 1.681) (writing took 12.353667318999214 seconds)\n",
            "2022-12-24 22:26:16 | INFO | fairseq_cli.train | end of epoch 463 (average epoch stats below)\n",
            "2022-12-24 22:26:16 | INFO | train | epoch 463 | loss 1.536 | nll_loss 0.788 | total 35852.4 | n_correct 30838.2 | ppl 1.73 | accuracy 86.014 | wps 25414.3 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 10178 | lr 2.97365e-05 | gnorm 2.264 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 14350\n",
            "2022-12-24 22:26:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 464:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:26:16 | INFO | fairseq.trainer | begin training epoch 464\n",
            "2022-12-24 22:26:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 464:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 22:26:34 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.22it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.92it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.33it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.27it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.96it/s]\u001b[A\n",
            "epoch 464 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 26.28it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:26:34 | INFO | dev_asr_nya | epoch 464 | valid on 'dev_asr_nya' subset | loss 1.77 | nll_loss 0.987 | total 3156.42 | n_correct 2545.79 | ppl 1.98 | accuracy 80.654 | wps 89380 | wpb 3156.4 | bsz 32.7 | num_updates 10200 | best_loss 1.681\n",
            "2022-12-24 22:26:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 464 @ 10200 updates\n",
            "2022-12-24 22:26:34 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint464.pt\n",
            "2022-12-24 22:26:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint464.pt\n",
            "2022-12-24 22:26:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint464.pt (epoch 464 @ 10200 updates, score 1.77) (writing took 7.779664483998204 seconds)\n",
            "2022-12-24 22:26:42 | INFO | fairseq_cli.train | end of epoch 464 (average epoch stats below)\n",
            "2022-12-24 22:26:42 | INFO | train | epoch 464 | loss 1.539 | nll_loss 0.792 | total 35852.4 | n_correct 30809.7 | ppl 1.73 | accuracy 85.935 | wps 30131.9 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10200 | lr 2.97044e-05 | gnorm 2.549 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 14376\n",
            "2022-12-24 22:26:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 465:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:26:42 | INFO | fairseq.trainer | begin training epoch 465\n",
            "2022-12-24 22:26:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 465:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 22:27:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.70it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.07it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.13it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.01it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.15it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.01it/s]\u001b[A\n",
            "epoch 465 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.88it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:27:01 | INFO | dev_asr_nya | epoch 465 | valid on 'dev_asr_nya' subset | loss 1.702 | nll_loss 0.903 | total 3156.42 | n_correct 2598.42 | ppl 1.87 | accuracy 82.322 | wps 86819.7 | wpb 3156.4 | bsz 32.7 | num_updates 10222 | best_loss 1.681\n",
            "2022-12-24 22:27:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 465 @ 10222 updates\n",
            "2022-12-24 22:27:01 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint465.pt\n",
            "2022-12-24 22:27:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint465.pt\n",
            "2022-12-24 22:27:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint465.pt (epoch 465 @ 10222 updates, score 1.702) (writing took 10.251112603000365 seconds)\n",
            "2022-12-24 22:27:11 | INFO | fairseq_cli.train | end of epoch 465 (average epoch stats below)\n",
            "2022-12-24 22:27:11 | INFO | train | epoch 465 | loss 1.532 | nll_loss 0.783 | total 35852.4 | n_correct 30879.4 | ppl 1.72 | accuracy 86.129 | wps 26967.4 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 10222 | lr 2.96724e-05 | gnorm 1.581 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.6 | wall 14405\n",
            "2022-12-24 22:27:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 466:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:27:12 | INFO | fairseq.trainer | begin training epoch 466\n",
            "2022-12-24 22:27:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 466:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:27:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.17it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.64it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.43it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.43it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.22it/s]\u001b[A\n",
            "epoch 466 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.16it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:27:30 | INFO | dev_asr_nya | epoch 466 | valid on 'dev_asr_nya' subset | loss 1.68 | nll_loss 0.876 | total 3156.42 | n_correct 2621.79 | ppl 1.84 | accuracy 83.062 | wps 93727.4 | wpb 3156.4 | bsz 32.7 | num_updates 10244 | best_loss 1.68\n",
            "2022-12-24 22:27:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 466 @ 10244 updates\n",
            "2022-12-24 22:27:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint466.pt\n",
            "2022-12-24 22:27:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint466.pt\n",
            "2022-12-24 22:27:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint466.pt (epoch 466 @ 10244 updates, score 1.68) (writing took 14.820118958999956 seconds)\n",
            "2022-12-24 22:27:45 | INFO | fairseq_cli.train | end of epoch 466 (average epoch stats below)\n",
            "2022-12-24 22:27:45 | INFO | train | epoch 466 | loss 1.523 | nll_loss 0.773 | total 35852.4 | n_correct 30983.6 | ppl 1.71 | accuracy 86.42 | wps 23661.6 | ups 0.66 | wpb 35852.4 | bsz 368.4 | num_updates 10244 | lr 2.96406e-05 | gnorm 1.255 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 14438\n",
            "2022-12-24 22:27:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 467:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:27:45 | INFO | fairseq.trainer | begin training epoch 467\n",
            "2022-12-24 22:27:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 467:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:28:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.14it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.78it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.03it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.25it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.65it/s]\u001b[A\n",
            "epoch 467 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.29it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:28:03 | INFO | dev_asr_nya | epoch 467 | valid on 'dev_asr_nya' subset | loss 1.691 | nll_loss 0.889 | total 3156.42 | n_correct 2610.84 | ppl 1.85 | accuracy 82.715 | wps 89361.3 | wpb 3156.4 | bsz 32.7 | num_updates 10266 | best_loss 1.68\n",
            "2022-12-24 22:28:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 467 @ 10266 updates\n",
            "2022-12-24 22:28:03 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint467.pt\n",
            "2022-12-24 22:28:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint467.pt\n",
            "2022-12-24 22:28:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint467.pt (epoch 467 @ 10266 updates, score 1.691) (writing took 7.806596828999318 seconds)\n",
            "2022-12-24 22:28:11 | INFO | fairseq_cli.train | end of epoch 467 (average epoch stats below)\n",
            "2022-12-24 22:28:11 | INFO | train | epoch 467 | loss 1.519 | nll_loss 0.768 | total 35852.4 | n_correct 31012.6 | ppl 1.7 | accuracy 86.501 | wps 29892 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 10266 | lr 2.96088e-05 | gnorm 1.131 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 14465\n",
            "2022-12-24 22:28:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 468:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:28:11 | INFO | fairseq.trainer | begin training epoch 468\n",
            "2022-12-24 22:28:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 468:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 22:28:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.15it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.48it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.97it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.53it/s]\u001b[A\n",
            "epoch 468 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:28:30 | INFO | dev_asr_nya | epoch 468 | valid on 'dev_asr_nya' subset | loss 1.726 | nll_loss 0.932 | total 3156.42 | n_correct 2582.32 | ppl 1.91 | accuracy 81.812 | wps 88747 | wpb 3156.4 | bsz 32.7 | num_updates 10288 | best_loss 1.68\n",
            "2022-12-24 22:28:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 468 @ 10288 updates\n",
            "2022-12-24 22:28:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint468.pt\n",
            "2022-12-24 22:28:36 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint468.pt\n",
            "2022-12-24 22:28:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint468.pt (epoch 468 @ 10288 updates, score 1.726) (writing took 10.641411225999036 seconds)\n",
            "2022-12-24 22:28:41 | INFO | fairseq_cli.train | end of epoch 468 (average epoch stats below)\n",
            "2022-12-24 22:28:41 | INFO | train | epoch 468 | loss 1.516 | nll_loss 0.765 | total 35852.4 | n_correct 31030.3 | ppl 1.7 | accuracy 86.55 | wps 26755 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 10288 | lr 2.95771e-05 | gnorm 1.057 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.5 | wall 14494\n",
            "2022-12-24 22:28:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 469:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:28:41 | INFO | fairseq.trainer | begin training epoch 469\n",
            "2022-12-24 22:28:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 469:  95% 21/22 [00:17<00:00,  1.27it/s, loss=1.523, nll_loss=0.773, total=35792, n_correct=30915.2, ppl=1.71, accuracy=86.375, wps=26107.8, ups=0.73, wpb=35792, bsz=366.5, num_updates=10300, lr=2.95599e-05, gnorm=1.302, clip=0, loss_scale=4, train_wall=79, gb_free=29.5, wall=14504]2022-12-24 22:28:59 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.98it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.31it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.40it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.08it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.74it/s]\u001b[A\n",
            "epoch 469 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.60it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:28:59 | INFO | dev_asr_nya | epoch 469 | valid on 'dev_asr_nya' subset | loss 1.681 | nll_loss 0.877 | total 3156.42 | n_correct 2618.37 | ppl 1.84 | accuracy 82.954 | wps 89792 | wpb 3156.4 | bsz 32.7 | num_updates 10310 | best_loss 1.68\n",
            "2022-12-24 22:28:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 469 @ 10310 updates\n",
            "2022-12-24 22:28:59 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint469.pt\n",
            "2022-12-24 22:29:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint469.pt\n",
            "2022-12-24 22:29:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint469.pt (epoch 469 @ 10310 updates, score 1.681) (writing took 9.513744294999924 seconds)\n",
            "2022-12-24 22:29:09 | INFO | fairseq_cli.train | end of epoch 469 (average epoch stats below)\n",
            "2022-12-24 22:29:09 | INFO | train | epoch 469 | loss 1.518 | nll_loss 0.767 | total 35852.4 | n_correct 31007.5 | ppl 1.7 | accuracy 86.487 | wps 27928.2 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 10310 | lr 2.95455e-05 | gnorm 1.449 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14523\n",
            "2022-12-24 22:29:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 470:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:29:09 | INFO | fairseq.trainer | begin training epoch 470\n",
            "2022-12-24 22:29:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 470:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:29:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.66it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.24it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.40it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.53it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.49it/s]\u001b[A\n",
            "epoch 470 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.09it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:29:27 | INFO | dev_asr_nya | epoch 470 | valid on 'dev_asr_nya' subset | loss 1.733 | nll_loss 0.94 | total 3156.42 | n_correct 2576.16 | ppl 1.92 | accuracy 81.616 | wps 91509.4 | wpb 3156.4 | bsz 32.7 | num_updates 10332 | best_loss 1.68\n",
            "2022-12-24 22:29:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 470 @ 10332 updates\n",
            "2022-12-24 22:29:27 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint470.pt\n",
            "2022-12-24 22:29:31 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint470.pt\n",
            "2022-12-24 22:29:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint470.pt (epoch 470 @ 10332 updates, score 1.733) (writing took 7.683320662999904 seconds)\n",
            "2022-12-24 22:29:35 | INFO | fairseq_cli.train | end of epoch 470 (average epoch stats below)\n",
            "2022-12-24 22:29:35 | INFO | train | epoch 470 | loss 1.517 | nll_loss 0.766 | total 35852.4 | n_correct 31013.3 | ppl 1.7 | accuracy 86.503 | wps 30158.2 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10332 | lr 2.95141e-05 | gnorm 1.939 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14549\n",
            "2022-12-24 22:29:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 471:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:29:35 | INFO | fairseq.trainer | begin training epoch 471\n",
            "2022-12-24 22:29:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 471:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:29:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.85it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.48it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.82it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.41it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.68it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.10it/s]\u001b[A\n",
            "epoch 471 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 27.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:29:53 | INFO | dev_asr_nya | epoch 471 | valid on 'dev_asr_nya' subset | loss 1.693 | nll_loss 0.892 | total 3156.42 | n_correct 2609.79 | ppl 1.86 | accuracy 82.682 | wps 83681 | wpb 3156.4 | bsz 32.7 | num_updates 10354 | best_loss 1.68\n",
            "2022-12-24 22:29:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 471 @ 10354 updates\n",
            "2022-12-24 22:29:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint471.pt\n",
            "2022-12-24 22:29:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint471.pt\n",
            "2022-12-24 22:30:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint471.pt (epoch 471 @ 10354 updates, score 1.693) (writing took 8.967304701000103 seconds)\n",
            "2022-12-24 22:30:02 | INFO | fairseq_cli.train | end of epoch 471 (average epoch stats below)\n",
            "2022-12-24 22:30:02 | INFO | train | epoch 471 | loss 1.519 | nll_loss 0.768 | total 35852.4 | n_correct 30999.2 | ppl 1.7 | accuracy 86.463 | wps 28778.4 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 10354 | lr 2.94827e-05 | gnorm 2.228 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 14576\n",
            "2022-12-24 22:30:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 472:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:30:03 | INFO | fairseq.trainer | begin training epoch 472\n",
            "2022-12-24 22:30:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 472:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:30:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.01it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.10it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.57it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.94it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.89it/s]\u001b[A\n",
            "epoch 472 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.52it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:30:21 | INFO | dev_asr_nya | epoch 472 | valid on 'dev_asr_nya' subset | loss 1.679 | nll_loss 0.874 | total 3156.42 | n_correct 2618.21 | ppl 1.83 | accuracy 82.949 | wps 92243.9 | wpb 3156.4 | bsz 32.7 | num_updates 10376 | best_loss 1.679\n",
            "2022-12-24 22:30:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 472 @ 10376 updates\n",
            "2022-12-24 22:30:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint472.pt\n",
            "2022-12-24 22:30:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint472.pt\n",
            "2022-12-24 22:30:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint472.pt (epoch 472 @ 10376 updates, score 1.679) (writing took 14.369866629000171 seconds)\n",
            "2022-12-24 22:30:35 | INFO | fairseq_cli.train | end of epoch 472 (average epoch stats below)\n",
            "2022-12-24 22:30:35 | INFO | train | epoch 472 | loss 1.517 | nll_loss 0.766 | total 35852.4 | n_correct 31022.8 | ppl 1.7 | accuracy 86.529 | wps 24023.5 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 10376 | lr 2.94514e-05 | gnorm 1.854 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14609\n",
            "2022-12-24 22:30:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 473:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:30:35 | INFO | fairseq.trainer | begin training epoch 473\n",
            "2022-12-24 22:30:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 473:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:30:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.81it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 11.98it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.47it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.85it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.21it/s]\u001b[A\n",
            "epoch 473 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.25it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:30:54 | INFO | dev_asr_nya | epoch 473 | valid on 'dev_asr_nya' subset | loss 1.713 | nll_loss 0.917 | total 3156.42 | n_correct 2593.68 | ppl 1.89 | accuracy 82.172 | wps 84831.4 | wpb 3156.4 | bsz 32.7 | num_updates 10398 | best_loss 1.679\n",
            "2022-12-24 22:30:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 473 @ 10398 updates\n",
            "2022-12-24 22:30:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint473.pt\n",
            "2022-12-24 22:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint473.pt\n",
            "2022-12-24 22:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint473.pt (epoch 473 @ 10398 updates, score 1.713) (writing took 9.442279292998137 seconds)\n",
            "2022-12-24 22:31:03 | INFO | fairseq_cli.train | end of epoch 473 (average epoch stats below)\n",
            "2022-12-24 22:31:03 | INFO | train | epoch 473 | loss 1.509 | nll_loss 0.757 | total 35852.4 | n_correct 31095.9 | ppl 1.69 | accuracy 86.733 | wps 28221 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 10398 | lr 2.94202e-05 | gnorm 1.404 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 28.8 | wall 14637\n",
            "2022-12-24 22:31:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 474:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:31:03 | INFO | fairseq.trainer | begin training epoch 474\n",
            "2022-12-24 22:31:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 474:  95% 21/22 [00:17<00:00,  1.27it/s, loss=1.514, nll_loss=0.762, total=35911.7, n_correct=31102.7, ppl=1.7, accuracy=86.609, wps=26695.8, ups=0.74, wpb=35911.7, bsz=370.9, num_updates=10400, lr=2.94174e-05, gnorm=1.789, clip=0, loss_scale=4, train_wall=78, gb_free=31.4, wall=14639]2022-12-24 22:31:21 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.90it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.93it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.38it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.50it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.20it/s]\u001b[A\n",
            "epoch 474 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.72it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:31:22 | INFO | dev_asr_nya | epoch 474 | valid on 'dev_asr_nya' subset | loss 1.678 | nll_loss 0.874 | total 3156.42 | n_correct 2623.53 | ppl 1.83 | accuracy 83.117 | wps 93301.8 | wpb 3156.4 | bsz 32.7 | num_updates 10420 | best_loss 1.678\n",
            "2022-12-24 22:31:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 474 @ 10420 updates\n",
            "2022-12-24 22:31:22 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint474.pt\n",
            "2022-12-24 22:31:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint474.pt\n",
            "2022-12-24 22:31:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint474.pt (epoch 474 @ 10420 updates, score 1.678) (writing took 17.304747935002524 seconds)\n",
            "2022-12-24 22:31:40 | INFO | fairseq_cli.train | end of epoch 474 (average epoch stats below)\n",
            "2022-12-24 22:31:40 | INFO | train | epoch 474 | loss 1.513 | nll_loss 0.761 | total 35852.4 | n_correct 31076.2 | ppl 1.69 | accuracy 86.678 | wps 21729.7 | ups 0.61 | wpb 35852.4 | bsz 368.4 | num_updates 10420 | lr 2.93892e-05 | gnorm 1.907 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.3 | wall 14673\n",
            "2022-12-24 22:31:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 475:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:31:40 | INFO | fairseq.trainer | begin training epoch 475\n",
            "2022-12-24 22:31:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 475:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:31:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.20it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.57it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.31it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.82it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.13it/s]\u001b[A\n",
            "epoch 475 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.68it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:31:58 | INFO | dev_asr_nya | epoch 475 | valid on 'dev_asr_nya' subset | loss 1.676 | nll_loss 0.871 | total 3156.42 | n_correct 2625.74 | ppl 1.83 | accuracy 83.187 | wps 90546.5 | wpb 3156.4 | bsz 32.7 | num_updates 10442 | best_loss 1.676\n",
            "2022-12-24 22:31:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 475 @ 10442 updates\n",
            "2022-12-24 22:31:58 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint475.pt\n",
            "2022-12-24 22:32:01 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint475.pt\n",
            "2022-12-24 22:32:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint475.pt (epoch 475 @ 10442 updates, score 1.676) (writing took 12.214369566998357 seconds)\n",
            "2022-12-24 22:32:10 | INFO | fairseq_cli.train | end of epoch 475 (average epoch stats below)\n",
            "2022-12-24 22:32:10 | INFO | train | epoch 475 | loss 1.506 | nll_loss 0.754 | total 35852.4 | n_correct 31119.3 | ppl 1.69 | accuracy 86.798 | wps 25766.5 | ups 0.72 | wpb 35852.4 | bsz 368.4 | num_updates 10442 | lr 2.93582e-05 | gnorm 1.53 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32 | wall 14704\n",
            "2022-12-24 22:32:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 476:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:32:10 | INFO | fairseq.trainer | begin training epoch 476\n",
            "2022-12-24 22:32:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 476:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:32:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.38it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.40it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.81it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.29it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.11it/s]\u001b[A\n",
            "epoch 476 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.54it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:32:29 | INFO | dev_asr_nya | epoch 476 | valid on 'dev_asr_nya' subset | loss 1.686 | nll_loss 0.885 | total 3156.42 | n_correct 2614.47 | ppl 1.85 | accuracy 82.83 | wps 91124.6 | wpb 3156.4 | bsz 32.7 | num_updates 10464 | best_loss 1.676\n",
            "2022-12-24 22:32:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 476 @ 10464 updates\n",
            "2022-12-24 22:32:29 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint476.pt\n",
            "2022-12-24 22:32:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint476.pt\n",
            "2022-12-24 22:32:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint476.pt (epoch 476 @ 10464 updates, score 1.686) (writing took 7.4677426850030315 seconds)\n",
            "2022-12-24 22:32:36 | INFO | fairseq_cli.train | end of epoch 476 (average epoch stats below)\n",
            "2022-12-24 22:32:36 | INFO | train | epoch 476 | loss 1.513 | nll_loss 0.761 | total 35852.4 | n_correct 31049.1 | ppl 1.69 | accuracy 86.603 | wps 30464.4 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 10464 | lr 2.93273e-05 | gnorm 2.321 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 14730\n",
            "2022-12-24 22:32:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 477:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:32:36 | INFO | fairseq.trainer | begin training epoch 477\n",
            "2022-12-24 22:32:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 477:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 22:32:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.19it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.06it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.78it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.53it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.60it/s]\u001b[A\n",
            "epoch 477 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.12it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:32:55 | INFO | dev_asr_nya | epoch 477 | valid on 'dev_asr_nya' subset | loss 1.693 | nll_loss 0.895 | total 3156.42 | n_correct 2608.05 | ppl 1.86 | accuracy 82.627 | wps 90220.9 | wpb 3156.4 | bsz 32.7 | num_updates 10486 | best_loss 1.676\n",
            "2022-12-24 22:32:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 477 @ 10486 updates\n",
            "2022-12-24 22:32:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint477.pt\n",
            "2022-12-24 22:32:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint477.pt\n",
            "2022-12-24 22:33:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint477.pt (epoch 477 @ 10486 updates, score 1.693) (writing took 7.779356611998082 seconds)\n",
            "2022-12-24 22:33:03 | INFO | fairseq_cli.train | end of epoch 477 (average epoch stats below)\n",
            "2022-12-24 22:33:03 | INFO | train | epoch 477 | loss 1.508 | nll_loss 0.755 | total 35852.4 | n_correct 31107 | ppl 1.69 | accuracy 86.764 | wps 29368.4 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10486 | lr 2.92965e-05 | gnorm 1.493 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.6 | wall 14757\n",
            "2022-12-24 22:33:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 478:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:33:03 | INFO | fairseq.trainer | begin training epoch 478\n",
            "2022-12-24 22:33:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 478:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.509, nll_loss=0.756, total=35893.9, n_correct=31133.7, ppl=1.69, accuracy=86.738, wps=27794.2, ups=0.77, wpb=35893.9, bsz=369.2, num_updates=10500, lr=2.9277e-05, gnorm=1.736, clip=0, loss_scale=4, train_wall=79, gb_free=31.8, wall=14768]2022-12-24 22:33:21 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.56it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.55it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.57it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 19.45it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 23.98it/s]\u001b[A\n",
            "epoch 478 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 25.41it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:33:22 | INFO | dev_asr_nya | epoch 478 | valid on 'dev_asr_nya' subset | loss 1.682 | nll_loss 0.881 | total 3156.42 | n_correct 2616.95 | ppl 1.84 | accuracy 82.909 | wps 82403 | wpb 3156.4 | bsz 32.7 | num_updates 10508 | best_loss 1.676\n",
            "2022-12-24 22:33:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 478 @ 10508 updates\n",
            "2022-12-24 22:33:22 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint478.pt\n",
            "2022-12-24 22:33:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint478.pt\n",
            "2022-12-24 22:33:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint478.pt (epoch 478 @ 10508 updates, score 1.682) (writing took 8.809486089998245 seconds)\n",
            "2022-12-24 22:33:30 | INFO | fairseq_cli.train | end of epoch 478 (average epoch stats below)\n",
            "2022-12-24 22:33:30 | INFO | train | epoch 478 | loss 1.498 | nll_loss 0.743 | total 35852.4 | n_correct 31192.5 | ppl 1.67 | accuracy 87.003 | wps 28693.2 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 10508 | lr 2.92659e-05 | gnorm 1.206 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 14784\n",
            "2022-12-24 22:33:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 479:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:33:30 | INFO | fairseq.trainer | begin training epoch 479\n",
            "2022-12-24 22:33:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 479:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 22:33:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.85it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.76it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.53it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.10it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.42it/s]\u001b[A\n",
            "epoch 479 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.02it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:33:49 | INFO | dev_asr_nya | epoch 479 | valid on 'dev_asr_nya' subset | loss 1.69 | nll_loss 0.892 | total 3156.42 | n_correct 2609.37 | ppl 1.86 | accuracy 82.669 | wps 90317.6 | wpb 3156.4 | bsz 32.7 | num_updates 10530 | best_loss 1.676\n",
            "2022-12-24 22:33:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 479 @ 10530 updates\n",
            "2022-12-24 22:33:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint479.pt\n",
            "2022-12-24 22:33:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint479.pt\n",
            "2022-12-24 22:33:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint479.pt (epoch 479 @ 10530 updates, score 1.69) (writing took 8.153707321002003 seconds)\n",
            "2022-12-24 22:33:57 | INFO | fairseq_cli.train | end of epoch 479 (average epoch stats below)\n",
            "2022-12-24 22:33:57 | INFO | train | epoch 479 | loss 1.495 | nll_loss 0.74 | total 35852.4 | n_correct 31235 | ppl 1.67 | accuracy 87.121 | wps 29523.7 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10530 | lr 2.92353e-05 | gnorm 1.064 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 14811\n",
            "2022-12-24 22:33:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 480:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:33:57 | INFO | fairseq.trainer | begin training epoch 480\n",
            "2022-12-24 22:33:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 480:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:34:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.48it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.43it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.26it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.55it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.62it/s]\u001b[A\n",
            "epoch 480 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.15it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:34:15 | INFO | dev_asr_nya | epoch 480 | valid on 'dev_asr_nya' subset | loss 1.683 | nll_loss 0.88 | total 3156.42 | n_correct 2617.47 | ppl 1.84 | accuracy 82.925 | wps 87414.2 | wpb 3156.4 | bsz 32.7 | num_updates 10552 | best_loss 1.676\n",
            "2022-12-24 22:34:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 480 @ 10552 updates\n",
            "2022-12-24 22:34:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint480.pt\n",
            "2022-12-24 22:34:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint480.pt\n",
            "2022-12-24 22:34:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint480.pt (epoch 480 @ 10552 updates, score 1.683) (writing took 8.248911456001224 seconds)\n",
            "2022-12-24 22:34:24 | INFO | fairseq_cli.train | end of epoch 480 (average epoch stats below)\n",
            "2022-12-24 22:34:24 | INFO | train | epoch 480 | loss 1.496 | nll_loss 0.742 | total 35852.4 | n_correct 31227.4 | ppl 1.67 | accuracy 87.1 | wps 29680.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 10552 | lr 2.92048e-05 | gnorm 1.192 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 14837\n",
            "2022-12-24 22:34:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 481:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:34:24 | INFO | fairseq.trainer | begin training epoch 481\n",
            "2022-12-24 22:34:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 481:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:34:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.62it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.32it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.16it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.08it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.06it/s]\u001b[A\n",
            "epoch 481 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.21it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:34:42 | INFO | dev_asr_nya | epoch 481 | valid on 'dev_asr_nya' subset | loss 1.669 | nll_loss 0.862 | total 3156.42 | n_correct 2628.58 | ppl 1.82 | accuracy 83.277 | wps 90181.8 | wpb 3156.4 | bsz 32.7 | num_updates 10574 | best_loss 1.669\n",
            "2022-12-24 22:34:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 481 @ 10574 updates\n",
            "2022-12-24 22:34:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint481.pt\n",
            "2022-12-24 22:34:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint481.pt\n",
            "2022-12-24 22:34:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint481.pt (epoch 481 @ 10574 updates, score 1.669) (writing took 14.350418860998616 seconds)\n",
            "2022-12-24 22:34:57 | INFO | fairseq_cli.train | end of epoch 481 (average epoch stats below)\n",
            "2022-12-24 22:34:57 | INFO | train | epoch 481 | loss 1.494 | nll_loss 0.739 | total 35852.4 | n_correct 31253.5 | ppl 1.67 | accuracy 87.173 | wps 24021.2 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 10574 | lr 2.91744e-05 | gnorm 1.144 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.7 | wall 14870\n",
            "2022-12-24 22:34:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 482:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:34:57 | INFO | fairseq.trainer | begin training epoch 482\n",
            "2022-12-24 22:34:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 482:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:35:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.72it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.77it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.29it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.65it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.58it/s]\u001b[A\n",
            "epoch 482 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.19it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:35:15 | INFO | dev_asr_nya | epoch 482 | valid on 'dev_asr_nya' subset | loss 1.679 | nll_loss 0.877 | total 3156.42 | n_correct 2620.05 | ppl 1.84 | accuracy 83.007 | wps 89646.5 | wpb 3156.4 | bsz 32.7 | num_updates 10596 | best_loss 1.669\n",
            "2022-12-24 22:35:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 482 @ 10596 updates\n",
            "2022-12-24 22:35:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint482.pt\n",
            "2022-12-24 22:35:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint482.pt\n",
            "2022-12-24 22:35:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint482.pt (epoch 482 @ 10596 updates, score 1.679) (writing took 9.824487841000519 seconds)\n",
            "2022-12-24 22:35:25 | INFO | fairseq_cli.train | end of epoch 482 (average epoch stats below)\n",
            "2022-12-24 22:35:25 | INFO | train | epoch 482 | loss 1.496 | nll_loss 0.742 | total 35852.4 | n_correct 31227.3 | ppl 1.67 | accuracy 87.1 | wps 27987.6 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 10596 | lr 2.91441e-05 | gnorm 1.968 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.8 | wall 14898\n",
            "2022-12-24 22:35:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 483:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:35:25 | INFO | fairseq.trainer | begin training epoch 483\n",
            "2022-12-24 22:35:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 483:  95% 21/22 [00:17<00:00,  1.27it/s, loss=1.496, nll_loss=0.741, total=35857.7, n_correct=31232.2, ppl=1.67, accuracy=87.1, wps=26747.9, ups=0.75, wpb=35857.7, bsz=368.1, num_updates=10600, lr=2.91386e-05, gnorm=1.371, clip=0, loss_scale=8, train_wall=78, gb_free=29.5, wall=14902]2022-12-24 22:35:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.88it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.49it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.42it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.93it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.42it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.35it/s]\u001b[A\n",
            "epoch 483 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.00it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:35:44 | INFO | dev_asr_nya | epoch 483 | valid on 'dev_asr_nya' subset | loss 1.672 | nll_loss 0.869 | total 3156.42 | n_correct 2628.47 | ppl 1.83 | accuracy 83.274 | wps 82302 | wpb 3156.4 | bsz 32.7 | num_updates 10618 | best_loss 1.669\n",
            "2022-12-24 22:35:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 483 @ 10618 updates\n",
            "2022-12-24 22:35:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint483.pt\n",
            "2022-12-24 22:35:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint483.pt\n",
            "2022-12-24 22:35:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint483.pt (epoch 483 @ 10618 updates, score 1.672) (writing took 9.921250919000158 seconds)\n",
            "2022-12-24 22:35:54 | INFO | fairseq_cli.train | end of epoch 483 (average epoch stats below)\n",
            "2022-12-24 22:35:54 | INFO | train | epoch 483 | loss 1.493 | nll_loss 0.738 | total 35852.4 | n_correct 31253.1 | ppl 1.67 | accuracy 87.172 | wps 27222.1 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 10618 | lr 2.91139e-05 | gnorm 1.531 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 31.7 | wall 14927\n",
            "2022-12-24 22:35:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 484:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:35:54 | INFO | fairseq.trainer | begin training epoch 484\n",
            "2022-12-24 22:35:54 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 484:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 22:36:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.03it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.85it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.47it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.92it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.90it/s]\u001b[A\n",
            "epoch 484 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.79it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:36:12 | INFO | dev_asr_nya | epoch 484 | valid on 'dev_asr_nya' subset | loss 1.676 | nll_loss 0.875 | total 3156.42 | n_correct 2624.05 | ppl 1.83 | accuracy 83.134 | wps 88519.8 | wpb 3156.4 | bsz 32.7 | num_updates 10640 | best_loss 1.669\n",
            "2022-12-24 22:36:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 484 @ 10640 updates\n",
            "2022-12-24 22:36:12 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint484.pt\n",
            "2022-12-24 22:36:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint484.pt\n",
            "2022-12-24 22:36:22 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint484.pt (epoch 484 @ 10640 updates, score 1.676) (writing took 9.88920304199928 seconds)\n",
            "2022-12-24 22:36:22 | INFO | fairseq_cli.train | end of epoch 484 (average epoch stats below)\n",
            "2022-12-24 22:36:22 | INFO | train | epoch 484 | loss 1.491 | nll_loss 0.735 | total 35852.4 | n_correct 31285.7 | ppl 1.66 | accuracy 87.263 | wps 27621.4 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 10640 | lr 2.90838e-05 | gnorm 1.744 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 14956\n",
            "2022-12-24 22:36:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 485:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:36:22 | INFO | fairseq.trainer | begin training epoch 485\n",
            "2022-12-24 22:36:22 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 485:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:36:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.52it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.80it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.74it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.97it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.36it/s]\u001b[A\n",
            "epoch 485 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 26.17it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:36:41 | INFO | dev_asr_nya | epoch 485 | valid on 'dev_asr_nya' subset | loss 1.672 | nll_loss 0.87 | total 3156.42 | n_correct 2628.79 | ppl 1.83 | accuracy 83.284 | wps 85897 | wpb 3156.4 | bsz 32.7 | num_updates 10662 | best_loss 1.669\n",
            "2022-12-24 22:36:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 485 @ 10662 updates\n",
            "2022-12-24 22:36:41 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint485.pt\n",
            "2022-12-24 22:36:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint485.pt\n",
            "2022-12-24 22:36:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint485.pt (epoch 485 @ 10662 updates, score 1.672) (writing took 10.286851328000921 seconds)\n",
            "2022-12-24 22:36:51 | INFO | fairseq_cli.train | end of epoch 485 (average epoch stats below)\n",
            "2022-12-24 22:36:51 | INFO | train | epoch 485 | loss 1.486 | nll_loss 0.73 | total 35852.4 | n_correct 31313.5 | ppl 1.66 | accuracy 87.34 | wps 27558.4 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 10662 | lr 2.90537e-05 | gnorm 1.081 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 14985\n",
            "2022-12-24 22:36:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 486:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:36:51 | INFO | fairseq.trainer | begin training epoch 486\n",
            "2022-12-24 22:36:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 486:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:37:09 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.30it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.79it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.47it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.72it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 25.17it/s]\u001b[A\n",
            "epoch 486 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.76it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:37:09 | INFO | dev_asr_nya | epoch 486 | valid on 'dev_asr_nya' subset | loss 1.688 | nll_loss 0.888 | total 3156.42 | n_correct 2613.79 | ppl 1.85 | accuracy 82.809 | wps 89421 | wpb 3156.4 | bsz 32.7 | num_updates 10684 | best_loss 1.669\n",
            "2022-12-24 22:37:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 486 @ 10684 updates\n",
            "2022-12-24 22:37:09 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint486.pt\n",
            "2022-12-24 22:37:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint486.pt\n",
            "2022-12-24 22:37:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint486.pt (epoch 486 @ 10684 updates, score 1.688) (writing took 7.8130451340002764 seconds)\n",
            "2022-12-24 22:37:17 | INFO | fairseq_cli.train | end of epoch 486 (average epoch stats below)\n",
            "2022-12-24 22:37:17 | INFO | train | epoch 486 | loss 1.487 | nll_loss 0.731 | total 35852.4 | n_correct 31304.1 | ppl 1.66 | accuracy 87.314 | wps 29919.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 10684 | lr 2.90238e-05 | gnorm 1.582 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.6 | wall 15011\n",
            "2022-12-24 22:37:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 487:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:37:17 | INFO | fairseq.trainer | begin training epoch 487\n",
            "2022-12-24 22:37:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 487:  95% 21/22 [00:17<00:00,  1.26it/s, loss=1.489, nll_loss=0.733, total=35851.3, n_correct=31290.2, ppl=1.66, accuracy=87.278, wps=29400.1, ups=0.82, wpb=35851.3, bsz=367.9, num_updates=10700, lr=2.90021e-05, gnorm=1.527, clip=0, loss_scale=8, train_wall=79, gb_free=30.6, wall=15024]2022-12-24 22:37:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.68it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.83it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.89it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.71it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.59it/s]\u001b[A\n",
            "epoch 487 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.96it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:37:36 | INFO | dev_asr_nya | epoch 487 | valid on 'dev_asr_nya' subset | loss 1.676 | nll_loss 0.872 | total 3156.42 | n_correct 2623.89 | ppl 1.83 | accuracy 83.129 | wps 86780.3 | wpb 3156.4 | bsz 32.7 | num_updates 10706 | best_loss 1.669\n",
            "2022-12-24 22:37:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 487 @ 10706 updates\n",
            "2022-12-24 22:37:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint487.pt\n",
            "2022-12-24 22:37:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint487.pt\n",
            "2022-12-24 22:37:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint487.pt (epoch 487 @ 10706 updates, score 1.676) (writing took 8.387302728999202 seconds)\n",
            "2022-12-24 22:37:44 | INFO | fairseq_cli.train | end of epoch 487 (average epoch stats below)\n",
            "2022-12-24 22:37:44 | INFO | train | epoch 487 | loss 1.49 | nll_loss 0.735 | total 35852.4 | n_correct 31268.6 | ppl 1.66 | accuracy 87.215 | wps 29244.2 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10706 | lr 2.8994e-05 | gnorm 2.158 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.7 | wall 15038\n",
            "2022-12-24 22:37:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 488:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:37:44 | INFO | fairseq.trainer | begin training epoch 488\n",
            "2022-12-24 22:37:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 488:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:38:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.94it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.10it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.06it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.90it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
            "epoch 488 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.44it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:38:03 | INFO | dev_asr_nya | epoch 488 | valid on 'dev_asr_nya' subset | loss 1.709 | nll_loss 0.913 | total 3156.42 | n_correct 2597.68 | ppl 1.88 | accuracy 82.298 | wps 91490.3 | wpb 3156.4 | bsz 32.7 | num_updates 10728 | best_loss 1.669\n",
            "2022-12-24 22:38:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 488 @ 10728 updates\n",
            "2022-12-24 22:38:03 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint488.pt\n",
            "2022-12-24 22:38:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint488.pt\n",
            "2022-12-24 22:38:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint488.pt (epoch 488 @ 10728 updates, score 1.709) (writing took 7.591979857999831 seconds)\n",
            "2022-12-24 22:38:10 | INFO | fairseq_cli.train | end of epoch 488 (average epoch stats below)\n",
            "2022-12-24 22:38:10 | INFO | train | epoch 488 | loss 1.482 | nll_loss 0.726 | total 35852.4 | n_correct 31338.7 | ppl 1.65 | accuracy 87.41 | wps 30382.5 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 10728 | lr 2.89642e-05 | gnorm 1.092 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.6 | wall 15064\n",
            "2022-12-24 22:38:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 489:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:38:10 | INFO | fairseq.trainer | begin training epoch 489\n",
            "2022-12-24 22:38:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 489:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:38:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.51it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.20it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.10it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.05it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.73it/s]\u001b[A\n",
            "epoch 489 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.85it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:38:28 | INFO | dev_asr_nya | epoch 489 | valid on 'dev_asr_nya' subset | loss 1.677 | nll_loss 0.876 | total 3156.42 | n_correct 2624.32 | ppl 1.84 | accuracy 83.142 | wps 91135.2 | wpb 3156.4 | bsz 32.7 | num_updates 10750 | best_loss 1.669\n",
            "2022-12-24 22:38:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 489 @ 10750 updates\n",
            "2022-12-24 22:38:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint489.pt\n",
            "2022-12-24 22:38:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint489.pt\n",
            "2022-12-24 22:38:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint489.pt (epoch 489 @ 10750 updates, score 1.677) (writing took 7.871821620999981 seconds)\n",
            "2022-12-24 22:38:36 | INFO | fairseq_cli.train | end of epoch 489 (average epoch stats below)\n",
            "2022-12-24 22:38:36 | INFO | train | epoch 489 | loss 1.489 | nll_loss 0.734 | total 35852.4 | n_correct 31283 | ppl 1.66 | accuracy 87.255 | wps 30095 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10750 | lr 2.89346e-05 | gnorm 2.072 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 15090\n",
            "2022-12-24 22:38:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 490:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:38:36 | INFO | fairseq.trainer | begin training epoch 490\n",
            "2022-12-24 22:38:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 490:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:38:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.58it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.74it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.31it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.03it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.89it/s]\u001b[A\n",
            "epoch 490 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:38:55 | INFO | dev_asr_nya | epoch 490 | valid on 'dev_asr_nya' subset | loss 1.661 | nll_loss 0.858 | total 3156.42 | n_correct 2636.89 | ppl 1.81 | accuracy 83.541 | wps 91877.4 | wpb 3156.4 | bsz 32.7 | num_updates 10772 | best_loss 1.661\n",
            "2022-12-24 22:38:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 490 @ 10772 updates\n",
            "2022-12-24 22:38:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint490.pt\n",
            "2022-12-24 22:38:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint490.pt\n",
            "2022-12-24 22:39:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint490.pt (epoch 490 @ 10772 updates, score 1.661) (writing took 12.900976398999774 seconds)\n",
            "2022-12-24 22:39:08 | INFO | fairseq_cli.train | end of epoch 490 (average epoch stats below)\n",
            "2022-12-24 22:39:08 | INFO | train | epoch 490 | loss 1.482 | nll_loss 0.726 | total 35852.4 | n_correct 31347.5 | ppl 1.65 | accuracy 87.435 | wps 25037.5 | ups 0.7 | wpb 35852.4 | bsz 368.4 | num_updates 10772 | lr 2.8905e-05 | gnorm 1.477 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 15122\n",
            "2022-12-24 22:39:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 491:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:39:08 | INFO | fairseq.trainer | begin training epoch 491\n",
            "2022-12-24 22:39:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 491:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:39:25 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.96it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 15.01it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.50it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 17.62it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.40it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.31it/s]\u001b[A\n",
            "epoch 491 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.14it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:39:26 | INFO | dev_asr_nya | epoch 491 | valid on 'dev_asr_nya' subset | loss 1.66 | nll_loss 0.857 | total 3156.42 | n_correct 2637.42 | ppl 1.81 | accuracy 83.557 | wps 85923.7 | wpb 3156.4 | bsz 32.7 | num_updates 10794 | best_loss 1.66\n",
            "2022-12-24 22:39:26 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 491 @ 10794 updates\n",
            "2022-12-24 22:39:26 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint491.pt\n",
            "2022-12-24 22:39:30 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint491.pt\n",
            "2022-12-24 22:39:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint491.pt (epoch 491 @ 10794 updates, score 1.66) (writing took 15.725269058999402 seconds)\n",
            "2022-12-24 22:39:42 | INFO | fairseq_cli.train | end of epoch 491 (average epoch stats below)\n",
            "2022-12-24 22:39:42 | INFO | train | epoch 491 | loss 1.483 | nll_loss 0.727 | total 35852.4 | n_correct 31336 | ppl 1.65 | accuracy 87.403 | wps 23081.8 | ups 0.64 | wpb 35852.4 | bsz 368.4 | num_updates 10794 | lr 2.88755e-05 | gnorm 1.791 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 15156\n",
            "2022-12-24 22:39:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 492:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:39:42 | INFO | fairseq.trainer | begin training epoch 492\n",
            "2022-12-24 22:39:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 492:  95% 21/22 [00:17<00:00,  1.28it/s, loss=1.484, nll_loss=0.728, total=35856.6, n_correct=31327.9, ppl=1.66, accuracy=87.37, wps=26200.3, ups=0.73, wpb=35856.6, bsz=368.6, num_updates=10800, lr=2.88675e-05, gnorm=1.654, clip=0, loss_scale=8, train_wall=78, gb_free=31.7, wall=15161]2022-12-24 22:40:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.58it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.38it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.78it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.16it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.02it/s]\u001b[A\n",
            "epoch 492 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.61it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:40:01 | INFO | dev_asr_nya | epoch 492 | valid on 'dev_asr_nya' subset | loss 1.683 | nll_loss 0.884 | total 3156.42 | n_correct 2620.32 | ppl 1.85 | accuracy 83.015 | wps 93604.5 | wpb 3156.4 | bsz 32.7 | num_updates 10816 | best_loss 1.66\n",
            "2022-12-24 22:40:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 492 @ 10816 updates\n",
            "2022-12-24 22:40:01 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint492.pt\n",
            "2022-12-24 22:40:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint492.pt\n",
            "2022-12-24 22:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint492.pt (epoch 492 @ 10816 updates, score 1.683) (writing took 7.644479454000248 seconds)\n",
            "2022-12-24 22:40:08 | INFO | fairseq_cli.train | end of epoch 492 (average epoch stats below)\n",
            "2022-12-24 22:40:08 | INFO | train | epoch 492 | loss 1.476 | nll_loss 0.718 | total 35852.4 | n_correct 31394 | ppl 1.65 | accuracy 87.565 | wps 30083.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10816 | lr 2.88462e-05 | gnorm 1.159 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.5 | wall 15182\n",
            "2022-12-24 22:40:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 493:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:40:08 | INFO | fairseq.trainer | begin training epoch 493\n",
            "2022-12-24 22:40:08 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 493:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 22:40:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.93it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.75it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.55it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.67it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.26it/s]\u001b[A\n",
            "epoch 493 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.01it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:40:27 | INFO | dev_asr_nya | epoch 493 | valid on 'dev_asr_nya' subset | loss 1.664 | nll_loss 0.862 | total 3156.42 | n_correct 2629.37 | ppl 1.82 | accuracy 83.302 | wps 86034.4 | wpb 3156.4 | bsz 32.7 | num_updates 10838 | best_loss 1.66\n",
            "2022-12-24 22:40:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 493 @ 10838 updates\n",
            "2022-12-24 22:40:27 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint493.pt\n",
            "2022-12-24 22:40:31 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint493.pt\n",
            "2022-12-24 22:40:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint493.pt (epoch 493 @ 10838 updates, score 1.664) (writing took 8.258678194000822 seconds)\n",
            "2022-12-24 22:40:36 | INFO | fairseq_cli.train | end of epoch 493 (average epoch stats below)\n",
            "2022-12-24 22:40:36 | INFO | train | epoch 493 | loss 1.482 | nll_loss 0.726 | total 35852.4 | n_correct 31341.4 | ppl 1.65 | accuracy 87.418 | wps 28795.2 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 10838 | lr 2.88169e-05 | gnorm 2.249 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 31.3 | wall 15209\n",
            "2022-12-24 22:40:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 494:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:40:36 | INFO | fairseq.trainer | begin training epoch 494\n",
            "2022-12-24 22:40:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 494:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:40:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.09it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.19it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.00it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.72it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.77it/s]\u001b[A\n",
            "epoch 494 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.32it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:40:54 | INFO | dev_asr_nya | epoch 494 | valid on 'dev_asr_nya' subset | loss 1.66 | nll_loss 0.859 | total 3156.42 | n_correct 2635.79 | ppl 1.81 | accuracy 83.506 | wps 89301.6 | wpb 3156.4 | bsz 32.7 | num_updates 10860 | best_loss 1.66\n",
            "2022-12-24 22:40:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 494 @ 10860 updates\n",
            "2022-12-24 22:40:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint494.pt\n",
            "2022-12-24 22:40:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint494.pt\n",
            "2022-12-24 22:41:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint494.pt (epoch 494 @ 10860 updates, score 1.66) (writing took 12.031708997998066 seconds)\n",
            "2022-12-24 22:41:06 | INFO | fairseq_cli.train | end of epoch 494 (average epoch stats below)\n",
            "2022-12-24 22:41:06 | INFO | train | epoch 494 | loss 1.484 | nll_loss 0.728 | total 35852.4 | n_correct 31325.2 | ppl 1.66 | accuracy 87.373 | wps 25728.5 | ups 0.72 | wpb 35852.4 | bsz 368.4 | num_updates 10860 | lr 2.87877e-05 | gnorm 2.43 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.9 | wall 15240\n",
            "2022-12-24 22:41:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 495:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:41:06 | INFO | fairseq.trainer | begin training epoch 495\n",
            "2022-12-24 22:41:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 495:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 22:41:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.37it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.66it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.37it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.11it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.08it/s]\u001b[A\n",
            "epoch 495 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:41:25 | INFO | dev_asr_nya | epoch 495 | valid on 'dev_asr_nya' subset | loss 1.662 | nll_loss 0.859 | total 3156.42 | n_correct 2636.74 | ppl 1.81 | accuracy 83.536 | wps 92390.2 | wpb 3156.4 | bsz 32.7 | num_updates 10882 | best_loss 1.66\n",
            "2022-12-24 22:41:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 495 @ 10882 updates\n",
            "2022-12-24 22:41:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint495.pt\n",
            "2022-12-24 22:41:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint495.pt\n",
            "2022-12-24 22:41:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint495.pt (epoch 495 @ 10882 updates, score 1.662) (writing took 7.722840982998605 seconds)\n",
            "2022-12-24 22:41:33 | INFO | fairseq_cli.train | end of epoch 495 (average epoch stats below)\n",
            "2022-12-24 22:41:33 | INFO | train | epoch 495 | loss 1.474 | nll_loss 0.717 | total 35852.4 | n_correct 31419.1 | ppl 1.64 | accuracy 87.635 | wps 29938.5 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10882 | lr 2.87585e-05 | gnorm 1.604 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.5 | wall 15266\n",
            "2022-12-24 22:41:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 496:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:41:33 | INFO | fairseq.trainer | begin training epoch 496\n",
            "2022-12-24 22:41:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 496:  95% 21/22 [00:17<00:00,  1.28it/s, loss=1.478, nll_loss=0.721, total=35872.2, n_correct=31398.6, ppl=1.65, accuracy=87.529, wps=29790.3, ups=0.83, wpb=35872.2, bsz=368.4, num_updates=10900, lr=2.87348e-05, gnorm=1.891, clip=0, loss_scale=8, train_wall=80, gb_free=31.4, wall=15281]2022-12-24 22:41:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.48it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.78it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.18it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.71it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 21.33it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 23.19it/s]\u001b[A\n",
            "epoch 496 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 24.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:41:52 | INFO | dev_asr_nya | epoch 496 | valid on 'dev_asr_nya' subset | loss 1.653 | nll_loss 0.849 | total 3156.42 | n_correct 2640.95 | ppl 1.8 | accuracy 83.669 | wps 76672.6 | wpb 3156.4 | bsz 32.7 | num_updates 10904 | best_loss 1.653\n",
            "2022-12-24 22:41:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 496 @ 10904 updates\n",
            "2022-12-24 22:41:52 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint496.pt\n",
            "2022-12-24 22:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint496.pt\n",
            "2022-12-24 22:42:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint496.pt (epoch 496 @ 10904 updates, score 1.653) (writing took 14.738146783998673 seconds)\n",
            "2022-12-24 22:42:06 | INFO | fairseq_cli.train | end of epoch 496 (average epoch stats below)\n",
            "2022-12-24 22:42:06 | INFO | train | epoch 496 | loss 1.474 | nll_loss 0.716 | total 35852.4 | n_correct 31415.4 | ppl 1.64 | accuracy 87.624 | wps 23442.8 | ups 0.65 | wpb 35852.4 | bsz 368.4 | num_updates 10904 | lr 2.87295e-05 | gnorm 1.807 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.7 | wall 15300\n",
            "2022-12-24 22:42:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 497:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:42:06 | INFO | fairseq.trainer | begin training epoch 497\n",
            "2022-12-24 22:42:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 497:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 22:42:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.30it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.79it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.18it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.73it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.59it/s]\u001b[A\n",
            "epoch 497 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.94it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:42:25 | INFO | dev_asr_nya | epoch 497 | valid on 'dev_asr_nya' subset | loss 1.686 | nll_loss 0.888 | total 3156.42 | n_correct 2614.21 | ppl 1.85 | accuracy 82.822 | wps 95155.3 | wpb 3156.4 | bsz 32.7 | num_updates 10926 | best_loss 1.653\n",
            "2022-12-24 22:42:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 497 @ 10926 updates\n",
            "2022-12-24 22:42:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint497.pt\n",
            "2022-12-24 22:42:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint497.pt\n",
            "2022-12-24 22:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint497.pt (epoch 497 @ 10926 updates, score 1.686) (writing took 8.189836688998184 seconds)\n",
            "2022-12-24 22:42:33 | INFO | fairseq_cli.train | end of epoch 497 (average epoch stats below)\n",
            "2022-12-24 22:42:33 | INFO | train | epoch 497 | loss 1.484 | nll_loss 0.728 | total 35852.4 | n_correct 31307.9 | ppl 1.66 | accuracy 87.324 | wps 29282.8 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 10926 | lr 2.87006e-05 | gnorm 2.842 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 15327\n",
            "2022-12-24 22:42:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 498:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:42:33 | INFO | fairseq.trainer | begin training epoch 498\n",
            "2022-12-24 22:42:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 498:  95% 21/22 [00:17<00:00,  1.22it/s]2022-12-24 22:42:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.58it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.44it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.52it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.65it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.63it/s]\u001b[A\n",
            "epoch 498 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.10it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:42:52 | INFO | dev_asr_nya | epoch 498 | valid on 'dev_asr_nya' subset | loss 1.66 | nll_loss 0.858 | total 3156.42 | n_correct 2636.11 | ppl 1.81 | accuracy 83.516 | wps 91979.5 | wpb 3156.4 | bsz 32.7 | num_updates 10948 | best_loss 1.653\n",
            "2022-12-24 22:42:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 498 @ 10948 updates\n",
            "2022-12-24 22:42:52 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint498.pt\n",
            "2022-12-24 22:42:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint498.pt\n",
            "2022-12-24 22:43:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint498.pt (epoch 498 @ 10948 updates, score 1.66) (writing took 9.91625454899986 seconds)\n",
            "2022-12-24 22:43:02 | INFO | fairseq_cli.train | end of epoch 498 (average epoch stats below)\n",
            "2022-12-24 22:43:02 | INFO | train | epoch 498 | loss 1.472 | nll_loss 0.716 | total 35852.4 | n_correct 31417.1 | ppl 1.64 | accuracy 87.629 | wps 27260.9 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 10948 | lr 2.86717e-05 | gnorm 1.742 | clip 0 | loss_scale 8 | train_wall 18 | gb_free 30.7 | wall 15356\n",
            "2022-12-24 22:43:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 499:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:43:02 | INFO | fairseq.trainer | begin training epoch 499\n",
            "2022-12-24 22:43:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 499:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:43:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.67it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.17it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.23it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.63it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.80it/s]\u001b[A\n",
            "epoch 499 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 25.96it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:43:21 | INFO | dev_asr_nya | epoch 499 | valid on 'dev_asr_nya' subset | loss 1.683 | nll_loss 0.885 | total 3156.42 | n_correct 2619.68 | ppl 1.85 | accuracy 82.995 | wps 86467.3 | wpb 3156.4 | bsz 32.7 | num_updates 10970 | best_loss 1.653\n",
            "2022-12-24 22:43:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 499 @ 10970 updates\n",
            "2022-12-24 22:43:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint499.pt\n",
            "2022-12-24 22:43:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint499.pt\n",
            "2022-12-24 22:43:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint499.pt (epoch 499 @ 10970 updates, score 1.683) (writing took 7.772070863000408 seconds)\n",
            "2022-12-24 22:43:28 | INFO | fairseq_cli.train | end of epoch 499 (average epoch stats below)\n",
            "2022-12-24 22:43:28 | INFO | train | epoch 499 | loss 1.47 | nll_loss 0.712 | total 35852.4 | n_correct 31457.2 | ppl 1.64 | accuracy 87.741 | wps 30068.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 10970 | lr 2.8643e-05 | gnorm 1.832 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 15382\n",
            "2022-12-24 22:43:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 500:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:43:28 | INFO | fairseq.trainer | begin training epoch 500\n",
            "2022-12-24 22:43:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 500:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 22:43:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.63it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.39it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.02it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.61it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.14it/s]\u001b[A\n",
            "epoch 500 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:43:47 | INFO | dev_asr_nya | epoch 500 | valid on 'dev_asr_nya' subset | loss 1.662 | nll_loss 0.859 | total 3156.42 | n_correct 2635.84 | ppl 1.81 | accuracy 83.507 | wps 91755.7 | wpb 3156.4 | bsz 32.7 | num_updates 10992 | best_loss 1.653\n",
            "2022-12-24 22:43:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 500 @ 10992 updates\n",
            "2022-12-24 22:43:47 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt\n",
            "2022-12-24 22:43:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt\n",
            "2022-12-24 22:43:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt (epoch 500 @ 10992 updates, score 1.662) (writing took 9.718082225997932 seconds)\n",
            "2022-12-24 22:43:57 | INFO | fairseq_cli.train | end of epoch 500 (average epoch stats below)\n",
            "2022-12-24 22:43:57 | INFO | train | epoch 500 | loss 1.467 | nll_loss 0.709 | total 35852.4 | n_correct 31487.5 | ppl 1.63 | accuracy 87.825 | wps 27700.1 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 10992 | lr 2.86143e-05 | gnorm 1.381 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.6 | wall 15411\n",
            "2022-12-24 22:43:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 501:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:43:57 | INFO | fairseq.trainer | begin training epoch 501\n",
            "2022-12-24 22:43:57 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 501:  95% 21/22 [00:16<00:00,  1.31it/s, loss=1.475, nll_loss=0.718, total=35745.5, n_correct=31311.8, ppl=1.64, accuracy=87.597, wps=26250, ups=0.73, wpb=35745.5, bsz=365.8, num_updates=11000, lr=2.86039e-05, gnorm=1.969, clip=0, loss_scale=8, train_wall=79, gb_free=31.2, wall=15418]2022-12-24 22:44:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.89it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.44it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.16it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.22it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.51it/s]\u001b[A\n",
            "epoch 501 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.69it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:44:15 | INFO | dev_asr_nya | epoch 501 | valid on 'dev_asr_nya' subset | loss 1.68 | nll_loss 0.883 | total 3156.42 | n_correct 2619.26 | ppl 1.84 | accuracy 82.982 | wps 91362.5 | wpb 3156.4 | bsz 32.7 | num_updates 11014 | best_loss 1.653\n",
            "2022-12-24 22:44:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 501 @ 11014 updates\n",
            "2022-12-24 22:44:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint501.pt\n",
            "2022-12-24 22:44:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint501.pt\n",
            "2022-12-24 22:44:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint501.pt (epoch 501 @ 11014 updates, score 1.68) (writing took 8.702307310999458 seconds)\n",
            "2022-12-24 22:44:24 | INFO | fairseq_cli.train | end of epoch 501 (average epoch stats below)\n",
            "2022-12-24 22:44:24 | INFO | train | epoch 501 | loss 1.47 | nll_loss 0.712 | total 35852.4 | n_correct 31447.4 | ppl 1.64 | accuracy 87.714 | wps 29026.4 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 11014 | lr 2.85857e-05 | gnorm 1.924 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.8 | wall 15438\n",
            "2022-12-24 22:44:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 502:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:44:24 | INFO | fairseq.trainer | begin training epoch 502\n",
            "2022-12-24 22:44:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 502:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:44:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.49it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.79it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.01it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.78it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.61it/s]\u001b[A\n",
            "epoch 502 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.55it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:44:42 | INFO | dev_asr_nya | epoch 502 | valid on 'dev_asr_nya' subset | loss 1.663 | nll_loss 0.861 | total 3156.42 | n_correct 2636 | ppl 1.82 | accuracy 83.512 | wps 88666.1 | wpb 3156.4 | bsz 32.7 | num_updates 11036 | best_loss 1.653\n",
            "2022-12-24 22:44:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 502 @ 11036 updates\n",
            "2022-12-24 22:44:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint502.pt\n",
            "2022-12-24 22:44:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint502.pt\n",
            "2022-12-24 22:44:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint502.pt (epoch 502 @ 11036 updates, score 1.663) (writing took 9.369682513999578 seconds)\n",
            "2022-12-24 22:44:52 | INFO | fairseq_cli.train | end of epoch 502 (average epoch stats below)\n",
            "2022-12-24 22:44:52 | INFO | train | epoch 502 | loss 1.463 | nll_loss 0.703 | total 35852.4 | n_correct 31532.9 | ppl 1.63 | accuracy 87.952 | wps 28590 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 11036 | lr 2.85572e-05 | gnorm 1.274 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 15465\n",
            "2022-12-24 22:44:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 503:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:44:52 | INFO | fairseq.trainer | begin training epoch 503\n",
            "2022-12-24 22:44:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 503:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:45:09 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.08it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.07it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.45it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.35it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.38it/s]\u001b[A\n",
            "epoch 503 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.13it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:45:10 | INFO | dev_asr_nya | epoch 503 | valid on 'dev_asr_nya' subset | loss 1.667 | nll_loss 0.867 | total 3156.42 | n_correct 2633.05 | ppl 1.82 | accuracy 83.419 | wps 90065.6 | wpb 3156.4 | bsz 32.7 | num_updates 11058 | best_loss 1.653\n",
            "2022-12-24 22:45:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 503 @ 11058 updates\n",
            "2022-12-24 22:45:10 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint503.pt\n",
            "2022-12-24 22:45:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint503.pt\n",
            "2022-12-24 22:45:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint503.pt (epoch 503 @ 11058 updates, score 1.667) (writing took 7.594427542000631 seconds)\n",
            "2022-12-24 22:45:18 | INFO | fairseq_cli.train | end of epoch 503 (average epoch stats below)\n",
            "2022-12-24 22:45:18 | INFO | train | epoch 503 | loss 1.459 | nll_loss 0.699 | total 35852.4 | n_correct 31562.8 | ppl 1.62 | accuracy 88.036 | wps 30352.1 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 11058 | lr 2.85288e-05 | gnorm 0.93 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.3 | wall 15491\n",
            "2022-12-24 22:45:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 504:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:45:18 | INFO | fairseq.trainer | begin training epoch 504\n",
            "2022-12-24 22:45:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 504:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:45:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.00it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.14it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.07it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.58it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.73it/s]\u001b[A\n",
            "epoch 504 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.07it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:45:36 | INFO | dev_asr_nya | epoch 504 | valid on 'dev_asr_nya' subset | loss 1.898 | nll_loss 1.139 | total 3156.42 | n_correct 2472.11 | ppl 2.2 | accuracy 78.32 | wps 88136.1 | wpb 3156.4 | bsz 32.7 | num_updates 11080 | best_loss 1.653\n",
            "2022-12-24 22:45:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 504 @ 11080 updates\n",
            "2022-12-24 22:45:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint504.pt\n",
            "2022-12-24 22:45:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint504.pt\n",
            "2022-12-24 22:45:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint504.pt (epoch 504 @ 11080 updates, score 1.898) (writing took 10.633591786998295 seconds)\n",
            "2022-12-24 22:45:47 | INFO | fairseq_cli.train | end of epoch 504 (average epoch stats below)\n",
            "2022-12-24 22:45:47 | INFO | train | epoch 504 | loss 1.465 | nll_loss 0.707 | total 35852.4 | n_correct 31482.2 | ppl 1.63 | accuracy 87.811 | wps 27072.5 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11080 | lr 2.85004e-05 | gnorm 1.97 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.8 | wall 15520\n",
            "2022-12-24 22:45:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 505:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:45:47 | INFO | fairseq.trainer | begin training epoch 505\n",
            "2022-12-24 22:45:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2022-12-24 22:45:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0\n",
            "epoch 505:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.47, nll_loss=0.713, total=35920.5, n_correct=31500.4, ppl=1.64, accuracy=87.695, wps=29952.1, ups=0.83, wpb=35920.5, bsz=370.8, num_updates=11100, lr=2.84747e-05, gnorm=1.831, clip=1, loss_scale=4, train_wall=78, gb_free=31.4, wall=15537]2022-12-24 22:46:04 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.34it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.07it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.52it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.09it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.30it/s]\u001b[A\n",
            "epoch 505 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.94it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:46:05 | INFO | dev_asr_nya | epoch 505 | valid on 'dev_asr_nya' subset | loss 1.654 | nll_loss 0.856 | total 3156.42 | n_correct 2636.42 | ppl 1.81 | accuracy 83.526 | wps 89388.3 | wpb 3156.4 | bsz 32.7 | num_updates 11101 | best_loss 1.653\n",
            "2022-12-24 22:46:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 505 @ 11101 updates\n",
            "2022-12-24 22:46:05 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint505.pt\n",
            "2022-12-24 22:46:09 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint505.pt\n",
            "2022-12-24 22:46:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint505.pt (epoch 505 @ 11101 updates, score 1.654) (writing took 7.774733341000683 seconds)\n",
            "2022-12-24 22:46:13 | INFO | fairseq_cli.train | end of epoch 505 (average epoch stats below)\n",
            "2022-12-24 22:46:13 | INFO | train | epoch 505 | loss 1.504 | nll_loss 0.754 | total 35797.4 | n_correct 31047.9 | ppl 1.69 | accuracy 86.732 | wps 28641.8 | ups 0.8 | wpb 35797.4 | bsz 368 | num_updates 11101 | lr 2.84735e-05 | gnorm 3.382 | clip 4.8 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 15547\n",
            "2022-12-24 22:46:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 506:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:46:13 | INFO | fairseq.trainer | begin training epoch 506\n",
            "2022-12-24 22:46:13 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 506:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:46:30 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.66it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.44it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.82it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.93it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.91it/s]\u001b[A\n",
            "epoch 506 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.01it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:46:31 | INFO | dev_asr_nya | epoch 506 | valid on 'dev_asr_nya' subset | loss 1.665 | nll_loss 0.866 | total 3156.42 | n_correct 2630.37 | ppl 1.82 | accuracy 83.334 | wps 92204.5 | wpb 3156.4 | bsz 32.7 | num_updates 11123 | best_loss 1.653\n",
            "2022-12-24 22:46:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 506 @ 11123 updates\n",
            "2022-12-24 22:46:31 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint506.pt\n",
            "2022-12-24 22:46:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint506.pt\n",
            "2022-12-24 22:46:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint506.pt (epoch 506 @ 11123 updates, score 1.665) (writing took 8.018346434000705 seconds)\n",
            "2022-12-24 22:46:39 | INFO | fairseq_cli.train | end of epoch 506 (average epoch stats below)\n",
            "2022-12-24 22:46:39 | INFO | train | epoch 506 | loss 1.46 | nll_loss 0.701 | total 35852.4 | n_correct 31540.8 | ppl 1.63 | accuracy 87.974 | wps 30023.2 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11123 | lr 2.84453e-05 | gnorm 1.293 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 15573\n",
            "2022-12-24 22:46:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 507:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:46:39 | INFO | fairseq.trainer | begin training epoch 507\n",
            "2022-12-24 22:46:39 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 507:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:46:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.87it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.95it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.83it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.45it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.21it/s]\u001b[A\n",
            "epoch 507 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.78it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:46:58 | INFO | dev_asr_nya | epoch 507 | valid on 'dev_asr_nya' subset | loss 1.671 | nll_loss 0.871 | total 3156.42 | n_correct 2629.47 | ppl 1.83 | accuracy 83.306 | wps 91961.9 | wpb 3156.4 | bsz 32.7 | num_updates 11145 | best_loss 1.653\n",
            "2022-12-24 22:46:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 507 @ 11145 updates\n",
            "2022-12-24 22:46:58 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint507.pt\n",
            "2022-12-24 22:47:01 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint507.pt\n",
            "2022-12-24 22:47:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint507.pt (epoch 507 @ 11145 updates, score 1.671) (writing took 8.86011656899791 seconds)\n",
            "2022-12-24 22:47:06 | INFO | fairseq_cli.train | end of epoch 507 (average epoch stats below)\n",
            "2022-12-24 22:47:06 | INFO | train | epoch 507 | loss 1.454 | nll_loss 0.693 | total 35852.4 | n_correct 31611.3 | ppl 1.62 | accuracy 88.171 | wps 28984.5 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 11145 | lr 2.84172e-05 | gnorm 1.133 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32 | wall 15600\n",
            "2022-12-24 22:47:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 508:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:47:07 | INFO | fairseq.trainer | begin training epoch 508\n",
            "2022-12-24 22:47:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 508:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:47:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.74it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.03it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.11it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.13it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.76it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.50it/s]\u001b[A\n",
            "epoch 508 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:47:25 | INFO | dev_asr_nya | epoch 508 | valid on 'dev_asr_nya' subset | loss 1.66 | nll_loss 0.859 | total 3156.42 | n_correct 2640.11 | ppl 1.81 | accuracy 83.642 | wps 86943.1 | wpb 3156.4 | bsz 32.7 | num_updates 11167 | best_loss 1.653\n",
            "2022-12-24 22:47:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 508 @ 11167 updates\n",
            "2022-12-24 22:47:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint508.pt\n",
            "2022-12-24 22:47:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint508.pt\n",
            "2022-12-24 22:47:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint508.pt (epoch 508 @ 11167 updates, score 1.66) (writing took 7.828592264002509 seconds)\n",
            "2022-12-24 22:47:33 | INFO | fairseq_cli.train | end of epoch 508 (average epoch stats below)\n",
            "2022-12-24 22:47:33 | INFO | train | epoch 508 | loss 1.451 | nll_loss 0.69 | total 35852.4 | n_correct 31638 | ppl 1.61 | accuracy 88.245 | wps 29862.6 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11167 | lr 2.83892e-05 | gnorm 0.927 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 15627\n",
            "2022-12-24 22:47:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 509:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:47:33 | INFO | fairseq.trainer | begin training epoch 509\n",
            "2022-12-24 22:47:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 509:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:47:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.14it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.54it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.22it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.39it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.82it/s]\u001b[A\n",
            "epoch 509 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:47:51 | INFO | dev_asr_nya | epoch 509 | valid on 'dev_asr_nya' subset | loss 1.68 | nll_loss 0.884 | total 3156.42 | n_correct 2624.47 | ppl 1.85 | accuracy 83.147 | wps 87832.2 | wpb 3156.4 | bsz 32.7 | num_updates 11189 | best_loss 1.653\n",
            "2022-12-24 22:47:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 509 @ 11189 updates\n",
            "2022-12-24 22:47:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint509.pt\n",
            "2022-12-24 22:47:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint509.pt\n",
            "2022-12-24 22:47:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint509.pt (epoch 509 @ 11189 updates, score 1.68) (writing took 8.032426155001303 seconds)\n",
            "2022-12-24 22:47:59 | INFO | fairseq_cli.train | end of epoch 509 (average epoch stats below)\n",
            "2022-12-24 22:47:59 | INFO | train | epoch 509 | loss 1.453 | nll_loss 0.693 | total 35852.4 | n_correct 31600.9 | ppl 1.62 | accuracy 88.142 | wps 29702.8 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11189 | lr 2.83613e-05 | gnorm 1.58 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 15653\n",
            "2022-12-24 22:48:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 510:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:48:00 | INFO | fairseq.trainer | begin training epoch 510\n",
            "2022-12-24 22:48:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 510:  95% 21/22 [00:16<00:00,  1.31it/s, loss=1.454, nll_loss=0.694, total=35829.6, n_correct=31577.4, ppl=1.62, accuracy=88.132, wps=28734.7, ups=0.8, wpb=35829.6, bsz=368.9, num_updates=11200, lr=2.83473e-05, gnorm=1.236, clip=0, loss_scale=4, train_wall=78, gb_free=30.3, wall=15662]2022-12-24 22:48:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.34it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.03it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.97it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 25.04it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.50it/s]\u001b[A\n",
            "epoch 510 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:48:18 | INFO | dev_asr_nya | epoch 510 | valid on 'dev_asr_nya' subset | loss 1.649 | nll_loss 0.845 | total 3156.42 | n_correct 2646 | ppl 1.8 | accuracy 83.829 | wps 95567.2 | wpb 3156.4 | bsz 32.7 | num_updates 11211 | best_loss 1.649\n",
            "2022-12-24 22:48:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 510 @ 11211 updates\n",
            "2022-12-24 22:48:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint510.pt\n",
            "2022-12-24 22:48:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint510.pt\n",
            "2022-12-24 22:48:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint510.pt (epoch 510 @ 11211 updates, score 1.649) (writing took 14.616546468998422 seconds)\n",
            "2022-12-24 22:48:32 | INFO | fairseq_cli.train | end of epoch 510 (average epoch stats below)\n",
            "2022-12-24 22:48:32 | INFO | train | epoch 510 | loss 1.45 | nll_loss 0.689 | total 35852.4 | n_correct 31631.9 | ppl 1.61 | accuracy 88.228 | wps 24002.5 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 11211 | lr 2.83334e-05 | gnorm 1.27 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 28.8 | wall 15686\n",
            "2022-12-24 22:48:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 511:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:48:32 | INFO | fairseq.trainer | begin training epoch 511\n",
            "2022-12-24 22:48:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 511:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:48:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.93it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 18.41it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.32it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.76it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.83it/s]\u001b[A\n",
            "epoch 511 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:48:51 | INFO | dev_asr_nya | epoch 511 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.847 | total 3156.42 | n_correct 2645.05 | ppl 1.8 | accuracy 83.799 | wps 94226.3 | wpb 3156.4 | bsz 32.7 | num_updates 11233 | best_loss 1.649\n",
            "2022-12-24 22:48:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 511 @ 11233 updates\n",
            "2022-12-24 22:48:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint511.pt\n",
            "2022-12-24 22:48:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint511.pt\n",
            "2022-12-24 22:48:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint511.pt (epoch 511 @ 11233 updates, score 1.651) (writing took 7.827349398998194 seconds)\n",
            "2022-12-24 22:48:59 | INFO | fairseq_cli.train | end of epoch 511 (average epoch stats below)\n",
            "2022-12-24 22:48:59 | INFO | train | epoch 511 | loss 1.455 | nll_loss 0.696 | total 35852.4 | n_correct 31576.1 | ppl 1.62 | accuracy 88.073 | wps 29993.6 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11233 | lr 2.83057e-05 | gnorm 2.158 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.6 | wall 15712\n",
            "2022-12-24 22:48:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 512:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:48:59 | INFO | fairseq.trainer | begin training epoch 512\n",
            "2022-12-24 22:48:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 512:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:49:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.37it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.58it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.03it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.39it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.79it/s]\u001b[A\n",
            "epoch 512 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:49:18 | INFO | dev_asr_nya | epoch 512 | valid on 'dev_asr_nya' subset | loss 1.667 | nll_loss 0.865 | total 3156.42 | n_correct 2633.79 | ppl 1.82 | accuracy 83.442 | wps 89064.2 | wpb 3156.4 | bsz 32.7 | num_updates 11255 | best_loss 1.649\n",
            "2022-12-24 22:49:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 512 @ 11255 updates\n",
            "2022-12-24 22:49:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint512.pt\n",
            "2022-12-24 22:49:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint512.pt\n",
            "2022-12-24 22:49:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint512.pt (epoch 512 @ 11255 updates, score 1.667) (writing took 9.681231849001051 seconds)\n",
            "2022-12-24 22:49:27 | INFO | fairseq_cli.train | end of epoch 512 (average epoch stats below)\n",
            "2022-12-24 22:49:27 | INFO | train | epoch 512 | loss 1.457 | nll_loss 0.698 | total 35852.4 | n_correct 31548 | ppl 1.62 | accuracy 87.994 | wps 27400 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11255 | lr 2.8278e-05 | gnorm 2.095 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 29.5 | wall 15741\n",
            "2022-12-24 22:49:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 513:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:49:27 | INFO | fairseq.trainer | begin training epoch 513\n",
            "2022-12-24 22:49:27 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 513:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:49:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.50it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.22it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.75it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.09it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.70it/s]\u001b[A\n",
            "epoch 513 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.13it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:49:46 | INFO | dev_asr_nya | epoch 513 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.849 | total 3156.42 | n_correct 2644.53 | ppl 1.8 | accuracy 83.782 | wps 89527.9 | wpb 3156.4 | bsz 32.7 | num_updates 11277 | best_loss 1.649\n",
            "2022-12-24 22:49:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 513 @ 11277 updates\n",
            "2022-12-24 22:49:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint513.pt\n",
            "2022-12-24 22:49:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint513.pt\n",
            "2022-12-24 22:49:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint513.pt (epoch 513 @ 11277 updates, score 1.651) (writing took 8.807584518999647 seconds)\n",
            "2022-12-24 22:49:55 | INFO | fairseq_cli.train | end of epoch 513 (average epoch stats below)\n",
            "2022-12-24 22:49:55 | INFO | train | epoch 513 | loss 1.46 | nll_loss 0.701 | total 35852.4 | n_correct 31514.7 | ppl 1.63 | accuracy 87.901 | wps 29079.6 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 11277 | lr 2.82504e-05 | gnorm 2.581 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 15768\n",
            "2022-12-24 22:49:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 514:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:49:55 | INFO | fairseq.trainer | begin training epoch 514\n",
            "2022-12-24 22:49:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 514:  95% 21/22 [00:16<00:00,  1.28it/s]2022-12-24 22:50:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.10it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.77it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.11it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.82it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.87it/s]\u001b[A\n",
            "epoch 514 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:50:13 | INFO | dev_asr_nya | epoch 514 | valid on 'dev_asr_nya' subset | loss 1.681 | nll_loss 0.885 | total 3156.42 | n_correct 2622.05 | ppl 1.85 | accuracy 83.07 | wps 93163.6 | wpb 3156.4 | bsz 32.7 | num_updates 11299 | best_loss 1.649\n",
            "2022-12-24 22:50:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 514 @ 11299 updates\n",
            "2022-12-24 22:50:13 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint514.pt\n",
            "2022-12-24 22:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint514.pt\n",
            "2022-12-24 22:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint514.pt (epoch 514 @ 11299 updates, score 1.681) (writing took 10.605411939999613 seconds)\n",
            "2022-12-24 22:50:24 | INFO | fairseq_cli.train | end of epoch 514 (average epoch stats below)\n",
            "2022-12-24 22:50:24 | INFO | train | epoch 514 | loss 1.451 | nll_loss 0.691 | total 35852.4 | n_correct 31614.7 | ppl 1.61 | accuracy 88.18 | wps 27132.2 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11299 | lr 2.82229e-05 | gnorm 1.719 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 15797\n",
            "2022-12-24 22:50:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 515:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:50:24 | INFO | fairseq.trainer | begin training epoch 515\n",
            "2022-12-24 22:50:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 515:  95% 21/22 [00:16<00:00,  1.29it/s, loss=1.455, nll_loss=0.696, total=35834.2, n_correct=31551.9, ppl=1.62, accuracy=88.05, wps=26280.7, ups=0.73, wpb=35834.2, bsz=367.4, num_updates=11300, lr=2.82216e-05, gnorm=2.067, clip=0, loss_scale=4, train_wall=79, gb_free=28.9, wall=15798]2022-12-24 22:50:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.18it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.58it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.82it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.59it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.47it/s]\u001b[A\n",
            "epoch 515 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:50:42 | INFO | dev_asr_nya | epoch 515 | valid on 'dev_asr_nya' subset | loss 1.653 | nll_loss 0.852 | total 3156.42 | n_correct 2640.42 | ppl 1.8 | accuracy 83.652 | wps 89691.9 | wpb 3156.4 | bsz 32.7 | num_updates 11321 | best_loss 1.649\n",
            "2022-12-24 22:50:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 515 @ 11321 updates\n",
            "2022-12-24 22:50:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint515.pt\n",
            "2022-12-24 22:50:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint515.pt\n",
            "2022-12-24 22:50:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint515.pt (epoch 515 @ 11321 updates, score 1.653) (writing took 10.667476987000555 seconds)\n",
            "2022-12-24 22:50:52 | INFO | fairseq_cli.train | end of epoch 515 (average epoch stats below)\n",
            "2022-12-24 22:50:52 | INFO | train | epoch 515 | loss 1.459 | nll_loss 0.701 | total 35852.4 | n_correct 31539.6 | ppl 1.63 | accuracy 87.971 | wps 27346.7 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11321 | lr 2.81954e-05 | gnorm 2.613 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 15826\n",
            "2022-12-24 22:50:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 516:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:50:53 | INFO | fairseq.trainer | begin training epoch 516\n",
            "2022-12-24 22:50:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 516:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 22:51:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.92it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.14it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.37it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.03it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.49it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 25.40it/s]\u001b[A\n",
            "epoch 516 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 25.18it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:51:11 | INFO | dev_asr_nya | epoch 516 | valid on 'dev_asr_nya' subset | loss 1.636 | nll_loss 0.831 | total 3156.42 | n_correct 2658.95 | ppl 1.78 | accuracy 84.239 | wps 81325.4 | wpb 3156.4 | bsz 32.7 | num_updates 11343 | best_loss 1.636\n",
            "2022-12-24 22:51:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 516 @ 11343 updates\n",
            "2022-12-24 22:51:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint516.pt\n",
            "2022-12-24 22:51:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint516.pt\n",
            "2022-12-24 22:51:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint516.pt (epoch 516 @ 11343 updates, score 1.636) (writing took 12.382690283000557 seconds)\n",
            "2022-12-24 22:51:23 | INFO | fairseq_cli.train | end of epoch 516 (average epoch stats below)\n",
            "2022-12-24 22:51:23 | INFO | train | epoch 516 | loss 1.462 | nll_loss 0.704 | total 35852.4 | n_correct 31498.8 | ppl 1.63 | accuracy 87.857 | wps 25398.7 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 11343 | lr 2.81681e-05 | gnorm 2.522 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 15857\n",
            "2022-12-24 22:51:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 517:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:51:24 | INFO | fairseq.trainer | begin training epoch 517\n",
            "2022-12-24 22:51:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 517:  95% 21/22 [00:16<00:00,  1.25it/s]2022-12-24 22:51:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.49it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.95it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.85it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.68it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.20it/s]\u001b[A\n",
            "epoch 517 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.56it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:51:42 | INFO | dev_asr_nya | epoch 517 | valid on 'dev_asr_nya' subset | loss 1.647 | nll_loss 0.845 | total 3156.42 | n_correct 2647.37 | ppl 1.8 | accuracy 83.872 | wps 91590.4 | wpb 3156.4 | bsz 32.7 | num_updates 11365 | best_loss 1.636\n",
            "2022-12-24 22:51:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 517 @ 11365 updates\n",
            "2022-12-24 22:51:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint517.pt\n",
            "2022-12-24 22:51:46 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint517.pt\n",
            "2022-12-24 22:51:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint517.pt (epoch 517 @ 11365 updates, score 1.647) (writing took 8.929337495999789 seconds)\n",
            "2022-12-24 22:51:51 | INFO | fairseq_cli.train | end of epoch 517 (average epoch stats below)\n",
            "2022-12-24 22:51:51 | INFO | train | epoch 517 | loss 1.443 | nll_loss 0.682 | total 35852.4 | n_correct 31677.4 | ppl 1.6 | accuracy 88.355 | wps 28742.5 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 11365 | lr 2.81408e-05 | gnorm 1.54 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 15885\n",
            "2022-12-24 22:51:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 518:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:51:51 | INFO | fairseq.trainer | begin training epoch 518\n",
            "2022-12-24 22:51:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 518:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 22:52:09 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.39it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.57it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.53it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.26it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.10it/s]\u001b[A\n",
            "epoch 518 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:52:10 | INFO | dev_asr_nya | epoch 518 | valid on 'dev_asr_nya' subset | loss 1.641 | nll_loss 0.835 | total 3156.42 | n_correct 2653 | ppl 1.78 | accuracy 84.051 | wps 90429.1 | wpb 3156.4 | bsz 32.7 | num_updates 11387 | best_loss 1.636\n",
            "2022-12-24 22:52:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 518 @ 11387 updates\n",
            "2022-12-24 22:52:10 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint518.pt\n",
            "2022-12-24 22:52:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint518.pt\n",
            "2022-12-24 22:52:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint518.pt (epoch 518 @ 11387 updates, score 1.641) (writing took 7.646375233998697 seconds)\n",
            "2022-12-24 22:52:18 | INFO | fairseq_cli.train | end of epoch 518 (average epoch stats below)\n",
            "2022-12-24 22:52:18 | INFO | train | epoch 518 | loss 1.438 | nll_loss 0.675 | total 35852.4 | n_correct 31755.1 | ppl 1.6 | accuracy 88.572 | wps 29632.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11387 | lr 2.81136e-05 | gnorm 1.053 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 29.4 | wall 15911\n",
            "2022-12-24 22:52:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 519:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:52:18 | INFO | fairseq.trainer | begin training epoch 519\n",
            "2022-12-24 22:52:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 519:  95% 21/22 [00:17<00:00,  1.25it/s, loss=1.448, nll_loss=0.687, total=35906.4, n_correct=31690.4, ppl=1.61, accuracy=88.259, wps=29019.4, ups=0.81, wpb=35906.4, bsz=369.6, num_updates=11400, lr=2.80976e-05, gnorm=1.839, clip=0, loss_scale=4, train_wall=79, gb_free=29.5, wall=15922]2022-12-24 22:52:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.13it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.16it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.83it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.65it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.93it/s]\u001b[A\n",
            "epoch 519 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.54it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:52:36 | INFO | dev_asr_nya | epoch 519 | valid on 'dev_asr_nya' subset | loss 1.673 | nll_loss 0.875 | total 3156.42 | n_correct 2630.32 | ppl 1.83 | accuracy 83.332 | wps 89082.7 | wpb 3156.4 | bsz 32.7 | num_updates 11409 | best_loss 1.636\n",
            "2022-12-24 22:52:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 519 @ 11409 updates\n",
            "2022-12-24 22:52:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint519.pt\n",
            "2022-12-24 22:52:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint519.pt\n",
            "2022-12-24 22:52:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint519.pt (epoch 519 @ 11409 updates, score 1.673) (writing took 8.091333472002589 seconds)\n",
            "2022-12-24 22:52:44 | INFO | fairseq_cli.train | end of epoch 519 (average epoch stats below)\n",
            "2022-12-24 22:52:44 | INFO | train | epoch 519 | loss 1.44 | nll_loss 0.677 | total 35852.4 | n_correct 31723.8 | ppl 1.6 | accuracy 88.485 | wps 29294.6 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 11409 | lr 2.80865e-05 | gnorm 1.375 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 31.2 | wall 15938\n",
            "2022-12-24 22:52:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 520:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:52:45 | INFO | fairseq.trainer | begin training epoch 520\n",
            "2022-12-24 22:52:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 520:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 22:53:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.15it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.56it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.30it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.64it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.00it/s]\u001b[A\n",
            "epoch 520 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.56it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:53:03 | INFO | dev_asr_nya | epoch 520 | valid on 'dev_asr_nya' subset | loss 1.678 | nll_loss 0.881 | total 3156.42 | n_correct 2624.89 | ppl 1.84 | accuracy 83.16 | wps 94447.6 | wpb 3156.4 | bsz 32.7 | num_updates 11431 | best_loss 1.636\n",
            "2022-12-24 22:53:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 520 @ 11431 updates\n",
            "2022-12-24 22:53:03 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint520.pt\n",
            "2022-12-24 22:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint520.pt\n",
            "2022-12-24 22:53:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint520.pt (epoch 520 @ 11431 updates, score 1.678) (writing took 7.876352096998744 seconds)\n",
            "2022-12-24 22:53:11 | INFO | fairseq_cli.train | end of epoch 520 (average epoch stats below)\n",
            "2022-12-24 22:53:11 | INFO | train | epoch 520 | loss 1.44 | nll_loss 0.678 | total 35852.4 | n_correct 31725.2 | ppl 1.6 | accuracy 88.488 | wps 30072.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11431 | lr 2.80594e-05 | gnorm 1.794 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 15964\n",
            "2022-12-24 22:53:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 521:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:53:11 | INFO | fairseq.trainer | begin training epoch 521\n",
            "2022-12-24 22:53:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 521:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 22:53:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.55it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.43it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.41it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.35it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.81it/s]\u001b[A\n",
            "epoch 521 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:53:29 | INFO | dev_asr_nya | epoch 521 | valid on 'dev_asr_nya' subset | loss 1.654 | nll_loss 0.853 | total 3156.42 | n_correct 2645.21 | ppl 1.81 | accuracy 83.804 | wps 88477.8 | wpb 3156.4 | bsz 32.7 | num_updates 11453 | best_loss 1.636\n",
            "2022-12-24 22:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 521 @ 11453 updates\n",
            "2022-12-24 22:53:29 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint521.pt\n",
            "2022-12-24 22:53:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint521.pt\n",
            "2022-12-24 22:53:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint521.pt (epoch 521 @ 11453 updates, score 1.654) (writing took 10.33588097699976 seconds)\n",
            "2022-12-24 22:53:39 | INFO | fairseq_cli.train | end of epoch 521 (average epoch stats below)\n",
            "2022-12-24 22:53:39 | INFO | train | epoch 521 | loss 1.435 | nll_loss 0.671 | total 35852.4 | n_correct 31768.9 | ppl 1.59 | accuracy 88.61 | wps 27398.8 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11453 | lr 2.80325e-05 | gnorm 1.234 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 15993\n",
            "2022-12-24 22:53:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 522:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:53:40 | INFO | fairseq.trainer | begin training epoch 522\n",
            "2022-12-24 22:53:40 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 522:  95% 21/22 [00:17<00:00,  1.28it/s]2022-12-24 22:53:57 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.42it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.65it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.84it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.93it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.91it/s]\u001b[A\n",
            "epoch 522 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:53:58 | INFO | dev_asr_nya | epoch 522 | valid on 'dev_asr_nya' subset | loss 1.659 | nll_loss 0.858 | total 3156.42 | n_correct 2642.53 | ppl 1.81 | accuracy 83.719 | wps 85434.9 | wpb 3156.4 | bsz 32.7 | num_updates 11475 | best_loss 1.636\n",
            "2022-12-24 22:53:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 522 @ 11475 updates\n",
            "2022-12-24 22:53:58 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint522.pt\n",
            "2022-12-24 22:54:01 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint522.pt\n",
            "2022-12-24 22:54:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint522.pt (epoch 522 @ 11475 updates, score 1.659) (writing took 7.848835136999696 seconds)\n",
            "2022-12-24 22:54:06 | INFO | fairseq_cli.train | end of epoch 522 (average epoch stats below)\n",
            "2022-12-24 22:54:06 | INFO | train | epoch 522 | loss 1.432 | nll_loss 0.668 | total 35852.4 | n_correct 31782.4 | ppl 1.59 | accuracy 88.648 | wps 29778.2 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11475 | lr 2.80056e-05 | gnorm 1.067 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 16020\n",
            "2022-12-24 22:54:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 523:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:54:06 | INFO | fairseq.trainer | begin training epoch 523\n",
            "2022-12-24 22:54:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 523:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:54:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.15it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.52it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.11it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.63it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.89it/s]\u001b[A\n",
            "epoch 523 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.67it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:54:25 | INFO | dev_asr_nya | epoch 523 | valid on 'dev_asr_nya' subset | loss 1.645 | nll_loss 0.841 | total 3156.42 | n_correct 2653.58 | ppl 1.79 | accuracy 84.069 | wps 89710.7 | wpb 3156.4 | bsz 32.7 | num_updates 11497 | best_loss 1.636\n",
            "2022-12-24 22:54:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 523 @ 11497 updates\n",
            "2022-12-24 22:54:25 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint523.pt\n",
            "2022-12-24 22:54:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint523.pt\n",
            "2022-12-24 22:54:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint523.pt (epoch 523 @ 11497 updates, score 1.645) (writing took 8.490486263999628 seconds)\n",
            "2022-12-24 22:54:33 | INFO | fairseq_cli.train | end of epoch 523 (average epoch stats below)\n",
            "2022-12-24 22:54:33 | INFO | train | epoch 523 | loss 1.431 | nll_loss 0.667 | total 35852.4 | n_correct 31812.7 | ppl 1.59 | accuracy 88.733 | wps 29114.2 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 11497 | lr 2.79788e-05 | gnorm 0.912 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 16047\n",
            "2022-12-24 22:54:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 524:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:54:33 | INFO | fairseq.trainer | begin training epoch 524\n",
            "2022-12-24 22:54:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 524:  95% 21/22 [00:16<00:00,  1.26it/s, loss=1.435, nll_loss=0.672, total=35831.2, n_correct=31746.4, ppl=1.59, accuracy=88.6, wps=28147, ups=0.79, wpb=35831.2, bsz=367.6, num_updates=11500, lr=2.79751e-05, gnorm=1.287, clip=0, loss_scale=4, train_wall=78, gb_free=30.7, wall=16050]2022-12-24 22:54:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.55it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.97it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.27it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.27it/s]\u001b[A\n",
            "epoch 524 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.09it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:54:51 | INFO | dev_asr_nya | epoch 524 | valid on 'dev_asr_nya' subset | loss 1.673 | nll_loss 0.874 | total 3156.42 | n_correct 2630.74 | ppl 1.83 | accuracy 83.346 | wps 91805 | wpb 3156.4 | bsz 32.7 | num_updates 11519 | best_loss 1.636\n",
            "2022-12-24 22:54:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 524 @ 11519 updates\n",
            "2022-12-24 22:54:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint524.pt\n",
            "2022-12-24 22:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint524.pt\n",
            "2022-12-24 22:54:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint524.pt (epoch 524 @ 11519 updates, score 1.673) (writing took 7.895034071996633 seconds)\n",
            "2022-12-24 22:54:59 | INFO | fairseq_cli.train | end of epoch 524 (average epoch stats below)\n",
            "2022-12-24 22:54:59 | INFO | train | epoch 524 | loss 1.432 | nll_loss 0.669 | total 35852.4 | n_correct 31793.4 | ppl 1.59 | accuracy 88.679 | wps 29991.9 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11519 | lr 2.79521e-05 | gnorm 1.575 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 16073\n",
            "2022-12-24 22:54:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 525:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:54:59 | INFO | fairseq.trainer | begin training epoch 525\n",
            "2022-12-24 22:54:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 525:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:55:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.95it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.67it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.76it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.52it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.81it/s]\u001b[A\n",
            "epoch 525 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.27it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:55:18 | INFO | dev_asr_nya | epoch 525 | valid on 'dev_asr_nya' subset | loss 1.696 | nll_loss 0.905 | total 3156.42 | n_correct 2612.37 | ppl 1.87 | accuracy 82.764 | wps 94322.7 | wpb 3156.4 | bsz 32.7 | num_updates 11541 | best_loss 1.636\n",
            "2022-12-24 22:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 525 @ 11541 updates\n",
            "2022-12-24 22:55:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint525.pt\n",
            "2022-12-24 22:55:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint525.pt\n",
            "2022-12-24 22:55:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint525.pt (epoch 525 @ 11541 updates, score 1.696) (writing took 10.157013888998335 seconds)\n",
            "2022-12-24 22:55:28 | INFO | fairseq_cli.train | end of epoch 525 (average epoch stats below)\n",
            "2022-12-24 22:55:28 | INFO | train | epoch 525 | loss 1.433 | nll_loss 0.67 | total 35852.4 | n_correct 31769.8 | ppl 1.59 | accuracy 88.613 | wps 27579.7 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 11541 | lr 2.79254e-05 | gnorm 1.594 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 16102\n",
            "2022-12-24 22:55:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 526:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:55:28 | INFO | fairseq.trainer | begin training epoch 526\n",
            "2022-12-24 22:55:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 526:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 22:55:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.82it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.79it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.87it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.80it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.14it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.57it/s]\u001b[A\n",
            "epoch 526 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:55:46 | INFO | dev_asr_nya | epoch 526 | valid on 'dev_asr_nya' subset | loss 1.656 | nll_loss 0.858 | total 3156.42 | n_correct 2640.58 | ppl 1.81 | accuracy 83.657 | wps 85040.7 | wpb 3156.4 | bsz 32.7 | num_updates 11563 | best_loss 1.636\n",
            "2022-12-24 22:55:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 526 @ 11563 updates\n",
            "2022-12-24 22:55:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint526.pt\n",
            "2022-12-24 22:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint526.pt\n",
            "2022-12-24 22:55:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint526.pt (epoch 526 @ 11563 updates, score 1.656) (writing took 9.25089726999795 seconds)\n",
            "2022-12-24 22:55:56 | INFO | fairseq_cli.train | end of epoch 526 (average epoch stats below)\n",
            "2022-12-24 22:55:56 | INFO | train | epoch 526 | loss 1.435 | nll_loss 0.672 | total 35852.4 | n_correct 31768.5 | ppl 1.59 | accuracy 88.609 | wps 28540.5 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 11563 | lr 2.78988e-05 | gnorm 2.188 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.6 | wall 16129\n",
            "2022-12-24 22:55:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 527:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:55:56 | INFO | fairseq.trainer | begin training epoch 527\n",
            "2022-12-24 22:55:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 527:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:56:13 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.28it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.81it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.86it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.45it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.23it/s]\u001b[A\n",
            "epoch 527 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.07it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:56:14 | INFO | dev_asr_nya | epoch 527 | valid on 'dev_asr_nya' subset | loss 1.669 | nll_loss 0.872 | total 3156.42 | n_correct 2630.74 | ppl 1.83 | accuracy 83.346 | wps 91015.2 | wpb 3156.4 | bsz 32.7 | num_updates 11585 | best_loss 1.636\n",
            "2022-12-24 22:56:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 527 @ 11585 updates\n",
            "2022-12-24 22:56:14 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint527.pt\n",
            "2022-12-24 22:56:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint527.pt\n",
            "2022-12-24 22:56:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint527.pt (epoch 527 @ 11585 updates, score 1.669) (writing took 8.42552125000293 seconds)\n",
            "2022-12-24 22:56:23 | INFO | fairseq_cli.train | end of epoch 527 (average epoch stats below)\n",
            "2022-12-24 22:56:23 | INFO | train | epoch 527 | loss 1.436 | nll_loss 0.674 | total 35852.4 | n_correct 31746.5 | ppl 1.6 | accuracy 88.548 | wps 29143.3 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 11585 | lr 2.78723e-05 | gnorm 2.314 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 16156\n",
            "2022-12-24 22:56:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 528:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:56:23 | INFO | fairseq.trainer | begin training epoch 528\n",
            "2022-12-24 22:56:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 528:  95% 21/22 [00:16<00:00,  1.30it/s, loss=1.433, nll_loss=0.67, total=35866.9, n_correct=31790.8, ppl=1.59, accuracy=88.636, wps=30101.1, ups=0.84, wpb=35866.9, bsz=369.9, num_updates=11600, lr=2.78543e-05, gnorm=1.891, clip=0, loss_scale=4, train_wall=78, gb_free=30.9, wall=16169]2022-12-24 22:56:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.35it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:01, 13.23it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 17.66it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.93it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.14it/s]\u001b[A\n",
            "epoch 528 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.95it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:56:41 | INFO | dev_asr_nya | epoch 528 | valid on 'dev_asr_nya' subset | loss 1.659 | nll_loss 0.859 | total 3156.42 | n_correct 2639.58 | ppl 1.81 | accuracy 83.626 | wps 89903 | wpb 3156.4 | bsz 32.7 | num_updates 11607 | best_loss 1.636\n",
            "2022-12-24 22:56:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 528 @ 11607 updates\n",
            "2022-12-24 22:56:41 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint528.pt\n",
            "2022-12-24 22:56:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint528.pt\n",
            "2022-12-24 22:56:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint528.pt (epoch 528 @ 11607 updates, score 1.659) (writing took 7.828143741000531 seconds)\n",
            "2022-12-24 22:56:49 | INFO | fairseq_cli.train | end of epoch 528 (average epoch stats below)\n",
            "2022-12-24 22:56:49 | INFO | train | epoch 528 | loss 1.434 | nll_loss 0.671 | total 35852.4 | n_correct 31757 | ppl 1.59 | accuracy 88.577 | wps 30000.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11607 | lr 2.78459e-05 | gnorm 2.018 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.4 | wall 16183\n",
            "2022-12-24 22:56:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 529:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:56:49 | INFO | fairseq.trainer | begin training epoch 529\n",
            "2022-12-24 22:56:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 529:  95% 21/22 [00:16<00:00,  1.35it/s]2022-12-24 22:57:06 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.04it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.28it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.42it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.62it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.06it/s]\u001b[A\n",
            "epoch 529 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.48it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:57:07 | INFO | dev_asr_nya | epoch 529 | valid on 'dev_asr_nya' subset | loss 1.669 | nll_loss 0.873 | total 3156.42 | n_correct 2632.47 | ppl 1.83 | accuracy 83.401 | wps 88764.1 | wpb 3156.4 | bsz 32.7 | num_updates 11629 | best_loss 1.636\n",
            "2022-12-24 22:57:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 529 @ 11629 updates\n",
            "2022-12-24 22:57:07 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint529.pt\n",
            "2022-12-24 22:57:11 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint529.pt\n",
            "2022-12-24 22:57:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint529.pt (epoch 529 @ 11629 updates, score 1.669) (writing took 10.053985869002645 seconds)\n",
            "2022-12-24 22:57:17 | INFO | fairseq_cli.train | end of epoch 529 (average epoch stats below)\n",
            "2022-12-24 22:57:17 | INFO | train | epoch 529 | loss 1.426 | nll_loss 0.662 | total 35852.4 | n_correct 31850.5 | ppl 1.58 | accuracy 88.838 | wps 27922.6 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 11629 | lr 2.78195e-05 | gnorm 1.347 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.1 | wall 16211\n",
            "2022-12-24 22:57:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 530:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:57:17 | INFO | fairseq.trainer | begin training epoch 530\n",
            "2022-12-24 22:57:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 530:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 22:57:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.17it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.99it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.06it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.02it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 22.80it/s]\u001b[A\n",
            "epoch 530 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 25.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:57:36 | INFO | dev_asr_nya | epoch 530 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.836 | total 3156.42 | n_correct 2658.95 | ppl 1.78 | accuracy 84.239 | wps 83850.2 | wpb 3156.4 | bsz 32.7 | num_updates 11651 | best_loss 1.636\n",
            "2022-12-24 22:57:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 530 @ 11651 updates\n",
            "2022-12-24 22:57:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint530.pt\n",
            "2022-12-24 22:57:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint530.pt\n",
            "2022-12-24 22:57:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint530.pt (epoch 530 @ 11651 updates, score 1.638) (writing took 7.747410623000178 seconds)\n",
            "2022-12-24 22:57:44 | INFO | fairseq_cli.train | end of epoch 530 (average epoch stats below)\n",
            "2022-12-24 22:57:44 | INFO | train | epoch 530 | loss 1.423 | nll_loss 0.659 | total 35852.4 | n_correct 31882.1 | ppl 1.58 | accuracy 88.926 | wps 29781.6 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11651 | lr 2.77933e-05 | gnorm 1.223 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 16237\n",
            "2022-12-24 22:57:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 531:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:57:44 | INFO | fairseq.trainer | begin training epoch 531\n",
            "2022-12-24 22:57:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 531:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 22:58:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.44it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.68it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.48it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.15it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.37it/s]\u001b[A\n",
            "epoch 531 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:58:02 | INFO | dev_asr_nya | epoch 531 | valid on 'dev_asr_nya' subset | loss 1.647 | nll_loss 0.847 | total 3156.42 | n_correct 2647.89 | ppl 1.8 | accuracy 83.889 | wps 90429.6 | wpb 3156.4 | bsz 32.7 | num_updates 11673 | best_loss 1.636\n",
            "2022-12-24 22:58:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 531 @ 11673 updates\n",
            "2022-12-24 22:58:02 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint531.pt\n",
            "2022-12-24 22:58:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint531.pt\n",
            "2022-12-24 22:58:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint531.pt (epoch 531 @ 11673 updates, score 1.647) (writing took 7.716888171999017 seconds)\n",
            "2022-12-24 22:58:10 | INFO | fairseq_cli.train | end of epoch 531 (average epoch stats below)\n",
            "2022-12-24 22:58:10 | INFO | train | epoch 531 | loss 1.422 | nll_loss 0.658 | total 35852.4 | n_correct 31877 | ppl 1.58 | accuracy 88.912 | wps 30143.7 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11673 | lr 2.77671e-05 | gnorm 1.472 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 16264\n",
            "2022-12-24 22:58:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 532:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:58:10 | INFO | fairseq.trainer | begin training epoch 532\n",
            "2022-12-24 22:58:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 532:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:58:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.09it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.44it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.02it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.58it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.40it/s]\u001b[A\n",
            "epoch 532 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.95it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:58:28 | INFO | dev_asr_nya | epoch 532 | valid on 'dev_asr_nya' subset | loss 1.647 | nll_loss 0.846 | total 3156.42 | n_correct 2647.32 | ppl 1.8 | accuracy 83.871 | wps 93895.2 | wpb 3156.4 | bsz 32.7 | num_updates 11695 | best_loss 1.636\n",
            "2022-12-24 22:58:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 532 @ 11695 updates\n",
            "2022-12-24 22:58:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint532.pt\n",
            "2022-12-24 22:58:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint532.pt\n",
            "2022-12-24 22:58:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint532.pt (epoch 532 @ 11695 updates, score 1.647) (writing took 7.758898533997126 seconds)\n",
            "2022-12-24 22:58:36 | INFO | fairseq_cli.train | end of epoch 532 (average epoch stats below)\n",
            "2022-12-24 22:58:36 | INFO | train | epoch 532 | loss 1.42 | nll_loss 0.655 | total 35852.4 | n_correct 31896.3 | ppl 1.57 | accuracy 88.966 | wps 30147.1 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11695 | lr 2.77409e-05 | gnorm 1.295 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 16290\n",
            "2022-12-24 22:58:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 533:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:58:36 | INFO | fairseq.trainer | begin training epoch 533\n",
            "2022-12-24 22:58:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 533:  95% 21/22 [00:16<00:00,  1.31it/s, loss=1.424, nll_loss=0.66, total=35839.8, n_correct=31850.6, ppl=1.58, accuracy=88.869, wps=28584.3, ups=0.8, wpb=35839.8, bsz=367.9, num_updates=11700, lr=2.7735e-05, gnorm=1.442, clip=0, loss_scale=4, train_wall=78, gb_free=31.2, wall=16294]2022-12-24 22:58:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.16it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.89it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.36it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.81it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.01it/s]\u001b[A\n",
            "epoch 533 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.01it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:58:55 | INFO | dev_asr_nya | epoch 533 | valid on 'dev_asr_nya' subset | loss 1.652 | nll_loss 0.851 | total 3156.42 | n_correct 2647.11 | ppl 1.8 | accuracy 83.864 | wps 88690.7 | wpb 3156.4 | bsz 32.7 | num_updates 11717 | best_loss 1.636\n",
            "2022-12-24 22:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 533 @ 11717 updates\n",
            "2022-12-24 22:58:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint533.pt\n",
            "2022-12-24 22:58:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint533.pt\n",
            "2022-12-24 22:59:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint533.pt (epoch 533 @ 11717 updates, score 1.652) (writing took 8.139938391999749 seconds)\n",
            "2022-12-24 22:59:03 | INFO | fairseq_cli.train | end of epoch 533 (average epoch stats below)\n",
            "2022-12-24 22:59:03 | INFO | train | epoch 533 | loss 1.427 | nll_loss 0.664 | total 35852.4 | n_correct 31824.4 | ppl 1.58 | accuracy 88.765 | wps 29630.2 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11717 | lr 2.77149e-05 | gnorm 1.927 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 28.8 | wall 16316\n",
            "2022-12-24 22:59:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 534:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:59:03 | INFO | fairseq.trainer | begin training epoch 534\n",
            "2022-12-24 22:59:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 534:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 22:59:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.87it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.25it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 16.29it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.51it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.56it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.38it/s]\u001b[A\n",
            "epoch 534 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:59:21 | INFO | dev_asr_nya | epoch 534 | valid on 'dev_asr_nya' subset | loss 1.634 | nll_loss 0.831 | total 3156.42 | n_correct 2659.68 | ppl 1.78 | accuracy 84.263 | wps 84033.5 | wpb 3156.4 | bsz 32.7 | num_updates 11739 | best_loss 1.634\n",
            "2022-12-24 22:59:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 534 @ 11739 updates\n",
            "2022-12-24 22:59:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint534.pt\n",
            "2022-12-24 22:59:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint534.pt\n",
            "2022-12-24 22:59:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint534.pt (epoch 534 @ 11739 updates, score 1.634) (writing took 13.565276729998004 seconds)\n",
            "2022-12-24 22:59:35 | INFO | fairseq_cli.train | end of epoch 534 (average epoch stats below)\n",
            "2022-12-24 22:59:35 | INFO | train | epoch 534 | loss 1.425 | nll_loss 0.662 | total 35852.4 | n_correct 31835 | ppl 1.58 | accuracy 88.795 | wps 24452.1 | ups 0.68 | wpb 35852.4 | bsz 368.4 | num_updates 11739 | lr 2.76889e-05 | gnorm 2.147 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.1 | wall 16349\n",
            "2022-12-24 22:59:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 535:   0% 0/22 [00:00<?, ?it/s]2022-12-24 22:59:35 | INFO | fairseq.trainer | begin training epoch 535\n",
            "2022-12-24 22:59:35 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 535:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 22:59:52 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.97it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.55it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.36it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.80it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.22it/s]\u001b[A\n",
            "epoch 535 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.76it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 22:59:53 | INFO | dev_asr_nya | epoch 535 | valid on 'dev_asr_nya' subset | loss 1.686 | nll_loss 0.896 | total 3156.42 | n_correct 2619.79 | ppl 1.86 | accuracy 82.999 | wps 91443.4 | wpb 3156.4 | bsz 32.7 | num_updates 11761 | best_loss 1.634\n",
            "2022-12-24 22:59:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 535 @ 11761 updates\n",
            "2022-12-24 22:59:53 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint535.pt\n",
            "2022-12-24 22:59:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint535.pt\n",
            "2022-12-24 23:00:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint535.pt (epoch 535 @ 11761 updates, score 1.686) (writing took 7.561473702000512 seconds)\n",
            "2022-12-24 23:00:01 | INFO | fairseq_cli.train | end of epoch 535 (average epoch stats below)\n",
            "2022-12-24 23:00:01 | INFO | train | epoch 535 | loss 1.422 | nll_loss 0.658 | total 35852.4 | n_correct 31873 | ppl 1.58 | accuracy 88.901 | wps 30483.7 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 11761 | lr 2.7663e-05 | gnorm 1.873 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 16374\n",
            "2022-12-24 23:00:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 536:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:00:01 | INFO | fairseq.trainer | begin training epoch 536\n",
            "2022-12-24 23:00:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 536:  95% 21/22 [00:17<00:00,  1.24it/s]2022-12-24 23:00:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.20it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.21it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.38it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 18.27it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.15it/s]\u001b[A\n",
            "epoch 536 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.39it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:00:20 | INFO | dev_asr_nya | epoch 536 | valid on 'dev_asr_nya' subset | loss 1.64 | nll_loss 0.837 | total 3156.42 | n_correct 2656.95 | ppl 1.79 | accuracy 84.176 | wps 83713.2 | wpb 3156.4 | bsz 32.7 | num_updates 11783 | best_loss 1.634\n",
            "2022-12-24 23:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 536 @ 11783 updates\n",
            "2022-12-24 23:00:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint536.pt\n",
            "2022-12-24 23:00:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint536.pt\n",
            "2022-12-24 23:00:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint536.pt (epoch 536 @ 11783 updates, score 1.64) (writing took 10.416014907998033 seconds)\n",
            "2022-12-24 23:00:30 | INFO | fairseq_cli.train | end of epoch 536 (average epoch stats below)\n",
            "2022-12-24 23:00:30 | INFO | train | epoch 536 | loss 1.424 | nll_loss 0.66 | total 35852.4 | n_correct 31845.1 | ppl 1.58 | accuracy 88.823 | wps 26947 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 11783 | lr 2.76372e-05 | gnorm 1.793 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.9 | wall 16404\n",
            "2022-12-24 23:00:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 537:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:00:30 | INFO | fairseq.trainer | begin training epoch 537\n",
            "2022-12-24 23:00:30 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 537:  95% 21/22 [00:16<00:00,  1.29it/s, loss=1.424, nll_loss=0.66, total=35845.8, n_correct=31846, ppl=1.58, accuracy=88.841, wps=29048.8, ups=0.81, wpb=35845.8, bsz=367.6, num_updates=11800, lr=2.76172e-05, gnorm=1.873, clip=0, loss_scale=4, train_wall=79, gb_free=29.6, wall=16417]2022-12-24 23:00:48 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.83it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.17it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 25.08it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.58it/s]\u001b[A\n",
            "epoch 537 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.55it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:00:48 | INFO | dev_asr_nya | epoch 537 | valid on 'dev_asr_nya' subset | loss 1.64 | nll_loss 0.837 | total 3156.42 | n_correct 2657.79 | ppl 1.79 | accuracy 84.203 | wps 94536.5 | wpb 3156.4 | bsz 32.7 | num_updates 11805 | best_loss 1.634\n",
            "2022-12-24 23:00:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 537 @ 11805 updates\n",
            "2022-12-24 23:00:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint537.pt\n",
            "2022-12-24 23:00:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint537.pt\n",
            "2022-12-24 23:00:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint537.pt (epoch 537 @ 11805 updates, score 1.64) (writing took 10.71074034400226 seconds)\n",
            "2022-12-24 23:00:59 | INFO | fairseq_cli.train | end of epoch 537 (average epoch stats below)\n",
            "2022-12-24 23:00:59 | INFO | train | epoch 537 | loss 1.414 | nll_loss 0.648 | total 35852.4 | n_correct 31951.5 | ppl 1.57 | accuracy 89.12 | wps 27218 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 11805 | lr 2.76114e-05 | gnorm 1.358 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 16433\n",
            "2022-12-24 23:00:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 538:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:00:59 | INFO | fairseq.trainer | begin training epoch 538\n",
            "2022-12-24 23:00:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 538:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 23:01:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.67it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.87it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.65it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.18it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.29it/s]\u001b[A\n",
            "epoch 538 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.70it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:01:18 | INFO | dev_asr_nya | epoch 538 | valid on 'dev_asr_nya' subset | loss 1.653 | nll_loss 0.855 | total 3156.42 | n_correct 2645.16 | ppl 1.81 | accuracy 83.802 | wps 92517.8 | wpb 3156.4 | bsz 32.7 | num_updates 11827 | best_loss 1.634\n",
            "2022-12-24 23:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 538 @ 11827 updates\n",
            "2022-12-24 23:01:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint538.pt\n",
            "2022-12-24 23:01:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint538.pt\n",
            "2022-12-24 23:01:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint538.pt (epoch 538 @ 11827 updates, score 1.653) (writing took 10.150116828001046 seconds)\n",
            "2022-12-24 23:01:28 | INFO | fairseq_cli.train | end of epoch 538 (average epoch stats below)\n",
            "2022-12-24 23:01:28 | INFO | train | epoch 538 | loss 1.412 | nll_loss 0.646 | total 35852.4 | n_correct 31963.3 | ppl 1.56 | accuracy 89.152 | wps 27529.9 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 11827 | lr 2.75857e-05 | gnorm 1.002 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 16461\n",
            "2022-12-24 23:01:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 539:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:01:28 | INFO | fairseq.trainer | begin training epoch 539\n",
            "2022-12-24 23:01:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 539:  95% 21/22 [00:17<00:00,  1.29it/s]2022-12-24 23:01:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.85it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.67it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.53it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.59it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.34it/s]\u001b[A\n",
            "epoch 539 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.11it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:01:46 | INFO | dev_asr_nya | epoch 539 | valid on 'dev_asr_nya' subset | loss 1.658 | nll_loss 0.86 | total 3156.42 | n_correct 2641 | ppl 1.81 | accuracy 83.671 | wps 90350.8 | wpb 3156.4 | bsz 32.7 | num_updates 11849 | best_loss 1.634\n",
            "2022-12-24 23:01:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 539 @ 11849 updates\n",
            "2022-12-24 23:01:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint539.pt\n",
            "2022-12-24 23:01:52 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint539.pt\n",
            "2022-12-24 23:01:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint539.pt (epoch 539 @ 11849 updates, score 1.658) (writing took 10.01205296599801 seconds)\n",
            "2022-12-24 23:01:56 | INFO | fairseq_cli.train | end of epoch 539 (average epoch stats below)\n",
            "2022-12-24 23:01:56 | INFO | train | epoch 539 | loss 1.41 | nll_loss 0.644 | total 35852.4 | n_correct 31988.1 | ppl 1.56 | accuracy 89.222 | wps 27643.8 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 11849 | lr 2.75601e-05 | gnorm 1.08 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 16490\n",
            "2022-12-24 23:01:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 540:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:01:56 | INFO | fairseq.trainer | begin training epoch 540\n",
            "2022-12-24 23:01:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 540:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:02:14 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.66it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.83it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.84it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.34it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.28it/s]\u001b[A\n",
            "epoch 540 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.98it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:02:15 | INFO | dev_asr_nya | epoch 540 | valid on 'dev_asr_nya' subset | loss 1.645 | nll_loss 0.847 | total 3156.42 | n_correct 2651.53 | ppl 1.8 | accuracy 84.004 | wps 90372.2 | wpb 3156.4 | bsz 32.7 | num_updates 11871 | best_loss 1.634\n",
            "2022-12-24 23:02:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 540 @ 11871 updates\n",
            "2022-12-24 23:02:15 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint540.pt\n",
            "2022-12-24 23:02:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint540.pt\n",
            "2022-12-24 23:02:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint540.pt (epoch 540 @ 11871 updates, score 1.645) (writing took 10.383181750999938 seconds)\n",
            "2022-12-24 23:02:25 | INFO | fairseq_cli.train | end of epoch 540 (average epoch stats below)\n",
            "2022-12-24 23:02:25 | INFO | train | epoch 540 | loss 1.411 | nll_loss 0.644 | total 35852.4 | n_correct 31985 | ppl 1.56 | accuracy 89.213 | wps 27475.4 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 11871 | lr 2.75345e-05 | gnorm 1.251 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 16519\n",
            "2022-12-24 23:02:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 541:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:02:25 | INFO | fairseq.trainer | begin training epoch 541\n",
            "2022-12-24 23:02:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 541:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:02:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.71it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.04it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.90it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.51it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.12it/s]\u001b[A\n",
            "epoch 541 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:02:43 | INFO | dev_asr_nya | epoch 541 | valid on 'dev_asr_nya' subset | loss 1.654 | nll_loss 0.854 | total 3156.42 | n_correct 2647.53 | ppl 1.81 | accuracy 83.877 | wps 90599.3 | wpb 3156.4 | bsz 32.7 | num_updates 11893 | best_loss 1.634\n",
            "2022-12-24 23:02:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 541 @ 11893 updates\n",
            "2022-12-24 23:02:43 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint541.pt\n",
            "2022-12-24 23:02:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint541.pt\n",
            "2022-12-24 23:02:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint541.pt (epoch 541 @ 11893 updates, score 1.654) (writing took 8.469451249002304 seconds)\n",
            "2022-12-24 23:02:52 | INFO | fairseq_cli.train | end of epoch 541 (average epoch stats below)\n",
            "2022-12-24 23:02:52 | INFO | train | epoch 541 | loss 1.417 | nll_loss 0.653 | total 35852.4 | n_correct 31906.4 | ppl 1.57 | accuracy 88.994 | wps 29267 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 11893 | lr 2.7509e-05 | gnorm 2.027 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 16546\n",
            "2022-12-24 23:02:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 542:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:02:52 | INFO | fairseq.trainer | begin training epoch 542\n",
            "2022-12-24 23:02:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 542:  95% 21/22 [00:16<00:00,  1.30it/s, loss=1.413, nll_loss=0.647, total=35880.7, n_correct=31980.2, ppl=1.57, accuracy=89.129, wps=26772.5, ups=0.75, wpb=35880.7, bsz=369.3, num_updates=11900, lr=2.7501e-05, gnorm=1.427, clip=0, loss_scale=4, train_wall=78, gb_free=30.3, wall=16551]2022-12-24 23:03:09 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.55it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.90it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.57it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.28it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.82it/s]\u001b[A\n",
            "epoch 542 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.53it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:03:10 | INFO | dev_asr_nya | epoch 542 | valid on 'dev_asr_nya' subset | loss 1.644 | nll_loss 0.846 | total 3156.42 | n_correct 2650.89 | ppl 1.8 | accuracy 83.984 | wps 89041.8 | wpb 3156.4 | bsz 32.7 | num_updates 11915 | best_loss 1.634\n",
            "2022-12-24 23:03:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 542 @ 11915 updates\n",
            "2022-12-24 23:03:10 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint542.pt\n",
            "2022-12-24 23:03:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint542.pt\n",
            "2022-12-24 23:03:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint542.pt (epoch 542 @ 11915 updates, score 1.644) (writing took 7.770953384999302 seconds)\n",
            "2022-12-24 23:03:18 | INFO | fairseq_cli.train | end of epoch 542 (average epoch stats below)\n",
            "2022-12-24 23:03:18 | INFO | train | epoch 542 | loss 1.423 | nll_loss 0.659 | total 35852.4 | n_correct 31856.6 | ppl 1.58 | accuracy 88.855 | wps 30302.5 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 11915 | lr 2.74836e-05 | gnorm 2.441 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.6 | wall 16572\n",
            "2022-12-24 23:03:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 543:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:03:18 | INFO | fairseq.trainer | begin training epoch 543\n",
            "2022-12-24 23:03:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 543:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 23:03:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.19it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.56it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.61it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.48it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.59it/s]\u001b[A\n",
            "epoch 543 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:03:36 | INFO | dev_asr_nya | epoch 543 | valid on 'dev_asr_nya' subset | loss 1.664 | nll_loss 0.868 | total 3156.42 | n_correct 2636.84 | ppl 1.83 | accuracy 83.539 | wps 91593.8 | wpb 3156.4 | bsz 32.7 | num_updates 11937 | best_loss 1.634\n",
            "2022-12-24 23:03:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 543 @ 11937 updates\n",
            "2022-12-24 23:03:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint543.pt\n",
            "2022-12-24 23:03:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint543.pt\n",
            "2022-12-24 23:03:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint543.pt (epoch 543 @ 11937 updates, score 1.664) (writing took 7.786344691998238 seconds)\n",
            "2022-12-24 23:03:44 | INFO | fairseq_cli.train | end of epoch 543 (average epoch stats below)\n",
            "2022-12-24 23:03:44 | INFO | train | epoch 543 | loss 1.408 | nll_loss 0.642 | total 35852.4 | n_correct 32003.5 | ppl 1.56 | accuracy 89.265 | wps 29910.4 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 11937 | lr 2.74583e-05 | gnorm 1.162 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 16598\n",
            "2022-12-24 23:03:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 544:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:03:44 | INFO | fairseq.trainer | begin training epoch 544\n",
            "2022-12-24 23:03:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 544:  95% 21/22 [00:16<00:00,  1.26it/s]2022-12-24 23:04:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.19it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.51it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.32it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.75it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.20it/s]\u001b[A\n",
            "epoch 544 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:04:03 | INFO | dev_asr_nya | epoch 544 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.838 | total 3156.42 | n_correct 2658 | ppl 1.79 | accuracy 84.209 | wps 91279.8 | wpb 3156.4 | bsz 32.7 | num_updates 11959 | best_loss 1.634\n",
            "2022-12-24 23:04:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 544 @ 11959 updates\n",
            "2022-12-24 23:04:03 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint544.pt\n",
            "2022-12-24 23:04:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint544.pt\n",
            "2022-12-24 23:04:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint544.pt (epoch 544 @ 11959 updates, score 1.638) (writing took 7.670216933998745 seconds)\n",
            "2022-12-24 23:04:11 | INFO | fairseq_cli.train | end of epoch 544 (average epoch stats below)\n",
            "2022-12-24 23:04:11 | INFO | train | epoch 544 | loss 1.408 | nll_loss 0.641 | total 35852.4 | n_correct 32018.6 | ppl 1.56 | accuracy 89.307 | wps 30049.8 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11959 | lr 2.7433e-05 | gnorm 1.564 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.7 | wall 16624\n",
            "2022-12-24 23:04:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 545:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:04:11 | INFO | fairseq.trainer | begin training epoch 545\n",
            "2022-12-24 23:04:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 545:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 23:04:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  6.99it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.05it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.33it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.52it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.67it/s]\u001b[A\n",
            "epoch 545 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.22it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:04:29 | INFO | dev_asr_nya | epoch 545 | valid on 'dev_asr_nya' subset | loss 1.689 | nll_loss 0.897 | total 3156.42 | n_correct 2619.05 | ppl 1.86 | accuracy 82.975 | wps 90770.8 | wpb 3156.4 | bsz 32.7 | num_updates 11981 | best_loss 1.634\n",
            "2022-12-24 23:04:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 545 @ 11981 updates\n",
            "2022-12-24 23:04:29 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint545.pt\n",
            "2022-12-24 23:04:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint545.pt\n",
            "2022-12-24 23:04:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint545.pt (epoch 545 @ 11981 updates, score 1.689) (writing took 7.779947368002468 seconds)\n",
            "2022-12-24 23:04:37 | INFO | fairseq_cli.train | end of epoch 545 (average epoch stats below)\n",
            "2022-12-24 23:04:37 | INFO | train | epoch 545 | loss 1.413 | nll_loss 0.648 | total 35852.4 | n_correct 31945.6 | ppl 1.57 | accuracy 89.103 | wps 30006 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 11981 | lr 2.74078e-05 | gnorm 2.112 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 16651\n",
            "2022-12-24 23:04:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 546:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:04:37 | INFO | fairseq.trainer | begin training epoch 546\n",
            "2022-12-24 23:04:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 546:  95% 21/22 [00:16<00:00,  1.28it/s, loss=1.412, nll_loss=0.646, total=35879.4, n_correct=31994.2, ppl=1.56, accuracy=89.172, wps=31327.9, ups=0.87, wpb=35879.4, bsz=367.7, num_updates=12000, lr=2.73861e-05, gnorm=1.727, clip=0, loss_scale=4, train_wall=78, gb_free=31.5, wall=16666]2022-12-24 23:04:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.30it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.30it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.48it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.92it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.13it/s]\u001b[A\n",
            "epoch 546 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.64it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:04:55 | INFO | dev_asr_nya | epoch 546 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.853 | total 3156.42 | n_correct 2652.47 | ppl 1.81 | accuracy 84.034 | wps 90130.6 | wpb 3156.4 | bsz 32.7 | num_updates 12003 | best_loss 1.634\n",
            "2022-12-24 23:04:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 546 @ 12003 updates\n",
            "2022-12-24 23:04:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint546.pt\n",
            "2022-12-24 23:04:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint546.pt\n",
            "2022-12-24 23:05:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint546.pt (epoch 546 @ 12003 updates, score 1.651) (writing took 7.602084381000168 seconds)\n",
            "2022-12-24 23:05:03 | INFO | fairseq_cli.train | end of epoch 546 (average epoch stats below)\n",
            "2022-12-24 23:05:03 | INFO | train | epoch 546 | loss 1.407 | nll_loss 0.641 | total 35852.4 | n_correct 32009.2 | ppl 1.56 | accuracy 89.281 | wps 30268.8 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 12003 | lr 2.73827e-05 | gnorm 1.638 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32.1 | wall 16677\n",
            "2022-12-24 23:05:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 547:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:05:03 | INFO | fairseq.trainer | begin training epoch 547\n",
            "2022-12-24 23:05:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 547:  95% 21/22 [00:16<00:00,  1.26it/s]2022-12-24 23:05:20 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.43it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.92it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.77it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.85it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.54it/s]\u001b[A\n",
            "epoch 547 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:05:21 | INFO | dev_asr_nya | epoch 547 | valid on 'dev_asr_nya' subset | loss 1.69 | nll_loss 0.9 | total 3156.42 | n_correct 2616.37 | ppl 1.87 | accuracy 82.89 | wps 92802.1 | wpb 3156.4 | bsz 32.7 | num_updates 12025 | best_loss 1.634\n",
            "2022-12-24 23:05:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 547 @ 12025 updates\n",
            "2022-12-24 23:05:21 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint547.pt\n",
            "2022-12-24 23:05:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint547.pt\n",
            "2022-12-24 23:05:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint547.pt (epoch 547 @ 12025 updates, score 1.69) (writing took 7.879612626999005 seconds)\n",
            "2022-12-24 23:05:29 | INFO | fairseq_cli.train | end of epoch 547 (average epoch stats below)\n",
            "2022-12-24 23:05:29 | INFO | train | epoch 547 | loss 1.407 | nll_loss 0.641 | total 35852.4 | n_correct 32001.5 | ppl 1.56 | accuracy 89.259 | wps 30018.2 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 12025 | lr 2.73576e-05 | gnorm 1.844 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 16703\n",
            "2022-12-24 23:05:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 548:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:05:29 | INFO | fairseq.trainer | begin training epoch 548\n",
            "2022-12-24 23:05:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 548:  95% 21/22 [00:17<00:00,  1.22it/s]2022-12-24 23:05:47 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.30it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.64it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.92it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.32it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.55it/s]\u001b[A\n",
            "epoch 548 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.02it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:05:48 | INFO | dev_asr_nya | epoch 548 | valid on 'dev_asr_nya' subset | loss 1.654 | nll_loss 0.857 | total 3156.42 | n_correct 2645.47 | ppl 1.81 | accuracy 83.812 | wps 92855.4 | wpb 3156.4 | bsz 32.7 | num_updates 12047 | best_loss 1.634\n",
            "2022-12-24 23:05:48 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 548 @ 12047 updates\n",
            "2022-12-24 23:05:48 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint548.pt\n",
            "2022-12-24 23:05:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint548.pt\n",
            "2022-12-24 23:05:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint548.pt (epoch 548 @ 12047 updates, score 1.654) (writing took 9.89367435299937 seconds)\n",
            "2022-12-24 23:05:58 | INFO | fairseq_cli.train | end of epoch 548 (average epoch stats below)\n",
            "2022-12-24 23:05:58 | INFO | train | epoch 548 | loss 1.404 | nll_loss 0.637 | total 35852.4 | n_correct 32029.7 | ppl 1.56 | accuracy 89.338 | wps 27253 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 12047 | lr 2.73327e-05 | gnorm 1.571 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 30.8 | wall 16732\n",
            "2022-12-24 23:05:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 549:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:05:58 | INFO | fairseq.trainer | begin training epoch 549\n",
            "2022-12-24 23:05:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 549:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 23:06:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.37it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.64it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.98it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.75it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.38it/s]\u001b[A\n",
            "epoch 549 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.92it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:06:17 | INFO | dev_asr_nya | epoch 549 | valid on 'dev_asr_nya' subset | loss 1.664 | nll_loss 0.868 | total 3156.42 | n_correct 2638.63 | ppl 1.82 | accuracy 83.596 | wps 89580.8 | wpb 3156.4 | bsz 32.7 | num_updates 12069 | best_loss 1.634\n",
            "2022-12-24 23:06:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 549 @ 12069 updates\n",
            "2022-12-24 23:06:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint549.pt\n",
            "2022-12-24 23:06:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint549.pt\n",
            "2022-12-24 23:06:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint549.pt (epoch 549 @ 12069 updates, score 1.664) (writing took 8.80040589499913 seconds)\n",
            "2022-12-24 23:06:25 | INFO | fairseq_cli.train | end of epoch 549 (average epoch stats below)\n",
            "2022-12-24 23:06:26 | INFO | train | epoch 549 | loss 1.399 | nll_loss 0.631 | total 35852.4 | n_correct 32085.6 | ppl 1.55 | accuracy 89.494 | wps 28773.6 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 12069 | lr 2.73077e-05 | gnorm 0.915 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 16759\n",
            "2022-12-24 23:06:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 550:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:06:26 | INFO | fairseq.trainer | begin training epoch 550\n",
            "2022-12-24 23:06:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 550:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 23:06:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.44it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.36it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.06it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.62it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.02it/s]\u001b[A\n",
            "epoch 550 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.28it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:06:44 | INFO | dev_asr_nya | epoch 550 | valid on 'dev_asr_nya' subset | loss 1.635 | nll_loss 0.834 | total 3156.42 | n_correct 2662.63 | ppl 1.78 | accuracy 84.356 | wps 88570.4 | wpb 3156.4 | bsz 32.7 | num_updates 12091 | best_loss 1.634\n",
            "2022-12-24 23:06:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 550 @ 12091 updates\n",
            "2022-12-24 23:06:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint550.pt\n",
            "2022-12-24 23:06:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint550.pt\n",
            "2022-12-24 23:06:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint550.pt (epoch 550 @ 12091 updates, score 1.635) (writing took 8.25276480499815 seconds)\n",
            "2022-12-24 23:06:52 | INFO | fairseq_cli.train | end of epoch 550 (average epoch stats below)\n",
            "2022-12-24 23:06:52 | INFO | train | epoch 550 | loss 1.399 | nll_loss 0.632 | total 35852.4 | n_correct 32092.2 | ppl 1.55 | accuracy 89.512 | wps 29507.9 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 12091 | lr 2.72829e-05 | gnorm 0.963 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.3 | wall 16786\n",
            "2022-12-24 23:06:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 551:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:06:52 | INFO | fairseq.trainer | begin training epoch 551\n",
            "2022-12-24 23:06:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 551:  95% 21/22 [00:16<00:00,  1.30it/s, loss=1.402, nll_loss=0.635, total=35750.4, n_correct=31962.3, ppl=1.55, accuracy=89.404, wps=28065.7, ups=0.79, wpb=35750.4, bsz=367, num_updates=12100, lr=2.72727e-05, gnorm=1.31, clip=0, loss_scale=4, train_wall=79, gb_free=28.8, wall=16793]2022-12-24 23:07:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.18it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.20it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.21it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.93it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.49it/s]\u001b[A\n",
            "epoch 551 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.50it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:07:11 | INFO | dev_asr_nya | epoch 551 | valid on 'dev_asr_nya' subset | loss 1.65 | nll_loss 0.852 | total 3156.42 | n_correct 2649.79 | ppl 1.81 | accuracy 83.949 | wps 93593.2 | wpb 3156.4 | bsz 32.7 | num_updates 12113 | best_loss 1.634\n",
            "2022-12-24 23:07:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 551 @ 12113 updates\n",
            "2022-12-24 23:07:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint551.pt\n",
            "2022-12-24 23:07:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint551.pt\n",
            "2022-12-24 23:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint551.pt (epoch 551 @ 12113 updates, score 1.65) (writing took 9.604185426000186 seconds)\n",
            "2022-12-24 23:07:20 | INFO | fairseq_cli.train | end of epoch 551 (average epoch stats below)\n",
            "2022-12-24 23:07:20 | INFO | train | epoch 551 | loss 1.395 | nll_loss 0.627 | total 35852.4 | n_correct 32124 | ppl 1.54 | accuracy 89.601 | wps 28278.8 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12113 | lr 2.72581e-05 | gnorm 1.02 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 16814\n",
            "2022-12-24 23:07:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 552:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:07:20 | INFO | fairseq.trainer | begin training epoch 552\n",
            "2022-12-24 23:07:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 552:  95% 21/22 [00:17<00:00,  1.27it/s]2022-12-24 23:07:38 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.74it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.22it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.79it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.95it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 27.01it/s]\u001b[A\n",
            "epoch 552 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.43it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:07:39 | INFO | dev_asr_nya | epoch 552 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.839 | total 3156.42 | n_correct 2657 | ppl 1.79 | accuracy 84.178 | wps 95129.1 | wpb 3156.4 | bsz 32.7 | num_updates 12135 | best_loss 1.634\n",
            "2022-12-24 23:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 552 @ 12135 updates\n",
            "2022-12-24 23:07:39 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint552.pt\n",
            "2022-12-24 23:07:44 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint552.pt\n",
            "2022-12-24 23:07:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint552.pt (epoch 552 @ 12135 updates, score 1.638) (writing took 9.751962092002941 seconds)\n",
            "2022-12-24 23:07:49 | INFO | fairseq_cli.train | end of epoch 552 (average epoch stats below)\n",
            "2022-12-24 23:07:49 | INFO | train | epoch 552 | loss 1.394 | nll_loss 0.626 | total 35852.4 | n_correct 32133.8 | ppl 1.54 | accuracy 89.628 | wps 27543.6 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 12135 | lr 2.72334e-05 | gnorm 0.934 | clip 0 | loss_scale 4 | train_wall 18 | gb_free 32 | wall 16842\n",
            "2022-12-24 23:07:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 553:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:07:49 | INFO | fairseq.trainer | begin training epoch 553\n",
            "2022-12-24 23:07:49 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 553:  95% 21/22 [00:16<00:00,  1.26it/s]2022-12-24 23:08:06 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.05it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.62it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.67it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.54it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.20it/s]\u001b[A\n",
            "epoch 553 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:08:07 | INFO | dev_asr_nya | epoch 553 | valid on 'dev_asr_nya' subset | loss 1.636 | nll_loss 0.837 | total 3156.42 | n_correct 2659.53 | ppl 1.79 | accuracy 84.258 | wps 89882.7 | wpb 3156.4 | bsz 32.7 | num_updates 12157 | best_loss 1.634\n",
            "2022-12-24 23:08:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 553 @ 12157 updates\n",
            "2022-12-24 23:08:07 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint553.pt\n",
            "2022-12-24 23:08:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint553.pt\n",
            "2022-12-24 23:08:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint553.pt (epoch 553 @ 12157 updates, score 1.636) (writing took 10.3672915620009 seconds)\n",
            "2022-12-24 23:08:18 | INFO | fairseq_cli.train | end of epoch 553 (average epoch stats below)\n",
            "2022-12-24 23:08:18 | INFO | train | epoch 553 | loss 1.398 | nll_loss 0.631 | total 35852.4 | n_correct 32087.1 | ppl 1.55 | accuracy 89.498 | wps 27293.9 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 12157 | lr 2.72087e-05 | gnorm 1.526 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.8 | wall 16871\n",
            "2022-12-24 23:08:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 554:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:08:18 | INFO | fairseq.trainer | begin training epoch 554\n",
            "2022-12-24 23:08:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 554:  95% 21/22 [00:17<00:00,  1.25it/s]2022-12-24 23:08:35 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.11it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.01it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.04it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.55it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.01it/s]\u001b[A\n",
            "epoch 554 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:08:36 | INFO | dev_asr_nya | epoch 554 | valid on 'dev_asr_nya' subset | loss 1.637 | nll_loss 0.837 | total 3156.42 | n_correct 2655.89 | ppl 1.79 | accuracy 84.143 | wps 90796.8 | wpb 3156.4 | bsz 32.7 | num_updates 12179 | best_loss 1.634\n",
            "2022-12-24 23:08:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 554 @ 12179 updates\n",
            "2022-12-24 23:08:36 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint554.pt\n",
            "2022-12-24 23:08:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint554.pt\n",
            "2022-12-24 23:08:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint554.pt (epoch 554 @ 12179 updates, score 1.637) (writing took 8.978255638998235 seconds)\n",
            "2022-12-24 23:08:45 | INFO | fairseq_cli.train | end of epoch 554 (average epoch stats below)\n",
            "2022-12-24 23:08:45 | INFO | train | epoch 554 | loss 1.409 | nll_loss 0.644 | total 35852.4 | n_correct 31964.4 | ppl 1.56 | accuracy 89.156 | wps 28562.7 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 12179 | lr 2.71841e-05 | gnorm 2.683 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 16899\n",
            "2022-12-24 23:08:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 555:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:08:45 | INFO | fairseq.trainer | begin training epoch 555\n",
            "2022-12-24 23:08:45 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 555:  95% 21/22 [00:16<00:00,  1.31it/s, loss=1.4, nll_loss=0.633, total=35918, n_correct=32122.7, ppl=1.55, accuracy=89.434, wps=29399.9, ups=0.82, wpb=35918, bsz=369.6, num_updates=12200, lr=2.71607e-05, gnorm=1.618, clip=0, loss_scale=4, train_wall=78, gb_free=30.7, wall=16916]2022-12-24 23:09:02 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.71it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.12it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.20it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.98it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.08it/s]\u001b[A\n",
            "epoch 555 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 27.52it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:09:03 | INFO | dev_asr_nya | epoch 555 | valid on 'dev_asr_nya' subset | loss 1.64 | nll_loss 0.841 | total 3156.42 | n_correct 2656.05 | ppl 1.79 | accuracy 84.148 | wps 88922.1 | wpb 3156.4 | bsz 32.7 | num_updates 12201 | best_loss 1.634\n",
            "2022-12-24 23:09:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 555 @ 12201 updates\n",
            "2022-12-24 23:09:03 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint555.pt\n",
            "2022-12-24 23:09:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint555.pt\n",
            "2022-12-24 23:09:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint555.pt (epoch 555 @ 12201 updates, score 1.64) (writing took 8.106562298999052 seconds)\n",
            "2022-12-24 23:09:11 | INFO | fairseq_cli.train | end of epoch 555 (average epoch stats below)\n",
            "2022-12-24 23:09:11 | INFO | train | epoch 555 | loss 1.403 | nll_loss 0.637 | total 35852.4 | n_correct 32023.6 | ppl 1.56 | accuracy 89.321 | wps 30203.3 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 12201 | lr 2.71596e-05 | gnorm 1.745 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 16925\n",
            "2022-12-24 23:09:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 556:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:09:11 | INFO | fairseq.trainer | begin training epoch 556\n",
            "2022-12-24 23:09:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 556:  95% 21/22 [00:17<00:00,  1.32it/s]2022-12-24 23:09:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.42it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.72it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.04it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.41it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.60it/s]\u001b[A\n",
            "epoch 556 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.26it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:09:30 | INFO | dev_asr_nya | epoch 556 | valid on 'dev_asr_nya' subset | loss 1.647 | nll_loss 0.847 | total 3156.42 | n_correct 2650.63 | ppl 1.8 | accuracy 83.976 | wps 90936.9 | wpb 3156.4 | bsz 32.7 | num_updates 12223 | best_loss 1.634\n",
            "2022-12-24 23:09:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 556 @ 12223 updates\n",
            "2022-12-24 23:09:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint556.pt\n",
            "2022-12-24 23:09:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint556.pt\n",
            "2022-12-24 23:09:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint556.pt (epoch 556 @ 12223 updates, score 1.647) (writing took 7.916657344998384 seconds)\n",
            "2022-12-24 23:09:38 | INFO | fairseq_cli.train | end of epoch 556 (average epoch stats below)\n",
            "2022-12-24 23:09:38 | INFO | train | epoch 556 | loss 1.395 | nll_loss 0.627 | total 35852.4 | n_correct 32113.8 | ppl 1.54 | accuracy 89.572 | wps 29626.9 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 12223 | lr 2.71352e-05 | gnorm 1.526 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.8 | wall 16952\n",
            "2022-12-24 23:09:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 557:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:09:38 | INFO | fairseq.trainer | begin training epoch 557\n",
            "2022-12-24 23:09:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 557:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:09:55 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.73it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.95it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.78it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.85it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.55it/s]\u001b[A\n",
            "epoch 557 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 30.00it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:09:56 | INFO | dev_asr_nya | epoch 557 | valid on 'dev_asr_nya' subset | loss 1.65 | nll_loss 0.853 | total 3156.42 | n_correct 2650.47 | ppl 1.81 | accuracy 83.971 | wps 94097.4 | wpb 3156.4 | bsz 32.7 | num_updates 12245 | best_loss 1.634\n",
            "2022-12-24 23:09:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 557 @ 12245 updates\n",
            "2022-12-24 23:09:56 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint557.pt\n",
            "2022-12-24 23:09:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint557.pt\n",
            "2022-12-24 23:10:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint557.pt (epoch 557 @ 12245 updates, score 1.65) (writing took 7.621747746998153 seconds)\n",
            "2022-12-24 23:10:04 | INFO | fairseq_cli.train | end of epoch 557 (average epoch stats below)\n",
            "2022-12-24 23:10:04 | INFO | train | epoch 557 | loss 1.39 | nll_loss 0.621 | total 35852.4 | n_correct 32164.5 | ppl 1.54 | accuracy 89.714 | wps 30778.2 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 12245 | lr 2.71108e-05 | gnorm 0.863 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 16977\n",
            "2022-12-24 23:10:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 558:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:10:04 | INFO | fairseq.trainer | begin training epoch 558\n",
            "2022-12-24 23:10:04 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 558:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:10:21 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.22it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.50it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.22it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.20it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 27.22it/s]\u001b[A\n",
            "epoch 558 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:10:22 | INFO | dev_asr_nya | epoch 558 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.854 | total 3156.42 | n_correct 2647.79 | ppl 1.81 | accuracy 83.886 | wps 95685.3 | wpb 3156.4 | bsz 32.7 | num_updates 12267 | best_loss 1.634\n",
            "2022-12-24 23:10:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 558 @ 12267 updates\n",
            "2022-12-24 23:10:22 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint558.pt\n",
            "2022-12-24 23:10:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint558.pt\n",
            "2022-12-24 23:10:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint558.pt (epoch 558 @ 12267 updates, score 1.651) (writing took 7.666488095001114 seconds)\n",
            "2022-12-24 23:10:29 | INFO | fairseq_cli.train | end of epoch 558 (average epoch stats below)\n",
            "2022-12-24 23:10:29 | INFO | train | epoch 558 | loss 1.393 | nll_loss 0.625 | total 35852.4 | n_correct 32135.8 | ppl 1.54 | accuracy 89.634 | wps 30771 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 12267 | lr 2.70864e-05 | gnorm 1.606 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 17003\n",
            "2022-12-24 23:10:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 559:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:10:29 | INFO | fairseq.trainer | begin training epoch 559\n",
            "2022-12-24 23:10:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 559:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:10:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.82it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.37it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.43it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.60it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.39it/s]\u001b[A\n",
            "epoch 559 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.88it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:10:47 | INFO | dev_asr_nya | epoch 559 | valid on 'dev_asr_nya' subset | loss 1.624 | nll_loss 0.822 | total 3156.42 | n_correct 2670.68 | ppl 1.77 | accuracy 84.611 | wps 94454.7 | wpb 3156.4 | bsz 32.7 | num_updates 12289 | best_loss 1.624\n",
            "2022-12-24 23:10:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 559 @ 12289 updates\n",
            "2022-12-24 23:10:47 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint559.pt\n",
            "2022-12-24 23:10:50 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint559.pt\n",
            "2022-12-24 23:11:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint559.pt (epoch 559 @ 12289 updates, score 1.624) (writing took 32.85960044300009 seconds)\n",
            "2022-12-24 23:11:20 | INFO | fairseq_cli.train | end of epoch 559 (average epoch stats below)\n",
            "2022-12-24 23:11:20 | INFO | train | epoch 559 | loss 1.388 | nll_loss 0.619 | total 35852.4 | n_correct 32185.3 | ppl 1.54 | accuracy 89.772 | wps 15564.8 | ups 0.43 | wpb 35852.4 | bsz 368.4 | num_updates 12289 | lr 2.70622e-05 | gnorm 1.052 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 17054\n",
            "2022-12-24 23:11:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 560:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:11:20 | INFO | fairseq.trainer | begin training epoch 560\n",
            "2022-12-24 23:11:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 560:  95% 21/22 [00:16<00:00,  1.30it/s, loss=1.392, nll_loss=0.623, total=35785.3, n_correct=32089.4, ppl=1.54, accuracy=89.672, wps=24355.8, ups=0.68, wpb=35785.3, bsz=366.5, num_updates=12300, lr=2.70501e-05, gnorm=1.29, clip=0, loss_scale=4, train_wall=77, gb_free=30.7, wall=17062]2022-12-24 23:11:37 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.98it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.72it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.87it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.45it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.78it/s]\u001b[A\n",
            "epoch 560 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.77it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:11:38 | INFO | dev_asr_nya | epoch 560 | valid on 'dev_asr_nya' subset | loss 1.645 | nll_loss 0.847 | total 3156.42 | n_correct 2653.26 | ppl 1.8 | accuracy 84.059 | wps 89241.9 | wpb 3156.4 | bsz 32.7 | num_updates 12311 | best_loss 1.624\n",
            "2022-12-24 23:11:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 560 @ 12311 updates\n",
            "2022-12-24 23:11:38 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint560.pt\n",
            "2022-12-24 23:11:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint560.pt\n",
            "2022-12-24 23:11:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint560.pt (epoch 560 @ 12311 updates, score 1.645) (writing took 7.700834859999304 seconds)\n",
            "2022-12-24 23:11:46 | INFO | fairseq_cli.train | end of epoch 560 (average epoch stats below)\n",
            "2022-12-24 23:11:46 | INFO | train | epoch 560 | loss 1.389 | nll_loss 0.62 | total 35852.4 | n_correct 32178.1 | ppl 1.54 | accuracy 89.752 | wps 30785.1 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 12311 | lr 2.7038e-05 | gnorm 1.49 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 17079\n",
            "2022-12-24 23:11:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 561:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:11:46 | INFO | fairseq.trainer | begin training epoch 561\n",
            "2022-12-24 23:11:46 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 561:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 23:12:03 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.24it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.82it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.32it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.27it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.98it/s]\u001b[A\n",
            "epoch 561 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.39it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:12:04 | INFO | dev_asr_nya | epoch 561 | valid on 'dev_asr_nya' subset | loss 1.645 | nll_loss 0.846 | total 3156.42 | n_correct 2653.89 | ppl 1.8 | accuracy 84.079 | wps 95061.9 | wpb 3156.4 | bsz 32.7 | num_updates 12333 | best_loss 1.624\n",
            "2022-12-24 23:12:04 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 561 @ 12333 updates\n",
            "2022-12-24 23:12:04 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint561.pt\n",
            "2022-12-24 23:12:07 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint561.pt\n",
            "2022-12-24 23:12:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint561.pt (epoch 561 @ 12333 updates, score 1.645) (writing took 8.03614768800253 seconds)\n",
            "2022-12-24 23:12:12 | INFO | fairseq_cli.train | end of epoch 561 (average epoch stats below)\n",
            "2022-12-24 23:12:12 | INFO | train | epoch 561 | loss 1.387 | nll_loss 0.618 | total 35852.4 | n_correct 32192.1 | ppl 1.53 | accuracy 89.791 | wps 30369.6 | ups 0.85 | wpb 35852.4 | bsz 368.4 | num_updates 12333 | lr 2.70139e-05 | gnorm 1.177 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.4 | wall 17105\n",
            "2022-12-24 23:12:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 562:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:12:12 | INFO | fairseq.trainer | begin training epoch 562\n",
            "2022-12-24 23:12:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 562:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:12:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.60it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.99it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.98it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.51it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.28it/s]\u001b[A\n",
            "epoch 562 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.27it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:12:29 | INFO | dev_asr_nya | epoch 562 | valid on 'dev_asr_nya' subset | loss 1.624 | nll_loss 0.823 | total 3156.42 | n_correct 2673.37 | ppl 1.77 | accuracy 84.696 | wps 87026.5 | wpb 3156.4 | bsz 32.7 | num_updates 12355 | best_loss 1.624\n",
            "2022-12-24 23:12:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 562 @ 12355 updates\n",
            "2022-12-24 23:12:29 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint562.pt\n",
            "2022-12-24 23:12:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint562.pt\n",
            "2022-12-24 23:12:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint562.pt (epoch 562 @ 12355 updates, score 1.624) (writing took 12.842323881999619 seconds)\n",
            "2022-12-24 23:12:42 | INFO | fairseq_cli.train | end of epoch 562 (average epoch stats below)\n",
            "2022-12-24 23:12:42 | INFO | train | epoch 562 | loss 1.386 | nll_loss 0.616 | total 35852.4 | n_correct 32212.9 | ppl 1.53 | accuracy 89.849 | wps 25617.2 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 12355 | lr 2.69898e-05 | gnorm 1.162 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31 | wall 17136\n",
            "2022-12-24 23:12:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 563:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:12:42 | INFO | fairseq.trainer | begin training epoch 563\n",
            "2022-12-24 23:12:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 563:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:13:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.20it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.95it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.41it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.72it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.05it/s]\u001b[A\n",
            "epoch 563 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.59it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:13:00 | INFO | dev_asr_nya | epoch 563 | valid on 'dev_asr_nya' subset | loss 1.656 | nll_loss 0.862 | total 3156.42 | n_correct 2646.95 | ppl 1.82 | accuracy 83.859 | wps 91214.8 | wpb 3156.4 | bsz 32.7 | num_updates 12377 | best_loss 1.624\n",
            "2022-12-24 23:13:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 563 @ 12377 updates\n",
            "2022-12-24 23:13:00 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint563.pt\n",
            "2022-12-24 23:13:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint563.pt\n",
            "2022-12-24 23:13:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint563.pt (epoch 563 @ 12377 updates, score 1.656) (writing took 9.746407824000926 seconds)\n",
            "2022-12-24 23:13:10 | INFO | fairseq_cli.train | end of epoch 563 (average epoch stats below)\n",
            "2022-12-24 23:13:10 | INFO | train | epoch 563 | loss 1.384 | nll_loss 0.615 | total 35852.4 | n_correct 32221.8 | ppl 1.53 | accuracy 89.873 | wps 28439.5 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12377 | lr 2.69658e-05 | gnorm 1.244 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 17164\n",
            "2022-12-24 23:13:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 564:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:13:10 | INFO | fairseq.trainer | begin training epoch 564\n",
            "2022-12-24 23:13:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 564:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 23:13:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.45it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.31it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.48it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.13it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.44it/s]\u001b[A\n",
            "epoch 564 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 26.86it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:13:28 | INFO | dev_asr_nya | epoch 564 | valid on 'dev_asr_nya' subset | loss 1.622 | nll_loss 0.82 | total 3156.42 | n_correct 2671.26 | ppl 1.77 | accuracy 84.629 | wps 84621.3 | wpb 3156.4 | bsz 32.7 | num_updates 12399 | best_loss 1.622\n",
            "2022-12-24 23:13:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 564 @ 12399 updates\n",
            "2022-12-24 23:13:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint564.pt\n",
            "2022-12-24 23:13:37 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint564.pt\n",
            "2022-12-24 23:13:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint564.pt (epoch 564 @ 12399 updates, score 1.622) (writing took 24.534424476998538 seconds)\n",
            "2022-12-24 23:13:53 | INFO | fairseq_cli.train | end of epoch 564 (average epoch stats below)\n",
            "2022-12-24 23:13:53 | INFO | train | epoch 564 | loss 1.39 | nll_loss 0.622 | total 35852.4 | n_correct 32147.1 | ppl 1.54 | accuracy 89.665 | wps 18548.3 | ups 0.52 | wpb 35852.4 | bsz 368.4 | num_updates 12399 | lr 2.69419e-05 | gnorm 2.102 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 17206\n",
            "2022-12-24 23:13:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 565:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:13:53 | INFO | fairseq.trainer | begin training epoch 565\n",
            "2022-12-24 23:13:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 565:  95% 21/22 [00:17<00:00,  1.27it/s, loss=1.387, nll_loss=0.618, total=35848.2, n_correct=32185.3, ppl=1.54, accuracy=89.782, wps=24725.7, ups=0.69, wpb=35848.2, bsz=368.8, num_updates=12400, lr=2.69408e-05, gnorm=1.462, clip=0, loss_scale=4, train_wall=76, gb_free=31.2, wall=17207]2022-12-24 23:14:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.01it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.19it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.02it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.75it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.65it/s]\u001b[A\n",
            "epoch 565 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 25.82it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:14:11 | INFO | dev_asr_nya | epoch 565 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.837 | total 3156.42 | n_correct 2660.79 | ppl 1.79 | accuracy 84.298 | wps 82513 | wpb 3156.4 | bsz 32.7 | num_updates 12421 | best_loss 1.622\n",
            "2022-12-24 23:14:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 565 @ 12421 updates\n",
            "2022-12-24 23:14:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint565.pt\n",
            "2022-12-24 23:14:21 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint565.pt\n",
            "2022-12-24 23:14:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint565.pt (epoch 565 @ 12421 updates, score 1.638) (writing took 13.610041965002893 seconds)\n",
            "2022-12-24 23:14:25 | INFO | fairseq_cli.train | end of epoch 565 (average epoch stats below)\n",
            "2022-12-24 23:14:25 | INFO | train | epoch 565 | loss 1.402 | nll_loss 0.637 | total 35852.4 | n_correct 32025.1 | ppl 1.56 | accuracy 89.325 | wps 24419.5 | ups 0.68 | wpb 35852.4 | bsz 368.4 | num_updates 12421 | lr 2.6918e-05 | gnorm 2.27 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 17239\n",
            "2022-12-24 23:14:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 566:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:14:25 | INFO | fairseq.trainer | begin training epoch 566\n",
            "2022-12-24 23:14:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 566:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:14:42 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.72it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.38it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.58it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.68it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.45it/s]\u001b[A\n",
            "epoch 566 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.96it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:14:43 | INFO | dev_asr_nya | epoch 566 | valid on 'dev_asr_nya' subset | loss 1.654 | nll_loss 0.86 | total 3156.42 | n_correct 2645.68 | ppl 1.82 | accuracy 83.819 | wps 94089.3 | wpb 3156.4 | bsz 32.7 | num_updates 12443 | best_loss 1.622\n",
            "2022-12-24 23:14:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 566 @ 12443 updates\n",
            "2022-12-24 23:14:43 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint566.pt\n",
            "2022-12-24 23:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint566.pt\n",
            "2022-12-24 23:14:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint566.pt (epoch 566 @ 12443 updates, score 1.654) (writing took 7.702449669999623 seconds)\n",
            "2022-12-24 23:14:51 | INFO | fairseq_cli.train | end of epoch 566 (average epoch stats below)\n",
            "2022-12-24 23:14:51 | INFO | train | epoch 566 | loss 1.386 | nll_loss 0.617 | total 35852.4 | n_correct 32197.8 | ppl 1.53 | accuracy 89.807 | wps 30694.1 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 12443 | lr 2.68942e-05 | gnorm 1.122 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 17264\n",
            "2022-12-24 23:14:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 567:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:14:51 | INFO | fairseq.trainer | begin training epoch 567\n",
            "2022-12-24 23:14:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 567:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:15:08 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.54it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.08it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.49it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.44it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.31it/s]\u001b[A\n",
            "epoch 567 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.01it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:15:09 | INFO | dev_asr_nya | epoch 567 | valid on 'dev_asr_nya' subset | loss 1.63 | nll_loss 0.829 | total 3156.42 | n_correct 2665.95 | ppl 1.78 | accuracy 84.461 | wps 90100.2 | wpb 3156.4 | bsz 32.7 | num_updates 12465 | best_loss 1.622\n",
            "2022-12-24 23:15:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 567 @ 12465 updates\n",
            "2022-12-24 23:15:09 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint567.pt\n",
            "2022-12-24 23:15:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint567.pt\n",
            "2022-12-24 23:15:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint567.pt (epoch 567 @ 12465 updates, score 1.63) (writing took 9.95449845300027 seconds)\n",
            "2022-12-24 23:15:19 | INFO | fairseq_cli.train | end of epoch 567 (average epoch stats below)\n",
            "2022-12-24 23:15:19 | INFO | train | epoch 567 | loss 1.38 | nll_loss 0.61 | total 35852.4 | n_correct 32256.1 | ppl 1.53 | accuracy 89.969 | wps 28188 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12465 | lr 2.68705e-05 | gnorm 1.095 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 17292\n",
            "2022-12-24 23:15:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 568:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:15:19 | INFO | fairseq.trainer | begin training epoch 568\n",
            "2022-12-24 23:15:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 568:  95% 21/22 [00:16<00:00,  1.35it/s]2022-12-24 23:15:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.96it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.03it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.19it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.60it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.34it/s]\u001b[A\n",
            "epoch 568 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.86it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:15:37 | INFO | dev_asr_nya | epoch 568 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.857 | total 3156.42 | n_correct 2650.84 | ppl 1.81 | accuracy 83.983 | wps 93054.8 | wpb 3156.4 | bsz 32.7 | num_updates 12487 | best_loss 1.622\n",
            "2022-12-24 23:15:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 568 @ 12487 updates\n",
            "2022-12-24 23:15:37 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint568.pt\n",
            "2022-12-24 23:15:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint568.pt\n",
            "2022-12-24 23:15:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint568.pt (epoch 568 @ 12487 updates, score 1.651) (writing took 7.249390554999991 seconds)\n",
            "2022-12-24 23:15:44 | INFO | fairseq_cli.train | end of epoch 568 (average epoch stats below)\n",
            "2022-12-24 23:15:44 | INFO | train | epoch 568 | loss 1.378 | nll_loss 0.608 | total 35852.4 | n_correct 32273 | ppl 1.52 | accuracy 90.017 | wps 31314.2 | ups 0.87 | wpb 35852.4 | bsz 368.4 | num_updates 12487 | lr 2.68468e-05 | gnorm 1.201 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 17317\n",
            "2022-12-24 23:15:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 569:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:15:44 | INFO | fairseq.trainer | begin training epoch 569\n",
            "2022-12-24 23:15:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 569:  95% 21/22 [00:16<00:00,  1.33it/s, loss=1.385, nll_loss=0.616, total=35849.1, n_correct=32198.7, ppl=1.53, accuracy=89.817, wps=29710, ups=0.83, wpb=35849.1, bsz=367, num_updates=12500, lr=2.68328e-05, gnorm=1.39, clip=0, loss_scale=4, train_wall=77, gb_free=31.4, wall=17328]2022-12-24 23:16:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.04it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.10it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.20it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.18it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.14it/s]\u001b[A\n",
            "epoch 569 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.64it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:16:02 | INFO | dev_asr_nya | epoch 569 | valid on 'dev_asr_nya' subset | loss 1.679 | nll_loss 0.886 | total 3156.42 | n_correct 2628.53 | ppl 1.85 | accuracy 83.276 | wps 91621 | wpb 3156.4 | bsz 32.7 | num_updates 12509 | best_loss 1.622\n",
            "2022-12-24 23:16:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 569 @ 12509 updates\n",
            "2022-12-24 23:16:02 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint569.pt\n",
            "2022-12-24 23:16:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint569.pt\n",
            "2022-12-24 23:16:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint569.pt (epoch 569 @ 12509 updates, score 1.679) (writing took 9.703823632000422 seconds)\n",
            "2022-12-24 23:16:12 | INFO | fairseq_cli.train | end of epoch 569 (average epoch stats below)\n",
            "2022-12-24 23:16:12 | INFO | train | epoch 569 | loss 1.379 | nll_loss 0.609 | total 35852.4 | n_correct 32269 | ppl 1.53 | accuracy 90.005 | wps 28314.1 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12509 | lr 2.68232e-05 | gnorm 1.424 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 17345\n",
            "2022-12-24 23:16:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 570:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:16:12 | INFO | fairseq.trainer | begin training epoch 570\n",
            "2022-12-24 23:16:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 570:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 23:16:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.85it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 15.07it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.19it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 22.62it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.36it/s]\u001b[A\n",
            "epoch 570 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.47it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:16:30 | INFO | dev_asr_nya | epoch 570 | valid on 'dev_asr_nya' subset | loss 1.648 | nll_loss 0.853 | total 3156.42 | n_correct 2650.16 | ppl 1.81 | accuracy 83.961 | wps 91735.6 | wpb 3156.4 | bsz 32.7 | num_updates 12531 | best_loss 1.622\n",
            "2022-12-24 23:16:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 570 @ 12531 updates\n",
            "2022-12-24 23:16:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint570.pt\n",
            "2022-12-24 23:16:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint570.pt\n",
            "2022-12-24 23:16:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint570.pt (epoch 570 @ 12531 updates, score 1.648) (writing took 7.489691342001606 seconds)\n",
            "2022-12-24 23:16:37 | INFO | fairseq_cli.train | end of epoch 570 (average epoch stats below)\n",
            "2022-12-24 23:16:37 | INFO | train | epoch 570 | loss 1.393 | nll_loss 0.626 | total 35852.4 | n_correct 32117.1 | ppl 1.54 | accuracy 89.582 | wps 31037.5 | ups 0.87 | wpb 35852.4 | bsz 368.4 | num_updates 12531 | lr 2.67996e-05 | gnorm 2.905 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 17371\n",
            "2022-12-24 23:16:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 571:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:16:37 | INFO | fairseq.trainer | begin training epoch 571\n",
            "2022-12-24 23:16:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 571:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:16:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.13it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.89it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.70it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 25.42it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 28.03it/s]\u001b[A\n",
            "epoch 571 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 30.41it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:16:55 | INFO | dev_asr_nya | epoch 571 | valid on 'dev_asr_nya' subset | loss 1.622 | nll_loss 0.825 | total 3156.42 | n_correct 2671.68 | ppl 1.77 | accuracy 84.643 | wps 96050.5 | wpb 3156.4 | bsz 32.7 | num_updates 12553 | best_loss 1.622\n",
            "2022-12-24 23:16:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 571 @ 12553 updates\n",
            "2022-12-24 23:16:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint571.pt\n",
            "2022-12-24 23:17:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint571.pt\n",
            "2022-12-24 23:17:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint571.pt (epoch 571 @ 12553 updates, score 1.622) (writing took 18.63170816999991 seconds)\n",
            "2022-12-24 23:17:14 | INFO | fairseq_cli.train | end of epoch 571 (average epoch stats below)\n",
            "2022-12-24 23:17:14 | INFO | train | epoch 571 | loss 1.39 | nll_loss 0.622 | total 35852.4 | n_correct 32143.5 | ppl 1.54 | accuracy 89.655 | wps 21608.7 | ups 0.6 | wpb 35852.4 | bsz 368.4 | num_updates 12553 | lr 2.67761e-05 | gnorm 2.468 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.7 | wall 17407\n",
            "2022-12-24 23:17:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 572:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:17:14 | INFO | fairseq.trainer | begin training epoch 572\n",
            "2022-12-24 23:17:14 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 572:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 23:17:31 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.17it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.36it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.02it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.57it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.05it/s]\u001b[A\n",
            "epoch 572 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.13it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:17:32 | INFO | dev_asr_nya | epoch 572 | valid on 'dev_asr_nya' subset | loss 1.632 | nll_loss 0.835 | total 3156.42 | n_correct 2662.79 | ppl 1.78 | accuracy 84.361 | wps 89154.9 | wpb 3156.4 | bsz 32.7 | num_updates 12575 | best_loss 1.622\n",
            "2022-12-24 23:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 572 @ 12575 updates\n",
            "2022-12-24 23:17:32 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint572.pt\n",
            "2022-12-24 23:17:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint572.pt\n",
            "2022-12-24 23:17:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint572.pt (epoch 572 @ 12575 updates, score 1.632) (writing took 8.698484371001541 seconds)\n",
            "2022-12-24 23:17:40 | INFO | fairseq_cli.train | end of epoch 572 (average epoch stats below)\n",
            "2022-12-24 23:17:40 | INFO | train | epoch 572 | loss 1.376 | nll_loss 0.606 | total 35852.4 | n_correct 32278.1 | ppl 1.52 | accuracy 90.031 | wps 29293.3 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 12575 | lr 2.67527e-05 | gnorm 0.972 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 17434\n",
            "2022-12-24 23:17:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 573:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:17:41 | INFO | fairseq.trainer | begin training epoch 573\n",
            "2022-12-24 23:17:41 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 573:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 23:17:58 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.16it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 18.77it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.73it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.51it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.17it/s]\u001b[A\n",
            "epoch 573 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.16it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:17:59 | INFO | dev_asr_nya | epoch 573 | valid on 'dev_asr_nya' subset | loss 1.615 | nll_loss 0.815 | total 3156.42 | n_correct 2676.26 | ppl 1.76 | accuracy 84.788 | wps 93402.3 | wpb 3156.4 | bsz 32.7 | num_updates 12597 | best_loss 1.615\n",
            "2022-12-24 23:17:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 573 @ 12597 updates\n",
            "2022-12-24 23:17:59 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint573.pt\n",
            "2022-12-24 23:18:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint573.pt\n",
            "2022-12-24 23:18:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint573.pt (epoch 573 @ 12597 updates, score 1.615) (writing took 12.957233826000447 seconds)\n",
            "2022-12-24 23:18:12 | INFO | fairseq_cli.train | end of epoch 573 (average epoch stats below)\n",
            "2022-12-24 23:18:12 | INFO | train | epoch 573 | loss 1.379 | nll_loss 0.609 | total 35852.4 | n_correct 32263 | ppl 1.53 | accuracy 89.988 | wps 25379.9 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 12597 | lr 2.67293e-05 | gnorm 1.884 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 17465\n",
            "2022-12-24 23:18:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 574:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:18:12 | INFO | fairseq.trainer | begin training epoch 574\n",
            "2022-12-24 23:18:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 574:  95% 21/22 [00:16<00:00,  1.33it/s, loss=1.383, nll_loss=0.615, total=35896.8, n_correct=32251.3, ppl=1.53, accuracy=89.844, wps=25655.1, ups=0.71, wpb=35896.8, bsz=370.4, num_updates=12600, lr=2.67261e-05, gnorm=2.021, clip=0, loss_scale=4, train_wall=76, gb_free=29.5, wall=17468]2022-12-24 23:18:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.79it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 18.19it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.66it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.67it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.44it/s]\u001b[A\n",
            "epoch 574 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:18:30 | INFO | dev_asr_nya | epoch 574 | valid on 'dev_asr_nya' subset | loss 1.624 | nll_loss 0.824 | total 3156.42 | n_correct 2670.58 | ppl 1.77 | accuracy 84.608 | wps 94246.5 | wpb 3156.4 | bsz 32.7 | num_updates 12619 | best_loss 1.615\n",
            "2022-12-24 23:18:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 574 @ 12619 updates\n",
            "2022-12-24 23:18:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint574.pt\n",
            "2022-12-24 23:18:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint574.pt\n",
            "2022-12-24 23:18:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint574.pt (epoch 574 @ 12619 updates, score 1.624) (writing took 7.290727757997956 seconds)\n",
            "2022-12-24 23:18:37 | INFO | fairseq_cli.train | end of epoch 574 (average epoch stats below)\n",
            "2022-12-24 23:18:37 | INFO | train | epoch 574 | loss 1.38 | nll_loss 0.611 | total 35852.4 | n_correct 32235.4 | ppl 1.53 | accuracy 89.912 | wps 31050.6 | ups 0.87 | wpb 35852.4 | bsz 368.4 | num_updates 12619 | lr 2.6706e-05 | gnorm 2.234 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32 | wall 17491\n",
            "2022-12-24 23:18:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 575:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:18:37 | INFO | fairseq.trainer | begin training epoch 575\n",
            "2022-12-24 23:18:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 575:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:18:54 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.35it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.90it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.13it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.72it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.15it/s]\u001b[A\n",
            "epoch 575 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.71it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:18:55 | INFO | dev_asr_nya | epoch 575 | valid on 'dev_asr_nya' subset | loss 1.625 | nll_loss 0.825 | total 3156.42 | n_correct 2670.74 | ppl 1.77 | accuracy 84.613 | wps 92745.2 | wpb 3156.4 | bsz 32.7 | num_updates 12641 | best_loss 1.615\n",
            "2022-12-24 23:18:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 575 @ 12641 updates\n",
            "2022-12-24 23:18:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint575.pt\n",
            "2022-12-24 23:19:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint575.pt\n",
            "2022-12-24 23:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint575.pt (epoch 575 @ 12641 updates, score 1.625) (writing took 9.479045791998942 seconds)\n",
            "2022-12-24 23:19:05 | INFO | fairseq_cli.train | end of epoch 575 (average epoch stats below)\n",
            "2022-12-24 23:19:05 | INFO | train | epoch 575 | loss 1.374 | nll_loss 0.603 | total 35852.4 | n_correct 32316.1 | ppl 1.52 | accuracy 90.137 | wps 28476.5 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12641 | lr 2.66827e-05 | gnorm 1.109 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.5 | wall 17518\n",
            "2022-12-24 23:19:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 576:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:19:05 | INFO | fairseq.trainer | begin training epoch 576\n",
            "2022-12-24 23:19:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 576:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:19:22 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.45it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.55it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.68it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.89it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.45it/s]\u001b[A\n",
            "epoch 576 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.91it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:19:23 | INFO | dev_asr_nya | epoch 576 | valid on 'dev_asr_nya' subset | loss 1.691 | nll_loss 0.903 | total 3156.42 | n_correct 2619.05 | ppl 1.87 | accuracy 82.975 | wps 93985.8 | wpb 3156.4 | bsz 32.7 | num_updates 12663 | best_loss 1.615\n",
            "2022-12-24 23:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 576 @ 12663 updates\n",
            "2022-12-24 23:19:23 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint576.pt\n",
            "2022-12-24 23:19:26 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint576.pt\n",
            "2022-12-24 23:19:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint576.pt (epoch 576 @ 12663 updates, score 1.691) (writing took 9.750049788999604 seconds)\n",
            "2022-12-24 23:19:33 | INFO | fairseq_cli.train | end of epoch 576 (average epoch stats below)\n",
            "2022-12-24 23:19:33 | INFO | train | epoch 576 | loss 1.375 | nll_loss 0.604 | total 35852.4 | n_correct 32290.7 | ppl 1.52 | accuracy 90.066 | wps 28104.3 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 12663 | lr 2.66596e-05 | gnorm 1.691 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 17546\n",
            "2022-12-24 23:19:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 577:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:19:33 | INFO | fairseq.trainer | begin training epoch 577\n",
            "2022-12-24 23:19:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 577:  95% 21/22 [00:16<00:00,  1.26it/s]2022-12-24 23:19:50 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.41it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.94it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.67it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.44it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.65it/s]\u001b[A\n",
            "epoch 577 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.81it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:19:51 | INFO | dev_asr_nya | epoch 577 | valid on 'dev_asr_nya' subset | loss 1.616 | nll_loss 0.815 | total 3156.42 | n_correct 2676.68 | ppl 1.76 | accuracy 84.801 | wps 92741.2 | wpb 3156.4 | bsz 32.7 | num_updates 12685 | best_loss 1.615\n",
            "2022-12-24 23:19:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 577 @ 12685 updates\n",
            "2022-12-24 23:19:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint577.pt\n",
            "2022-12-24 23:19:55 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint577.pt\n",
            "2022-12-24 23:19:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint577.pt (epoch 577 @ 12685 updates, score 1.616) (writing took 7.813354853999044 seconds)\n",
            "2022-12-24 23:19:59 | INFO | fairseq_cli.train | end of epoch 577 (average epoch stats below)\n",
            "2022-12-24 23:19:59 | INFO | train | epoch 577 | loss 1.373 | nll_loss 0.603 | total 35852.4 | n_correct 32305.1 | ppl 1.52 | accuracy 90.106 | wps 30185.5 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 12685 | lr 2.66364e-05 | gnorm 1.596 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 17573\n",
            "2022-12-24 23:19:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 578:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:19:59 | INFO | fairseq.trainer | begin training epoch 578\n",
            "2022-12-24 23:19:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 578:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.374, nll_loss=0.604, total=35841.8, n_correct=32284.8, ppl=1.52, accuracy=90.076, wps=30688.9, ups=0.86, wpb=35841.8, bsz=368.2, num_updates=12700, lr=2.66207e-05, gnorm=1.573, clip=0, loss_scale=4, train_wall=77, gb_free=31.8, wall=17585]2022-12-24 23:20:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.80it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.18it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.72it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.93it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.95it/s]\u001b[A\n",
            "epoch 578 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.31it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:20:17 | INFO | dev_asr_nya | epoch 578 | valid on 'dev_asr_nya' subset | loss 1.633 | nll_loss 0.835 | total 3156.42 | n_correct 2664.42 | ppl 1.78 | accuracy 84.413 | wps 91902.9 | wpb 3156.4 | bsz 32.7 | num_updates 12707 | best_loss 1.615\n",
            "2022-12-24 23:20:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 578 @ 12707 updates\n",
            "2022-12-24 23:20:17 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint578.pt\n",
            "2022-12-24 23:20:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint578.pt\n",
            "2022-12-24 23:20:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint578.pt (epoch 578 @ 12707 updates, score 1.633) (writing took 18.844891184002336 seconds)\n",
            "2022-12-24 23:20:36 | INFO | fairseq_cli.train | end of epoch 578 (average epoch stats below)\n",
            "2022-12-24 23:20:36 | INFO | train | epoch 578 | loss 1.37 | nll_loss 0.6 | total 35852.4 | n_correct 32324.4 | ppl 1.52 | accuracy 90.16 | wps 21266.7 | ups 0.59 | wpb 35852.4 | bsz 368.4 | num_updates 12707 | lr 2.66134e-05 | gnorm 1.237 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 17610\n",
            "2022-12-24 23:20:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 579:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:20:36 | INFO | fairseq.trainer | begin training epoch 579\n",
            "2022-12-24 23:20:36 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 579:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 23:20:53 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.08it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.13it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.24it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.58it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.42it/s]\u001b[A\n",
            "epoch 579 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.89it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:20:54 | INFO | dev_asr_nya | epoch 579 | valid on 'dev_asr_nya' subset | loss 1.634 | nll_loss 0.839 | total 3156.42 | n_correct 2665.74 | ppl 1.79 | accuracy 84.454 | wps 93842.8 | wpb 3156.4 | bsz 32.7 | num_updates 12729 | best_loss 1.615\n",
            "2022-12-24 23:20:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 579 @ 12729 updates\n",
            "2022-12-24 23:20:54 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint579.pt\n",
            "2022-12-24 23:21:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint579.pt\n",
            "2022-12-24 23:21:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint579.pt (epoch 579 @ 12729 updates, score 1.634) (writing took 17.437178066000342 seconds)\n",
            "2022-12-24 23:21:12 | INFO | fairseq_cli.train | end of epoch 579 (average epoch stats below)\n",
            "2022-12-24 23:21:12 | INFO | train | epoch 579 | loss 1.367 | nll_loss 0.595 | total 35852.4 | n_correct 32374.8 | ppl 1.51 | accuracy 90.3 | wps 22037.6 | ups 0.61 | wpb 35852.4 | bsz 368.4 | num_updates 12729 | lr 2.65904e-05 | gnorm 1.198 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 28.8 | wall 17645\n",
            "2022-12-24 23:21:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 580:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:21:12 | INFO | fairseq.trainer | begin training epoch 580\n",
            "2022-12-24 23:21:12 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 580:  95% 21/22 [00:17<00:00,  1.30it/s]2022-12-24 23:21:29 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.77it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.91it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.88it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 20.83it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.07it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.44it/s]\u001b[A\n",
            "epoch 580 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 26.49it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:21:30 | INFO | dev_asr_nya | epoch 580 | valid on 'dev_asr_nya' subset | loss 1.631 | nll_loss 0.834 | total 3156.42 | n_correct 2668.42 | ppl 1.78 | accuracy 84.539 | wps 81990.6 | wpb 3156.4 | bsz 32.7 | num_updates 12751 | best_loss 1.615\n",
            "2022-12-24 23:21:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 580 @ 12751 updates\n",
            "2022-12-24 23:21:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint580.pt\n",
            "2022-12-24 23:21:39 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint580.pt\n",
            "2022-12-24 23:21:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint580.pt (epoch 580 @ 12751 updates, score 1.631) (writing took 21.704618355001003 seconds)\n",
            "2022-12-24 23:21:52 | INFO | fairseq_cli.train | end of epoch 580 (average epoch stats below)\n",
            "2022-12-24 23:21:52 | INFO | train | epoch 580 | loss 1.365 | nll_loss 0.593 | total 35852.4 | n_correct 32396.4 | ppl 1.51 | accuracy 90.36 | wps 19557.7 | ups 0.55 | wpb 35852.4 | bsz 368.4 | num_updates 12751 | lr 2.65674e-05 | gnorm 1.097 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 17686\n",
            "2022-12-24 23:21:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 581:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:21:52 | INFO | fairseq.trainer | begin training epoch 581\n",
            "2022-12-24 23:21:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 581:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:22:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.88it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.25it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.31it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.72it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.15it/s]\u001b[A\n",
            "epoch 581 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.56it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:22:10 | INFO | dev_asr_nya | epoch 581 | valid on 'dev_asr_nya' subset | loss 1.658 | nll_loss 0.865 | total 3156.42 | n_correct 2646.74 | ppl 1.82 | accuracy 83.852 | wps 91029.4 | wpb 3156.4 | bsz 32.7 | num_updates 12773 | best_loss 1.615\n",
            "2022-12-24 23:22:10 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 581 @ 12773 updates\n",
            "2022-12-24 23:22:10 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint581.pt\n",
            "2022-12-24 23:22:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint581.pt\n",
            "2022-12-24 23:22:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint581.pt (epoch 581 @ 12773 updates, score 1.658) (writing took 9.169541279999976 seconds)\n",
            "2022-12-24 23:22:20 | INFO | fairseq_cli.train | end of epoch 581 (average epoch stats below)\n",
            "2022-12-24 23:22:20 | INFO | train | epoch 581 | loss 1.363 | nll_loss 0.591 | total 35852.4 | n_correct 32409.5 | ppl 1.51 | accuracy 90.397 | wps 28701.7 | ups 0.8 | wpb 35852.4 | bsz 368.4 | num_updates 12773 | lr 2.65445e-05 | gnorm 1.18 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 17713\n",
            "2022-12-24 23:22:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 582:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:22:20 | INFO | fairseq.trainer | begin training epoch 582\n",
            "2022-12-24 23:22:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 582:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:22:37 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.89it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.58it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.77it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 17.53it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 22.44it/s]\u001b[A\n",
            "epoch 582 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 25.63it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:22:38 | INFO | dev_asr_nya | epoch 582 | valid on 'dev_asr_nya' subset | loss 1.624 | nll_loss 0.827 | total 3156.42 | n_correct 2672.16 | ppl 1.77 | accuracy 84.658 | wps 81425.3 | wpb 3156.4 | bsz 32.7 | num_updates 12795 | best_loss 1.615\n",
            "2022-12-24 23:22:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 582 @ 12795 updates\n",
            "2022-12-24 23:22:38 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint582.pt\n",
            "2022-12-24 23:22:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint582.pt\n",
            "2022-12-24 23:23:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint582.pt (epoch 582 @ 12795 updates, score 1.624) (writing took 27.41853072700178 seconds)\n",
            "2022-12-24 23:23:05 | INFO | fairseq_cli.train | end of epoch 582 (average epoch stats below)\n",
            "2022-12-24 23:23:05 | INFO | train | epoch 582 | loss 1.363 | nll_loss 0.591 | total 35852.4 | n_correct 32399.6 | ppl 1.51 | accuracy 90.37 | wps 17212.1 | ups 0.48 | wpb 35852.4 | bsz 368.4 | num_updates 12795 | lr 2.65217e-05 | gnorm 0.952 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.7 | wall 17759\n",
            "2022-12-24 23:23:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 583:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:23:05 | INFO | fairseq.trainer | begin training epoch 583\n",
            "2022-12-24 23:23:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 583:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.366, nll_loss=0.594, total=35835.5, n_correct=32368.6, ppl=1.51, accuracy=90.326, wps=20073.1, ups=0.56, wpb=35835.5, bsz=367.4, num_updates=12800, lr=2.65165e-05, gnorm=1.123, clip=0, loss_scale=4, train_wall=78, gb_free=28.8, wall=17763]2022-12-24 23:23:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.99it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.93it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.70it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.03it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 24.63it/s]\u001b[A\n",
            "epoch 583 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.40it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:23:24 | INFO | dev_asr_nya | epoch 583 | valid on 'dev_asr_nya' subset | loss 1.62 | nll_loss 0.823 | total 3156.42 | n_correct 2672.42 | ppl 1.77 | accuracy 84.666 | wps 86522.5 | wpb 3156.4 | bsz 32.7 | num_updates 12817 | best_loss 1.615\n",
            "2022-12-24 23:23:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 583 @ 12817 updates\n",
            "2022-12-24 23:23:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint583.pt\n",
            "2022-12-24 23:23:29 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint583.pt\n",
            "2022-12-24 23:23:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint583.pt (epoch 583 @ 12817 updates, score 1.62) (writing took 18.617088386999967 seconds)\n",
            "2022-12-24 23:23:42 | INFO | fairseq_cli.train | end of epoch 583 (average epoch stats below)\n",
            "2022-12-24 23:23:42 | INFO | train | epoch 583 | loss 1.368 | nll_loss 0.597 | total 35852.4 | n_correct 32367.5 | ppl 1.51 | accuracy 90.28 | wps 21316 | ups 0.59 | wpb 35852.4 | bsz 368.4 | num_updates 12817 | lr 2.64989e-05 | gnorm 1.804 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 17796\n",
            "2022-12-24 23:23:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 584:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:23:42 | INFO | fairseq.trainer | begin training epoch 584\n",
            "2022-12-24 23:23:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 584:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:24:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.92it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.37it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.17it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.40it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.26it/s]\u001b[A\n",
            "epoch 584 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:24:01 | INFO | dev_asr_nya | epoch 584 | valid on 'dev_asr_nya' subset | loss 1.616 | nll_loss 0.814 | total 3156.42 | n_correct 2678.84 | ppl 1.76 | accuracy 84.87 | wps 93783.8 | wpb 3156.4 | bsz 32.7 | num_updates 12839 | best_loss 1.615\n",
            "2022-12-24 23:24:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 584 @ 12839 updates\n",
            "2022-12-24 23:24:01 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint584.pt\n",
            "2022-12-24 23:24:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint584.pt\n",
            "2022-12-24 23:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint584.pt (epoch 584 @ 12839 updates, score 1.616) (writing took 22.449934320997272 seconds)\n",
            "2022-12-24 23:24:23 | INFO | fairseq_cli.train | end of epoch 584 (average epoch stats below)\n",
            "2022-12-24 23:24:23 | INFO | train | epoch 584 | loss 1.365 | nll_loss 0.593 | total 35852.4 | n_correct 32375.2 | ppl 1.51 | accuracy 90.301 | wps 19417.1 | ups 0.54 | wpb 35852.4 | bsz 368.4 | num_updates 12839 | lr 2.64762e-05 | gnorm 1.413 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 29.5 | wall 17837\n",
            "2022-12-24 23:24:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 585:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:24:23 | INFO | fairseq.trainer | begin training epoch 585\n",
            "2022-12-24 23:24:23 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 585:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:24:40 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.45it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.53it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.84it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.05it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.29it/s]\u001b[A\n",
            "epoch 585 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.83it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:24:41 | INFO | dev_asr_nya | epoch 585 | valid on 'dev_asr_nya' subset | loss 1.617 | nll_loss 0.817 | total 3156.42 | n_correct 2673.84 | ppl 1.76 | accuracy 84.711 | wps 90342.4 | wpb 3156.4 | bsz 32.7 | num_updates 12861 | best_loss 1.615\n",
            "2022-12-24 23:24:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 585 @ 12861 updates\n",
            "2022-12-24 23:24:41 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint585.pt\n",
            "2022-12-24 23:24:44 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint585.pt\n",
            "2022-12-24 23:24:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint585.pt (epoch 585 @ 12861 updates, score 1.617) (writing took 11.88861037300012 seconds)\n",
            "2022-12-24 23:24:53 | INFO | fairseq_cli.train | end of epoch 585 (average epoch stats below)\n",
            "2022-12-24 23:24:53 | INFO | train | epoch 585 | loss 1.368 | nll_loss 0.597 | total 35852.4 | n_correct 32351.4 | ppl 1.51 | accuracy 90.235 | wps 26329.6 | ups 0.73 | wpb 35852.4 | bsz 368.4 | num_updates 12861 | lr 2.64535e-05 | gnorm 2.028 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.3 | wall 17867\n",
            "2022-12-24 23:24:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 586:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:24:53 | INFO | fairseq.trainer | begin training epoch 586\n",
            "2022-12-24 23:24:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 586:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:25:10 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.34it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.70it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.05it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.22it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.88it/s]\u001b[A\n",
            "epoch 586 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.48it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:25:11 | INFO | dev_asr_nya | epoch 586 | valid on 'dev_asr_nya' subset | loss 1.647 | nll_loss 0.853 | total 3156.42 | n_correct 2653.21 | ppl 1.81 | accuracy 84.058 | wps 91183.5 | wpb 3156.4 | bsz 32.7 | num_updates 12883 | best_loss 1.615\n",
            "2022-12-24 23:25:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 586 @ 12883 updates\n",
            "2022-12-24 23:25:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint586.pt\n",
            "2022-12-24 23:25:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint586.pt\n",
            "2022-12-24 23:25:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint586.pt (epoch 586 @ 12883 updates, score 1.647) (writing took 12.782604747997539 seconds)\n",
            "2022-12-24 23:25:24 | INFO | fairseq_cli.train | end of epoch 586 (average epoch stats below)\n",
            "2022-12-24 23:25:24 | INFO | train | epoch 586 | loss 1.361 | nll_loss 0.589 | total 35852.4 | n_correct 32430.7 | ppl 1.5 | accuracy 90.456 | wps 25586.5 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 12883 | lr 2.64309e-05 | gnorm 1.377 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.8 | wall 17897\n",
            "2022-12-24 23:25:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 587:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:25:24 | INFO | fairseq.trainer | begin training epoch 587\n",
            "2022-12-24 23:25:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 587:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.366, nll_loss=0.594, total=35888.3, n_correct=32406.8, ppl=1.51, accuracy=90.299, wps=24316.8, ups=0.68, wpb=35888.3, bsz=370.9, num_updates=12900, lr=2.64135e-05, gnorm=1.821, clip=0, loss_scale=4, train_wall=77, gb_free=30.3, wall=17911]2022-12-24 23:25:41 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.82it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.14it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.23it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 16.77it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.43it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 25.82it/s]\u001b[A\n",
            "epoch 587 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 27.91it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:25:42 | INFO | dev_asr_nya | epoch 587 | valid on 'dev_asr_nya' subset | loss 1.625 | nll_loss 0.827 | total 3156.42 | n_correct 2668.11 | ppl 1.77 | accuracy 84.529 | wps 82440.3 | wpb 3156.4 | bsz 32.7 | num_updates 12905 | best_loss 1.615\n",
            "2022-12-24 23:25:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 587 @ 12905 updates\n",
            "2022-12-24 23:25:42 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint587.pt\n",
            "2022-12-24 23:25:49 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint587.pt\n",
            "2022-12-24 23:25:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint587.pt (epoch 587 @ 12905 updates, score 1.625) (writing took 16.469628382998053 seconds)\n",
            "2022-12-24 23:25:58 | INFO | fairseq_cli.train | end of epoch 587 (average epoch stats below)\n",
            "2022-12-24 23:25:58 | INFO | train | epoch 587 | loss 1.37 | nll_loss 0.599 | total 35852.4 | n_correct 32322.6 | ppl 1.51 | accuracy 90.155 | wps 22837.1 | ups 0.64 | wpb 35852.4 | bsz 368.4 | num_updates 12905 | lr 2.64084e-05 | gnorm 2.359 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 17932\n",
            "2022-12-24 23:25:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 588:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:25:58 | INFO | fairseq.trainer | begin training epoch 588\n",
            "2022-12-24 23:25:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 588:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:26:16 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.24it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.92it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 18.99it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.05it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.50it/s]\u001b[A\n",
            "epoch 588 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:26:16 | INFO | dev_asr_nya | epoch 588 | valid on 'dev_asr_nya' subset | loss 1.633 | nll_loss 0.837 | total 3156.42 | n_correct 2664.58 | ppl 1.79 | accuracy 84.418 | wps 90522.7 | wpb 3156.4 | bsz 32.7 | num_updates 12927 | best_loss 1.615\n",
            "2022-12-24 23:26:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 588 @ 12927 updates\n",
            "2022-12-24 23:26:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint588.pt\n",
            "2022-12-24 23:26:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint588.pt\n",
            "2022-12-24 23:26:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint588.pt (epoch 588 @ 12927 updates, score 1.633) (writing took 11.189311725000152 seconds)\n",
            "2022-12-24 23:26:28 | INFO | fairseq_cli.train | end of epoch 588 (average epoch stats below)\n",
            "2022-12-24 23:26:28 | INFO | train | epoch 588 | loss 1.36 | nll_loss 0.588 | total 35852.4 | n_correct 32419.4 | ppl 1.5 | accuracy 90.425 | wps 26935.6 | ups 0.75 | wpb 35852.4 | bsz 368.4 | num_updates 12927 | lr 2.63859e-05 | gnorm 1.449 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 17961\n",
            "2022-12-24 23:26:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 589:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:26:28 | INFO | fairseq.trainer | begin training epoch 589\n",
            "2022-12-24 23:26:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 589:  95% 21/22 [00:16<00:00,  1.32it/s]2022-12-24 23:26:45 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.08it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.15it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.66it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.57it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.72it/s]\u001b[A\n",
            "epoch 589 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:26:46 | INFO | dev_asr_nya | epoch 589 | valid on 'dev_asr_nya' subset | loss 1.627 | nll_loss 0.829 | total 3156.42 | n_correct 2667.74 | ppl 1.78 | accuracy 84.518 | wps 93180.3 | wpb 3156.4 | bsz 32.7 | num_updates 12949 | best_loss 1.615\n",
            "2022-12-24 23:26:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 589 @ 12949 updates\n",
            "2022-12-24 23:26:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint589.pt\n",
            "2022-12-24 23:26:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint589.pt\n",
            "2022-12-24 23:26:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint589.pt (epoch 589 @ 12949 updates, score 1.627) (writing took 11.924143146999995 seconds)\n",
            "2022-12-24 23:26:58 | INFO | fairseq_cli.train | end of epoch 589 (average epoch stats below)\n",
            "2022-12-24 23:26:58 | INFO | train | epoch 589 | loss 1.358 | nll_loss 0.586 | total 35852.4 | n_correct 32437.1 | ppl 1.5 | accuracy 90.474 | wps 26176.4 | ups 0.73 | wpb 35852.4 | bsz 368.4 | num_updates 12949 | lr 2.63635e-05 | gnorm 1.148 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.9 | wall 17991\n",
            "2022-12-24 23:26:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 590:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:26:58 | INFO | fairseq.trainer | begin training epoch 590\n",
            "2022-12-24 23:26:58 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 590:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:27:15 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.52it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.18it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.38it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.79it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.14it/s]\u001b[A\n",
            "epoch 590 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.73it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:27:16 | INFO | dev_asr_nya | epoch 590 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.844 | total 3156.42 | n_correct 2661.84 | ppl 1.79 | accuracy 84.331 | wps 92675.8 | wpb 3156.4 | bsz 32.7 | num_updates 12971 | best_loss 1.615\n",
            "2022-12-24 23:27:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 590 @ 12971 updates\n",
            "2022-12-24 23:27:16 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint590.pt\n",
            "2022-12-24 23:27:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint590.pt\n",
            "2022-12-24 23:27:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint590.pt (epoch 590 @ 12971 updates, score 1.638) (writing took 9.587776013999246 seconds)\n",
            "2022-12-24 23:27:26 | INFO | fairseq_cli.train | end of epoch 590 (average epoch stats below)\n",
            "2022-12-24 23:27:26 | INFO | train | epoch 590 | loss 1.356 | nll_loss 0.583 | total 35852.4 | n_correct 32475.9 | ppl 1.5 | accuracy 90.582 | wps 28276.1 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 12971 | lr 2.63411e-05 | gnorm 1.31 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.4 | wall 18019\n",
            "2022-12-24 23:27:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 591:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:27:26 | INFO | fairseq.trainer | begin training epoch 591\n",
            "2022-12-24 23:27:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 591:  95% 21/22 [00:17<00:00,  1.26it/s]2022-12-24 23:27:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.18it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.98it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.73it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.88it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.59it/s]\u001b[A\n",
            "epoch 591 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.93it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:27:44 | INFO | dev_asr_nya | epoch 591 | valid on 'dev_asr_nya' subset | loss 1.632 | nll_loss 0.836 | total 3156.42 | n_correct 2666.58 | ppl 1.79 | accuracy 84.481 | wps 94872 | wpb 3156.4 | bsz 32.7 | num_updates 12993 | best_loss 1.615\n",
            "2022-12-24 23:27:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 591 @ 12993 updates\n",
            "2022-12-24 23:27:44 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint591.pt\n",
            "2022-12-24 23:27:50 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint591.pt\n",
            "2022-12-24 23:27:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint591.pt (epoch 591 @ 12993 updates, score 1.632) (writing took 10.367502561999572 seconds)\n",
            "2022-12-24 23:27:55 | INFO | fairseq_cli.train | end of epoch 591 (average epoch stats below)\n",
            "2022-12-24 23:27:55 | INFO | train | epoch 591 | loss 1.356 | nll_loss 0.583 | total 35852.4 | n_correct 32472 | ppl 1.5 | accuracy 90.571 | wps 27297.6 | ups 0.76 | wpb 35852.4 | bsz 368.4 | num_updates 12993 | lr 2.63188e-05 | gnorm 1.076 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 32 | wall 18048\n",
            "2022-12-24 23:27:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 592:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:27:55 | INFO | fairseq.trainer | begin training epoch 592\n",
            "2022-12-24 23:27:55 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 592:  95% 21/22 [00:16<00:00,  1.34it/s, loss=1.357, nll_loss=0.585, total=35850.5, n_correct=32451.3, ppl=1.5, accuracy=90.518, wps=25049.9, ups=0.7, wpb=35850.5, bsz=368.5, num_updates=13000, lr=2.63117e-05, gnorm=1.253, clip=0, loss_scale=4, train_wall=77, gb_free=31.3, wall=18054]2022-12-24 23:28:12 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.40it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.31it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 19.74it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 23.35it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 27.00it/s]\u001b[A\n",
            "epoch 592 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 29.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:28:12 | INFO | dev_asr_nya | epoch 592 | valid on 'dev_asr_nya' subset | loss 1.626 | nll_loss 0.828 | total 3156.42 | n_correct 2671.95 | ppl 1.78 | accuracy 84.651 | wps 94339.6 | wpb 3156.4 | bsz 32.7 | num_updates 13015 | best_loss 1.615\n",
            "2022-12-24 23:28:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 592 @ 13015 updates\n",
            "2022-12-24 23:28:12 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint592.pt\n",
            "2022-12-24 23:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint592.pt\n",
            "2022-12-24 23:28:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint592.pt (epoch 592 @ 13015 updates, score 1.626) (writing took 12.775530090999382 seconds)\n",
            "2022-12-24 23:28:25 | INFO | fairseq_cli.train | end of epoch 592 (average epoch stats below)\n",
            "2022-12-24 23:28:25 | INFO | train | epoch 592 | loss 1.359 | nll_loss 0.587 | total 35852.4 | n_correct 32422.3 | ppl 1.5 | accuracy 90.433 | wps 25722.9 | ups 0.72 | wpb 35852.4 | bsz 368.4 | num_updates 13015 | lr 2.62966e-05 | gnorm 1.646 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 18079\n",
            "2022-12-24 23:28:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 593:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:28:25 | INFO | fairseq.trainer | begin training epoch 593\n",
            "2022-12-24 23:28:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 593:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:28:43 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.99it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.98it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 22.03it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.54it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 27.27it/s]\u001b[A\n",
            "epoch 593 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 29.57it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:28:43 | INFO | dev_asr_nya | epoch 593 | valid on 'dev_asr_nya' subset | loss 1.623 | nll_loss 0.825 | total 3156.42 | n_correct 2669.79 | ppl 1.77 | accuracy 84.583 | wps 95655.5 | wpb 3156.4 | bsz 32.7 | num_updates 13037 | best_loss 1.615\n",
            "2022-12-24 23:28:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 593 @ 13037 updates\n",
            "2022-12-24 23:28:43 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint593.pt\n",
            "2022-12-24 23:28:47 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint593.pt\n",
            "2022-12-24 23:28:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint593.pt (epoch 593 @ 13037 updates, score 1.623) (writing took 7.396456419999595 seconds)\n",
            "2022-12-24 23:28:51 | INFO | fairseq_cli.train | end of epoch 593 (average epoch stats below)\n",
            "2022-12-24 23:28:51 | INFO | train | epoch 593 | loss 1.353 | nll_loss 0.58 | total 35852.4 | n_correct 32482.5 | ppl 1.49 | accuracy 90.601 | wps 30920.3 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 13037 | lr 2.62744e-05 | gnorm 1.034 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.2 | wall 18104\n",
            "2022-12-24 23:28:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 594:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:28:51 | INFO | fairseq.trainer | begin training epoch 594\n",
            "2022-12-24 23:28:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 594:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:29:08 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.29it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 11.27it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 14.45it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.24it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.35it/s]\u001b[A\n",
            "epoch 594 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.03it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:29:09 | INFO | dev_asr_nya | epoch 594 | valid on 'dev_asr_nya' subset | loss 1.638 | nll_loss 0.842 | total 3156.42 | n_correct 2660.32 | ppl 1.79 | accuracy 84.283 | wps 87349.5 | wpb 3156.4 | bsz 32.7 | num_updates 13059 | best_loss 1.615\n",
            "2022-12-24 23:29:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 594 @ 13059 updates\n",
            "2022-12-24 23:29:09 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint594.pt\n",
            "2022-12-24 23:29:12 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint594.pt\n",
            "2022-12-24 23:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint594.pt (epoch 594 @ 13059 updates, score 1.638) (writing took 7.728850212999532 seconds)\n",
            "2022-12-24 23:29:17 | INFO | fairseq_cli.train | end of epoch 594 (average epoch stats below)\n",
            "2022-12-24 23:29:17 | INFO | train | epoch 594 | loss 1.353 | nll_loss 0.58 | total 35852.4 | n_correct 32490.5 | ppl 1.49 | accuracy 90.623 | wps 30201 | ups 0.84 | wpb 35852.4 | bsz 368.4 | num_updates 13059 | lr 2.62522e-05 | gnorm 1.32 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 18130\n",
            "2022-12-24 23:29:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 595:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:29:17 | INFO | fairseq.trainer | begin training epoch 595\n",
            "2022-12-24 23:29:17 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 595:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:29:34 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.09it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:01, 14.90it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.21it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.50it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.54it/s]\u001b[A\n",
            "epoch 595 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:29:35 | INFO | dev_asr_nya | epoch 595 | valid on 'dev_asr_nya' subset | loss 1.616 | nll_loss 0.817 | total 3156.42 | n_correct 2678.63 | ppl 1.76 | accuracy 84.863 | wps 91787.8 | wpb 3156.4 | bsz 32.7 | num_updates 13081 | best_loss 1.615\n",
            "2022-12-24 23:29:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 595 @ 13081 updates\n",
            "2022-12-24 23:29:35 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint595.pt\n",
            "2022-12-24 23:29:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint595.pt\n",
            "2022-12-24 23:29:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint595.pt (epoch 595 @ 13081 updates, score 1.616) (writing took 8.999930403999315 seconds)\n",
            "2022-12-24 23:29:44 | INFO | fairseq_cli.train | end of epoch 595 (average epoch stats below)\n",
            "2022-12-24 23:29:44 | INFO | train | epoch 595 | loss 1.358 | nll_loss 0.585 | total 35852.4 | n_correct 32433.3 | ppl 1.5 | accuracy 90.463 | wps 29242.4 | ups 0.82 | wpb 35852.4 | bsz 368.4 | num_updates 13081 | lr 2.62302e-05 | gnorm 1.997 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 31.6 | wall 18157\n",
            "2022-12-24 23:29:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 596:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:29:44 | INFO | fairseq.trainer | begin training epoch 596\n",
            "2022-12-24 23:29:44 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 596:  95% 21/22 [00:16<00:00,  1.33it/s, loss=1.356, nll_loss=0.584, total=35896.4, n_correct=32492.2, ppl=1.5, accuracy=90.517, wps=30263.5, ups=0.84, wpb=35896.4, bsz=368, num_updates=13100, lr=2.62111e-05, gnorm=1.571, clip=0, loss_scale=4, train_wall=77, gb_free=31.2, wall=18173]2022-12-24 23:30:01 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.08it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.81it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.72it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.95it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "epoch 596 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 28.38it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:30:02 | INFO | dev_asr_nya | epoch 596 | valid on 'dev_asr_nya' subset | loss 1.626 | nll_loss 0.826 | total 3156.42 | n_correct 2669.74 | ppl 1.77 | accuracy 84.581 | wps 90021 | wpb 3156.4 | bsz 32.7 | num_updates 13103 | best_loss 1.615\n",
            "2022-12-24 23:30:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 596 @ 13103 updates\n",
            "2022-12-24 23:30:02 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint596.pt\n",
            "2022-12-24 23:30:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint596.pt\n",
            "2022-12-24 23:30:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint596.pt (epoch 596 @ 13103 updates, score 1.626) (writing took 9.002766982001049 seconds)\n",
            "2022-12-24 23:30:11 | INFO | fairseq_cli.train | end of epoch 596 (average epoch stats below)\n",
            "2022-12-24 23:30:11 | INFO | train | epoch 596 | loss 1.359 | nll_loss 0.588 | total 35852.4 | n_correct 32432.2 | ppl 1.5 | accuracy 90.46 | wps 29076.9 | ups 0.81 | wpb 35852.4 | bsz 368.4 | num_updates 13103 | lr 2.62081e-05 | gnorm 1.682 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.8 | wall 18185\n",
            "2022-12-24 23:30:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 597:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:30:11 | INFO | fairseq.trainer | begin training epoch 597\n",
            "2022-12-24 23:30:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 597:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:30:28 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.97it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.97it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.32it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.54it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.36it/s]\u001b[A\n",
            "epoch 597 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.41it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:30:29 | INFO | dev_asr_nya | epoch 597 | valid on 'dev_asr_nya' subset | loss 1.656 | nll_loss 0.862 | total 3156.42 | n_correct 2647.11 | ppl 1.82 | accuracy 83.864 | wps 92795.6 | wpb 3156.4 | bsz 32.7 | num_updates 13125 | best_loss 1.615\n",
            "2022-12-24 23:30:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 597 @ 13125 updates\n",
            "2022-12-24 23:30:29 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint597.pt\n",
            "2022-12-24 23:30:42 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint597.pt\n",
            "2022-12-24 23:30:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint597.pt (epoch 597 @ 13125 updates, score 1.656) (writing took 18.728187193999474 seconds)\n",
            "2022-12-24 23:30:48 | INFO | fairseq_cli.train | end of epoch 597 (average epoch stats below)\n",
            "2022-12-24 23:30:48 | INFO | train | epoch 597 | loss 1.354 | nll_loss 0.581 | total 35852.4 | n_correct 32476.3 | ppl 1.5 | accuracy 90.583 | wps 21440.9 | ups 0.6 | wpb 35852.4 | bsz 368.4 | num_updates 13125 | lr 2.61861e-05 | gnorm 1.579 | clip 0 | loss_scale 4 | train_wall 17 | gb_free 30.7 | wall 18221\n",
            "2022-12-24 23:30:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 598:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:30:48 | INFO | fairseq.trainer | begin training epoch 598\n",
            "2022-12-24 23:30:48 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 598:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:31:05 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.11it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.77it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.85it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.37it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.26it/s]\u001b[A\n",
            "epoch 598 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.79it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:31:06 | INFO | dev_asr_nya | epoch 598 | valid on 'dev_asr_nya' subset | loss 1.619 | nll_loss 0.82 | total 3156.42 | n_correct 2673.95 | ppl 1.77 | accuracy 84.715 | wps 93607.2 | wpb 3156.4 | bsz 32.7 | num_updates 13147 | best_loss 1.615\n",
            "2022-12-24 23:31:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 598 @ 13147 updates\n",
            "2022-12-24 23:31:06 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint598.pt\n",
            "2022-12-24 23:31:09 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint598.pt\n",
            "2022-12-24 23:31:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint598.pt (epoch 598 @ 13147 updates, score 1.619) (writing took 12.92536927999754 seconds)\n",
            "2022-12-24 23:31:19 | INFO | fairseq_cli.train | end of epoch 598 (average epoch stats below)\n",
            "2022-12-24 23:31:19 | INFO | train | epoch 598 | loss 1.349 | nll_loss 0.575 | total 35852.4 | n_correct 32528.4 | ppl 1.49 | accuracy 90.729 | wps 25439.6 | ups 0.71 | wpb 35852.4 | bsz 368.4 | num_updates 13147 | lr 2.61642e-05 | gnorm 1.05 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 18252\n",
            "2022-12-24 23:31:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 599:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:31:19 | INFO | fairseq.trainer | begin training epoch 599\n",
            "2022-12-24 23:31:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 599:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:31:36 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.36it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 14.60it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 17.05it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.68it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.68it/s]\u001b[A\n",
            "epoch 599 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.32it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:31:37 | INFO | dev_asr_nya | epoch 599 | valid on 'dev_asr_nya' subset | loss 1.651 | nll_loss 0.858 | total 3156.42 | n_correct 2652.42 | ppl 1.81 | accuracy 84.033 | wps 88935.3 | wpb 3156.4 | bsz 32.7 | num_updates 13169 | best_loss 1.615\n",
            "2022-12-24 23:31:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 599 @ 13169 updates\n",
            "2022-12-24 23:31:37 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint599.pt\n",
            "2022-12-24 23:31:45 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint599.pt\n",
            "2022-12-24 23:31:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint599.pt (epoch 599 @ 13169 updates, score 1.651) (writing took 13.766690289001417 seconds)\n",
            "2022-12-24 23:31:51 | INFO | fairseq_cli.train | end of epoch 599 (average epoch stats below)\n",
            "2022-12-24 23:31:51 | INFO | train | epoch 599 | loss 1.346 | nll_loss 0.571 | total 35852.4 | n_correct 32550.4 | ppl 1.49 | accuracy 90.79 | wps 24775.5 | ups 0.69 | wpb 35852.4 | bsz 368.4 | num_updates 13169 | lr 2.61424e-05 | gnorm 0.977 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.9 | wall 18284\n",
            "2022-12-24 23:31:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 600:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:31:51 | INFO | fairseq.trainer | begin training epoch 600\n",
            "2022-12-24 23:31:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 600:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:32:08 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.21it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.40it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.68it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.81it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.55it/s]\u001b[A\n",
            "epoch 600 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.71it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:32:08 | INFO | dev_asr_nya | epoch 600 | valid on 'dev_asr_nya' subset | loss 1.632 | nll_loss 0.837 | total 3156.42 | n_correct 2666.16 | ppl 1.79 | accuracy 84.468 | wps 93936.6 | wpb 3156.4 | bsz 32.7 | num_updates 13191 | best_loss 1.615\n",
            "2022-12-24 23:32:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 600 @ 13191 updates\n",
            "2022-12-24 23:32:08 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint600.pt\n",
            "2022-12-24 23:32:12 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint600.pt\n",
            "2022-12-24 23:32:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint600.pt (epoch 600 @ 13191 updates, score 1.632) (writing took 7.597519568997086 seconds)\n",
            "2022-12-24 23:32:16 | INFO | fairseq_cli.train | end of epoch 600 (average epoch stats below)\n",
            "2022-12-24 23:32:16 | INFO | train | epoch 600 | loss 1.345 | nll_loss 0.571 | total 35852.4 | n_correct 32560.2 | ppl 1.49 | accuracy 90.817 | wps 31007 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 13191 | lr 2.61206e-05 | gnorm 1.077 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.1 | wall 18310\n",
            "2022-12-24 23:32:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 601:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:32:16 | INFO | fairseq.trainer | begin training epoch 601\n",
            "2022-12-24 23:32:16 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 601:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.348, nll_loss=0.575, total=35789, n_correct=32472, ppl=1.49, accuracy=90.732, wps=24799.2, ups=0.69, wpb=35789, bsz=367.7, num_updates=13200, lr=2.61116e-05, gnorm=1.16, clip=0, loss_scale=8, train_wall=76, gb_free=31.4, wall=18317]2022-12-24 23:32:33 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.61it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.22it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.03it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.51it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.32it/s]\u001b[A\n",
            "epoch 601 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.76it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:32:34 | INFO | dev_asr_nya | epoch 601 | valid on 'dev_asr_nya' subset | loss 1.641 | nll_loss 0.847 | total 3156.42 | n_correct 2660.58 | ppl 1.8 | accuracy 84.291 | wps 93279.1 | wpb 3156.4 | bsz 32.7 | num_updates 13213 | best_loss 1.615\n",
            "2022-12-24 23:32:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 601 @ 13213 updates\n",
            "2022-12-24 23:32:34 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint601.pt\n",
            "2022-12-24 23:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint601.pt\n",
            "2022-12-24 23:32:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint601.pt (epoch 601 @ 13213 updates, score 1.641) (writing took 7.597378389000369 seconds)\n",
            "2022-12-24 23:32:42 | INFO | fairseq_cli.train | end of epoch 601 (average epoch stats below)\n",
            "2022-12-24 23:32:42 | INFO | train | epoch 601 | loss 1.346 | nll_loss 0.571 | total 35852.4 | n_correct 32551.4 | ppl 1.49 | accuracy 90.793 | wps 30681.2 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 13213 | lr 2.60988e-05 | gnorm 1.178 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.5 | wall 18335\n",
            "2022-12-24 23:32:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 602:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:32:42 | INFO | fairseq.trainer | begin training epoch 602\n",
            "2022-12-24 23:32:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 602:  95% 21/22 [00:16<00:00,  1.34it/s]2022-12-24 23:32:59 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.15it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.57it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.51it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.50it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 24.15it/s]\u001b[A\n",
            "epoch 602 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 27.20it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:33:00 | INFO | dev_asr_nya | epoch 602 | valid on 'dev_asr_nya' subset | loss 1.635 | nll_loss 0.84 | total 3156.42 | n_correct 2663 | ppl 1.79 | accuracy 84.368 | wps 85804.6 | wpb 3156.4 | bsz 32.7 | num_updates 13235 | best_loss 1.615\n",
            "2022-12-24 23:33:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 602 @ 13235 updates\n",
            "2022-12-24 23:33:00 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint602.pt\n",
            "2022-12-24 23:33:04 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint602.pt\n",
            "2022-12-24 23:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint602.pt (epoch 602 @ 13235 updates, score 1.635) (writing took 10.424717279001925 seconds)\n",
            "2022-12-24 23:33:10 | INFO | fairseq_cli.train | end of epoch 602 (average epoch stats below)\n",
            "2022-12-24 23:33:10 | INFO | train | epoch 602 | loss 1.346 | nll_loss 0.572 | total 35852.4 | n_correct 32543.5 | ppl 1.49 | accuracy 90.771 | wps 27714.5 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 13235 | lr 2.60771e-05 | gnorm 1.255 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 18364\n",
            "2022-12-24 23:33:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 603:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:33:10 | INFO | fairseq.trainer | begin training epoch 603\n",
            "2022-12-24 23:33:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 603:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:33:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.48it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 15.91it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 16.56it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.59it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.03it/s]\u001b[A\n",
            "epoch 603 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.65it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:33:28 | INFO | dev_asr_nya | epoch 603 | valid on 'dev_asr_nya' subset | loss 1.601 | nll_loss 0.8 | total 3156.42 | n_correct 2688.53 | ppl 1.74 | accuracy 85.176 | wps 89905.6 | wpb 3156.4 | bsz 32.7 | num_updates 13257 | best_loss 1.601\n",
            "2022-12-24 23:33:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 603 @ 13257 updates\n",
            "2022-12-24 23:33:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint603.pt\n",
            "2022-12-24 23:33:32 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint603.pt\n",
            "2022-12-24 23:33:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint603.pt (epoch 603 @ 13257 updates, score 1.601) (writing took 14.643843998001103 seconds)\n",
            "2022-12-24 23:33:43 | INFO | fairseq_cli.train | end of epoch 603 (average epoch stats below)\n",
            "2022-12-24 23:33:43 | INFO | train | epoch 603 | loss 1.346 | nll_loss 0.572 | total 35852.4 | n_correct 32538.8 | ppl 1.49 | accuracy 90.758 | wps 24136.1 | ups 0.67 | wpb 35852.4 | bsz 368.4 | num_updates 13257 | lr 2.60555e-05 | gnorm 1.455 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 29.8 | wall 18397\n",
            "2022-12-24 23:33:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 604:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:33:43 | INFO | fairseq.trainer | begin training epoch 604\n",
            "2022-12-24 23:33:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 604:  95% 21/22 [00:16<00:00,  1.30it/s]2022-12-24 23:34:00 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.96it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.54it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.58it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 20.14it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 22.93it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.00it/s]\u001b[A\n",
            "epoch 604 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 28.61it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:34:01 | INFO | dev_asr_nya | epoch 604 | valid on 'dev_asr_nya' subset | loss 1.659 | nll_loss 0.868 | total 3156.42 | n_correct 2649 | ppl 1.82 | accuracy 83.924 | wps 85494.6 | wpb 3156.4 | bsz 32.7 | num_updates 13279 | best_loss 1.601\n",
            "2022-12-24 23:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 604 @ 13279 updates\n",
            "2022-12-24 23:34:01 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint604.pt\n",
            "2022-12-24 23:34:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint604.pt\n",
            "2022-12-24 23:34:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint604.pt (epoch 604 @ 13279 updates, score 1.659) (writing took 8.363826409997273 seconds)\n",
            "2022-12-24 23:34:09 | INFO | fairseq_cli.train | end of epoch 604 (average epoch stats below)\n",
            "2022-12-24 23:34:09 | INFO | train | epoch 604 | loss 1.347 | nll_loss 0.573 | total 35852.4 | n_correct 32535.9 | ppl 1.49 | accuracy 90.75 | wps 29609.8 | ups 0.83 | wpb 35852.4 | bsz 368.4 | num_updates 13279 | lr 2.60339e-05 | gnorm 1.469 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.8 | wall 18423\n",
            "2022-12-24 23:34:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 605:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:34:10 | INFO | fairseq.trainer | begin training epoch 605\n",
            "2022-12-24 23:34:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 605:  95% 21/22 [00:16<00:00,  1.32it/s, loss=1.346, nll_loss=0.572, total=35864.6, n_correct=32555.2, ppl=1.49, accuracy=90.773, wps=29195.6, ups=0.81, wpb=35864.6, bsz=367.9, num_updates=13300, lr=2.60133e-05, gnorm=1.329, clip=0, loss_scale=8, train_wall=77, gb_free=31.2, wall=18440]2022-12-24 23:34:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.86it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.15it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.58it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.62it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.73it/s]\u001b[A\n",
            "epoch 605 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.92it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:34:28 | INFO | dev_asr_nya | epoch 605 | valid on 'dev_asr_nya' subset | loss 1.705 | nll_loss 0.924 | total 3156.42 | n_correct 2612.32 | ppl 1.9 | accuracy 82.762 | wps 92229.8 | wpb 3156.4 | bsz 32.7 | num_updates 13301 | best_loss 1.601\n",
            "2022-12-24 23:34:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 605 @ 13301 updates\n",
            "2022-12-24 23:34:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint605.pt\n",
            "2022-12-24 23:34:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint605.pt\n",
            "2022-12-24 23:34:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint605.pt (epoch 605 @ 13301 updates, score 1.705) (writing took 9.665264351999213 seconds)\n",
            "2022-12-24 23:34:37 | INFO | fairseq_cli.train | end of epoch 605 (average epoch stats below)\n",
            "2022-12-24 23:34:37 | INFO | train | epoch 605 | loss 1.341 | nll_loss 0.566 | total 35852.4 | n_correct 32599.5 | ppl 1.48 | accuracy 90.927 | wps 28396.9 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 13301 | lr 2.60123e-05 | gnorm 1.133 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.7 | wall 18451\n",
            "2022-12-24 23:34:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 606:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:34:37 | INFO | fairseq.trainer | begin training epoch 606\n",
            "2022-12-24 23:34:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 606:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:34:55 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.55it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.63it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.23it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.81it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.50it/s]\u001b[A\n",
            "epoch 606 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.85it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:34:55 | INFO | dev_asr_nya | epoch 606 | valid on 'dev_asr_nya' subset | loss 1.618 | nll_loss 0.822 | total 3156.42 | n_correct 2673.95 | ppl 1.77 | accuracy 84.715 | wps 93465.2 | wpb 3156.4 | bsz 32.7 | num_updates 13323 | best_loss 1.601\n",
            "2022-12-24 23:34:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 606 @ 13323 updates\n",
            "2022-12-24 23:34:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint606.pt\n",
            "2022-12-24 23:34:59 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint606.pt\n",
            "2022-12-24 23:35:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint606.pt (epoch 606 @ 13323 updates, score 1.618) (writing took 9.870439345002524 seconds)\n",
            "2022-12-24 23:35:05 | INFO | fairseq_cli.train | end of epoch 606 (average epoch stats below)\n",
            "2022-12-24 23:35:05 | INFO | train | epoch 606 | loss 1.347 | nll_loss 0.574 | total 35852.4 | n_correct 32546.4 | ppl 1.49 | accuracy 90.779 | wps 28057.4 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 13323 | lr 2.59908e-05 | gnorm 2.141 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.4 | wall 18479\n",
            "2022-12-24 23:35:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 607:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:35:05 | INFO | fairseq.trainer | begin training epoch 607\n",
            "2022-12-24 23:35:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 607:  95% 21/22 [00:16<00:00,  1.27it/s]2022-12-24 23:35:23 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.55it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.24it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.17it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 21.50it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 24.98it/s]\u001b[A\n",
            "epoch 607 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 26.53it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:35:24 | INFO | dev_asr_nya | epoch 607 | valid on 'dev_asr_nya' subset | loss 1.649 | nll_loss 0.857 | total 3156.42 | n_correct 2656.42 | ppl 1.81 | accuracy 84.159 | wps 85935.7 | wpb 3156.4 | bsz 32.7 | num_updates 13345 | best_loss 1.601\n",
            "2022-12-24 23:35:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 607 @ 13345 updates\n",
            "2022-12-24 23:35:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint607.pt\n",
            "2022-12-24 23:35:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint607.pt\n",
            "2022-12-24 23:35:34 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint607.pt (epoch 607 @ 13345 updates, score 1.649) (writing took 10.278037115000188 seconds)\n",
            "2022-12-24 23:35:34 | INFO | fairseq_cli.train | end of epoch 607 (average epoch stats below)\n",
            "2022-12-24 23:35:34 | INFO | train | epoch 607 | loss 1.347 | nll_loss 0.574 | total 35852.4 | n_correct 32525.5 | ppl 1.49 | accuracy 90.721 | wps 27529.7 | ups 0.77 | wpb 35852.4 | bsz 368.4 | num_updates 13345 | lr 2.59694e-05 | gnorm 1.98 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 32 | wall 18508\n",
            "2022-12-24 23:35:34 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 608:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:35:34 | INFO | fairseq.trainer | begin training epoch 608\n",
            "2022-12-24 23:35:34 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 608:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:35:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.26it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 17.49it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.09it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 22.97it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 25.96it/s]\u001b[A\n",
            "epoch 608 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.61it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:35:52 | INFO | dev_asr_nya | epoch 608 | valid on 'dev_asr_nya' subset | loss 1.625 | nll_loss 0.829 | total 3156.42 | n_correct 2673.53 | ppl 1.78 | accuracy 84.701 | wps 91949.4 | wpb 3156.4 | bsz 32.7 | num_updates 13367 | best_loss 1.601\n",
            "2022-12-24 23:35:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 608 @ 13367 updates\n",
            "2022-12-24 23:35:52 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint608.pt\n",
            "2022-12-24 23:35:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint608.pt\n",
            "2022-12-24 23:36:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint608.pt (epoch 608 @ 13367 updates, score 1.625) (writing took 10.01236731300014 seconds)\n",
            "2022-12-24 23:36:02 | INFO | fairseq_cli.train | end of epoch 608 (average epoch stats below)\n",
            "2022-12-24 23:36:02 | INFO | train | epoch 608 | loss 1.341 | nll_loss 0.566 | total 35852.4 | n_correct 32592.6 | ppl 1.48 | accuracy 90.908 | wps 28393.7 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 13367 | lr 2.5948e-05 | gnorm 1.169 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31 | wall 18535\n",
            "2022-12-24 23:36:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 609:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:36:02 | INFO | fairseq.trainer | begin training epoch 609\n",
            "2022-12-24 23:36:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 609:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:36:19 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.52it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 13.28it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.57it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.77it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 23.13it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 26.54it/s]\u001b[A\n",
            "epoch 609 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.44it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:36:20 | INFO | dev_asr_nya | epoch 609 | valid on 'dev_asr_nya' subset | loss 1.609 | nll_loss 0.809 | total 3156.42 | n_correct 2683.79 | ppl 1.75 | accuracy 85.026 | wps 87317.6 | wpb 3156.4 | bsz 32.7 | num_updates 13389 | best_loss 1.601\n",
            "2022-12-24 23:36:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 609 @ 13389 updates\n",
            "2022-12-24 23:36:20 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint609.pt\n",
            "2022-12-24 23:36:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint609.pt\n",
            "2022-12-24 23:36:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint609.pt (epoch 609 @ 13389 updates, score 1.609) (writing took 13.074452282999118 seconds)\n",
            "2022-12-24 23:36:33 | INFO | fairseq_cli.train | end of epoch 609 (average epoch stats below)\n",
            "2022-12-24 23:36:33 | INFO | train | epoch 609 | loss 1.342 | nll_loss 0.568 | total 35852.4 | n_correct 32567.3 | ppl 1.48 | accuracy 90.837 | wps 25096.6 | ups 0.7 | wpb 35852.4 | bsz 368.4 | num_updates 13389 | lr 2.59267e-05 | gnorm 1.701 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 18567\n",
            "2022-12-24 23:36:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 610:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:36:33 | INFO | fairseq.trainer | begin training epoch 610\n",
            "2022-12-24 23:36:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 610:  95% 21/22 [00:16<00:00,  1.34it/s, loss=1.344, nll_loss=0.57, total=35779.5, n_correct=32497.7, ppl=1.48, accuracy=90.828, wps=26293.7, ups=0.73, wpb=35779.5, bsz=367.3, num_updates=13400, lr=2.59161e-05, gnorm=1.671, clip=0, loss_scale=8, train_wall=77, gb_free=31.2, wall=18576]2022-12-24 23:36:51 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.14it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.33it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.26it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.16it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.33it/s]\u001b[A\n",
            "epoch 610 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.75it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:36:51 | INFO | dev_asr_nya | epoch 610 | valid on 'dev_asr_nya' subset | loss 1.619 | nll_loss 0.822 | total 3156.42 | n_correct 2675.68 | ppl 1.77 | accuracy 84.77 | wps 91959.8 | wpb 3156.4 | bsz 32.7 | num_updates 13411 | best_loss 1.601\n",
            "2022-12-24 23:36:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 610 @ 13411 updates\n",
            "2022-12-24 23:36:51 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint610.pt\n",
            "2022-12-24 23:37:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint610.pt\n",
            "2022-12-24 23:37:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint610.pt (epoch 610 @ 13411 updates, score 1.619) (writing took 18.774768220002443 seconds)\n",
            "2022-12-24 23:37:10 | INFO | fairseq_cli.train | end of epoch 610 (average epoch stats below)\n",
            "2022-12-24 23:37:10 | INFO | train | epoch 610 | loss 1.337 | nll_loss 0.561 | total 35852.4 | n_correct 32643.7 | ppl 1.48 | accuracy 91.05 | wps 21374.9 | ups 0.6 | wpb 35852.4 | bsz 368.4 | num_updates 13411 | lr 2.59054e-05 | gnorm 1.022 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 28.8 | wall 18604\n",
            "2022-12-24 23:37:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 611:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:37:10 | INFO | fairseq.trainer | begin training epoch 611\n",
            "2022-12-24 23:37:10 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 611:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:37:27 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.37it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 15.23it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:  26% 5/19 [00:00<00:00, 15.84it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:  42% 8/19 [00:00<00:00, 19.55it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:  63% 12/19 [00:00<00:00, 23.88it/s]\u001b[A\n",
            "epoch 611 | valid on 'dev_asr_nya' subset:  84% 16/19 [00:00<00:00, 26.77it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:37:28 | INFO | dev_asr_nya | epoch 611 | valid on 'dev_asr_nya' subset | loss 1.609 | nll_loss 0.81 | total 3156.42 | n_correct 2683.16 | ppl 1.75 | accuracy 85.006 | wps 85253.2 | wpb 3156.4 | bsz 32.7 | num_updates 13433 | best_loss 1.601\n",
            "2022-12-24 23:37:28 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 611 @ 13433 updates\n",
            "2022-12-24 23:37:28 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint611.pt\n",
            "2022-12-24 23:37:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint611.pt\n",
            "2022-12-24 23:37:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint611.pt (epoch 611 @ 13433 updates, score 1.609) (writing took 9.971444990002055 seconds)\n",
            "2022-12-24 23:37:38 | INFO | fairseq_cli.train | end of epoch 611 (average epoch stats below)\n",
            "2022-12-24 23:37:38 | INFO | train | epoch 611 | loss 1.336 | nll_loss 0.56 | total 35852.4 | n_correct 32650.8 | ppl 1.47 | accuracy 91.07 | wps 28023.1 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 13433 | lr 2.58842e-05 | gnorm 1.03 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.3 | wall 18632\n",
            "2022-12-24 23:37:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 612:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:37:38 | INFO | fairseq.trainer | begin training epoch 612\n",
            "2022-12-24 23:37:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 612:  95% 21/22 [00:16<00:00,  1.35it/s]2022-12-24 23:37:56 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.87it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.47it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.58it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:  58% 11/19 [00:00<00:00, 24.26it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset:  79% 15/19 [00:00<00:00, 27.22it/s]\u001b[A\n",
            "epoch 612 | valid on 'dev_asr_nya' subset: 100% 19/19 [00:00<00:00, 29.66it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:37:57 | INFO | dev_asr_nya | epoch 612 | valid on 'dev_asr_nya' subset | loss 1.613 | nll_loss 0.817 | total 3156.42 | n_correct 2680.74 | ppl 1.76 | accuracy 84.93 | wps 93316.1 | wpb 3156.4 | bsz 32.7 | num_updates 13455 | best_loss 1.601\n",
            "2022-12-24 23:37:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 612 @ 13455 updates\n",
            "2022-12-24 23:37:57 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint612.pt\n",
            "2022-12-24 23:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint612.pt\n",
            "2022-12-24 23:38:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint612.pt (epoch 612 @ 13455 updates, score 1.613) (writing took 9.80811606700081 seconds)\n",
            "2022-12-24 23:38:06 | INFO | fairseq_cli.train | end of epoch 612 (average epoch stats below)\n",
            "2022-12-24 23:38:06 | INFO | train | epoch 612 | loss 1.335 | nll_loss 0.559 | total 35852.4 | n_correct 32649 | ppl 1.47 | accuracy 91.065 | wps 28099.6 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 13455 | lr 2.5863e-05 | gnorm 1.024 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.7 | wall 18660\n",
            "2022-12-24 23:38:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 613:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:38:06 | INFO | fairseq.trainer | begin training epoch 613\n",
            "2022-12-24 23:38:06 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 613:  95% 21/22 [00:16<00:00,  1.31it/s]2022-12-24 23:38:24 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:01,  9.12it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 18.30it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 21.20it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 24.02it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 27.13it/s]\u001b[A\n",
            "epoch 613 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.95it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:38:24 | INFO | dev_asr_nya | epoch 613 | valid on 'dev_asr_nya' subset | loss 1.609 | nll_loss 0.81 | total 3156.42 | n_correct 2684.21 | ppl 1.75 | accuracy 85.04 | wps 92959.8 | wpb 3156.4 | bsz 32.7 | num_updates 13477 | best_loss 1.601\n",
            "2022-12-24 23:38:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 613 @ 13477 updates\n",
            "2022-12-24 23:38:24 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint613.pt\n",
            "2022-12-24 23:38:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint613.pt\n",
            "2022-12-24 23:38:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint613.pt (epoch 613 @ 13477 updates, score 1.609) (writing took 7.530766806998145 seconds)\n",
            "2022-12-24 23:38:32 | INFO | fairseq_cli.train | end of epoch 613 (average epoch stats below)\n",
            "2022-12-24 23:38:32 | INFO | train | epoch 613 | loss 1.351 | nll_loss 0.579 | total 35852.4 | n_correct 32481.8 | ppl 1.49 | accuracy 90.599 | wps 30701.4 | ups 0.86 | wpb 35852.4 | bsz 368.4 | num_updates 13477 | lr 2.58419e-05 | gnorm 2.963 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.7 | wall 18686\n",
            "2022-12-24 23:38:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 614:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:38:32 | INFO | fairseq.trainer | begin training epoch 614\n",
            "2022-12-24 23:38:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 614:  95% 21/22 [00:16<00:00,  1.33it/s]2022-12-24 23:38:49 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  8.44it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.85it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 20.40it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.34it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.05it/s]\u001b[A\n",
            "epoch 614 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.23it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:38:50 | INFO | dev_asr_nya | epoch 614 | valid on 'dev_asr_nya' subset | loss 1.618 | nll_loss 0.821 | total 3156.42 | n_correct 2675.79 | ppl 1.77 | accuracy 84.773 | wps 89101.3 | wpb 3156.4 | bsz 32.7 | num_updates 13499 | best_loss 1.601\n",
            "2022-12-24 23:38:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 614 @ 13499 updates\n",
            "2022-12-24 23:38:50 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint614.pt\n",
            "2022-12-24 23:38:56 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint614.pt\n",
            "2022-12-24 23:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint614.pt (epoch 614 @ 13499 updates, score 1.618) (writing took 10.041848262000713 seconds)\n",
            "2022-12-24 23:39:00 | INFO | fairseq_cli.train | end of epoch 614 (average epoch stats below)\n",
            "2022-12-24 23:39:00 | INFO | train | epoch 614 | loss 1.347 | nll_loss 0.575 | total 35852.4 | n_correct 32534.3 | ppl 1.49 | accuracy 90.745 | wps 28192.7 | ups 0.79 | wpb 35852.4 | bsz 368.4 | num_updates 13499 | lr 2.58208e-05 | gnorm 2.095 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 30.7 | wall 18714\n",
            "2022-12-24 23:39:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 615:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:39:00 | INFO | fairseq.trainer | begin training epoch 615\n",
            "2022-12-24 23:39:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 615:  95% 21/22 [00:16<00:00,  1.31it/s, loss=1.341, nll_loss=0.567, total=35900.1, n_correct=32636.2, ppl=1.48, accuracy=90.908, wps=25833.4, ups=0.72, wpb=35900.1, bsz=369.6, num_updates=13500, lr=2.58199e-05, gnorm=1.676, clip=0, loss_scale=8, train_wall=77, gb_free=30.7, wall=18715]2022-12-24 23:39:17 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.45it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:  16% 3/19 [00:00<00:01, 12.86it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:  32% 6/19 [00:00<00:00, 18.10it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:  47% 9/19 [00:00<00:00, 21.96it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:  68% 13/19 [00:00<00:00, 25.73it/s]\u001b[A\n",
            "epoch 615 | valid on 'dev_asr_nya' subset:  89% 17/19 [00:00<00:00, 27.99it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:39:18 | INFO | dev_asr_nya | epoch 615 | valid on 'dev_asr_nya' subset | loss 1.607 | nll_loss 0.809 | total 3156.42 | n_correct 2684.63 | ppl 1.75 | accuracy 85.053 | wps 90135.3 | wpb 3156.4 | bsz 32.7 | num_updates 13521 | best_loss 1.601\n",
            "2022-12-24 23:39:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 615 @ 13521 updates\n",
            "2022-12-24 23:39:18 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint615.pt\n",
            "2022-12-24 23:39:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint615.pt\n",
            "2022-12-24 23:39:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint615.pt (epoch 615 @ 13521 updates, score 1.607) (writing took 9.889634871000453 seconds)\n",
            "2022-12-24 23:39:28 | INFO | fairseq_cli.train | end of epoch 615 (average epoch stats below)\n",
            "2022-12-24 23:39:28 | INFO | train | epoch 615 | loss 1.344 | nll_loss 0.57 | total 35852.4 | n_correct 32548.6 | ppl 1.49 | accuracy 90.785 | wps 28138.6 | ups 0.78 | wpb 35852.4 | bsz 368.4 | num_updates 13521 | lr 2.57998e-05 | gnorm 2.161 | clip 0 | loss_scale 8 | train_wall 17 | gb_free 31.2 | wall 18742\n",
            "2022-12-24 23:39:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 22\n",
            "epoch 616:   0% 0/22 [00:00<?, ?it/s]2022-12-24 23:39:28 | INFO | fairseq.trainer | begin training epoch 616\n",
            "2022-12-24 23:39:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 616:  95% 21/22 [00:16<00:00,  1.29it/s]2022-12-24 23:39:46 | INFO | fairseq_cli.train | begin validation on \"dev_asr_nya\" subset\n",
            "\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:   5% 1/19 [00:00<00:02,  7.36it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:  21% 4/19 [00:00<00:00, 16.54it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:  37% 7/19 [00:00<00:00, 19.72it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:  53% 10/19 [00:00<00:00, 23.13it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:  74% 14/19 [00:00<00:00, 26.41it/s]\u001b[A\n",
            "epoch 616 | valid on 'dev_asr_nya' subset:  95% 18/19 [00:00<00:00, 28.92it/s]\u001b[A\n",
            "                                                                              \u001b[A2022-12-24 23:39:46 | INFO | dev_asr_nya | epoch 616 | valid on 'dev_asr_nya' subset | loss 1.626 | nll_loss 0.831 | total 3156.42 | n_correct 2669.84 | ppl 1.78 | accuracy 84.584 | wps 93480.7 | wpb 3156.4 | bsz 32.7 | num_updates 13543 | best_loss 1.601\n",
            "2022-12-24 23:39:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 616 @ 13543 updates\n",
            "2022-12-24 23:39:46 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint616.pt\n",
            "terminate called after throwing an instance of 'c10::Error'\n",
            "  what():  [enforce fail at inline_container.cc:325] . unexpected pos 768526656 vs 768526544\n",
            "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x55 (0x7f8b2a506725 in /usr/local/lib/python3.8/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x3cbad1c (0x7f8acfea6d1c in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: mz_zip_writer_add_mem_ex_v2 + 0x567 (0x7f8acfea1107 in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xb9 (0x7f8acfea8309 in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0x2c3 (0x7f8acfea87d3 in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x125 (0x7f8acfea8a45 in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #6: <unknown function> + 0x7fa915 (0x7f8af68ae915 in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #7: <unknown function> + 0x3d40ff (0x7f8af64880ff in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #8: <unknown function> + 0x3d503f (0x7f8af648903f in /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #9: /usr/bin/python3() [0x5d169c]\n",
            "frame #10: /usr/bin/python3() [0x545fd8]\n",
            "frame #11: /usr/bin/python3() [0x545f3e]\n",
            "frame #12: _PyEval_EvalFrameDefault + 0x23ae (0x55fafe in /usr/bin/python3)\n",
            "frame #13: _PyFunction_Vectorcall + 0x108 (0x5d8868 in /usr/bin/python3)\n",
            "frame #14: /usr/bin/python3() [0x4990ca]\n",
            "frame #15: _PyEval_EvalCodeWithName + 0x481 (0x55cd91 in /usr/bin/python3)\n",
            "frame #16: _PyFunction_Vectorcall + 0x1e1 (0x5d8941 in /usr/bin/python3)\n",
            "frame #17: /usr/bin/python3() [0x49abe4]\n",
            "frame #18: _PyFunction_Vectorcall + 0x108 (0x5d8868 in /usr/bin/python3)\n",
            "frame #19: /usr/bin/python3() [0x4997a2]\n",
            "frame #20: _PyEval_EvalCodeWithName + 0x768 (0x55d078 in /usr/bin/python3)\n",
            "frame #21: _PyFunction_Vectorcall + 0x1e1 (0x5d8941 in /usr/bin/python3)\n",
            "frame #22: /usr/bin/python3() [0x4997c7]\n",
            "frame #23: _PyFunction_Vectorcall + 0x108 (0x5d8868 in /usr/bin/python3)\n",
            "frame #24: /usr/bin/python3() [0x4990ca]\n",
            "frame #25: _PyFunction_Vectorcall + 0x108 (0x5d8868 in /usr/bin/python3)\n",
            "frame #26: PyVectorcall_Call + 0x356 (0x5d8506 in /usr/bin/python3)\n",
            "frame #27: _PyEval_EvalFrameDefault + 0x2047 (0x55f797 in /usr/bin/python3)\n",
            "frame #28: _PyEval_EvalCodeWithName + 0x768 (0x55d078 in /usr/bin/python3)\n",
            "frame #29: _PyFunction_Vectorcall + 0x1e1 (0x5d8941 in /usr/bin/python3)\n",
            "frame #30: /usr/bin/python3() [0x4990ca]\n",
            "frame #31: _PyFunction_Vectorcall + 0x108 (0x5d8868 in /usr/bin/python3)\n",
            "frame #32: PyVectorcall_Call + 0x356 (0x5d8506 in /usr/bin/python3)\n",
            "frame #33: _PyEval_EvalFrameDefault + 0x2047 (0x55f797 in /usr/bin/python3)\n",
            "frame #34: _PyEval_EvalCodeWithName + 0x481 (0x55cd91 in /usr/bin/python3)\n",
            "frame #35: _PyFunction_Vectorcall + 0x1e1 (0x5d8941 in /usr/bin/python3)\n",
            "frame #36: /usr/bin/python3() [0x4997c7]\n",
            "frame #37: /usr/bin/python3() [0x5d86e9]\n",
            "frame #38: /usr/bin/python3() [0x4990ca]\n",
            "frame #39: _PyEval_EvalCodeWithName + 0x481 (0x55cd91 in /usr/bin/python3)\n",
            "frame #40: PyEval_EvalCode + 0x23 (0x55d743 in /usr/bin/python3)\n",
            "frame #41: /usr/bin/python3() [0x642630]\n",
            "frame #42: /usr/bin/python3() [0x6426ae]\n",
            "frame #43: /usr/bin/python3() [0x644b78]\n",
            "frame #44: PyRun_SimpleFileExFlags + 0x19c (0x64511c in /usr/bin/python3)\n",
            "frame #45: Py_RunMain + 0x2be (0x677e5e in /usr/bin/python3)\n",
            "frame #46: Py_BytesMain + 0x29 (0x678029 in /usr/bin/python3)\n",
            "frame #47: __libc_start_main + 0xe7 (0x7f8b37d47c87 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #48: _start + 0x2a (0x5e1baa in /usr/bin/python3)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!fairseq-train /content/zambezi-voice/nyanja/nya \\\n",
        "  --config-yaml config_asr_nya.yaml \\\n",
        "  --train-subset train_asr_nya \\\n",
        "  --valid-subset dev_asr_nya \\\n",
        "  --save-dir /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints \\\n",
        "  --num-workers 4 \\\n",
        "  --max-tokens 50000 \\\n",
        "  --max-update 20000 \\\n",
        "  --keep-interval-updates 10 \\\n",
        "  --task speech_to_text \\\n",
        "  --criterion label_smoothed_cross_entropy \\\n",
        "  --label-smoothing 0.1 \\\n",
        "  --report-accuracy \\\n",
        "  --arch s2t_transformer_m \\\n",
        "  --dropout 0.15 \\\n",
        "  --optimizer adam \\\n",
        "  --lr 3e-5 \\\n",
        "  --fp16 \\\n",
        "  --lr-scheduler inverse_sqrt \\\n",
        "  --warmup-updates 10000 \\\n",
        "  --clip-norm 10.0 \\\n",
        "  --scoring wer \\\n",
        "  --seed 1 \\\n",
        "  --update-freq 8 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0D2qv686eJy",
        "outputId": "4ee003f9-808f-49f9-8afb-fa908a685cf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(checkpoint_upper_bound=None, inputs=['/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints'], num_best_checkpoints=0, num_epoch_checkpoints=615, num_update_checkpoints=None, output='/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/avg_last_615_checkpoint.pt')\n",
            "averaging checkpoints:  ['/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint615.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint614.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint613.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint612.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint611.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint610.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint609.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint608.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint607.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint606.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint605.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint604.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint603.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint602.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint601.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint600.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint599.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint598.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint597.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint596.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint595.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint594.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint593.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint592.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint591.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint590.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint589.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint588.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint587.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint586.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint585.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint584.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint583.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint582.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint581.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint580.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint579.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint578.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint577.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint576.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint575.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint574.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint573.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint572.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint571.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint570.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint569.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint568.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint567.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint566.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint565.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint564.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint563.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint562.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint561.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint560.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint559.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint558.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint557.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint556.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint555.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint554.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint553.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint552.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint551.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint550.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint549.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint548.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint547.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint546.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint545.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint544.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint543.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint542.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint541.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint540.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint539.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint538.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint537.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint536.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint535.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint534.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint533.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint532.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint531.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint530.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint529.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint528.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint527.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint526.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint525.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint524.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint523.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint522.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint521.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint520.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint519.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint518.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint517.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint516.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint515.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint514.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint513.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint512.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint511.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint510.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint509.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint508.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint507.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint506.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint505.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint504.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint503.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint502.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint501.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint499.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint498.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint497.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint496.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint495.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint494.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint493.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint492.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint491.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint490.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint489.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint488.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint487.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint486.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint485.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint484.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint483.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint482.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint481.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint480.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint479.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint478.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint477.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint476.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint475.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint474.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint473.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint472.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint471.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint470.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint469.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint468.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint467.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint466.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint465.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint464.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint463.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint462.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint461.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint460.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint459.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint458.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint457.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint456.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint455.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint454.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint453.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint452.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint451.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint450.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint449.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint448.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint447.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint446.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint445.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint444.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint443.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint442.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint441.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint440.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint439.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint438.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint437.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint436.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint435.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint434.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint433.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint432.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint431.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint430.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint429.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint428.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint427.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint426.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint425.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint424.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint423.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint422.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint421.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint420.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint419.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint418.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint417.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint416.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint415.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint414.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint413.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint412.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint411.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint410.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint409.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint408.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint407.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint406.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint405.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint404.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint403.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint402.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint401.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint400.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint399.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint398.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint397.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint396.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint395.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint394.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint393.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint392.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint391.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint390.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint389.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint388.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint387.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint386.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint385.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint384.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint383.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint382.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint381.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint380.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint379.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint378.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint377.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint376.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint375.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint374.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint373.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint372.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint371.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint370.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint369.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint368.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint367.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint366.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint365.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint364.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint363.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint362.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint361.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint360.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint359.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint358.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint357.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint356.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint355.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint354.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint353.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint352.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint351.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint350.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint349.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint348.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint347.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint346.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint345.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint344.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint343.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint342.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint341.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint340.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint339.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint338.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint337.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint336.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint335.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint334.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint333.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint332.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint331.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint330.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint329.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint328.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint327.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint326.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint325.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint324.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint323.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint322.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint321.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint320.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint319.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint318.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint317.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint316.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint315.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint314.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint313.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint312.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint311.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint310.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint309.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint308.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint307.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint306.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint305.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint304.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint303.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint302.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint301.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint300.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint299.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint298.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint297.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint296.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint295.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint294.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint293.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint292.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint291.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint290.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint289.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint288.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint287.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint286.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint285.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint284.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint283.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint282.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint281.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint280.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint279.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint278.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint277.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint276.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint275.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint274.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint273.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint272.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint271.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint270.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint269.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint268.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint267.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint266.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint265.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint264.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint263.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint262.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint261.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint260.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint259.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint258.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint257.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint256.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint255.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint254.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint253.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint252.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint251.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint250.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint249.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint248.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint247.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint246.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint245.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint244.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint243.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint242.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint241.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint240.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint239.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint238.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint237.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint236.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint235.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint234.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint233.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint232.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint231.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint230.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint229.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint228.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint227.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint226.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint225.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint224.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint223.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint222.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint221.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint220.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint219.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint218.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint217.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint216.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint215.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint214.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint213.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint212.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint211.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint210.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint209.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint208.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint207.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint206.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint205.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint204.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint203.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint202.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint201.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint200.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint199.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint198.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint197.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint196.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint195.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint194.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint193.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint192.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint191.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint190.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint189.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint188.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint187.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint186.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint185.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint184.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint183.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint182.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint181.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint180.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint179.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint178.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint177.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint176.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint175.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint174.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint173.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint172.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint171.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint170.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint169.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint168.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint167.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint166.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint165.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint164.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint163.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint162.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint161.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint160.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint159.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint158.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint157.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint156.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint155.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint154.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint153.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint152.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint151.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint150.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint149.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint148.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint147.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint146.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint145.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint144.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint143.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint142.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint141.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint140.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint139.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint138.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint137.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint136.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint135.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint134.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint133.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint132.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint131.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint130.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint129.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint128.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint127.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint126.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint125.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint124.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint123.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint122.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint121.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint120.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint119.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint118.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint117.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint116.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint115.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint114.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint113.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint112.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint111.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint110.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint109.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint108.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint107.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint106.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint105.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint104.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint103.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint102.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint101.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint100.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint99.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint98.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint97.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint96.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint95.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint94.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint93.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint92.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint91.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint90.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint89.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint88.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint87.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint86.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint85.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint84.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint83.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint82.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint81.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint80.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint79.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint78.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint77.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint76.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint75.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint74.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint73.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint72.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint71.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint70.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint69.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint68.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint67.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint66.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint65.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint64.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint63.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint62.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint61.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint60.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint59.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint58.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint57.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint56.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint55.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint54.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint53.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint52.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint51.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint50.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint49.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint48.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint47.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint46.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint45.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint44.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint43.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint42.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint41.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint40.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint39.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint38.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint37.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint36.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint35.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint34.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint33.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint32.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint31.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint30.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint29.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint28.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint27.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint26.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint25.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint24.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint23.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint22.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint21.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint20.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint19.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint18.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint17.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint16.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint15.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint14.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint13.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint12.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint11.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint10.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint9.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint8.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint7.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint6.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint5.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint4.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint3.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint2.pt', '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint1.pt']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fairseq/scripts/average_checkpoints.py\", line 176, in <module>\n",
            "    main()\n",
            "  File \"/content/fairseq/scripts/average_checkpoints.py\", line 169, in main\n",
            "    new_state = average_checkpoints(args.inputs)\n",
            "  File \"/content/fairseq/scripts/average_checkpoints.py\", line 35, in average_checkpoints\n",
            "    state = torch.load(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 795, in load\n",
            "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 1002, in _legacy_load\n",
            "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
            "EOFError: Ran out of input\n"
          ]
        }
      ],
      "source": [
        "!python /content/fairseq/scripts/average_checkpoints.py \\\n",
        "  --inputs /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints \\\n",
        "  --num-epoch-checkpoints 10 \\\n",
        "  --output /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/avg_last_10_checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint_best.pt /content/"
      ],
      "metadata": {
        "id": "SR8T4PbBjVKv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2bqCRKS7SBo",
        "outputId": "9acfec08-06c8-408e-c6ed-dcdccd84a6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-25 00:18:53 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test_asr_nya', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': Namespace(_name='speech_to_text', aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='wav2vec2', azureml_logging=False, batch_size=None, batch_size_valid=None, beam=5, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', combine_valid_subsets=None, config_yaml='config_asr_nya.yaml', constraints=None, continue_once=None, cpu=False, cpu_offload=False, criterion='cross_entropy', curriculum=0, data='/content/zambezi-voice/nyanja/nya', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eos_token=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test_asr_nya', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, lenpen=1, lm_path=None, lm_weight=0.0, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_source_positions=6000, max_target_positions=1024, max_tokens=50000, max_tokens_valid=50000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_repeat_ngram_size=0, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer=None, optimizer_overrides='{}', path='/content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', post_process=None, prefix_size=0, print_alignment=None, print_step=False, profile=False, quantization_config_path=None, quiet=False, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, save_dir='checkpoints', save_interval=1, save_interval_updates=0, score_reference=False, scoring='wer', seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, suppress_crashes=False, task='speech_to_text', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', unkpen=0, unnormalized=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=0, wer_char_level=False, wer_lowercase=True, wer_remove_punct=True, wer_tokenizer='13a', write_checkpoints_asynchronously=False, zero_sharding='none'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': '13a', 'wer_remove_punct': True, 'wer_char_level': False, 'wer_lowercase': True}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-25 00:18:53 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm_char_asr_nya.txt): 31\n",
            "2022-12-25 00:18:53 | INFO | fairseq_cli.generate | loading model(s) from /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt\n",
            "2022-12-25 00:18:55 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2022-12-25 00:18:55 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "2022-12-25 00:18:55 | INFO | fairseq.data.audio.speech_to_text_dataset | 'test_asr_nya' has 0.00% OOV\n",
            "2022-12-25 00:18:55 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split=\"test_asr_nya\", n_samples=428, prepend_tgt_lang_tag=False, shuffle=False, transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "), n_frames_per_step=1\n",
            "  0% 0/13 [00:00<?, ?it/s]2022-12-25 00:18:57 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}\n",
            "2022-12-25 00:18:57 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/content/zambezi-voice/nyanja/nya/spm_char_asr_nya.model'}\n",
            "T-40\tanthu amitundu yosiyanasiyana amuna kapena akazi ndi zaka amasangalala kwambiri pamene amuna awiri ali mu mpikisano wa masewera a karati amuna amavala zovala zoyera nthawi zonse pamene wina akuyesa kumenyana ndi nyumba yozungulira osewera awiri amatsogolera masewerawo ndi mmodzi atakhala pampando akuomba muluzi pomwe winayo ali pafupi ndi omenyana awiriwa\n",
            "H-40\t-0.44192707538604736\t▁ a n t h u ▁ a m b i r i ▁ a m i t u n d u ▁ y a c h i n y a m a t a ▁ p a m w a m b a ▁ p a ▁ c h i n t h u ▁ c h o k h a l a ▁ n g a t i ▁ m a l a y a ▁ o b i r i w i r a ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ y o f i i r a ▁ n d i ▁ m a y i ▁ w i n a ▁ w a c h i k a s u ▁ y e m w e ▁ w a v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ m a l a y a ▁ o f i i r a ▁ n d\n",
            "D-40\t-0.44192707538604736\tanthu ambiri amitundu yachinyamata pamwamba pa chinthu chokhala ngati malaya obiriwira pamene mwamuna wina wovala jekete yofiira ndi mayi wina wachikasu yemwe wavala malaya oyera ndi malaya ofiira nd\n",
            "P-40\t-0.1182 -0.9206 -0.2178 -0.2137 -0.0563 -0.0810 -0.1080 -0.0799 -0.0957 -1.6361 -0.0648 -0.2873 -0.1115 -0.1119 -1.5199 -0.1252 -1.6947 -0.4426 -0.0802 -0.1131 -0.1473 -0.0969 -0.1229 -0.0262 -0.8698 -0.5662 -0.0558 -0.0700 -1.1607 -2.3006 -0.1239 -0.5730 -0.7181 -0.2778 -0.0628 -0.1696 -0.4764 -0.1762 -0.5306 -0.7725 -0.1121 -0.0392 -0.1042 -0.1010 -0.0958 -0.2235 -0.2336 -0.1834 -0.8178 -0.1600 -0.1240 -1.7348 -1.6539 -0.1118 -0.1154 -0.1159 -0.5884 -0.1169 -2.2813 -0.3379 -0.1364 -0.1254 -0.0282 -0.1177 -0.1208 -0.8011 -1.6347 -0.1288 -0.1191 -0.0753 -0.0884 -1.8240 -0.5205 -0.4691 -0.2970 -0.9920 -0.1155 -0.0862 -0.2643 -0.6512 -0.0476 -0.0307 -0.0776 -0.0305 -0.0725 -0.0300 -0.1871 -0.1620 -1.2478 -0.1377 -0.1345 -0.0356 -0.0746 -0.0406 -0.1190 -0.1445 -1.6317 -0.1336 -0.0268 -0.3569 -0.0472 -0.0925 -0.1190 -0.0425 -0.1553 -0.1628 -0.0971 -0.1266 -0.4432 -2.0117 -0.7203 -0.1940 -0.0724 -0.3629 -0.1144 -2.0746 -1.1357 -0.3499 -0.0711 -0.0788 -0.1804 -0.0842 -0.6275 -1.2675 -2.2373 -0.1954 -0.2590 -0.0898 -0.1621 -0.1255 -0.7235 -0.0718 -0.0898 -0.3649 -0.4029 -0.1816 -1.5345 -0.1678 -0.1123 -0.0770 -0.1663 -0.1115 -0.1562 -0.2105 -0.3591 -0.6248 -0.4263 -0.0633 -0.0849 -0.2181 -0.3634 -0.2103 -0.0406 -0.0553 -2.4279 -0.4836 -0.0734 -0.0466 -0.0551 -0.0950 -0.5615 -1.3681 -1.3394 -0.0866 -0.0814 -0.1240 -0.0963 -1.3715 -0.1234 -0.0927 -0.1142 -0.0194 -0.0866 -0.0644 -0.7363 -0.8614 -0.0878 -0.0674 -0.0897 -0.0778 -0.6477 -0.0249 -0.0434 -0.1914 -1.2810 -0.4321 -1.0267 -0.1937 -0.0687 -0.0935 -0.0566 -0.6595 -1.0970 -0.0492 -0.1380 -0.0312 -0.1065 -0.0981 -1.8075 -0.0394 -9.6484\n",
            "T-41\tomenyera nkhondo awiri ovala zoyera atayima papulatifomu limodzi ndi mwamuna wina wovala thalauza lakuda ndi batani lamanja lalifupi yemwe amawona ngati phazi la munthu wina likuloza kumaso kwa mdani wake wotsekereza\n",
            "H-41\t-0.42990145087242126\t▁ w o m e n y a n a ▁ w a m t u n d u ▁ w o v a l a ▁ c h o v a l a ▁ c h o y e r a ▁ a k u l a n k h u l a ▁ p a t e b u l o ▁ n d i ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ l a k u d a ▁ n d i ▁ m a t h a l a u z a ▁ a k u d a ▁ n d i ▁ m a n j a ▁ a k e ▁ p a m e n e ▁ m w a m u n a ▁ w o c h i t i r a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ z i t h u n z i ▁ k o m a\n",
            "D-41\t-0.42990145087242126\twomenyana wamtundu wovala chovala choyera akulankhula patebulo ndi mwamuna wina wovala jekete lakuda ndi mathalauza akuda ndi manja ake pamene mwamuna wochitira wovala malaya ofiira ndi zithunzi koma\n",
            "P-41\t-0.1185 -0.4357 -0.0267 -0.0427 -0.3311 -0.2454 -0.9248 -0.2876 -0.7005 -0.2556 -0.1071 -1.0257 -0.8375 -1.1829 -1.9044 -0.1529 -0.1551 -0.0367 -0.1160 -0.0772 -0.1192 -0.4506 -0.4006 -0.1265 -0.0585 -0.1226 -0.1054 -1.7623 -0.0738 -0.0988 -1.3135 -0.2039 -0.0684 -0.1488 -0.1052 -1.4891 -0.1660 -0.4303 -1.0431 -0.3536 -0.0537 -0.1252 -0.1511 -0.2800 -0.3519 -0.0986 -2.0714 -1.0347 -0.8175 -0.0554 -0.0558 -0.1601 -0.0210 -0.1446 -0.1202 -0.2014 -0.3076 -2.3402 -0.3086 -0.2231 -0.1206 -0.0541 -0.0397 -0.1331 -1.3839 -0.1000 -0.0901 -0.1278 -0.3162 -0.4772 -0.1309 -0.0507 -0.0518 -0.0453 -0.1126 -0.1292 -0.1186 -1.3242 -0.0525 -0.1082 -0.1294 -0.2729 -0.4348 -0.0742 -0.1034 -0.0753 -0.1222 -0.1321 -0.2412 -0.3643 -0.2228 -0.0842 -0.0130 -0.3374 -0.1092 -0.0703 -0.1310 -1.2258 -0.0534 -0.0228 -0.0925 -0.1193 -0.1325 -0.0963 -0.0920 -0.4311 -0.9903 -0.3029 -1.7818 -0.4054 -0.0921 -0.0314 -0.1320 -0.0117 -0.1224 -0.0820 -0.1076 -0.4548 -1.9283 -0.1926 -0.1452 -0.0805 -0.1173 -0.2440 -0.0982 -0.1140 -0.6277 -0.6507 -0.2346 -0.3009 -0.0357 -0.0958 -0.0987 -1.1505 -1.0730 -0.3488 -0.0795 -1.3207 -0.1383 -0.1362 -1.1653 -0.2269 -0.0705 -0.0943 -0.1618 -0.4255 -0.0852 -0.0824 -0.0457 -0.0516 -0.1125 -0.1053 -0.0212 -0.3697 -1.5324 -0.0861 -0.3584 -0.0311 -0.4339 -0.5682 -0.1099 -0.1000 -2.0106 -0.7859 -0.8538 -0.0858 -0.0709 -0.1099 -0.0960 -0.9411 -0.4501 -0.7224 -0.1514 -0.0431 -0.0928 -0.0666 -0.6877 -1.9693 -0.2709 -0.0668 -0.0586 -0.2071 -0.0953 -0.7632 -0.0493 -0.0582 -0.1521 -1.5931 -0.8131 -0.7959 -1.6153 -0.1727 -0.2879 -1.0526 -0.0635 -0.1326 -1.8656 -1.1376 -0.1163 -0.6228 -8.6420\n",
            "T-313\tbanja lina lachinyamata likukhala pampando mkaziyo atavala malaya a ntchito ya buluu maso ake atatsekedwa pamene mwamunayo akukhala ndi mkono wake mozungulira akuyang ana kamera mu malaya otuwa\n",
            "H-313\t-0.3203614056110382\t▁ b a n j a ▁ l i n a ▁ l a c h i n y a m a t a ▁ l i k u k h a l a ▁ p a m p a n d o ▁ w o k h a l a ▁ n d i ▁ z i d a ▁ a t a n y a m u l a ▁ c h i t h u n z i ▁ n d i ▁ m a s o ▁ a k e ▁ a t a t s e k e ▁ p a m e n e ▁ m w a m u n a ▁ w a k e ▁ p a m e n e ▁ m w a m u n a ▁ w o k h a l a ▁ n d i ▁ m a l a y a ▁ a k u d a ▁ a k u y a n g ▁ a n a ▁ k u m b u y o ▁ k w a k e\n",
            "D-313\t-0.3203614056110382\tbanja lina lachinyamata likukhala pampando wokhala ndi zida atanyamula chithunzi ndi maso ake atatseke pamene mwamuna wake pamene mwamuna wokhala ndi malaya akuda akuyang ana kumbuyo kwake\n",
            "P-313\t-0.1189 -1.5633 -0.1085 -0.7026 -0.0323 -0.0991 -0.1209 -0.0723 -0.3806 -0.0920 -0.0987 -0.1810 -0.5279 -0.1524 -0.3743 -0.0794 -0.0594 -0.4277 -0.0862 -0.1234 -0.0760 -0.0865 -0.0084 -0.0801 -0.1214 -0.0501 -0.0871 -0.0222 -0.0570 -0.4393 -0.3882 -0.1313 -0.0695 -0.1493 -0.1231 -0.0549 -0.1191 -0.1309 -0.1787 -0.2006 -0.0772 -0.0174 -0.0287 -0.1137 -1.9492 -1.0920 -0.3425 -0.7055 -0.1267 -0.3512 -0.1178 -0.1487 -0.5190 -0.1136 -0.0965 -0.1195 -1.8275 -0.0405 -0.7470 -0.1494 -0.1096 -1.7234 -0.0847 -0.0926 -1.1281 -0.0477 -0.0847 -0.0389 -0.1096 -0.0526 -0.1105 -0.1281 -1.7015 -0.0949 -0.0657 -0.4148 -0.7074 -0.0244 -0.0486 -0.1517 -0.0717 -0.1945 -2.0581 -0.1230 -0.1226 -0.6796 -0.4342 -0.1920 -0.1930 -0.5316 -0.1211 -0.1613 -1.0618 -0.1116 -0.1289 -0.7308 -0.7558 -0.0825 -0.8596 -0.5859 -0.0545 -0.5869 -0.0285 -0.8523 -0.1372 -0.2443 -0.3934 -0.0910 -0.0352 -0.0179 -0.1124 -0.4794 -0.4081 -0.1271 -0.0250 -0.0212 -0.0389 -0.0808 -0.1227 -0.3761 -0.5132 -0.8603 -0.5453 -0.1005 -1.3918 -0.1352 -0.3041 -0.1114 -0.0509 -0.0183 -0.1188 -0.2780 -0.2922 -0.0992 -0.0346 -0.0195 -0.0555 -0.0730 -0.1154 -0.3411 -3.1294 -0.2074 -0.1040 -0.1162 -0.0806 -0.1078 -0.0938 -0.2579 -0.0472 -0.0866 -0.3187 -0.3208 -0.4067 -1.1319 -0.1763 -0.0599 -0.0790 -0.0702 -1.0159 -0.2265 -0.1509 -0.2753 -0.6780 -0.0951 -1.3522 -0.7886 -0.1263 -0.6998 -0.1394 -0.0338 -0.0898 -0.0745 -0.0745 -0.0238 -0.1564 -0.1040 -0.4866 -0.2725 -0.4415 -1.8373 -0.0375 -0.0174 -0.0460 -0.1251 -0.0849 -0.1589 -0.1557 -0.2791 -0.0514 -1.5072\n",
            "T-341\tgulu la anthu kuphatikizapo mwamuna ndi mkazi wokhala ndi zopalasa aimirira pafupi ndi charging bull yomwe nthawi zina imatchedwa wall street bull chosema chachikulu cha mkuwa chomwe chili ku bowling green park pafupi ndi wall street ku manhattan new york city\n",
            "H-341\t-0.37595975399017334\t▁ g u l u ▁ l a ▁ a n t h u ▁ o v a l a ▁ t ▁ s h i r t ▁ k o m a n s o ▁ n d i ▁ m k a z i ▁ w o k h a l a ▁ n d i ▁ z o v a l a ▁ z o b i r i w i r a ▁ a k u k h a l a ▁ p a f u p i ▁ n d i ▁ n j i n g a ▁ z i n t h u ▁ z a m a s e w e r a ▁ c h i k u w o n e t s e d w a ▁ c h a c h i k u l u ▁ k u m b u y o ▁ k w a ▁ c h i t h u n z i ▁ c h a c h i k u l u ▁ c h o f i i r a\n",
            "D-341\t-0.37595975399017334\tgulu la anthu ovala t shirt komanso ndi mkazi wokhala ndi zovala zobiriwira akukhala pafupi ndi njinga zinthu zamasewera chikuwonetsedwa chachikulu kumbuyo kwa chithunzi chachikulu chofiira\n",
            "P-341\t-0.1072 -0.2020 -0.0260 -0.0764 -0.0662 -0.0907 -0.0259 -0.0963 -0.0961 -0.1079 -0.2647 -0.0252 -0.0509 -0.0528 -0.0962 -2.4210 -0.5853 -0.1561 -0.1109 -0.1697 -0.1129 -1.2866 -0.1690 -0.1517 -0.2214 -0.1886 -0.0400 -0.0288 -0.1165 -2.8566 -0.5265 -0.3708 -0.2347 -0.0385 -0.7696 -0.0932 -0.0991 -0.8423 -0.1682 -0.1025 -0.1514 -0.4672 -0.5591 -0.2056 -0.0080 -0.0654 -0.1031 -0.1875 -0.0703 -0.3794 -0.0140 -0.1253 -0.1231 -0.1181 -0.1513 -0.1609 -0.0500 -0.0852 -0.1079 -0.1060 -0.0670 -0.7376 -0.0896 -0.0636 -0.1231 -0.1201 -0.0927 -0.8483 -2.2147 -0.1269 -0.0735 -0.0939 -0.0656 -0.0952 -0.0427 -0.0950 -0.1261 -0.6630 -1.2425 -0.1533 -1.7254 -0.6210 -0.1537 -0.1893 -0.1503 -0.1112 -0.1875 -0.1250 -0.4065 -0.0783 -0.0600 -0.0646 -0.1197 -0.0274 -0.0586 -0.1279 -0.1100 -2.3854 -0.4937 -0.1491 -0.0463 -0.2746 -0.0807 -0.1320 -0.3082 -0.8949 -0.9061 -1.3394 -0.1238 -0.0698 -0.1220 -0.1561 -0.2864 -1.1215 -0.3670 -0.7754 -0.0949 -0.6135 -0.1790 -0.1949 -0.1537 -0.1321 -1.8547 -0.1817 -1.1638 -0.6562 -0.0667 -0.4096 -0.3492 -0.3445 -0.5241 -0.4484 -0.1390 -0.0718 -0.8273 -0.0345 -0.1118 -0.1143 -0.1433 -0.0612 -0.2039 -1.0161 -0.0999 -0.0434 -0.0276 -0.0713 -0.0710 -0.0534 -0.0846 -2.0217 -0.1906 -1.9649 -0.7160 -0.0865 -0.1062 -0.0568 -0.1113 -0.2946 -0.6429 -0.1125 -0.6685 -0.6197 -0.0507 -0.0642 -1.0521 -0.9184 -0.1390 -0.1486 -0.4071 -0.0499 -0.1441 -0.5759 -0.0736 -0.4454 -3.2114 -0.0713 -0.0922 -0.1064 -0.2134 -0.0757 -0.2091 -0.1272 -1.5112 -0.0580 -1.5358 -0.9884 -0.1727 -0.1954 -0.0698 -0.1622 -2.8381\n",
            "T-398\tmagulu awiri othamanga omwe ali ndi osewera anayi ovala mayunifolomu ofiira ndi oyera komanso osewera awiri ovala mayunifolomu obiriwira ndi achikasu amagwira maukonde pamitengo ndikuthamangira m bwalo kutsogolo kwa mpanda wautali wazitsulo\n",
            "H-398\t-0.34995806217193604\t▁ m a g u l u ▁ a w i r i ▁ o t h a m a n g a ▁ o m w e ▁ a l i ▁ n d i ▁ m a s e w e r a ▁ n d i ▁ o v a l a ▁ m a y u n i f o l o m u ▁ o f i i r a ▁ n d i ▁ o y e r a ▁ n d i ▁ o s e w e r a ▁ a k u y e n d a ▁ m u m s e w u ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a c h i k a s u ▁ n d i ▁ y a c h i k a s u ▁ n d i p o ▁ m w a m u n a ▁ w o k h a l a ▁ n d i ▁ m a g u l u ▁ o k h a l a ▁ n d i\n",
            "D-398\t-0.34995806217193604\tmagulu awiri othamanga omwe ali ndi masewera ndi ovala mayunifolomu ofiira ndi oyera ndi osewera akuyenda mumsewu wovala yunifolomu yachikasu ndi yachikasu ndipo mwamuna wokhala ndi magulu okhala ndi\n",
            "P-398\t-0.1126 -0.1246 -0.2457 -0.2706 -0.0482 -0.1745 -0.0876 -0.1141 -0.1927 -1.4448 -0.0845 -0.0651 -0.0881 -0.0902 -0.2038 -1.6703 -0.4923 -0.1185 -0.0577 -0.0689 -0.0682 -0.0187 -0.1093 -0.0905 -0.3014 -1.2024 -0.0815 -0.1109 -0.0807 -0.2822 -0.6130 -0.0708 -0.1099 -0.0198 -0.0560 -0.0978 -0.0917 -1.2242 -0.2354 -0.7097 -0.1092 -0.0278 -0.2182 -0.0564 -0.0948 -0.1302 -1.1474 -0.0705 -0.0873 -0.1543 -0.4218 -1.5315 -0.0872 -0.0895 -0.1129 -0.1211 -1.4494 -0.0741 -0.5715 -0.3894 -0.1118 -0.0632 -0.0650 -0.0120 -0.0221 -0.0312 -0.0706 -0.0194 -0.1056 -0.0637 -0.9756 -0.0497 -0.2103 -0.0414 -0.1482 -0.1264 -0.0742 -0.0544 -0.1251 -0.2253 -0.4465 -0.0258 -0.1080 -0.0262 -0.1072 -0.1345 -1.1604 -0.0738 -0.0848 -0.2248 -1.1547 -1.0912 -0.0887 -0.0408 -0.0658 -0.0417 -0.0997 -0.1554 -0.4543 -1.2651 -0.1301 -0.5217 -0.6559 -0.5550 -0.0668 -0.6712 -0.1369 -0.3444 -2.3938 -0.0825 -0.8613 -0.0513 -0.0474 -0.0690 -0.0988 -0.2715 -0.1818 -0.2066 -0.0985 -0.0589 -0.1388 -0.1372 -2.2317 -0.0490 -0.0431 -0.0478 -0.0397 -0.0312 -0.0366 -0.1932 -0.0553 -0.0206 -0.1133 -0.2142 -0.2850 -0.3899 -0.0475 -0.0737 -0.1660 -0.1200 -0.0096 -0.0575 -0.0949 -0.1812 -0.0504 -0.1452 -0.3144 -1.0055 -0.1718 -0.2717 -0.0864 -0.0651 -0.0193 -0.2258 -0.0240 -0.0972 -0.0623 -1.1545 -0.0580 -0.1330 -2.1463 -0.0836 -0.0842 -1.3712 -1.2932 -0.1330 -0.0496 -0.1892 -0.0349 -0.1161 -0.0868 -0.1652 -0.7583 -0.5507 -0.8621 -0.2714 -0.0781 -0.1218 -0.0900 -0.0501 -0.0358 -0.0777 -0.2225 -0.7949 -0.3013 -2.0014 -1.0274 -0.1641 -0.4183 -0.1069 -0.4061 -1.6698 -0.4639 -0.1164 -0.4421 -0.1103 -0.0888 -0.0956 -0.0296 -0.0856 -9.2655\n",
            "T-99\takuluakulu anayi kuphatikizapo mayi wovala malaya ofiirira ndi mwana wamng ono amakhala mozungulira tebulo lokutidwa ndi nsalu ya patebulo yamizeremizere pamene agalu anayi akugona pansi mozungulira tebulo\n",
            "H-99\t-0.35332995653152466\t▁ a k u l u a k u l u ▁ a n a y i ▁ a t a t s i k a n a ▁ o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ m w a m u n a ▁ w a k h a l a ▁ m o z u n g u l i r a ▁ t e b u l o ▁ l o k h a l a ▁ n d i ▁ t ▁ s h e t i ▁ y a k u d a ▁ n d i ▁ z i p e w a ▁ z a ▁ m i y a l a ▁ n d i ▁ z i n t h u ▁ z o m w e ▁ a k u y a n g ▁ a n a ▁ k u m b u y o ▁ k w a k e\n",
            "D-99\t-0.35332995653152466\takuluakulu anayi atatsikana ovala malaya ofiira ndi mwamuna wakhala mozungulira tebulo lokhala ndi t sheti yakuda ndi zipewa za miyala ndi zinthu zomwe akuyang ana kumbuyo kwake\n",
            "P-99\t-0.1188 -0.7227 -0.9100 -0.0859 -0.0921 -0.0384 -0.1378 -0.1298 -0.0825 -0.0420 -0.0430 -0.1377 -0.1169 -0.3112 -0.0588 -0.1492 -0.0655 -0.1229 -0.3473 -0.1500 -0.2094 -0.1659 -1.9026 -0.6913 -0.7767 -0.2134 -1.6563 -0.1045 -0.1607 -1.1255 -0.0846 -0.1102 -0.0663 -0.1326 -0.1200 -0.2670 -0.0873 -0.2804 -0.1521 -0.0229 -0.1028 -0.0879 -0.0155 -0.4091 -0.0517 -0.1389 -0.0327 -0.1501 -0.1174 -0.0542 -0.0419 -0.1002 -0.1064 -0.0655 -0.0589 -0.0981 -0.1383 -0.0447 -0.0435 -0.0767 -0.1138 -0.1906 -0.5090 -1.3050 -0.1983 -0.1087 -0.0926 -0.1162 -0.1332 -1.5033 -0.1863 -0.0656 -0.0580 -0.0263 -0.0261 -0.0444 -0.0863 -0.0441 -0.0432 -0.1062 -0.1671 -2.4099 -0.1424 -0.2843 -0.0513 -0.0857 -0.0478 -0.1161 -1.0151 -0.5051 -0.2340 -1.2640 -0.1910 -0.0865 -0.1200 -0.1083 -0.0962 -0.1421 -0.1197 -0.4191 -0.9574 -1.3900 -0.2301 -0.7771 -1.6143 -0.6814 -0.0479 -0.1510 -0.5978 -0.1382 -1.3635 -0.0887 -0.0205 -0.2558 -0.1298 -1.6089 -0.0853 -0.0961 -0.4000 -0.8271 -1.3486 -0.9476 -0.3336 -0.1226 -0.1039 -0.1201 -0.5229 -0.9765 -0.6691 -1.8911 -0.3718 -1.2376 -0.3057 -0.0291 -0.1135 -0.0831 -1.2505 -0.0614 -0.1448 -0.1243 -0.4381 -0.9472 -0.4221 -0.9534 -0.2023 -0.0943 -0.0630 -0.3592 -1.5253 -1.2783 -0.0920 -0.0623 -0.0787 -0.9244 -1.8523 -0.1815 -0.7966 -0.2425 -0.0285 -0.1408 -0.0769 -0.0545 -0.0205 -0.1042 -0.2469 -0.8334 -0.1515 -0.1477 -0.7287 -0.0522 -0.0159 -0.0269 -0.4378 -0.1261 -0.0846 -0.1138 -0.1962 -0.0176 -0.2195\n",
            "T-18\tanyamata awiri ovala masuti abuluu ndi zipewa zachikasu akugwiritsa ntchito zinthu zooneka ngati masiponji okhala ndi zogwirira kufalitsa zinthu pamalo athyathyathya m nyengo yozizira\n",
            "H-18\t-0.38341695070266724\t▁ m n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a s u t i ▁ a ▁ b u l u u ▁ n d i ▁ t h a l a u z a ▁ l a c h i k a s u ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ z i n t h u ▁ n d i ▁ z o k h a l a ▁ n d i ▁ m a g a l i m o t o ▁ o k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ k u k h a l a ▁ n d i ▁ m a g a l i m o t o ▁ a m a y a n g ▁ a n a ▁ p a n j a ▁ y a k e\n",
            "D-18\t-0.38341695070266724\tmnyamata wina wovala masuti a buluu ndi thalauza lachikasu akugwiritsa ntchito zinthu ndi zokhala ndi magalimoto okhala ndi chipale chofewa kukhala ndi magalimoto amayang ana panja yake\n",
            "P-18\t-0.1155 -2.2441 -0.2812 -0.0819 -0.1177 -0.0466 -0.0864 -0.0181 -0.1040 -0.1077 -0.6301 -0.1364 -0.0912 -0.1225 -0.1018 -0.3354 -0.1010 -0.0545 -0.1139 -0.0881 -0.1023 -0.0902 -0.7623 -0.0930 -0.6560 -0.2977 -0.0929 -0.1730 -0.0838 -0.3462 -1.1230 -0.0371 -0.5198 -0.0362 -0.0915 -0.0447 -0.0911 -0.0728 -0.0888 -0.0689 -0.1031 -1.9706 -0.6866 -0.0840 -0.2255 -0.1425 -0.0833 -0.1039 -0.0902 -0.1115 -0.6056 -0.1511 -0.2844 -0.0739 -0.0418 -0.1522 -0.1920 -0.0384 -0.0619 -0.0924 -0.1724 -0.3140 -0.1059 -1.2983 -0.0307 -0.2465 -0.0673 -0.1770 -0.0101 -0.0812 -0.1303 -0.1334 -0.1690 -0.1024 -0.0145 -0.0696 -0.0550 -0.0074 -0.0266 -0.0988 -0.6420 -0.5289 -0.4631 -0.6427 -0.0744 -0.0366 -0.1331 -1.3287 -0.0826 -0.0708 -0.2766 -0.8362 -0.9703 -0.7814 -0.1695 -0.1481 -0.1492 -0.2288 -0.1312 -1.1975 -0.1096 -0.1109 -0.2773 -2.3328 -0.1853 -0.5322 -0.1348 -0.1214 -0.3309 -0.7121 -0.6984 -0.0495 -0.7061 -0.1362 -0.3112 -1.6490 -0.1143 -0.1306 -0.2027 -0.1711 -0.1329 -0.1990 -0.0820 -0.1440 -0.2209 -1.5600 -0.0697 -0.0661 -0.9906 -2.8779 -0.2404 -0.1306 -0.0666 -0.3946 -0.0714 -0.0421 -0.0980 -0.2774 -0.0783 -0.5000 -0.1909 -1.9206 -0.3913 -1.5043 -0.8338 -0.1338 -0.1703 -0.3762 -0.0923 -0.4156 -0.0690 -0.2605 -0.1095 -1.1000 -0.4622 -2.5844 -0.0930 -0.0597 -0.8133 -0.0341 -0.1095 -0.0756 -0.1227 -0.1036 -0.9437 -0.9590 -0.4932 -1.1656 -1.0492 -0.1599 -0.0457 -0.1250 -0.1160 -0.0585 -0.5125 -0.1280 -1.9628 -0.1800 -0.8938 -1.1351 -0.1512 -0.1451 -0.4990 -0.7009 -1.6291 -0.5233 -1.4914\n",
            "T-94\tmahatchi awiri onyamula katundu omangidwa m ngolo yotchinga yooneka ngati yokhoza kunyamula anthu angapo anaima mwakachetechete pamene mayi wina wachikulire akuyang ana munthu wachikulire m ngoloyo\n",
            "H-94\t-0.3844044804573059\t▁ m a t s i k a n a ▁ w i n a ▁ w o n y a m u l a ▁ k a t u n d u ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a c h i k a s u ▁ y o k o n g o l a ▁ z a k u n y a m u l a ▁ k w a ▁ m t u n d a ▁ w a k h a l a ▁ p a m w a m b a ▁ p a ▁ c h i t h u n z i ▁ c h o m w e ▁ c h i l i ▁ n d i ▁ m a g a l a s i ▁ a k u y a n g ▁ a n a ▁ k u m b u y o ▁ k w a c h i k u l u\n",
            "D-94\t-0.3844044804573059\tmatsikana wina wonyamula katundu wamng ono wovala yunifolomu yachikasu yokongola zakunyamula kwa mtunda wakhala pamwamba pa chithunzi chomwe chili ndi magalasi akuyang ana kumbuyo kwachikulu\n",
            "P-94\t-0.1121 -0.1531 -0.0835 -3.9573 -0.2818 -0.0884 -0.1175 -0.1264 -0.0914 -0.1013 -0.1062 -0.9431 -0.1317 -0.2016 -0.1002 -0.1025 -0.1431 -0.3379 -1.4817 -0.1343 -0.2623 -0.0655 -0.0530 -0.0789 -0.1613 -0.1010 -0.2270 -0.1161 -0.5002 -0.0732 -0.0762 -0.0385 -0.0253 -0.1353 -0.2753 -0.2316 -0.7609 -2.7366 -0.1563 -0.2172 -0.0802 -0.0360 -0.0984 -0.1560 -1.0422 -0.1692 -1.8513 -0.1468 -0.1125 -0.1684 -0.1130 -2.5582 -0.0459 -0.0509 -0.0825 -0.1649 -0.0533 -0.0303 -0.0396 -0.0275 -0.0605 -0.0992 -0.0040 -1.4604 -0.9845 -0.0601 -0.0754 -0.0425 -0.0752 -0.1242 -0.5550 -0.0880 -0.5441 -0.1568 -1.2056 -0.2416 -0.0246 -0.8088 -1.5247 -0.3364 -0.2568 -0.1313 -1.8630 -0.1348 -0.4250 -0.2073 -0.2585 -0.6128 -0.1267 -0.0572 -0.5318 -0.0625 -0.1280 -0.1046 -1.2031 -2.5588 -0.2139 -0.3610 -1.0357 -0.4498 -0.5402 -0.0287 -0.0670 -0.1024 -0.1058 -0.0852 -0.3043 -3.1665 -1.1742 -0.5574 -0.0566 -0.1176 -0.1175 -0.2673 -0.1778 -0.3129 -1.6293 -0.1441 -0.0379 -0.0851 -0.0899 -0.0877 -0.3412 -0.1623 -0.1052 -0.5691 -0.0897 -0.0814 -0.1852 -0.4946 -0.2022 -0.0396 -1.1726 -0.0615 -0.1048 -0.2602 -0.0416 -0.7726 -1.1086 -0.2088 -0.1744 -0.0946 -0.8191 -0.0595 -0.0601 -0.2137 -0.0538 -0.0943 -0.8467 -0.2619 -0.1480 -0.1636 -1.2220 -0.1973 -1.1515 -0.0874 -0.1260 -0.2723 -0.5061 -0.0799 -0.0768 -0.6714 -0.8245 -0.1163 -0.7219 -0.1205 -0.1406 -0.0344 -0.0678 -0.0994 -0.0343 -0.1522 -0.1293 -1.0565 -0.0629 -1.5566 -0.0770 -0.0592 -0.0307 -0.0340 -0.3518 -0.1557 -0.1054 -0.0996 -1.8188 -0.0365 -0.0604 -0.1079 -0.4802 -0.0143 -0.2444 -1.0677\n",
            "  8% 1/13 [00:05<01:05,  5.43s/it, wps=284]T-328\tmayi wina wovala blazer ya beige ndi magalasi adzuwa akuyang ana mwamuna wina wovala t sheti yamizeremizere yemwe akuyang anitsitsa azimayi awiri omwe akumwetulira ovala zankhondo m mphepete mwa mzindawo\n",
            "H-328\t-0.321837455034256\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ m a g e t s i ▁ o y e r a ▁ n d i ▁ m a g a l a s i ▁ a d z u w a ▁ a k u y a n g ▁ a n a ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ t ▁ s h i r t ▁ y o y e r a ▁ n d i ▁ j e a n s ▁ y a k u y e n d a ▁ n d i ▁ z i n t h u ▁ z a m e n e ▁ a k u m w e t u l i r a ▁ n d i ▁ z i n t h u ▁ z o m w e ▁ z i l i ▁ m ▁ m p h e p e t e ▁ m w a ▁ m s e w u\n",
            "D-328\t-0.321837455034256\tmayi wina wovala magetsi oyera ndi magalasi adzuwa akuyang ana mwamuna wina wovala t shirt yoyera ndi jeans yakuyenda ndi zinthu zamene akumwetulira ndi zinthu zomwe zili m mphepete mwa msewu\n",
            "P-328\t-0.1062 -0.0601 -0.0814 -0.0381 -0.0896 -0.0819 -0.0524 -0.0993 -0.0567 -0.1132 -0.0900 -0.1095 -0.0622 -0.0485 -0.1087 -0.0846 -0.1052 -0.0821 -0.3983 -0.4689 -1.0521 -1.4622 -1.1705 -0.7113 -0.5248 -0.0590 -2.1118 -0.2124 -0.1569 -0.0703 -0.1113 -0.1200 -0.1688 -0.0790 -0.0856 -0.0654 -0.2232 -0.0738 -0.6134 -0.1595 -0.1956 -0.0981 -0.0233 -0.0348 -0.0723 -0.1116 -1.7121 -0.1414 -0.0721 -0.0579 -0.1093 -0.0876 -0.1114 -0.1075 -0.0804 -0.0157 -0.1184 -0.0327 -0.0469 -0.0649 -0.0894 -0.0557 -0.1341 -0.1107 -0.3710 -0.7096 -0.1983 -0.1018 -0.2847 -0.0368 -0.1313 -0.0976 -0.0769 -0.0741 -0.0588 -0.1269 -0.0943 -0.4899 -0.0982 -0.0320 -0.0999 -0.0825 -0.1039 -0.0966 -1.6904 -0.1704 -0.1128 -0.0582 -0.6037 -0.0993 -0.0514 -0.2293 -0.3687 -1.0560 -0.3069 -0.0448 -1.1062 -0.4215 -0.1201 -0.1641 -0.1684 -0.1006 -0.0935 -2.7352 -0.4248 -0.1523 -0.0306 -0.0772 -0.1012 -0.1210 -0.1808 -0.5081 -0.0891 -0.2216 -0.6731 -0.1149 -0.0906 -0.1143 -0.0996 -2.2776 -0.1776 -0.0813 -0.1389 -1.0804 -0.0598 -0.6759 -1.0410 -0.2651 -0.0541 -0.0858 -0.2906 -0.4875 -1.5636 -0.9733 -0.1330 -0.0881 -0.0936 -0.3583 -0.6050 -0.0628 -0.6190 -0.6223 -0.0359 -0.0185 -0.0270 -0.0138 -0.0419 -0.0503 -0.0783 -0.0929 -1.1655 -0.1142 -0.1039 -0.2696 -1.3133 -0.6411 -1.4282 -0.7282 -0.0507 -0.0456 -0.0542 -0.3494 -0.2357 -1.1864 -0.0394 -0.0611 -0.0751 -0.8639 -0.5305 -0.1784 -0.0866 -0.1124 -1.7010 -0.3410 -0.4915 -0.9110 -0.0564 -0.0631 -0.3125 -0.2453 -0.0115 -0.0466 -0.1128 -0.1888 -0.0196 -0.1055 -0.1313 -1.2030 -1.5183 -0.2682 -0.0867 -0.0445 -1.1112\n",
            "T-350\tbambo ovala malaya oyera ndi akabudula a khaki akupsompsona mwachikondi mwana wawo yemwe amamuwona atavala malaya ofiira akuda ndi mathalauza a denim pamutu pamene akukhala chete atakhala pakhomo la galimoto\n",
            "H-350\t-0.2829780876636505\t▁ b a m b o ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ a b u l u u ▁ a t a k h a l a ▁ k u t s o g o l o ▁ k w a ▁ m a d z i ▁ n d i ▁ m w a n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a t a n y a m u l a ▁ m a l a y a ▁ a b u l u u ▁ a t a n y a m u l a ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ m a g a l i m o t o ▁ a k u y a n g ▁ a n a ▁ k u m b u y o ▁ k w a k e\n",
            "D-350\t-0.2829780876636505\tbambo wovala malaya oyera ndi abuluu atakhala kutsogolo kwa madzi ndi mwana wovala malaya oyera atanyamula malaya abuluu atanyamula chipale chofewa ndi magalimoto akuyang ana kumbuyo kwake\n",
            "P-350\t-0.1084 -0.0404 -0.1101 -0.0356 -0.0562 -0.0788 -0.0860 -0.1258 -0.4127 -0.2473 -0.1273 -0.1000 -0.1282 -0.0932 -0.0210 -0.1052 -0.0821 -0.1191 -0.0432 -0.1113 -0.0862 -0.0280 -0.0525 -0.1032 -0.1907 -0.1058 -0.1102 -0.1084 -0.0763 -0.1163 -0.1074 -0.3717 -0.2575 -0.0924 -0.0965 -0.7120 -0.0466 -0.0811 -0.1442 -0.4457 -0.1028 -0.0936 -0.0495 -0.1115 -0.0543 -0.1191 -0.1066 -1.7759 -0.1318 -1.1721 -0.1207 -0.0379 -0.0647 -0.0846 -0.4662 -0.2010 -0.1275 -0.4393 -0.4625 -0.1229 -0.0904 -0.6158 -0.1806 -1.1950 -0.0881 -0.1522 -0.1396 -0.8924 -0.0774 -0.1068 -0.4219 -0.0829 -0.3704 -0.1218 -0.3652 -0.1246 -0.1209 -0.0217 -0.7868 -0.8704 -0.1357 -0.0776 -0.1297 -0.1070 -0.5168 -0.1261 -0.4617 -0.1094 -0.0790 -0.0926 -0.0976 -0.1819 -0.3597 -0.0514 -0.1762 -0.0980 -0.1243 -0.5323 -1.7865 -0.0934 -0.2549 -0.0647 -0.0721 -0.0200 -0.0637 -0.0550 -0.1036 -0.0963 -0.2410 -0.1199 -0.3494 -0.2561 -0.2725 -0.1036 -0.0753 -1.3906 -1.3082 -0.0543 -0.0488 -0.2112 -0.0319 -0.0857 -0.5477 -0.6601 -0.0769 -1.1289 -0.3507 -0.0831 -0.0336 -0.1244 -0.0925 -0.1120 -0.0916 -1.8770 -0.0962 -0.1226 -0.5005 -0.1930 -1.4281 -0.6362 -0.0808 -0.1633 -0.1107 -0.2421 -0.2970 -0.0683 -0.1160 -0.0854 -0.0998 -1.2582 -0.0621 -0.0914 -0.1471 -0.3595 -0.3694 -2.9310 -0.5805 -0.1196 -0.6142 -0.0133 -0.0345 -0.0237 -0.0942 -0.0893 -0.3400 -0.6980 -0.0678 -1.9892 -0.4672 -0.1745 -0.1257 -0.0629 -0.0775 -0.0757 -0.1344 -0.1302 -0.7417 -0.2766 -1.6454 -0.4251 -0.0949 -0.0455 -0.0530 -0.1910 -0.0786 -0.2521 -0.0988 -0.1584 -0.0782 -0.2275\n",
            "T-221\tachinyamata asanu ndi anayi ovala jekeseni ya jeans akuwoneka pamasitepe akutsogolo ndi khonde la nyumba ya three level clapboard monga momwe mwana amawonera ali pakhonde lachiwiri\n",
            "H-221\t-0.4220452606678009\t▁ a c h i n y a m a t a ▁ a c h i n y a m a t a ▁ n d i ▁ m n y a n j a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ t ▁ s h e t i ▁ y a k u d a ▁ a k u w o n e k a ▁ m a g o l o t s i ▁ n d i p o ▁ k u t i ▁ a l i ▁ n d i ▁ t h u p i ▁ l a l i t a l i ▁ l o t u w a ▁ l o t u w a ▁ n d i ▁ m w a m u n a ▁ w o t h a m a n g a ▁ p a m w a m b a ▁ p a ▁ t e b u l o ▁ l a k u y a n g ▁ a n a\n",
            "D-221\t-0.4220452606678009\tachinyamata achinyamata ndi mnyanja wovala jekete la t sheti yakuda akuwoneka magolotsi ndipo kuti ali ndi thupi lalitali lotuwa lotuwa ndi mwamuna wothamanga pamwamba pa tebulo lakuyang ana\n",
            "P-221\t-0.1206 -0.0903 -2.6264 -0.1055 -0.1106 -0.0479 -0.0151 -0.1001 -0.0431 -0.1090 -0.0236 -0.0987 -0.1037 -0.1734 -0.3301 -0.0755 -0.1599 -0.3476 -0.8496 -0.1097 -0.2825 -0.9073 -0.3944 -0.1162 -0.1687 -0.1499 -0.0469 -0.1552 -0.1146 -1.0319 -1.3373 -0.3881 -0.1586 -1.0847 -0.3121 -0.0886 -0.1024 -0.6933 -0.0750 -0.5787 -0.1345 -0.0975 -0.1254 -0.1041 -0.5705 -0.1946 -0.0650 -0.0623 -0.0042 -0.0791 -0.0894 -1.5589 -0.1082 -0.6043 -1.1457 -1.2723 -0.1424 -0.1495 -1.3317 -0.0225 -0.0512 -0.1337 -0.2389 -0.1354 -0.6720 -0.2834 -0.2156 -0.2920 -0.1422 -0.6326 -0.1440 -0.1197 -0.1599 -0.0419 -0.0388 -0.0438 -0.9503 -0.1187 -0.1111 -1.7292 -0.1272 -1.3313 -0.4788 -0.2455 -0.0620 -1.2491 -0.4839 -0.1491 -0.1548 -2.4312 -0.1592 -0.1109 -0.8222 -0.0812 -0.1435 -1.3835 -0.3567 -0.0958 -0.7516 -0.0999 -0.3520 -0.9576 -0.1576 -0.1652 -0.0551 -0.0437 -0.1238 -0.2808 -2.1327 -0.4313 -0.3941 -1.2002 -0.2402 -0.0858 -0.5001 -1.6164 -0.2093 -0.0763 -0.1472 -1.1949 -0.0431 -0.0817 -0.1758 -0.5260 -0.3293 -0.7674 -0.4713 -0.1502 -0.0954 -0.1928 -1.9194 -0.9567 -0.2935 -0.5418 -0.0981 -0.1161 -0.1928 -1.4977 -0.3830 -0.0933 -0.2856 -0.8162 -0.6133 -0.1211 -0.0331 -0.0860 -0.0944 -0.1579 -0.0913 -0.1945 -0.6021 -0.2869 -1.6723 -1.2709 -0.0365 -0.1220 -0.0605 -0.0244 -0.2914 -0.0927 -1.4268 -0.1325 -0.5564 -2.1902 -0.1173 -0.0767 -0.0674 -0.0877 -0.1053 -0.2609 -0.2352 -0.2507 -1.8749 -1.4803 -0.2652 -0.1488 -0.1382 -0.1246 -0.2210 -0.2297 -0.2002 -1.0602 -1.2123 -1.1113 -1.0268 -0.0722 -0.1841 -0.1427 -0.1594 -0.0301 -0.2835 -0.6561\n",
            "T-134\tatsikana awiri yemwe ali kuseriyo wavala zakuda pamene msungwana wina kutsogoloyo wavala kabudula wa khaki malaya ofiirira ndi ma sneakers ndikuchita manja ngati akupsompsona\n",
            "H-134\t-0.3520626723766327\t▁ a t s i k a n a ▁ a w i r i ▁ y e m w e ▁ a l i ▁ k u s e r i ▁ o v a l a ▁ z a k u d a ▁ a k u j a m b u l a ▁ n d i ▁ n s o n g a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y o w a l a ▁ k o k h a l a ▁ n d i ▁ m a t h a l a u z a ▁ o f i i r a ▁ n d i ▁ m a s i t a l a ▁ o f i i r a ▁ n d i ▁ m a g a l a s i ▁ a k u t h a m a n g a ▁ m ▁ m a d z i\n",
            "D-134\t-0.3520626723766327\tatsikana awiri yemwe ali kuseri ovala zakuda akujambula ndi nsonga kutsogolo kwa nyumba yowala kokhala ndi mathalauza ofiira ndi masitala ofiira ndi magalasi akuthamanga m madzi\n",
            "P-134\t-0.1223 -0.0689 -0.1074 -0.0237 -0.0796 -0.0206 -0.1242 -0.0519 -0.1301 -0.1065 -0.1013 -0.1961 -0.1431 -0.0398 -0.0941 -0.1147 -3.0064 -0.0669 -0.0764 -0.0194 -0.0513 -0.0789 -0.0848 -0.1648 -0.1378 -0.1276 -0.5291 -0.0647 -0.4717 -0.0888 -0.5749 -0.0322 -0.0985 -1.0912 -0.2036 -0.1269 -0.0959 -0.1442 -0.1208 -0.0420 -0.1405 -0.2934 -0.0852 -0.0688 -0.1559 -0.0973 -1.6222 -0.0568 -0.1135 -1.3603 -0.1013 -0.1777 -0.2498 -0.1271 -0.1381 -0.5453 -0.1362 -2.6669 -0.5080 -0.0848 -0.2517 -1.4672 -0.2992 -0.1083 -0.6118 -0.2235 -0.2939 -0.1022 -1.8017 -0.3531 -1.0401 -0.0189 -0.0290 -0.0192 -0.1144 -0.0620 -0.0827 -0.1263 -0.4042 -0.0380 -0.1145 -0.1721 -2.3902 -0.2758 -0.1759 -0.1413 -0.0346 -0.0945 -0.1812 -0.0435 -0.1007 -0.5257 -0.4015 -0.1008 -0.0950 -0.1359 -0.2335 -0.6147 -2.8123 -0.3792 -0.1914 -0.0920 -0.1297 -0.1307 -0.0940 -0.0455 -0.1621 -0.1867 -0.2755 -0.1232 -1.2129 -0.3296 -0.0733 -0.0470 -0.1618 -0.0443 -0.0804 -0.0745 -0.1065 -0.5554 -0.0835 -0.0317 -0.1198 -0.0381 -0.2775 -0.1207 -0.7609 -0.0502 -0.1252 -0.1767 -0.0523 -0.0792 -2.0025 -0.7721 -1.5737 -0.2290 -0.1743 -0.1060 -0.2652 -0.6558 -0.0839 -0.0434 -0.0846 -0.0391 -0.2073 -0.1074 -0.2980 -0.0362 -0.1303 -0.1658 -0.5507 -0.3159 -2.3054 -0.1666 -0.9314 -0.1920 -0.0456 -0.2668 -0.1126 -0.9028 -1.4514 -0.1522 -1.6816 -0.0784 -0.1286 -0.1599 -0.0958 -0.2079 -0.1396 -0.2225 -0.1819 -1.6176 -0.4153 -0.5265 -0.9615 -0.6642 -0.0800 -0.0826 -1.1526\n",
            "T-77\tophunzira ochuluka omwe amawoneka ngati aku asia asonkhana mozungulira matebulo osiyanasiyana ndi tebulo lomwe linali ndi chikwangwani cholembedwa kuti new york city pakati pake\n",
            "H-77\t-0.33014869689941406\t▁ w o k w e r a ▁ p o c h i t i r a ▁ w o k h a l a ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ j e k e t e ▁ l a c h i k a s u ▁ a k u k h a l a ▁ m o z u n g u l i r a ▁ n d i ▁ m a g u l u ▁ o s i y a n a s i y a n a ▁ n d i ▁ t h a l a u z a ▁ l o m w e ▁ l i l i ▁ n d i ▁ c h i k w a n g w a n i ▁ c h o k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-77\t-0.33014869689941406\twokwera pochitira wokhala ndi mwamuna wovala jekete lachikasu akukhala mozungulira ndi magulu osiyanasiyana ndi thalauza lomwe lili ndi chikwangwani chokhala ndi chipale chofewa\n",
            "P-77\t-0.1026 -1.0845 -0.0527 -0.3255 -1.0813 -0.4679 -0.5235 -0.1059 -0.0861 -1.6633 -0.2504 -0.3819 -0.0959 -0.0559 -1.7929 -0.1738 -0.7604 -0.1261 -0.1119 -1.3502 -0.3861 -0.0107 -0.0756 -0.1032 -0.0554 -0.1143 -0.1117 -1.0707 -0.3680 -0.1095 -0.1472 -0.3522 -2.0729 -0.1094 -0.0993 -0.1269 -0.0253 -0.1133 -0.1127 -0.3404 -0.8069 -0.7412 -0.1075 -0.1021 -0.1080 -0.0965 -0.3099 -0.1820 -0.2636 -0.0927 -0.0426 -0.2040 -0.1020 -1.1836 -0.1132 -2.2140 -0.1177 -0.1247 -0.3916 -0.1053 -0.0293 -0.4641 -0.0887 -0.1800 -1.0156 -0.2116 -0.7880 -0.4573 -0.1175 -0.1013 -0.1245 -0.1068 -0.6685 -0.1216 -0.5767 -0.2570 -0.0148 -0.0105 -0.0518 -0.0725 -0.0612 -0.0451 -0.1010 -0.1437 -1.3672 -0.1861 -0.1017 -0.1988 -1.8943 -0.0651 -1.1369 -0.7258 -0.0777 -0.8235 -0.1777 -0.1448 -0.5628 -0.0426 -0.0309 -0.1288 -0.0823 -0.0936 -0.2243 -0.0306 -0.0910 -0.1321 -0.0689 -0.1018 -0.1332 -0.2198 -0.0481 -0.0851 -0.1872 -1.7678 -0.6596 -1.0488 -0.0953 -0.5867 -0.0264 -0.1271 -0.0784 -0.1008 -0.0492 -0.3243 -0.3561 -0.0713 -0.0549 -0.0844 -0.2182 -0.1382 -0.6898 -0.1080 -0.0910 -0.0197 -0.0353 -0.1186 -0.1441 -0.0731 -0.0769 -0.0699 -0.4282 -0.2204 -0.0954 -1.3713 -0.2956 -0.0324 -0.0908 -0.0600 -0.0592 -0.1081 -0.0976 -0.0896 -0.7195 -1.0014 -2.2832 -0.1870 -0.0779 -0.3259 -0.0804 -0.1436 -0.0821 -0.1305 -0.1234 -1.7439 -0.0902 -0.2524 -0.5534 -0.2772 -0.0839 -0.0360 -0.0563 -0.0977 -0.0939 -0.0369 -0.1184 -0.1810 -0.0206 -0.1114 -1.1481\n",
            "T-257\tmwamuna wokhala ndi chipewa ndi malaya abulauni atayima pamtunda waudzu pafupi ndi mulu wa udzu kapena udzu pamtundu wina wa matabwa womangidwa pa kavalo wokhala ndi maunyolo\n",
            "H-257\t-0.2820001542568207\t▁ m w a m u n a ▁ w o k h a l a ▁ n d i ▁ c h i p e w a ▁ n d i ▁ m a l a y a ▁ a b u l a u n i ▁ a t a y i m a ▁ p a m t u n d a ▁ w a u d a ▁ w o z u n g u l i r a ▁ p a f u p i ▁ n d i ▁ m k a z i ▁ w a u d a ▁ w o k h a l a ▁ n d i ▁ m n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ w o k h a l a ▁ n d i ▁ m a l o ▁ o k h a l a ▁ n d i ▁ m a w u\n",
            "D-257\t-0.2820001542568207\tmwamuna wokhala ndi chipewa ndi malaya abulauni atayima pamtunda wauda wozungulira pafupi ndi mkazi wauda wokhala ndi mnyamata wina wovala malaya abulauni wokhala ndi malo okhala ndi mawu\n",
            "P-257\t-0.1180 -0.3114 -0.0470 -0.1102 -0.0333 -0.0577 -0.0658 -0.1111 -0.1168 -0.1821 -0.0738 -0.4912 -0.0779 -0.1214 -0.2177 -0.1091 -0.1063 -0.0263 -0.0625 -0.1455 -0.0850 -1.0157 -0.0881 -0.1649 -0.0574 -0.2229 -0.0885 -0.1086 -0.1060 -0.6985 -0.0797 -0.1168 -0.0889 -0.1015 -0.3599 -0.3547 -0.1101 -0.0377 -0.1052 -0.0784 -0.0737 -2.2968 -0.1960 -0.1576 -0.2315 -0.0984 -0.0346 -0.0902 -0.0866 -0.2660 -0.0288 -0.0957 -1.9965 -0.0427 -0.0296 -0.0997 -0.0958 -0.4582 -0.2311 -0.1990 -0.1557 -0.2850 -0.0354 -0.0291 -0.1125 -0.1458 -0.0280 -0.1331 -0.3775 -0.6280 -1.2241 -0.1585 -0.0965 -1.7977 -0.3041 -0.0297 -0.0373 -0.2260 -0.2026 -0.0885 -0.0962 -0.9103 -0.2600 -0.1818 -1.9134 -0.1120 -0.0385 -0.0823 -0.1641 -0.0405 -0.1133 -0.0217 -0.0544 -0.0870 -0.1303 -0.6262 -1.0472 -0.1080 -0.1212 -0.2004 -0.1349 -0.0383 -0.2735 -0.6829 -0.9055 -0.4223 -0.1434 -0.5340 -0.5204 -0.6608 -0.0967 -0.0745 -0.1470 -0.1088 -0.1456 -0.0476 -0.0497 -0.1535 -0.2044 -1.2695 -2.2310 -0.2958 -0.1543 -0.0551 -0.0856 -0.0209 -0.0839 -0.0957 -0.0197 -0.1537 -0.0487 -0.0709 -0.0994 -0.0604 -1.1380 -0.3114 -0.0958 -0.0904 -0.1234 -0.1173 -1.1384 -0.1379 -1.0075 -0.1753 -0.1348 -0.1245 -0.0715 -0.7363 -0.7521 -0.1602 -0.0604 -0.9978 -0.0290 -0.0663 -0.1118 -0.1333 -1.3449 -0.3287 -0.1009 -0.0435 -0.1221 -0.0893 -0.1375 -0.0889 -0.0797 -0.0519 -0.1101 -0.2833 -0.1214 -0.1064 -0.6131 -0.2684 -0.1483 -0.0644 -0.6790 -0.0450 -0.1111 -0.1173 -0.1197 -0.1158 -0.1609 -0.0693 -0.0756 -0.1218 -0.1314 -0.2046 -1.7319 -0.8738 -0.9698\n",
            "T-397\twosewera wa lacrosse wovala yunifolomu yofiira yokhala ndi nambala thirty three kumbuyo amayang ana kumwamba pomwe wosewera wovala yunifolomu yobiriwira yokhala ndi chikasu chachikasu amawonekera kumbuyo\n",
            "H-397\t-0.2979836165904999\t▁ w o s e w e r a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ y o f i i r a ▁ n d i ▁ y o k h a l a ▁ n d i ▁ j i n z i ▁ y o k h a l a ▁ n d i ▁ c h i p e w a ▁ a m a y a n g ▁ a n a ▁ k u m b u y o ▁ k w a ▁ m a s e w e r a ▁ o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ y o k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ k u m b u y o ▁ k w a k e\n",
            "D-397\t-0.2979836165904999\twosewera wovala yunifolomu yobiriwira yofiira ndi yokhala ndi jinzi yokhala ndi chipewa amayang ana kumbuyo kwa masewera ovala yunifolomu yobiriwira yokhala ndi chipale chofewa kumbuyo kwake\n",
            "P-397\t-0.1207 -0.1670 -0.0494 -0.0701 -0.1078 -0.0395 -0.0730 -0.0523 -0.1397 -0.0979 -0.4346 -2.6775 -0.2961 -0.1263 -0.0879 -0.1377 -0.1169 -2.5264 -0.0367 -0.0954 -0.0365 -0.0591 -0.0323 -0.0940 -0.0733 -0.1638 -0.1174 -0.0939 -0.3030 -0.7120 -1.7621 -0.2629 -0.0656 -0.0831 -0.0886 -0.1364 -0.0840 -0.0892 -0.1322 -0.3848 -0.0707 -0.1566 -0.3421 -0.6921 -0.0255 -0.1268 -0.1122 -1.1121 -0.0599 -0.0748 -0.1008 -0.0919 -0.0584 -0.3479 -0.0528 -0.1215 -0.0672 -0.1273 -0.1000 -0.0706 -0.0870 -0.0888 -0.0910 -1.8265 -1.3527 -0.0268 -0.7821 -0.0532 -0.0877 -0.2199 -0.9925 -0.3620 -0.0351 -0.1022 -0.1720 -0.1294 -0.0942 -0.0859 -0.0863 -0.0970 -0.2569 -2.1398 -0.1067 -0.0488 -0.7426 -0.8301 -0.0224 -0.0869 -0.1368 -0.2760 -0.8045 -0.0966 -0.0431 -0.3801 -0.0400 -0.0526 -0.0866 -0.0727 -0.0713 -0.1004 -0.1141 -0.4043 -0.1689 -0.2339 -1.1544 -0.3190 -0.0204 -0.0594 -0.0881 -0.1595 -0.7010 -0.1902 -0.2361 -0.1436 -0.3371 -2.6736 -0.0495 -0.0445 -0.0929 -0.0477 -0.0993 -0.0941 -0.2871 -1.7604 -0.1135 -0.0523 -0.1096 -0.1132 -1.8376 -0.0556 -0.0311 -0.0545 -0.0548 -0.0282 -0.0560 -0.0691 -0.0194 -0.0357 -0.1083 -0.1148 -0.1052 -1.2162 -0.0712 -0.0288 -0.0889 -0.0343 -0.0988 -0.0552 -0.1144 -0.1019 -1.4313 -0.2190 -1.1846 -0.0102 -0.1461 -0.0721 -0.1300 -0.0900 -0.2549 -0.2772 -0.0697 -0.1163 -0.0982 -0.0744 -0.0590 -1.5218 -0.2976 -0.2909 -0.1975 -0.0484 -0.0467 -0.0709 -0.4066 -0.5690 -0.0609 -0.0556 -0.1049 -0.3107 -2.5157 -0.6315 -0.1188 -0.2103 -0.1484 -0.0343 -0.0531 -0.4564 -0.5161 -0.2644 -0.1213 -0.1827 -0.0263 -0.1651\n",
            "T-148\tpanthawi ya masewera olimbitsa thupi katswiri wa masewera olimbitsa thupi ovala yunifolomu ya buluu ndi golide adzakhala akugwiritsa ntchito ma hoops awo kuti azichita\n",
            "H-148\t-0.3860400319099426\t▁ a n t h u ▁ a m a s e w e r a ▁ o l i m b i t s a ▁ t h u p i ▁ a t a t s i k i ▁ w o y e r a ▁ m s e w u ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ n d i ▁ a b u l u u ▁ a l i ▁ k u t e t e z a ▁ k h a l a ▁ n d i ▁ c h i s a n u ▁ k u t s o g o l o ▁ k w a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-148\t-0.3860400319099426\tanthu amasewera olimbitsa thupi atatsiki woyera msewu wovala yunifolomu yobiriwira ndi abuluu ali kuteteza khala ndi chisanu kutsogolo kwa chipale chofewa\n",
            "P-148\t-0.1058 -0.1674 -0.0572 -0.0228 -0.0351 -0.0558 -0.1057 -0.1898 -0.3684 -0.6118 -0.0304 -0.1300 -0.0376 -0.2071 -0.0302 -0.1183 -0.1303 -1.6637 -2.2888 -0.3774 -0.1944 -0.0338 -0.0832 -0.0196 -0.0232 -0.1388 -0.0947 -0.1413 -0.1397 -0.0290 -0.2274 -0.3538 -0.1472 -1.6654 -0.9973 -0.2811 -0.1871 -0.0817 -1.4093 -0.4947 -0.6327 -0.5344 -0.6836 -1.6993 -0.8424 -0.2082 -0.1839 -0.1491 -0.1441 -0.9802 -0.6188 -0.0856 -0.0238 -0.0833 -0.0887 -0.0432 -0.5174 -1.0904 -0.2167 -0.0893 -0.1030 -0.1033 -1.6138 -0.0696 -0.0300 -0.0705 -0.0758 -0.0402 -0.0507 -0.1324 -0.0245 -0.0364 -0.1228 -0.0237 -0.5991 -1.9929 -0.1436 -0.0652 -0.0820 -0.1261 -0.1330 -0.1038 -0.1006 -0.1191 -1.5623 -0.5770 -0.0988 -0.5126 -0.7686 -0.5420 -0.0825 -0.0613 -0.0384 -0.0308 -0.0833 -1.1951 -0.3440 -0.1006 -0.1390 -2.2123 -0.3658 -0.2824 -0.4015 -0.3823 -0.2013 -0.4995 -0.3238 -0.0867 -2.1935 -0.5091 -0.2015 -0.5887 -0.1513 -0.1303 -1.3520 -0.2569 -0.1479 -0.1401 -0.4911 -0.1433 -0.0835 -1.1244 -0.1013 -0.0563 -0.7598 -0.1467 -1.5415 -0.0515 -0.6255 -0.4777 -0.7308 -0.0674 -0.1034 -0.0997 -0.0811 -0.1894 -0.4730 -0.1257 -0.1509 -0.3032 -1.7349 -0.0978 -0.0946 -2.3287 -0.3161 -0.4351 -0.0968 -0.2442 -0.0736 -0.1024 -0.2352 -1.2222 -0.1013 -0.0927 -0.0797 -0.1231\n",
            "T-228\tmwamuna wamutu wofiira atavala kilt akuvina ndi mkazi wamutu wofiira atavala siketi yobiriwira poyang ana siteji yakuda\n",
            "H-228\t-0.29517897963523865\t▁ m w a m u n a ▁ w a m n g ▁ o n o ▁ w o f i i r a ▁ a t a v a l a ▁ t ▁ s h i r t ▁ y a k u d a ▁ n d i ▁ m k a z i ▁ w a m u t u ▁ w o f i i r a ▁ a t a v a l a ▁ j e k e t e ▁ y o b i r i w i r a ▁ n d i ▁ y o y e r a ▁ n d i ▁ g a l i m o t o ▁ y a k e ▁ y a k u d a\n",
            "D-228\t-0.29517897963523865\tmwamuna wamng ono wofiira atavala t shirt yakuda ndi mkazi wamutu wofiira atavala jekete yobiriwira ndi yoyera ndi galimoto yake yakuda\n",
            "P-228\t-0.1191 -0.0580 -0.0361 -0.1080 -0.0406 -0.0847 -0.0757 -0.1463 -0.1079 -0.0981 -0.4054 -0.7093 -1.0402 -0.1227 -0.0902 -0.0791 -0.1850 -0.0684 -0.1257 -1.7004 -0.0514 -0.0843 -0.0727 -0.1402 -0.0637 -0.2855 -0.1092 -0.0972 -0.0281 -0.1012 -0.8280 -0.1381 -0.1290 -0.1152 -0.1004 -0.7594 -0.5621 -0.4777 -0.0409 -0.2700 -0.0883 -0.0094 -0.1257 -2.2247 -0.2781 -0.1229 -0.1192 -0.0984 -0.5853 -0.1083 -0.0912 -0.0670 -0.0692 -0.1328 -0.0874 -1.0361 -0.1742 -0.0261 -0.0505 -0.1264 -0.0306 -0.5315 -0.9954 -0.8837 -0.2669 -0.0391 -0.0865 -0.1240 -0.0762 -0.2530 -0.1122 -0.1946 -0.0342 -0.1515 -0.1417 -0.3062 -0.0354 -0.0948 -0.0692 -0.1137 -0.0953 -0.1335 -0.1047 -1.5649 -0.2365 -0.0674 -0.0639 -0.0020 -0.1989 -0.1189 -0.7828 -0.0359 -2.0539 -0.0400 -0.0630 -0.0525 -0.0066 -0.0480 -0.0587 -0.1024 -0.1927 -0.3117 -0.0918 -0.0575 -0.1639 -0.7011 -0.0870 -0.4467 -0.5685 -0.0963 -0.1090 -0.1165 -1.9874 -0.2025 -0.0730 -0.3937 -3.5792 -0.6676 -0.2460 -0.8934 -0.1606 -0.2284 -0.0171 -0.1443 -0.1639 -0.0086 -0.1158 -0.2853 -0.1429 -0.4478 -0.0682 -0.1410 -0.4815 -0.0923 -0.0315 -0.1292 -0.9488\n",
            "T-196\tbambo akugwira ntchito yonola m mphepete mwa mpeni patebulo m khitchini yowotchedwa ndi dzuwa\n",
            "H-196\t-0.34859591722488403\t▁ b a m b o ▁ a k u g w i r a ▁ n t c h i t o ▁ y o y e r a ▁ n d i ▁ m a p e t i ▁ p a ▁ t e b u l o ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ z i k w a n g w a n i ▁ k u t i\n",
            "D-196\t-0.34859591722488403\tbambo akugwira ntchito yoyera ndi mapeti pa tebulo ndi chipale chofewa ndi zikwangwani kuti\n",
            "P-196\t-0.1213 -0.0298 -0.1059 -0.0451 -0.0594 -0.0697 -0.1119 -0.8193 -0.0459 -0.1498 -0.1013 -0.1830 -0.0443 -0.0423 -0.1321 -0.1143 -0.0644 -0.0292 -0.0177 -0.0898 -0.0524 -0.0097 -0.0330 -0.1071 -0.4995 -0.1899 -0.4252 -0.5259 -0.0783 -0.1080 -0.1380 -2.1104 -0.2316 -0.0885 -0.1459 -0.4708 -0.1530 -0.6368 -0.1167 -0.4922 -1.0529 -0.1592 -1.5973 -0.0889 -0.7721 -0.6152 -0.1450 -0.0861 -0.0430 -0.0673 -0.0988 -0.1414 -0.8825 -0.4272 -0.1051 -0.1123 -1.5120 -0.1736 -0.0418 -1.5060 -0.3005 -0.1182 -0.5037 -0.0695 -0.1039 -0.1010 -0.2152 -0.8899 -0.2337 -0.1165 -0.0922 -0.2066 -0.0735 -0.0559 -0.0834 -0.1052 -0.6344 -0.0950 -2.6983 -0.8203 -0.2183 -0.3965 -0.0676 -0.0403 -0.1628 -0.2528 -0.1944 -0.6746 -1.0365 -0.0528 -0.5052 -0.2810 -2.4028\n",
            "T-181\twosewera mpira wa tennis amayang ana kwambiri mpirawo pamene akukonzekera kuwumenya pamene wojambula zithunzi amaima kumbuyo pafupi ndi chizindikiro cha malonda a la quinta\n",
            "H-181\t-0.3797951638698578\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ a m a y a n g ▁ a n a ▁ m p i r a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ k u m e n y a ▁ k u m b u y o ▁ p a m e n e ▁ w a n y a m u l a ▁ z i t h u n z i ▁ k u m b u y o ▁ k w a ▁ c h i t h u n z i ▁ n d i ▁ c h i n t h u ▁ c h a m a k w e r o ▁ a k u y a n g ▁ a n a ▁ c h a k u d a\n",
            "D-181\t-0.3797951638698578\twosewera mpira wa tenisi amayang ana mpira wovala malaya ofiira kumenya kumbuyo pamene wanyamula zithunzi kumbuyo kwa chithunzi ndi chinthu chamakwero akuyang ana chakuda\n",
            "P-181\t-0.1093 -0.0685 -0.0599 -0.1305 -0.0567 -0.0459 -0.0733 -0.0339 -0.1196 -0.1092 -0.0338 -0.0292 -0.0732 -0.0434 -0.0961 -0.1200 -0.0380 -0.1775 -0.1405 -0.0666 -0.8460 -0.1789 -0.4726 -0.1220 -0.7944 -0.0788 -0.4337 -1.3390 -0.1921 -1.9272 -0.1315 -0.1216 -0.0239 -0.1661 -0.1172 -0.1056 -0.1345 -0.1021 -2.3833 -0.8525 -0.0891 -0.0430 -0.2802 -0.2526 -0.1080 -0.2466 -1.2064 -0.1089 -0.1019 -0.1380 -0.1081 -0.5089 -0.1614 -0.5381 -1.8763 -0.1068 -0.1224 -0.0776 -0.0459 -1.2192 -0.1549 -0.1379 -0.0453 -0.3206 -0.1000 -0.4947 -0.2403 -0.3797 -0.8276 -0.2688 -0.5537 -0.2412 -0.0964 -0.3657 -0.0982 -0.1981 -2.1244 -0.1139 -0.0131 -0.0940 -0.0995 -1.1892 -0.1521 -0.2579 -0.1096 -0.0392 -0.0717 -0.0842 -2.2489 -0.3826 -1.2683 -0.3698 -0.0858 -0.2048 -0.2984 -0.1162 -0.1071 -0.1126 -0.0843 -0.1111 -0.1339 -1.6824 -0.0449 -0.0331 -0.0594 -0.0473 -0.1110 -1.5910 -0.1134 -0.7934 -0.5149 -0.1127 -0.0350 -0.0619 -0.0908 -0.2076 -0.2334 -0.1126 -1.0801 -2.4363 -0.0733 -0.0657 -1.0127 -0.0971 -0.0151 -0.0354 -0.0351 -0.0467 -0.1194 -2.4723 -0.0516 -0.0774 -0.2655 -1.1790 -0.0608 -0.5214 -0.9156 -0.8963 -0.0244 -0.0344 -0.0933 -0.1808 -0.0632 -0.4444 -1.3300 -0.4052 -0.7694 -1.9367 -0.3586 -0.1493 -0.2233 -0.2012 -0.6128 -0.9213 -0.1952 -0.5553 -0.5739 -0.1043 -0.0721 -0.0710 -0.0724 -0.0616 -0.1761 -0.4719 -2.1229 -0.1141 -0.4239 -0.1874 -0.0872 -0.2913 -0.2154 -0.5958\n",
            "T-330\tmwamuna wina wovala chipewa choweta ng ombe akuyendetsa ngolo ya ayisikilimu yokhala ndi mawu akuti sorvete e gelados nicolau\n",
            "H-330\t-0.3686909079551697\t▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ c h i p e w a ▁ c h o w e t a ▁ n g ▁ o m b e ▁ y a k u d a ▁ n d i ▁ t s i t s i ▁ l a l i t a l i ▁ l o y i m i t s i d w a ▁ n d i ▁ m u n t h u ▁ w a k u d a ▁ n d i ▁ g a l a s i ▁ l o t u w a\n",
            "D-330\t-0.3686909079551697\tmwamuna wina wovala chipewa choweta ng ombe yakuda ndi tsitsi lalitali loyimitsidwa ndi munthu wakuda ndi galasi lotuwa\n",
            "P-330\t-0.1226 -0.1067 -0.0255 -0.1146 -0.0660 -0.0800 -0.0721 -0.1345 -0.1162 -0.0606 -0.1077 -0.0582 -0.1328 -0.1092 -0.0567 -0.0586 -0.0278 -0.1315 -0.1298 -0.1160 -0.1005 -0.3882 -0.0821 -0.0718 -0.6778 -0.0931 -0.0604 -0.0898 -0.1116 -0.0136 -0.0692 -0.0856 -1.1752 -0.1558 -0.8631 -0.0804 -0.1099 -0.2086 -0.0143 -0.0593 -0.1826 -0.0167 -0.0133 -0.0956 -0.0877 -0.3511 -0.1128 -0.7332 -0.1120 -0.6702 -0.9138 -0.1574 -0.5599 -0.0883 -0.1389 -0.1233 -2.1411 -0.2391 -0.9146 -0.3832 -0.4096 -0.3704 -0.0822 -0.1801 -0.2626 -1.0081 -0.0753 -0.3969 -0.0849 -0.0694 -0.2425 -0.1734 -0.5629 -0.4989 -1.3655 -0.2254 -0.6927 -0.4927 -0.5349 -0.2407 -0.0602 -0.4227 -0.0609 -0.1414 -0.1185 -0.7792 -0.1388 -0.0829 -0.1601 -0.4480 -3.1008 -0.8718 -0.1690 -0.3848 -0.1043 -0.0821 -0.2582 -0.1393 -1.0036 -2.0410 -0.1097 -0.1316 -0.1207 -1.4450 -0.1695 -0.1070 -0.1054 -1.5346 -0.0795 -0.1352 -1.8028 -0.1878 -0.1317 -0.1482 -0.5195 -0.7043 -0.5514 -1.5177 -0.4413 -0.0703 -1.6897\n",
            "T-166\tachinyamata awiri akukwera pa makwerero mtsikanayo ali pakati pa mtengo wokutidwa ndi masamba ndipo mnzake wovala malaya abuluu akumwetulira kumbuyo\n",
            "H-166\t-0.3248674273490906\t▁ a c h i n y a m a t a ▁ a w i r i ▁ a k u k w e r a ▁ p a m a p e w e r o ▁ n ▁ k u t i ▁ a y i k a ▁ n d i p o ▁ a t a y i k a ▁ p a m t e n g o ▁ w o t e n t i d w a ▁ n d i ▁ m a s a m b a ▁ a k e ▁ n d i p o ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u m w e t u l i r a ▁ k u m b u y o\n",
            "D-166\t-0.3248674273490906\tachinyamata awiri akukwera pamapewero n kuti ayika ndipo atayika pamtengo wotentidwa ndi masamba ake ndipo wovala malaya abuluu akumwetulira kumbuyo\n",
            "P-166\t-0.1140 -0.0868 -2.0814 -0.1120 -0.0899 -0.0364 -0.0222 -0.0900 -0.0482 -0.0934 -0.0058 -0.0837 -0.1099 -0.0688 -0.0470 -0.0971 -0.0437 -0.0865 -0.1133 -0.2133 -0.1967 -0.1420 -0.1610 -0.2517 -0.0713 -0.0851 -0.2103 -0.1206 -0.2676 -0.1421 -0.4105 -0.1816 -0.6846 -0.1172 -0.4161 -1.6627 -0.1812 -0.2647 -0.1040 -0.7636 -0.5460 -0.2945 -0.7433 -0.6499 -0.0866 -0.0779 -0.7486 -0.1516 -0.5981 -0.8788 -0.3213 -0.2020 -1.0138 -0.1970 -0.0582 -0.9107 -0.0910 -0.0910 -0.7587 -0.2037 -0.1588 -0.9116 -0.0752 -0.3600 -0.3880 -0.1592 -0.4521 -0.1437 -0.9400 -0.5089 -0.1298 -0.0395 -0.2134 -0.0213 -0.0920 -1.2742 -0.2308 -0.7143 -1.7086 -0.4614 -0.6023 -0.6372 -1.0515 -0.0149 -0.0916 -0.1304 -0.3935 -0.1475 -0.0742 -0.5489 -0.2941 -0.1469 -0.2857 -0.2174 -0.0775 -0.0051 -0.0737 -0.1049 -1.2112 -1.6986 -0.3089 -0.0866 -1.6578 -0.1054 -0.0761 -0.0722 -0.0387 -0.0907 -1.0787 -0.7726 -0.1034 -0.1042 -0.0896 -0.1137 -0.1118 -0.3974 -0.1002 -0.1569 -0.1185 -0.0214 -0.0890 -0.0853 -0.1544 -0.6068 -0.0408 -0.0583 -0.0328 -0.0340 -0.0769 -0.1101 -0.1998 -0.0972 -2.1805 -1.3445 -0.0695 -0.0210 -0.0110 -0.0304 -0.0351 -0.0279 -0.0770 -0.5001 -0.3000 -0.2436 -0.0939 -0.0373 -0.0305 -0.0187 -0.0386 -0.9896\n",
            "T-96\tanthu awiri omwe ali ndi ma jekete alalanje ndi oyera ofanana ndi zipewa zoyera atakhala panjinga yamoto panjira yonyowa njerwa yotuwa masitepe a njerwa imvi akukwera kumbuyo kwawo\n",
            "H-96\t-0.31473809480667114\t▁ a n t h u ▁ a w i r i ▁ o m w e ▁ a l i ▁ n d i ▁ m a ▁ j a k e t e ▁ a t a v a l a ▁ j e k e t e ▁ y o y e r a ▁ n d i p o ▁ w i n a ▁ w o v a l a ▁ z o y e r a ▁ n d i ▁ z o y e r a ▁ a t a k h a l a ▁ p a n j i n g a ▁ y a m o t o ▁ y o t u w a ▁ n d i ▁ y o w a l a ▁ n d i ▁ c h i p e w a ▁ c h o w a l a ▁ k u m b u y o ▁ k w a ▁ n j i r a ▁ k u m b u y o ▁ k w a k e\n",
            "D-96\t-0.31473809480667114\tanthu awiri omwe ali ndi ma jakete atavala jekete yoyera ndipo wina wovala zoyera ndi zoyera atakhala panjinga yamoto yotuwa ndi yowala ndi chipewa chowala kumbuyo kwa njira kumbuyo kwake\n",
            "P-96\t-0.1060 -0.1941 -0.5849 -0.0680 -0.3565 -0.0791 -0.0870 -0.1692 -0.2828 -0.1006 -0.0348 -0.1137 -0.0979 -0.0380 -0.2385 -0.1459 -0.1293 -0.0704 -0.0575 -0.0459 -0.0774 -0.0925 -0.0342 -0.0746 -0.1239 -0.0717 -0.0372 -0.1938 -2.4150 -0.4458 -0.6032 -0.7209 -0.2950 -0.0094 -0.7212 -0.0819 -0.3265 -0.1503 -0.0641 -0.3066 -0.1079 -0.0918 -0.0976 -0.1011 -0.2068 -0.2439 -0.9417 -0.1003 -0.0284 -0.1280 -0.0771 -2.3327 -0.9002 -0.0248 -0.0980 -0.0368 -0.1000 -0.1042 -0.0490 -0.0631 -0.0874 -0.5439 -0.0439 -0.0872 -1.7930 -0.4654 -0.0613 -0.1252 -0.1443 -0.3358 -0.0423 -1.0421 -0.0991 -0.1235 -0.1146 -0.1015 -0.2711 -0.4956 -0.2147 -0.0880 -0.0382 -0.0967 -0.0936 -0.1773 -0.0412 -0.0851 -0.2496 -0.3920 -0.6822 -0.0238 -0.0716 -0.0566 -0.1108 -0.1025 -0.1596 -0.1980 -0.1227 -0.0783 -0.0207 -0.1178 -0.0571 -0.1302 -0.0947 -0.0772 -0.1275 -0.6024 -0.1989 -0.1800 -0.2155 -0.0799 -0.0940 -0.1133 -0.3329 -1.5676 -0.3138 -0.0328 -0.0805 -0.0522 -0.1414 -0.1865 -0.0640 -1.8950 -0.0879 -0.0537 -0.0801 -0.1339 -0.3889 -0.1856 -0.0965 -0.2158 -1.4096 -0.0827 -0.2853 -0.1179 -0.4112 -0.7301 -0.0905 -0.9917 -0.6346 -0.1241 -0.1307 -2.4256 -0.1036 -0.0565 -0.8272 -1.0355 -0.0299 -0.0696 -0.0898 -0.8664 -0.1053 -0.3175 -1.1192 -0.2454 -2.5941 -0.5681 -0.1228 -1.9557 -0.1669 -1.2512 -0.7149 -0.1337 -0.0341 -0.0950 -0.0859 -0.1505 -0.1891 -0.1193 -1.1488 -1.1974 -0.2706 -0.2088 -0.8296 -0.1446 -0.1207 -0.3517 -0.1805 -0.2644 -0.0368 -0.0532 -0.0282 -0.0577 -0.1713 -0.0093 -0.0535 -0.0960 -0.5742 -0.1651 -0.2852\n",
            "T-52\tkamtsikana kakang ono m bafa ndikumwetulira kwakukulu ndipo tsitsi lake lonyowa likulunjika ngati tsitsi la alfalfa mu pulogalamu yakale yapa tv the little rascals\n",
            "H-52\t-0.4090004861354828\t▁ k a m t s i k a n a ▁ k a k a n g ▁ o n o ▁ k a ▁ m p i r a ▁ w a i m i r i r a ▁ k u t u l u k w a ▁ k u t i ▁ n d i ▁ t s i t s i ▁ l a k e ▁ l o w a l a ▁ n d i ▁ c h i t h u n z i ▁ c h a ▁ m p a n d a ▁ w a c h i k a s u ▁ k u m b u y o ▁ k w a w o\n",
            "D-52\t-0.4090004861354828\tkamtsikana kakang ono ka mpira waimirira kutulukwa kuti ndi tsitsi lake lowala ndi chithunzi cha mpanda wachikasu kumbuyo kwawo\n",
            "P-52\t-0.1221 -0.6095 -0.3051 -0.0307 -0.0111 -0.0498 -0.0533 -0.0272 -0.1317 -0.0691 -0.1290 -0.1233 -0.0118 -0.0805 -0.1490 -0.0731 -0.0948 -0.0172 -0.0740 -0.1410 -0.0424 -0.0673 -0.1147 -0.1665 -0.5375 -0.2147 -0.6812 -0.7485 -1.6295 -0.9410 -0.1040 -0.1349 -1.4970 -0.4378 -0.4526 -0.0562 -0.8475 -0.2337 -0.0656 -0.0676 -0.1115 -0.1102 -0.9900 -0.1347 -0.5112 -0.4552 -1.5934 -0.7927 -0.0689 -1.5131 -0.1227 -0.1393 -0.3703 -0.6045 -0.7084 -0.0795 -0.0805 -0.8160 -0.0887 -0.1004 -0.1740 -2.1942 -0.5111 -0.0688 -0.1013 -0.2771 -0.0533 -0.0899 -0.1633 -0.2660 -0.8726 -0.0241 -0.0943 -1.9841 -0.0738 -0.4084 -0.2438 -0.7036 -0.1167 -0.1071 -0.9690 -0.0484 -0.1182 -0.2818 -1.9888 -0.0808 -0.0616 -1.2849 -1.4633 -0.0499 -0.0337 -0.0306 -0.0399 -0.1902 -0.4769 -0.0405 -0.1794 -0.3417 -1.6252 -2.0497 -0.4252 -0.8632 -0.1020 -0.0964 -0.0962 -0.2959 -0.2425 -3.1798 -0.1201 -0.0763 -0.4308 -0.4973 -0.1728 -0.0408 -0.2338 -2.3154 -0.1685 -0.9463 -0.1009 -0.0346 -0.0480 -0.0543 -0.4398 -0.1012 -0.1966 -0.0793 -0.5367 -0.0935 -0.1565\n",
            "T-2\tbambo wakuda yemwe akuoneka kuti alibe pokhala ndi nsapato zosagwirizana mathalauza awiri ndi jekete lolemera amayesa kutenthetsa manja ake atakhala pakhomo\n",
            "H-2\t-0.4221547544002533\t▁ b a m b o ▁ w o k o n z e k e r a ▁ w a n y a m u l a ▁ k u t i ▁ a l i ▁ p o m w e ▁ a k h a l a ▁ p a n s i ▁ n d i ▁ z o t h a m a n g i t s a ▁ z a k e ▁ z o f i i r a ▁ n d i ▁ c h i p e w a ▁ c h o l e m b e d w a ▁ a m a y e s a ▁ k u t e t e z a ▁ m a n j a ▁ a k e ▁ a k u m a n j a ▁ k w a k e\n",
            "D-2\t-0.4221547544002533\tbambo wokonzekera wanyamula kuti ali pomwe akhala pansi ndi zothamangitsa zake zofiira ndi chipewa cholembedwa amayesa kuteteza manja ake akumanja kwake\n",
            "P-2\t-0.1051 -1.0101 -0.0974 -0.0477 -0.0461 -0.0688 -0.1137 -0.4757 -0.9640 -0.2365 -2.3098 -0.1166 -0.5129 -0.2397 -1.6962 -0.2805 -0.1859 -0.6068 -0.1004 -0.0964 -0.2423 -1.3075 -0.1301 -0.2205 -0.0426 -0.1116 -0.1516 -0.5442 -0.0879 -0.6840 -0.2941 -0.6127 -0.4133 -0.0648 -0.2212 -0.3314 -0.1293 -0.1342 -1.1570 -0.1433 -0.3535 -0.3828 -0.0921 -0.0786 -0.8138 -1.9925 -0.0641 -0.1181 -0.3014 -0.1020 -0.1172 -0.5408 -0.1287 -0.8748 -0.2220 -0.4436 -0.1031 -0.3032 -0.3348 -0.0997 -0.1527 -0.1240 -0.1721 -1.0323 -1.0436 -0.0994 -1.4416 -0.0838 -0.0713 -0.2414 -0.3299 -1.4064 -0.0538 -0.1246 -0.0785 -0.5023 -0.3486 -2.3691 -0.5786 -0.0739 -1.3433 -0.3296 -0.2064 -1.1313 -0.1528 -0.0331 -0.4104 -0.1473 -0.8907 -0.1276 -0.0814 -1.0818 -1.9364 -0.1148 -0.3177 -0.2854 -0.4584 -0.0617 -0.0816 -0.1565 -0.6712 -0.0866 -0.2543 -0.2540 -0.4115 -0.1134 -0.2110 -0.1008 -0.5843 -0.2022 -0.4573 -0.1693 -0.8036 -0.9136 -0.0687 -1.7719 -0.2084 -0.3100 -0.2191 -0.0926 -0.0756 -0.0532 -0.4041 -0.8437 -0.4397 -0.0569 -0.4491 -0.1512 -0.0700 -0.6473 -0.2019 -0.2250 -0.0112 -0.0946 -0.0881 -0.2751 -0.2916 -0.0685 -0.1278 -2.2761 -0.6898 -0.0680 -1.0110 -1.2056 -0.2633 -0.2151 -0.0755 -0.4521 -1.1543 -0.3177 -0.2216 -0.7697 -0.0303 -0.3068\n",
            " 15% 2/13 [00:07<00:39,  3.56s/it, wps=542]T-283\tmtsikana wina wosewera mpira wa basketball yemwe wavala yunifolomu yofiira wanyamula mpira wa basketball akuyang ana m mwamba kwinaku dzanja likufuna kumutsekereza\n",
            "H-283\t-0.3241533935070038\t▁ m t s i k a n a ▁ w i n a ▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ t s i t s i ▁ l o y e r a ▁ n d i p o ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ y u n i f o l o m u ▁ y o f i i r a ▁ n d i p o ▁ w i n a ▁ w a k u y a n g ▁ a n a ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ k u t s o g o l o ▁ k w a ▁ m i t e n g o ▁ y o f i i r a\n",
            "D-283\t-0.3241533935070038\tmtsikana wina wosewera mpira wa tsitsi loyera ndipo wina yemwe wavala yunifolomu yofiira ndipo wina wakuyang ana m mphepete mwa nyanja kutsogolo kwa mitengo yofiira\n",
            "P-283\t-0.1125 -2.1456 -0.1222 -0.0338 -0.0613 -0.0346 -0.1066 -0.0692 -0.1088 -0.1121 -0.0381 -0.4900 -0.1122 -0.1201 -0.1085 -0.0415 -0.3374 -0.2180 -0.0351 -0.0291 -0.1293 -0.0710 -0.0967 -0.1456 -0.0801 -0.6127 -0.1030 -0.6557 -0.1017 -0.1272 -0.0623 -0.2439 -0.1164 -1.4731 -1.0860 -0.1097 -0.0890 -0.1488 -0.1367 -0.0982 -0.1950 -0.9266 -0.1313 -0.1194 -1.4531 -0.0934 -0.1374 -1.4805 -0.1204 -0.1061 -0.4351 -0.0610 -0.0856 -1.5562 -0.1937 -0.0531 -0.0814 -0.4528 -1.3034 -0.0747 -0.0431 -0.2820 -0.0733 -0.1033 -0.0971 -0.2747 -0.1763 -0.0815 -0.0732 -0.0929 -0.1334 -0.5491 -0.1001 -0.0242 -0.0537 -0.0324 -0.0212 -0.0310 -0.0424 -0.0332 -0.0345 -0.1316 -0.5102 -0.5361 -0.1710 -0.0415 -0.2194 -0.0403 -0.1372 -0.1485 -1.3300 -0.1010 -0.1024 -0.2521 -0.0343 -0.1097 -0.7775 -2.2766 -0.1153 -0.1167 -0.1340 -0.1160 -0.8761 -0.5624 -0.2106 -0.3923 -0.0965 -0.0537 -0.0748 -0.0870 -0.0666 -0.0511 -0.1368 -0.1266 -0.3577 -0.8437 -0.1270 -0.6054 -0.2808 -1.2710 -0.1906 -0.3527 -0.0087 -0.1088 -0.0733 -0.0787 -0.0584 -0.1234 -0.1068 -0.7651 -0.9761 -0.2215 -0.0500 -0.0402 -0.1054 -0.1476 -0.6758 -0.1920 -0.9381 -0.7841 -0.0638 -0.0898 -0.0945 -0.1273 -0.1262 -0.1684 -0.3187 -0.1908 -0.2607 -0.2122 -1.0978 -1.2299 -0.7910 -1.8091 -0.2721 -0.3908 -0.3145 -0.4217 -0.6394 -0.9255 -1.5710 -0.2194 -0.3979 -0.2359 -0.3428 -0.3428\n",
            "T-65\tachinyamata atatu amawoloka msewu pa nyali yofiyira m modzi wavala kapu ya baseball yoyera ndi ya bulauni m modzi wavala kapu yakuda ya baseball ndipo wina wapakati wavala kapu ya sitoko\n",
            "H-65\t-0.39129024744033813\t▁ a c h i n y a m a t a ▁ a t a t u ▁ o m w e ▁ a m a k h a l a ▁ m u m s e w u ▁ p a m e n e ▁ a l i ▁ n d i ▁ n y u m b a ▁ z o s e w e r a ▁ a k u y e s e r a ▁ k u y e s e r a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y a k u d a ▁ n d i p o ▁ a k u y a n g ▁ a n a ▁ k u j a m b u l a ▁ c h i p a l e ▁ c h o f e w a ▁ k u m b u y o ▁ k w a k e\n",
            "D-65\t-0.39129024744033813\tachinyamata atatu omwe amakhala mumsewu pamene ali ndi nyumba zosewera akuyesera kuyesera kutsogolo kwa nyumba yakuda ndipo akuyang ana kujambula chipale chofewa kumbuyo kwake\n",
            "P-65\t-0.1017 -0.3018 -0.5758 -0.0979 -0.0563 -0.1420 -0.0361 -0.1009 -0.0526 -0.0982 -0.0161 -0.0954 -0.1119 -0.1516 -0.0299 -0.1054 -0.0268 -0.0979 -0.0865 -0.5766 -0.3585 -0.2379 -0.1525 -0.0811 -1.6564 -1.3585 -0.1066 -2.3051 -0.2752 -0.1258 -0.0711 -0.1165 -0.1074 -0.5293 -1.1491 -0.3046 -0.0823 -0.0956 -0.0195 -0.0272 -0.0826 -0.8913 -0.1199 -1.3868 -0.1315 -0.0465 -0.0763 -0.0870 -1.4381 -0.5877 -0.0888 -0.1444 -0.2175 -0.0364 -0.0871 -0.1024 -1.5490 -1.1857 -0.8666 -0.4128 -0.3362 -0.1535 -0.1024 -0.1265 -0.3276 -1.0797 -1.2764 -0.1680 -0.0756 -0.0764 -0.1068 -0.1279 -0.7270 -0.4349 -0.2116 -0.3058 -0.3439 -0.7188 -0.5897 -0.0994 -0.1344 -0.1078 -0.2565 -0.5453 -0.8024 -0.3652 -0.8630 -0.6401 -0.0438 -0.1417 -0.1102 -0.3718 -1.1591 -1.0109 -0.2625 -0.0741 -0.0269 -0.1909 -0.0258 -0.3489 -0.1522 -0.9159 -0.0320 -0.3323 -0.1100 -0.7624 -0.6213 -0.5833 -0.1023 -0.0858 -0.3972 -0.1287 -0.0481 -0.6402 -1.8461 -0.3613 -0.3396 -0.1462 -0.0969 -1.3639 -0.0700 -0.0906 -2.0481 -0.0519 -0.0908 -2.0434 -0.3950 -0.2602 -0.1470 -0.3268 -0.2914 -0.4077 -0.0861 -0.0823 -0.0590 -0.2286 -0.0762 -0.8566 -0.1643 -2.3821 -0.0837 -1.4985 -0.0319 -0.0550 -0.0734 -1.1171 -0.0748 -1.1965 -0.0779 -0.0955 -1.7496 -0.1235 -0.1401 -0.0790 -0.0578 -0.0674 -0.0627 -0.0486 -0.3356 -0.0894 -0.0144 -0.1173 -0.2172 -1.3864 -0.8801 -0.4179 -1.1611 -1.0010 -0.0953 -0.0854 -0.1771 -0.1579 -0.0603 -0.1308 -0.2594 -0.0475 -0.3385\n",
            "T-211\tmunthu wovekedwa mikanjo yakuda amadziunjikira potsegula mlatho ndi zakumwa zoziziritsa kukhosi pamapazi obisika\n",
            "H-211\t-0.43180209398269653\t▁ m u n t h u ▁ w o v a l a ▁ t ▁ s h i r t ▁ y a k u d a ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ n d i p o ▁ a m a k u t u l u t s a ▁ z i n t h u ▁ z o z i z i r i t s a ▁ k u k o n z e k a ▁ k u t s o g o l o ▁ k w a ▁ m a p i k i\n",
            "D-211\t-0.43180209398269653\tmunthu wovala t shirt yakuda akujambula chithunzi ndipo amakutulutsa zinthu zoziziritsa kukonzeka kutsogolo kwa mapiki\n",
            "P-211\t-0.1235 -0.4197 -1.0911 -0.1382 -0.0668 -0.0475 -0.0908 -0.1575 -0.1605 -0.0598 -0.1762 -0.7259 -0.0936 -0.4584 -0.1003 -1.5369 -1.2000 -0.3147 -0.0889 -0.9418 -0.0501 -0.0040 -0.1576 -0.0615 -0.3214 -1.2143 -0.0970 -0.1618 -0.1208 -0.1196 -0.0761 -0.6156 -0.1079 -2.0417 -0.1029 -0.0258 -0.3634 -0.3790 -0.1340 -0.1865 -0.1228 -2.1023 -0.1013 -0.0673 -0.5093 -0.0464 -0.0250 -0.0221 -0.1881 -0.0366 -0.1500 -1.3191 -0.0779 -0.0547 -1.0091 -0.0405 -0.1159 -0.6996 -1.0072 -1.7200 -1.2499 -0.4513 -0.2253 -0.2520 -0.0436 -0.8381 -0.3962 -0.8718 -0.8346 -0.1306 -1.5405 -0.1151 -1.7823 -0.0715 -0.0644 -0.1407 -0.1556 -0.0227 -0.4079 -0.8635 -0.8636 -0.3718 -0.0226 -0.1356 -0.0987 -1.6369 -1.0428 -0.0989 -0.1354 -0.1818 -0.1655 -0.5084 -0.8953 -0.5553 -0.7568 -0.9116 -0.2749 -0.9258 -0.1190 -0.7569 -0.2471 -0.5681 -1.4544 -0.5975 -0.1198 -0.0800 -0.0892 -0.1090 -0.1711 -0.3385 -0.0721 -0.1146 -0.1511 -0.6287 -0.1655 -0.7329 -0.6097 -0.5785 -0.0402 -0.2848\n",
            "T-317\tmayi wina wachikulire wovala diresi lamitundumitundu jekete lachikopa komanso chipewa chakuda amakhala pabenchi moyang anizana ndi khoma lakale kwambiri\n",
            "H-317\t-0.4082666039466858\t▁ a m u n a ▁ a w i r i ▁ w a c h i k u l i r e ▁ w o v a l a ▁ j i n z i ▁ a m i t u n d u m i t u n d u ▁ y a ▁ c h i t h u n z i ▁ c h a k e ▁ p o m a n s o ▁ c h i t h u n z i ▁ c h a k u d y a ▁ a k u j a m b u l a ▁ c h i p a l e ▁ c h o y e n d a ▁ p o m w e ▁ a n a l i ▁ n d i ▁ z a k o m a ▁ a l i ▁ n d i ▁ k o m a n g i d w a\n",
            "D-317\t-0.4082666039466858\tamuna awiri wachikulire wovala jinzi amitundumitundu ya chithunzi chake pomanso chithunzi chakudya akujambula chipale choyenda pomwe anali ndi zakoma ali ndi komangidwa\n",
            "P-317\t-0.1073 -0.2416 -1.7305 -0.2308 -0.1438 -0.1039 -0.1484 -0.1174 -0.4202 -0.0759 -0.0867 -0.0966 -0.0890 -1.3780 -0.2412 -0.2699 -0.0603 -0.0471 -0.0585 -0.0682 -0.0374 -0.0980 -0.0344 -0.0951 -0.0940 -0.1847 -0.0513 -0.1184 -0.1102 -0.0689 -0.1165 -0.0993 -0.9018 -1.3895 -0.1562 -0.3090 -0.0811 -0.0986 -0.2642 -1.0641 -0.3381 -0.0102 -0.0348 -0.0823 -0.0395 -0.0206 -0.7126 -0.3904 -0.0684 -0.0644 -0.0430 -0.0376 -0.0552 -0.2321 -0.8914 -0.2211 -1.4151 -0.5310 -0.1042 -0.0669 -1.3689 -0.9570 -0.0527 -0.0554 -0.2954 -0.0896 -0.1972 -2.2069 -0.0647 -0.2457 -0.4875 -0.3550 -0.0769 -0.1150 -0.7861 -0.1864 -2.6113 -0.0518 -0.2707 -0.0593 -0.0893 -1.2227 -0.0480 -0.1161 -1.1074 -0.8176 -0.5816 -0.0917 -0.0126 -0.1693 -0.1590 -0.1376 -0.0545 -0.1081 -0.4554 -0.5556 -0.0323 -0.4589 -0.1518 -0.1292 -1.0560 -0.2572 -0.1267 -1.9795 -0.0933 -0.0401 -0.3925 -0.2208 -0.0473 -0.3314 -0.0910 -2.5526 -0.0934 -0.0984 -0.7452 -0.5674 -0.2565 -0.2986 -0.1990 -0.9467 -0.0878 -0.5242 -0.1434 -0.7059 -0.9724 -0.1549 -0.8343 -0.1381 -1.7575 -0.4676 -0.0947 -0.2312 -0.1089 -0.0850 -0.6614 -1.2182 -0.8300 -0.9158 -0.3855 -0.1223 -0.2289 -0.0506 -0.0991 -0.2359 -0.7016 -0.2614 -0.3770 -1.5200 -0.4609 -0.1608 -0.4700 -1.4531 -0.1688 -0.3281 -0.2104 -0.7092 -0.0410 -0.1124 -0.2499 -1.4508 -0.7829 -0.2095 -0.1535 -0.8208 -2.1097 -0.0989 -0.7673 -0.1189 -0.1692 -0.5727\n",
            "T-324\toyimba violin atatu wamkazi wina wamwamuna m modzi wobisika ndi woyimba cell waamuna atakhala posewera ndikuvala zakuda\n",
            "H-324\t-0.40843403339385986\t▁ o i m b a ▁ p a l i ▁ m a t a t u ▁ a t a t u ▁ a m a d z i ▁ n d i ▁ m w a m u n a ▁ w a m n g ▁ o n o ▁ m ▁ m o d z i ▁ n d i ▁ m w a m u n a ▁ w o z i m b a ▁ n d i ▁ m u n d a ▁ w a i m a ▁ a t a t s e k a ▁ n d i p o ▁ w a z a k u d a\n",
            "D-324\t-0.40843403339385986\toimba pali matatu atatu amadzi ndi mwamuna wamng ono m modzi ndi mwamuna wozimba ndi munda waima atatseka ndipo wazakuda\n",
            "P-324\t-0.1213 -0.7312 -1.1111 -0.2452 -0.0084 -0.1455 -0.1075 -0.7328 -0.1098 -0.8246 -0.2962 -0.0966 -0.8957 -0.1947 -0.0488 -0.4761 -0.1021 -0.2943 -0.1040 -0.4772 -0.4192 -0.1170 -0.2179 -0.0829 -0.1115 -1.4534 -0.3253 -1.3207 -0.6833 -0.0235 -0.0711 -0.0924 -1.4984 -0.3410 -0.1155 -0.1909 -0.1439 -0.0187 -0.1162 -0.0839 -0.1172 -0.0861 -0.1139 -0.1011 -0.5238 -0.1272 -0.5080 -2.1258 -0.1810 -0.0618 -0.1965 -0.1082 -0.0475 -0.2173 -0.2801 -1.0117 -0.0857 -0.8261 -0.2049 -0.0488 -0.0777 -0.1158 -1.5964 -0.1795 -0.0941 -0.2117 -0.4774 -1.0268 -0.1239 -0.7163 -0.0969 -0.0440 -0.1616 -0.1017 -0.1225 -1.1306 -1.6364 -0.2440 -0.8654 -0.1298 -0.5665 -0.1983 -0.2548 -0.0516 -0.1186 -0.5430 -1.2480 -0.3626 -0.0939 -0.8246 -0.0774 -0.0959 -0.1757 -0.1905 -1.9539 -0.1436 -0.4670 -0.0747 -1.1199 -0.0969 -0.1038 -0.3494 -1.2569 -0.3091 -1.1676 -0.1859 -0.1047 -0.9698 -0.1218 -0.0838 -0.1709 -0.0373 -0.1073 -0.9093 -0.1302 -1.9233 -0.2012 -0.2311 -0.2403 -0.0399 -0.2545 -1.5992\n",
            "T-95\tanthu awiri ovala zipewa zofiira za njinga yamoto akukwera limodzi panjinga yamoto yofiyira m mphepete mwa msewu kudutsa zikwangwani zonena za chikomyunizimu\n",
            "H-95\t-0.35712069272994995\t▁ a n t h u ▁ a w i r i ▁ o v a l a ▁ z i p e w a ▁ z o f i i r a ▁ z a n j i n g a ▁ y a m o t o ▁ a k u k w e r a ▁ m o z i m b a ▁ y a i k u l u ▁ y o f i i r a ▁ n d i ▁ y a m o t o ▁ y o f i i r a ▁ k u t e t e z e d w a ▁ k u t i ▁ w a n y a m u l a ▁ z i k w a n g w a n i ▁ z a c h i t s u l o\n",
            "D-95\t-0.35712069272994995\tanthu awiri ovala zipewa zofiira zanjinga yamoto akukwera mozimba yaikulu yofiira ndi yamoto yofiira kutetezedwa kuti wanyamula zikwangwani zachitsulo\n",
            "P-95\t-0.1028 -0.1085 -0.1217 -0.0178 -0.1203 -0.0899 -0.1155 -0.1282 -1.2171 -0.0651 -0.0686 -0.0771 -0.1005 -0.0875 -0.0720 -0.1045 -0.0858 -0.1193 -0.1040 -0.0832 -0.0801 -0.1537 -0.3151 -0.0278 -0.1133 -0.1106 -0.0069 -0.1114 -0.7080 -0.0494 -0.1236 -0.0351 -0.1154 -0.1088 -0.0987 -0.6523 -2.1249 -0.0789 -0.4740 -0.1296 -0.0890 -0.1042 -0.1288 -0.5763 -0.0829 -0.3205 -0.1666 -0.0278 -0.3182 -0.1496 -0.8018 -0.0792 -0.0882 -0.9913 -0.0657 -0.0374 -0.1323 -0.1604 -0.1343 -1.3477 -1.3985 -0.1226 -0.4150 -0.7754 -0.9242 -0.1457 -0.2087 -1.3602 -0.4610 -1.2096 -0.8978 -0.1913 -0.0861 -0.1931 -0.1191 -0.6545 -0.3328 -0.2450 -0.0467 -0.3869 -0.0484 -0.1389 -0.1435 -0.8978 -0.0749 -0.0512 -0.1865 -1.4267 -1.3052 -0.5059 -0.0593 -0.0590 -0.1610 -0.1685 -0.2845 -0.3575 -1.0729 -0.0620 -0.4547 -0.0536 -0.2479 -0.1443 -0.5123 -0.1328 -0.3942 -2.5720 -0.4569 -0.1224 -0.2127 -0.0520 -0.6117 -0.0853 -0.2323 -0.1135 -0.1434 -0.4574 -0.0633 -0.6274 -0.0739 -1.6391 -0.1665 -2.7645 -0.1767 -0.1189 -0.1428 -0.2498 -0.0987 -0.1182 -0.0875 -0.9740 -0.7618 -0.5803 -0.0282 -0.1208 -0.7419 -0.2949 -0.1022 -0.1180 -0.0522 -0.0384 -0.3645 -0.3759 -0.3969 -0.6446 -0.0745 -0.0622 -1.6856 -0.5214 -0.4479 -0.1289 -0.0763 -0.7767\n",
            "T-292\tbambo wina wovala jekete la buluu atakwera galu akuwolokera pa chigwa chokutidwa ndi chipale chofewa\n",
            "H-292\t-0.3369063138961792\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ b u l u u ▁ a t a k h a l a ▁ p a ▁ b u l u u ▁ k u t i ▁ l a ▁ c h i n g w e ▁ c h o k o n g o l a ▁ c h o k u t i d w a ▁ k u t i ▁ c h o f i i r a ▁ n d i ▁ c h o f i i r a\n",
            "D-292\t-0.3369063138961792\tbambo wina wovala jekete la buluu atakhala pa buluu kuti la chingwe chokongola chokutidwa kuti chofiira ndi chofiira\n",
            "P-292\t-0.1182 -2.0940 -0.1138 -0.0354 -0.0321 -0.0920 -0.1062 -0.0595 -0.1340 -0.0795 -0.1388 -0.1215 -0.0499 -0.0499 -0.0434 -0.1468 -0.1213 -0.1120 -0.1008 -1.9669 -0.4508 -0.1340 -0.1017 -0.0211 -0.4559 -0.1071 -0.2410 -0.0722 -0.2307 -0.4276 -0.4807 -0.0594 -0.0676 -0.0251 -0.0760 -0.2319 -0.0180 -0.0964 -0.0853 -0.1347 -0.1371 -0.0388 -0.1201 -0.0978 -0.3976 -0.2696 -1.1086 -0.9355 -0.4467 -0.2890 -0.0790 -0.0304 -0.0938 -0.8072 -1.0674 -0.6253 -0.1347 -0.0588 -1.2311 -0.2329 -1.4292 -0.2972 -0.1810 -0.0734 -0.3290 -0.6315 -0.0620 -0.8920 -0.1211 -0.1129 -0.1322 -0.1107 -0.3343 -2.2068 -0.4153 -0.2344 -0.1812 -0.2101 -0.2030 -0.1766 -1.2711 -0.0834 -0.4723 -1.1994 -0.9130 -0.0168 -0.0411 -0.3192 -0.0319 -0.1015 -0.1803 -0.7057 -0.4153 -0.2747 -0.1684 -0.0811 -0.6502 -0.0631 -0.4427 -0.5783 -0.6472 -0.3752 -0.1014 -0.4315 -0.7567 -0.2102 -0.0453 -0.1001 -0.1456 -0.0625 -0.1158 -0.9795 -0.3209 -0.7632 -0.1101 -0.0412 -0.4000 -0.3712\n",
            "T-42\tbambo akuyesera kuti atsike pamasewera a baseball pomwe woponya mpira akuponyera mpirawo kuti amuponyere kunja\n",
            "H-42\t-0.39225631952285767\t▁ b a m b o ▁ a k u g w i r a ▁ t s i t s i ▁ l a k u t i ▁ a t a t i ▁ p a ▁ m a s e w e r a ▁ a ▁ b u l u u ▁ p o m w e ▁ w o v a l a ▁ m p i r a ▁ a k u p o n y a ▁ m p i r a ▁ a w o ▁ a k u c h o k e r a\n",
            "D-42\t-0.39225631952285767\tbambo akugwira tsitsi lakuti atati pa masewera a buluu pomwe wovala mpira akuponya mpira awo akuchokera\n",
            "P-42\t-0.1275 -0.2874 -0.0949 -0.0363 -0.0589 -0.0823 -0.1439 -0.1648 -0.0336 -0.1208 -0.7323 -0.1298 -0.0382 -0.0392 -0.1622 -0.0869 -1.7645 -1.1014 -0.3917 -0.1460 -0.1343 -0.1399 -0.0789 -0.2662 -0.1325 -0.0930 -0.3065 -0.7472 -0.3266 -0.1176 -0.2793 -0.1919 -0.1653 -0.8016 -2.9927 -0.2407 -0.2996 -0.1100 -0.6712 -0.2451 -0.0594 -0.4662 -0.1938 -0.0898 -0.0592 -0.0617 -0.1320 -0.1200 -0.3180 -0.1538 -0.0498 -1.9514 -0.6834 -1.2849 -0.0403 -0.0866 -0.5060 -0.0896 -0.1136 -0.0594 -0.1333 -0.1107 -1.5936 -0.2840 -0.7694 -0.2341 -0.0929 -0.0972 -0.1155 -0.7908 -0.5637 -0.0884 -0.0542 -0.0808 -0.1424 -0.9671 -0.4054 -0.1228 -1.2320 -0.5957 -0.5029 -0.0468 -0.1607 -0.1388 -0.2655 -0.6079 -0.0844 -0.0798 -0.0975 -0.2285 -1.3368 -0.6099 -0.1688 -0.6175 -0.8292 -0.6895 -0.0734 -1.2848 -0.1196 -1.9986 -0.1118 -0.0653 -0.0351 -0.3289 -1.6294\n",
            "T-225\tmunthu atanyamula baibulo lokhala ndi chikwangwani cholembedwa kuti lapani yesu khristu adzaweruza dziko lapansi\n",
            "H-225\t-0.3758057653903961\t▁ g u l u ▁ l a ▁ a t a n y a m u l a ▁ b u l u u ▁ l o k h a l a ▁ n d i ▁ c h i k w a n g w a n i ▁ c h o l e m b e d w a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ z o k o n g o l a ▁ p a n s i\n",
            "D-225\t-0.3758057653903961\tgulu la atanyamula buluu lokhala ndi chikwangwani cholembedwa ndi chipale chofewa akugwiritsa ntchito zokongola pansi\n",
            "P-225\t-0.1126 -1.2712 -0.1086 -0.2272 -0.1046 -0.1087 -0.1246 -0.0920 -0.1823 -0.0723 -2.1475 -0.2128 -0.2059 -0.0090 -0.0980 -0.0531 -0.0792 -0.0683 -0.0915 -0.1216 -0.6488 -1.8899 -0.0504 -0.2703 -0.0591 -0.0999 -0.5107 -0.8557 -0.1653 -0.0267 -0.1549 -0.0471 -0.1221 -0.1080 -0.0493 -0.0984 -0.1022 -0.1412 -1.1454 -0.1065 -0.0434 -0.4146 -0.0540 -0.0996 -0.5901 -0.0288 -0.0560 -0.0799 -0.0400 -0.1108 -0.1299 -0.5049 -0.0884 -0.0272 -2.7661 -0.2560 -0.2311 -0.0470 -0.0409 -0.0266 -0.0237 -0.0814 -0.1607 -0.3106 -0.1580 -0.1648 -0.2260 -1.5923 -0.1191 -0.3891 -0.5693 -0.1625 -1.4389 -0.7799 -0.0857 -0.1646 -0.1305 -0.3872 -1.2189 -1.4075 -0.2370 -0.3909 -0.1702 -1.0110 -1.3308 -0.1815 -0.7417 -0.0228 -0.3652 -0.4947 -0.5042 -0.0350 -0.1280 -0.1044 -0.1468 -0.7992 -0.1005 -0.0297 -0.1031 -0.1370 -0.0418 -0.0648 -0.1284 -1.7026 -2.0236 -1.4072 -0.1498 -0.0178 -1.2533 -0.1252 -0.1633 -0.2431 -0.4587 -0.3356 -0.1607 -0.8983 -0.5047 -0.0676 -0.5918\n",
            "T-293\tanthu ambiri akhala pamatebulo amatabwa moyang anizana ndi mapiri okutidwa ndi chipale chofewa\n",
            "H-293\t-0.3728208541870117\t▁ a n t h u ▁ a m b i r i ▁ a t a k h a l a ▁ p a t e b u l o ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ n d i ▁ m a t h i r a ▁ k u t i ▁ a k u s e w e r a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-293\t-0.3728208541870117\tanthu ambiri atakhala patebulo m mphepete mwa nyanja ndi mathira kuti akusewera chipale chofewa\n",
            "P-293\t-0.1536 -1.3829 -0.6725 -0.0352 -0.1364 -0.0843 -0.1185 -0.2536 -2.8475 -0.3253 -0.0575 -0.0480 -0.0665 -0.1336 -0.1051 -0.2224 -0.1172 -0.1099 -0.0483 -0.1457 -0.0514 -0.0951 -0.1082 -0.1755 -0.1110 -3.1369 -0.1307 -0.0315 -0.0236 -0.0840 -0.0928 -0.0964 -1.3520 -0.5933 -0.5081 -0.5458 -0.0336 -0.4417 -0.2285 -1.5019 -0.1344 -0.4852 -0.0975 -0.1397 -0.1241 -0.2480 -0.0962 -0.0903 -0.0692 -0.1421 -0.0224 -0.0853 -0.1128 -0.1138 -1.2812 -0.5898 -0.0883 -0.1518 -0.2668 -0.1822 -0.1855 -1.1705 -0.6178 -0.5570 -0.6107 -0.5883 -2.3110 -0.1119 -0.3304 -0.2512 -0.0853 -0.0608 -2.0341 -0.2959 -1.4729 -0.0786 -0.6138 -0.1499 -0.2453 -0.1434 -0.3012 -0.9168 -0.1526 -0.1526 -0.8068 -0.1060 -0.0832 -0.0281 -0.1963 -0.0321 -0.1233 -0.0424 -0.1044 -0.0207 -0.0763 -0.0575 -0.1219\n",
            "T-405\tgulu la anyamata achichepere mkati mwamasewera a lacrosse mamembala awiri a timu imodzi akuthamangira kumbuyo kwa osewera awiri a timu ina\n",
            "H-405\t-0.3935701549053192\t▁ g u l u ▁ l a ▁ a n y a m a t a ▁ c h i c h e p e r e ▁ m ▁ k a t i ▁ m w a ▁ m a ▁ t s i t s i ▁ l a k e ▁ l o s e w e r a ▁ m a l a y a ▁ a m e n e ▁ a n t h u ▁ a w i r i ▁ a k u t h a m a n g i r a ▁ k u t s o g o l o ▁ k w a ▁ c h i n a c h a k e\n",
            "D-405\t-0.3935701549053192\tgulu la anyamata chichepere m kati mwa ma tsitsi lake losewera malaya amene anthu awiri akuthamangira kutsogolo kwa chinachake\n",
            "P-405\t-0.1102 -0.0984 -0.0569 -0.1209 -0.0698 -0.0931 -0.0625 -0.0897 -0.0796 -0.1098 -0.2552 -0.0270 -0.1030 -0.0699 -0.0958 -0.0664 -0.1018 -0.1112 -1.7225 -0.0957 -0.1746 -2.2105 -0.1491 -0.0616 -0.1873 -0.1656 -0.2559 -0.1100 -0.2479 -0.0885 -0.6469 -1.3040 -0.3594 -0.2179 -0.0930 -0.1462 -0.0227 -0.0944 -0.1237 -0.2409 -0.0383 -0.8350 -2.7386 -1.3094 -0.2606 -0.7916 -0.0962 -0.0816 -0.2656 -0.0707 -0.0184 -0.4614 -1.0569 -0.0761 -0.0860 -1.1876 -0.0944 -0.7583 -0.1072 -0.3984 -0.0903 -0.0389 -0.1256 -0.1385 -0.5405 -0.3010 -0.9651 -0.5664 -0.3486 -0.1052 -0.0776 -0.2358 -1.2524 -1.4733 -0.1049 -0.3073 -0.0972 -0.1449 -2.6065 -1.7672 -0.2229 -0.2512 -0.0878 -0.7713 -1.1743 -0.1139 -0.0438 -0.1034 -0.0837 -1.0260 -0.2180 -0.1079 -0.8310 -0.5126 -0.1058 -0.2824 -0.0629 -0.0334 -0.4047 -0.1349 -0.6930 -0.0894 -0.0932 -0.1740 -0.8425 -0.2248 -0.1427 -0.1416 -0.1080 -0.1037 -0.0563 -0.2448 -0.1068 -0.0925 -0.0747 -0.1430 -0.1237 -3.2685 -0.1648 -0.0530 -0.7283 -1.2214 -0.5127 -0.0675 -0.9052 -0.0880 -0.0258 -0.8561\n",
            "T-27\tosewera mpira wa basketball otsutsa amadumphira pansi kuti awongolere mpirawo pomwe wosewera mpira amawomba mluzu wake\n",
            "H-27\t-0.421769380569458\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ t a v a l a ▁ s u t i ▁ o s u n g i t s a ▁ a m a d u t s i k i r a ▁ p a n s i ▁ p a ▁ u d z u ▁ w o l e m p h i r a ▁ w o s e w e r a ▁ m p i r a ▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ m ▁ m a d z i\n",
            "D-27\t-0.421769380569458\twosewera mpira wa tavala suti osungitsa amadutsikira pansi pa udzu wolemphira wosewera mpira wosewera mpira wa m madzi\n",
            "P-27\t-0.1139 -0.5522 -0.0607 -0.0389 -0.0324 -0.0249 -0.0806 -0.0367 -0.1181 -0.1088 -0.1535 -0.2047 -0.0802 -0.0421 -0.0949 -0.1171 -0.1041 -0.2385 -0.1508 -0.4810 -0.7408 -1.2437 -0.1997 -0.0943 -0.1369 -0.1141 -0.1306 -1.0202 -0.2357 -0.8439 -0.1281 -1.9783 -0.7889 -0.8579 -0.4732 -0.7705 -0.2205 -1.2743 -0.2484 -0.1613 -0.2234 -1.3696 -0.4142 -0.1466 -1.4831 -1.2596 -0.2151 -0.3418 -0.6042 -0.9403 -0.4045 -0.2466 -0.1023 -0.2215 -0.1760 -0.1446 -0.1116 -1.1751 -0.0788 -0.1166 -0.5270 -0.3920 -1.2769 -0.7626 -1.0549 -0.0464 -0.2188 -0.0987 -1.4059 -0.0277 -0.9796 -0.2404 -1.1415 -0.8172 -0.1669 -0.7039 -0.0542 -0.0843 -0.1568 -0.3969 -0.0741 -1.9953 -0.0465 -0.0773 -0.1720 -0.0490 -0.1060 -0.1518 -1.1084 -0.2037 -0.0895 -0.0303 -0.1013 -0.1979 -0.2298 -0.1942 -0.6874 -0.0486 -0.0682 -0.1760 -0.0549 -0.1156 -0.1528 -0.4723 -1.4604 -1.1399 -0.0906 -0.0890 -0.3716 -1.3326 -0.1527 -0.1740 -0.8642 -0.9123 -0.5416 -0.5005 -0.7145 -0.1375 -0.0455 -0.6593\n",
            "T-59\tmnyamata wina wakhala pamsika akuyang ana kutsogolo mosayang ana pakati pa nsalu zokongola komanso zosindikizidwa kumbuyo kwake ndipo patsogolo pake pali mulu wa tirigu\n",
            "H-59\t-0.3505457043647766\t▁ m n y a m a t a ▁ w i n a ▁ w a k h a l a ▁ p o y a n g ▁ a n a ▁ k u t s o g o l o ▁ k w a ▁ n j a n j i ▁ a t a k h a l a ▁ k u m b u y o ▁ k o m a n s o ▁ z o z i z i r i d w a ▁ k u m b u y o ▁ k w a k e ▁ n d i p o ▁ k u t s o g o l o ▁ k w a ▁ c h i p a l e ▁ c h o m w e\n",
            "D-59\t-0.3505457043647766\tmnyamata wina wakhala poyang ana kutsogolo kwa njanji atakhala kumbuyo komanso zoziziridwa kumbuyo kwake ndipo kutsogolo kwa chipale chomwe\n",
            "P-59\t-0.1084 -0.0741 -0.0337 -0.0600 -0.1170 -0.0454 -0.0879 -0.0142 -0.1044 -0.1011 -0.0624 -0.0833 -0.0568 -0.1332 -0.1019 -0.0274 -0.3971 -0.5966 -0.0593 -0.1109 -0.0929 -0.1008 -0.1230 -1.8616 -1.5332 -0.3799 -0.1280 -0.1995 -0.3997 -0.2247 -0.0990 -0.0472 -0.1567 -0.0767 -1.5247 -1.4690 -0.3014 -0.0163 -0.1015 -0.0571 -0.0630 -0.0524 -0.0532 -0.1384 -0.6003 -0.7079 -0.1263 -0.0706 -1.2694 -0.4945 -0.1879 -0.3052 -0.4179 -0.2434 -0.0927 -0.7840 -0.3882 -0.1430 -0.6199 -0.0227 -0.1828 -0.0477 -0.1277 -0.1099 -1.0533 -0.1885 -0.3302 -1.0168 -0.2027 -0.1167 -0.1107 -0.1041 -0.3807 -1.9631 -0.1778 -0.0793 -0.0321 -0.0908 -0.0278 -0.0809 -0.1750 -1.9308 -1.3036 -0.6402 -0.7105 -0.0337 -0.5693 -0.1232 -1.5839 -0.2112 -0.0963 -0.1317 -1.7920 -0.4141 -0.2939 -0.0223 -0.2713 -0.1791 -0.0435 -0.0920 -0.3217 -0.0668 -0.1253 -0.2208 -0.0330 -0.1361 -0.3043 -0.0610 -0.1085 -0.0906 -0.0533 -0.0990 -1.5379 -0.2000 -0.2082 -1.4022 -0.0199 -0.0100 -0.0855 -0.0459 -0.0696 -0.1684 -0.0253 -0.0734 -0.1038 -0.2528 -0.7866 -0.1070 -0.0538 -2.1898 -0.3709 -0.1265 -0.3699 -0.4163 -0.1646 -0.0866 -0.0385 -2.5164 -0.1050 -0.0519 -1.1299\n",
            "T-370\tbambo wina wovala malaya apinki ndi achikasu komanso chomangira chabuluu kumutu ali ndi mpikisano wamasewera a tenisi ali chilili chotsegula kukamwa\n",
            "H-370\t-0.31439009308815\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ n d i ▁ c h i p a t a l a ▁ c h a c h i k u l u ▁ c h o m a n s o ▁ c h a ▁ b u l u u ▁ n d i ▁ m u n t h u ▁ a l i ▁ n d i ▁ c h i s a n u ▁ p a m a s e w e r a ▁ o c h i t i r a ▁ c h o k h a l a ▁ n d i ▁ c h o k o n g o l a\n",
            "D-370\t-0.31439009308815\tbambo wina wovala malaya apinki ndi chipatala chachikulu chomanso cha buluu ndi munthu ali ndi chisanu pamasewera ochitira chokhala ndi chokongola\n",
            "P-370\t-0.1183 -0.0286 -0.1130 -0.0297 -0.0561 -0.0536 -0.0971 -0.0717 -0.0963 -0.0810 -0.1265 -0.1121 -0.1011 -0.0485 -0.0588 -0.1173 -0.1006 -0.1217 -0.0969 -0.0581 -0.1081 -0.0624 -0.1327 -0.0433 -0.1229 -0.0860 -0.5198 -0.6721 -0.1640 -0.0151 -0.0344 -0.0617 -0.1175 -0.0328 -0.1138 -0.0934 -0.1097 -0.6952 -0.0524 -0.0746 -0.8670 -0.2547 -1.3735 -0.1249 -0.4640 -0.5075 -0.1747 -0.0346 -0.0406 -1.4197 -1.2105 -0.0890 -0.0416 -0.0132 -0.3261 -1.4102 -0.1138 -0.1590 -0.4190 -0.0709 -0.0399 -1.2171 -0.3036 -0.0221 -0.2444 -0.0759 -0.0940 -0.2464 -0.0544 -0.4701 -0.4646 -1.3604 -0.6702 -0.1062 -0.0612 -0.0278 -0.1039 -0.1866 -0.1165 -0.1185 -0.1805 -1.0640 -2.1133 -0.3574 -0.0306 -0.0519 -0.0797 -0.1244 -0.9539 -0.0154 -0.0745 -0.1151 -0.0845 -0.0732 -0.1340 -0.1566 -1.7232 -0.1873 -0.1088 -0.8626 -0.1620 -0.0211 -0.0260 -0.1546 -0.6585 -0.2213 -0.2135 -0.2405 -0.1734 -0.1745 -0.0300 -0.0534 -0.0273 -0.2348 -0.1235 -1.3600 -1.5616 -0.0828 -0.6090 -0.1476 -0.0612 -0.4883 -0.3433 -0.1422 -0.4555 -0.0564 -0.9289 -0.7813 -0.3919 -1.1627 -0.0801 -0.5862 -0.1428 -1.1369 -0.0844 -0.0791 -0.1128 -0.2167 -0.0867 -0.4262 -0.8223 -1.1546 -0.7201 -0.2079 -0.1156 -0.0445 -0.3077 -0.5292\n",
            "T-114\tagalu awiri akuda pa nthaka yokutidwa ndi chipale chofewa pansi pakuwoneka buluu kumbuyo galu mmodzi akudumpha ndi mapazi pansi\n",
            "H-114\t-0.38933730125427246\t▁ a n y a m a t a ▁ a w i r i ▁ a k u d a ▁ a t a k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ c h o p a n s i k a ▁ p a m e n e ▁ g u l u ▁ l a ▁ a n t h u ▁ l i k u m b u y o ▁ z i d a ▁ p a n s i ▁ p a n s i\n",
            "D-114\t-0.38933730125427246\tanyamata awiri akuda atakhala ndi chipale chofewa ndi chopansika pamene gulu la anthu likumbuyo zida pansi pansi\n",
            "P-114\t-0.1153 -0.0703 -0.7184 -2.6127 -0.1154 -0.1042 -0.1017 -0.0896 -0.1011 -0.1126 -0.1324 -0.0342 -0.1386 -0.0382 -0.1177 -0.1089 -0.1294 -0.0481 -0.1027 -0.0818 -0.0925 -0.1262 -0.6084 -0.3757 -0.1123 -0.0485 -0.0819 -0.1297 -0.0633 -0.1166 -0.0949 -0.4920 -0.1008 -0.1867 -0.3036 -2.4606 -0.1346 -0.4077 -1.0198 -0.6247 -1.6065 -0.0391 -0.0670 -0.2547 -0.1087 -0.0215 -0.2910 -0.0560 -0.0233 -0.1013 -0.1229 -0.9424 -0.0720 -0.1186 -0.9164 -0.3738 -0.0905 -0.0767 -1.1758 -0.3347 -0.7106 -0.4274 -0.1775 -0.8870 -0.0902 -0.1728 -1.0204 -0.1343 -0.5020 -0.5132 -0.0559 -0.0708 -0.0807 -1.4503 -0.1443 -0.0671 -0.0422 -0.0820 -0.1049 -1.0342 -0.1811 -1.6762 -1.2078 -0.3661 -0.0536 -0.0525 -0.0875 -0.6248 -0.4314 -0.3000 -0.0628 -1.4205 -0.6405 -0.2394 -0.2289 -0.0625 -0.1339 -2.0081 -0.1229 -0.1593 -0.2681 -0.1306 -1.3980 -0.1106 -0.6227 -0.2093 -0.0474 -0.2037 -0.0734 -0.1156 -2.4611 -0.2848 -0.0351 -1.1502\n",
            "T-124\tmwamuna wina wovala malaya obiriwira ndi bandana yofiira ataphimba theka lakumtunda la nkhope yake wagona muudzu pamene njiwa ikuyenda pambali pake\n",
            "H-124\t-0.41562581062316895\t▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o b i r i w i r a ▁ n d i ▁ b a n d a n a ▁ y o f i i r a ▁ a t a k h a l a ▁ p a t e b u l o ▁ m ▁ m u n t h u ▁ a k u d a ▁ a t e n g a ▁ k u t e m b e n u z i ▁ k w a ▁ m a w o ▁ k w a m b i r i ▁ p a ▁ n j i n g a ▁ y a k e ▁ p a m b a l i ▁ p a k e\n",
            "D-124\t-0.41562581062316895\tmwamuna wina wovala malaya obiriwira ndi bandana yofiira atakhala patebulo m munthu akuda atenga kutembenuzi kwa mawo kwambiri pa njinga yake pambali pake\n",
            "P-124\t-0.1090 -0.1641 -0.0171 -0.0949 -0.0460 -0.0624 -0.1188 -0.1100 -0.1056 -0.1393 -0.0555 -0.0994 -0.1199 -0.1057 -0.0753 -0.0532 -0.0773 -0.1241 -0.1058 -0.1226 -0.1024 -0.0611 -0.1224 -0.0301 -0.1276 -0.0785 -0.1225 -0.0811 -0.0702 -0.6995 -0.0418 -0.0352 -0.0806 -0.0201 -0.0758 -0.0434 -0.1103 -0.1246 -0.0435 -0.1168 -0.0734 -0.1884 -2.1970 -0.1760 -0.0724 -0.2584 -0.1800 -0.0567 -0.7405 -0.1346 -1.3694 -0.0542 -1.3726 -0.0437 -0.2938 -0.0339 -0.1728 -0.0999 -0.2279 -0.1516 -0.0920 -1.9982 -0.3735 -1.0693 -0.0936 -0.1553 -0.0908 -0.1803 -0.1229 -1.7076 -0.0446 -0.7745 -0.0763 -0.2082 -0.1674 -0.0800 -1.6846 -1.4316 -0.4947 -0.6885 -0.1491 -0.4962 -0.0394 -0.0973 -0.0955 -0.9549 -0.7467 -0.6206 -1.0110 -0.1158 -0.0954 -0.7862 -0.7410 -1.1883 -0.6070 -1.3247 -0.3772 -0.1092 -0.8242 -0.6689 -0.5012 -1.8852 -0.4705 -0.0304 -0.4039 -0.5390 -0.5053 -0.8594 -0.6071 -1.6502 -0.9227 -0.2053 -0.1079 -0.4485 -0.2491 -0.5156 -0.7522 -0.3567 -0.0746 -1.6370 -1.0654 -0.2197 -1.3934 -1.0173 -0.9520 -0.0541 -0.0655 -0.1371 -0.3817 -0.1058 -0.5230 -1.9357 -0.4783 -0.1411 -0.2175 -0.2205 -0.0725 -0.1573 -0.1864 -0.2230 -0.8217 -0.6371 -0.9381 -0.0922 -0.1095 -0.4713 -1.9265 -0.0542 -0.0708 -0.0530 -0.6070 -0.0801 -0.1094 -1.6801 -0.2391 -0.1059\n",
            "T-108\tmayi wina wachikulire wagwira mwamphamvu galu wamkulu woyera atakhala pampando waukulu wofiira kutsogolo kwa zipangizo zina zamagetsi\n",
            "H-108\t-0.293697327375412\t▁ m a y i ▁ w i n a ▁ w a c h i k u l i r e ▁ w i n a ▁ m ▁ m w a m b a ▁ a k u d u m p h a ▁ m ▁ m u n t h u ▁ w o y e r a ▁ a t a k h a l a ▁ p a m p a n d o ▁ w a u k u l u ▁ w o f i i r a ▁ n d i ▁ z o k o n g o l a ▁ n d i ▁ z i n a ▁ z o s i y a n a s i y a n a\n",
            "D-108\t-0.293697327375412\tmayi wina wachikulire wina m mwamba akudumpha m munthu woyera atakhala pampando waukulu wofiira ndi zokongola ndi zina zosiyanasiyana\n",
            "P-108\t-0.1085 -0.0698 -0.0822 -0.0241 -0.0718 -0.0854 -0.0323 -0.0674 -0.0531 -0.1321 -0.1123 -0.0535 -0.1033 -0.2603 -0.0624 -0.0754 -0.0455 -0.0926 -0.0516 -0.0603 -0.0490 -0.0288 -0.0911 -0.1136 -3.1624 -0.2638 -0.1043 -0.1253 -0.5155 -0.7458 -0.2462 -0.8205 -0.1242 -0.2078 -0.4859 -0.1385 -0.1057 -1.9158 -0.5994 -0.1530 -1.2926 -0.0678 -0.0555 -0.0515 -0.0303 -0.1133 -0.1368 -0.4194 -0.6428 -0.7658 -2.2961 -0.0716 -1.0724 -0.0314 -0.1359 -0.1010 -0.0888 -0.0843 -0.0931 -0.0774 -0.0756 -0.1107 -0.1153 -0.1241 -0.0818 -0.1141 -0.0703 -0.0823 -0.1177 -0.0634 -0.1284 -0.1001 -0.0393 -0.1198 -0.1869 -0.2109 -0.2245 -0.1332 -0.2477 -0.0269 -0.0998 -0.0394 -0.3186 -1.0008 -0.7690 -0.0765 -0.0451 -0.1167 -0.0949 -1.2407 -0.7471 -0.2736 -0.0785 -0.0759 -0.0482 -0.1688 -0.1197 -0.1702 -0.0687 -0.0794 -0.3729 -0.5702 -0.1872 -0.1303 -0.6212 -0.1341 -1.7307 -0.1229 -0.1494 -0.6019 -0.2108 -1.3136 -0.1666 -0.0853 -0.1147 -0.0357 -0.2844 -0.2153 -0.1184 -0.7267 -0.0244 -1.3179 -0.5200 -0.5966 -0.1985 -0.1719 -0.0571 -0.1003 -0.4267 -0.0420 -0.4853 -0.1910 -0.0383 -0.0915 -0.2221\n",
            "T-267\tsitima yapamadzi yaikulu imadutsa m mphepete mwa nyanja kumene owotchera dzuwa amakhala pansi pa maambulera achikasu\n",
            "H-267\t-0.39055439829826355\t▁ m t s i k a n a ▁ p a ▁ m a d z i ▁ y a i k u l u ▁ i n a ▁ l i m a d u t s a ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ k u m e n y a ▁ c h i w o t c h e r a ▁ m k a z i ▁ a m a k h a l a ▁ p a m p a n d o ▁ m ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-267\t-0.39055439829826355\tmtsikana pa madzi yaikulu ina limadutsa m mphepete mwa nyanja kumenya chiwotchera mkazi amakhala pampando m chipale chofewa\n",
            "P-267\t-0.1224 -0.2545 -0.0457 -0.1691 -0.0445 -0.0805 -0.2141 -0.2766 -0.1242 -0.1234 -1.1293 -0.1185 -2.0541 -0.0232 -0.0622 -0.4752 -0.0650 -0.0484 -0.0806 -2.2915 -0.1339 -1.5597 -0.2023 -0.0889 -0.0298 -0.0403 -0.0992 -1.5405 -0.5463 -0.1187 -0.3125 -1.9340 -0.0667 -0.7731 -0.5929 -0.4028 -0.9977 -0.0903 -0.2330 -0.1670 -0.1222 -0.3227 -1.2939 -0.1093 -0.0201 -0.0700 -0.0551 -0.0377 -0.0519 -0.0053 -0.0645 -0.0755 -0.1351 -0.0184 -0.1799 -0.1100 -0.0470 -0.0782 -0.1160 -0.0167 -0.0071 -0.1046 -0.1155 -0.7390 -0.1221 -0.6766 -0.2150 -0.7972 -0.7405 -0.5173 -0.1057 -1.4632 -0.0651 -0.2224 -1.7158 -0.9075 -0.5333 -0.6755 -0.0607 -0.5680 -0.1424 -0.8069 -0.1422 -1.3736 -0.8869 -0.1525 -0.2458 -0.0477 -0.0940 -1.1456 -1.0765 -0.2103 -0.0760 -0.0771 -0.1210 -0.2455 -0.1196 -0.1024 -0.8438 -0.1156 -0.6171 -0.7489 -0.2661 -0.5005 -0.3285 -0.0958 -0.1727 -0.7016 -0.5828 -2.2331 -0.1132 -0.1209 -0.4572 -0.1526 -0.2401 -0.1369 -0.0806 -0.2339 -0.0935 -0.6613 -0.7815 -0.0911 -0.0563 -0.1046 -0.2091\n",
            "T-87\tgulu la azimayi azaka zapakati limayima pamalo okwerera basi awiri mwa amayiwa akukonzekera kukwera basi\n",
            "H-87\t-0.3237783908843994\t▁ g u l u ▁ l a ▁ a z i m a y i ▁ a t a z a k a ▁ z a p a k a t i ▁ n d i ▁ m a y i ▁ w i n a ▁ p a m a l o ▁ o k w e r a ▁ p a m a s i t e p e ▁ a ▁ m a y i ▁ w i n a ▁ a k u k o n z e k e r a ▁ k u k o n z e k e r a\n",
            "D-87\t-0.3237783908843994\tgulu la azimayi atazaka zapakati ndi mayi wina pamalo okwera pamasitepe a mayi wina akukonzekera kukonzekera\n",
            "P-87\t-0.1057 -0.1014 -0.0323 -0.1119 -0.0570 -0.0993 -0.0346 -0.1163 -0.1659 -0.1535 -0.0786 -0.0565 -0.5713 -0.0792 -0.1987 -0.3054 -0.0915 -1.0982 -1.0843 -0.7187 -0.6684 -0.2007 -0.0911 -0.6809 -0.1001 -0.2427 -0.1237 -1.2406 -0.1606 -0.1944 -0.1289 -0.0282 -0.0475 -0.1209 -1.8929 -0.5525 -0.0949 -0.2197 -0.2051 -0.1339 -1.0868 -0.1321 -0.0856 -0.5227 -0.2089 -0.0719 -0.1158 -0.1283 -0.9284 -0.1229 -0.1995 -0.1190 -0.0797 -0.0603 -0.0888 -0.2625 -1.2610 -0.1622 -0.0854 -0.0405 -0.6307 -0.1429 -0.3539 -0.1530 -3.1656 -0.0640 -0.2010 -0.0873 -0.0616 -0.9528 -0.4891 -0.2233 -0.1196 -0.1870 -0.2005 -0.3095 -0.0816 -0.9144 -0.1431 -0.1486 -0.2814 -0.0519 -0.2547 -0.1858 -0.1444 -0.1193 -0.1247 -0.1412 -0.1932 -1.0137 -0.0926 -0.0059 -0.0244 -0.0181 -0.0376 -0.1222 -0.0776 -0.1858 -0.2214 -0.1166 -1.4442 -1.4587 -0.2654 -0.0461 -0.0397 -0.1657 -0.0284 -0.2227 -0.0920 -1.6602\n",
            "T-117\tmayi wina wovala mathalauza abuluu komanso pamwamba pabuluu akuyang ana pansi pa dzanja lake ataima pafupi ndi galimoto yakuda yotuwa ndipo atazunguliridwa ndi dothi\n",
            "H-117\t-0.3095712959766388\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ m a t h a l a u z a ▁ a b u l u u ▁ k o m a n s o ▁ p a m w a m b a ▁ w i n a ▁ a k u y a n g ▁ a n a ▁ p a n s i ▁ a t a k h a l a ▁ p a n j a ▁ p a f u p i ▁ n d i ▁ g a l i m o t o ▁ y a k u d a ▁ y a i k u l u ▁ n d i ▁ t h u m b a ▁ l a c h i t h u n z i\n",
            "D-117\t-0.3095712959766388\tmayi wina wovala mathalauza abuluu komanso pamwamba wina akuyang ana pansi atakhala panja pafupi ndi galimoto yakuda yaikulu ndi thumba lachithunzi\n",
            "P-117\t-0.1106 -0.0601 -0.0761 -0.0475 -0.0959 -0.0807 -0.0892 -0.0976 -0.0668 -0.1295 -0.0982 -0.0552 -0.0634 -0.1174 -0.1145 -0.0795 -0.1134 -0.0969 -0.1575 -0.1088 -0.1482 -0.0189 -0.1126 -0.0785 -0.1082 -0.0402 -0.0476 -0.0737 -0.1035 -1.1259 -2.0915 -0.0978 -0.1121 -0.0858 -0.0707 -0.1102 -0.3494 -0.4039 -0.0345 -0.0921 -0.0528 -0.0300 -0.0308 -0.0801 -2.4079 -0.1136 -0.4107 -0.0375 -0.1109 -0.0381 -0.0566 -0.1777 -0.0798 -2.1261 -1.0330 -0.0536 -0.0894 -0.1052 -0.8534 -0.1097 -0.0762 -0.0825 -0.1903 -0.0604 -0.1459 -0.0937 -0.0881 -0.0635 -0.1750 -0.1091 -0.6705 -0.1770 -0.0848 -0.3341 -0.0429 -0.0800 -2.0845 -0.2637 -0.1483 -1.6671 -0.3090 -0.1222 -0.0688 -0.1296 -0.0931 -0.1806 -0.1148 -2.0374 -0.1012 -0.1325 -0.1827 -0.4789 -0.1583 -0.1125 -0.0886 -0.0400 -0.0544 -0.0824 -0.0826 -0.0663 -0.1225 -0.1156 -0.3869 -0.0663 -0.0566 -0.0592 -0.0157 -0.0238 -0.0145 -0.0431 -0.0906 -0.0304 -0.2062 -1.0341 -0.1291 -0.0593 -0.1038 -0.0946 -0.9595 -0.5042 -1.1304 -1.6016 -0.1692 -0.0379 -0.1087 -0.1054 -0.3314 -0.0608 -0.0842 -0.2861 -1.6723 -0.1793 -0.1970 -0.8284 -0.0425 -0.7662 -0.0940 -0.0586 -0.1580 -2.0021 -0.0786 -0.0540 -0.7359 -2.5336 -0.0385 -0.0760 -0.2521 -0.1933 -1.6991\n",
            "T-321\tmayi wina wokhwima mwauzimu amanyamula mavwende awiri imodzi pa dzanja lililonse pamene akuyenda kudutsa galimoto yoyera\n",
            "H-321\t-0.33764681220054626\t▁ m a y i ▁ w i n a ▁ w o k w e r a ▁ m ▁ m o d z i ▁ a n y a m u l a ▁ m p h e p e t e ▁ m w a ▁ n y u m b a ▁ z i d a ▁ z a n j a ▁ l i l i ▁ p a n s i ▁ p a m e n e ▁ a k u y e n d a ▁ k u t s o g o l o ▁ k w a ▁ g a l i m o t o\n",
            "D-321\t-0.33764681220054626\tmayi wina wokwera m modzi anyamula mphepete mwa nyumba zida zanja lili pansi pamene akuyenda kutsogolo kwa galimoto\n",
            "P-321\t-0.1130 -0.0753 -0.0839 -0.0699 -0.0866 -0.0885 -0.0431 -0.0672 -0.0733 -0.1258 -0.0995 -0.2349 -0.8167 -0.0969 -0.2659 -0.5102 -0.3163 -0.0923 -0.1859 -0.1135 -1.0114 -0.0915 -1.6848 -0.0267 -0.0172 -0.0578 -0.0941 -0.2886 -0.7728 -0.6000 -0.0988 -0.3575 -0.8029 -0.0384 -0.1112 -0.1045 -0.4096 -1.7091 -0.3844 -0.0402 -0.3955 -0.0656 -0.0230 -0.0521 -0.0649 -0.1992 -0.0207 -0.1201 -0.1435 -0.9114 -0.2773 -1.0429 -0.4802 -0.0981 -0.0919 -0.1586 -1.1859 -0.5145 -1.4507 -0.1169 -0.1019 -0.6453 -0.2186 -1.4305 -0.0503 -0.1043 -0.1131 -0.2541 -0.1481 -0.7114 -0.1590 -0.1329 -0.4188 -0.1353 -1.4531 -0.1158 -0.4519 -0.0575 -0.1497 -0.1558 -0.6991 -0.0734 -0.0300 -0.0394 -0.0739 -1.6879 -0.5944 -0.0942 -0.1622 -0.3131 -0.1002 -0.0686 -0.0772 -0.1021 -0.3620 -0.0743 -1.8558 -0.5680 -0.0774 -0.0279 -0.0872 -0.0357 -0.4242 -0.2181 -0.3192 -0.1021 -0.7129 -0.2492 -2.0317 -0.1516 -0.0660 -0.0520 -0.0339 -0.0344 -0.0260 -0.0398 -1.1593\n",
            "T-351\tkamwana kakang ono ka jekete yofiira akuwonetsa zoseweretsa zake pomwe mwamuna wamkulu wovala malaya oyera akuwoneka akuyendetsa galimotoyo\n",
            "H-351\t-0.2873719036579132\t▁ k a m w a n a ▁ k a k a n g ▁ o n o ▁ k a ▁ j e k e t e ▁ y o f i i r a ▁ a k u w o n e t s a ▁ z o w e t s e r e t s a ▁ z a k e ▁ p o m w e ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u w o n e k a ▁ k u m b u y o ▁ k w a k e\n",
            "D-351\t-0.2873719036579132\tkamwana kakang ono ka jekete yofiira akuwonetsa zowetseretsa zake pomwe mwamuna wina wovala malaya oyera akuwoneka kumbuyo kwake\n",
            "P-351\t-0.1104 -0.2193 -0.2048 -0.0293 -0.0990 -0.1449 -0.1580 -0.1415 -0.1054 -0.1615 -0.0805 -1.2169 -0.0747 -0.2060 -0.0284 -0.0720 -0.0673 -0.0812 -0.0538 -0.1082 -0.2102 -0.1921 -0.1140 -1.4135 -0.1303 -0.5376 -0.1046 -0.0116 -0.2250 -0.0857 -1.4609 -0.1999 -0.0862 -0.0859 -0.3819 -0.0424 -0.1336 -0.1233 -0.4835 -0.0517 -0.1261 -0.1629 -0.1141 -0.1419 -0.1218 -0.0458 -0.0307 -0.5708 -0.0809 -0.0421 -0.3347 -1.0494 -0.1625 -0.1116 -0.0723 -0.5105 -1.4432 -0.3415 -1.2974 -0.0695 -0.1307 -0.1172 -0.4464 -0.1484 -0.8051 -0.2661 -0.0785 -0.4694 -0.4715 -0.0467 -0.1064 -0.0647 -0.0865 -0.4184 -1.7865 -0.2350 -0.0372 -0.0996 -0.0476 -0.0941 -0.1166 -0.0502 -0.9443 -0.0920 -0.0744 -0.1272 -0.1285 -1.0354 -0.0512 -0.1088 -0.0844 -0.1352 -0.1308 -0.1765 -0.1246 -0.0676 -0.2137 -0.0488 -0.1076 -0.0892 -0.0772 -0.0953 -0.0869 -0.0931 -0.0899 -0.1069 -0.3158 -0.0590 -0.1352 -0.0956 -0.5836 -0.0549 -0.1523 -0.0614 -0.0991 -0.0818 -0.4820 -0.0778 -2.5961 -0.9472 -1.2478 -0.0881 -0.1952 -0.1747 -0.6435 -0.3799 -0.1657 -0.4161 -0.0924 -1.5337\n",
            "T-152\tmnyamata watsitsi labulauni atavala zovala zosewerera akuthamanga mwachangu ngati mpira wawung ono wabuluu woyera ndi wofiira uli paudzu kumbuyo kwake\n",
            "H-152\t-0.3018728792667389\t▁ m n y a m a t a ▁ w o v a l a ▁ t ▁ s h i r t ▁ y a b u l a u n i ▁ a t a v a l a ▁ z o v a l a ▁ z o s e w e r a ▁ a k u t h a m a n g a ▁ m ▁ m w a m b a ▁ n d i ▁ m t s i k a n a ▁ w a m n g ▁ o n o ▁ w a b u l u u ▁ w a i m a ▁ p a f u p i ▁ n d i ▁ w o y e r a ▁ k u m b u y o ▁ k w a k e\n",
            "D-152\t-0.3018728792667389\tmnyamata wovala t shirt yabulauni atavala zovala zosewera akuthamanga m mwamba ndi mtsikana wamng ono wabuluu waima pafupi ndi woyera kumbuyo kwake\n",
            "P-152\t-0.1068 -0.0457 -0.7053 -0.1293 -0.0998 -0.0542 -0.0894 -0.0314 -0.1021 -0.1054 -0.0441 -0.8240 -0.4229 -0.1215 -0.1303 -0.1133 -0.0974 -1.0524 -0.3111 -0.0171 -0.3891 -0.3115 -0.0257 -0.0295 -0.2140 -0.3656 -0.0902 -0.7531 -0.1126 -0.0591 -0.4877 -0.0350 -0.0390 -0.0969 -0.0701 -1.7068 -0.1213 -0.0927 -0.0412 -0.0992 -0.0956 -0.1088 -0.1191 -0.1287 -0.0269 -1.0347 -0.0755 -0.0779 -0.1159 -0.1179 -0.0234 -0.0510 -1.9046 -0.1708 -0.0537 -0.0913 -0.1067 -0.0975 -0.1170 -0.2283 -0.2099 -0.1052 -0.2761 -0.0737 -0.0965 -0.0325 -0.1067 -0.1044 -0.0321 -0.1336 -0.0859 -0.1000 -0.4720 -1.2699 -1.0501 -0.1190 -0.1204 -0.0503 -0.1165 -0.0964 -1.9093 -0.4471 -0.1012 -0.1786 -0.2062 -0.8586 -1.0477 -0.0688 -1.3590 -0.1493 -0.1247 -0.1290 -0.1565 -0.0057 -0.2038 -1.6478 -0.8718 -0.0832 -0.1711 -0.0393 -0.0726 -0.0325 -0.1398 -0.1397 -0.5782 -2.3437 -0.1059 -0.1253 -0.3637 -0.0779 -0.1097 -0.6227 -1.2453 -0.1552 -0.1586 -0.3501 -0.0696 -1.2695 -0.1369 -0.0557 -0.0682 -0.2458 -0.0664 -0.0886 -0.0631 -0.0581 -0.1396 -0.1287 -1.1634 -0.5133 -0.0541 -0.1131 -0.0372 -0.1018 -0.1255 -1.7827 -0.2318 -0.5236 -0.0434 -0.0462 -0.0620 -0.0529 -0.1520 -0.2456 -0.1406 -0.1155 -0.9735 -0.4079 -0.1833\n",
            "T-311\tmtsikana wina yemwe ali ndi chipewa chakuda ndi jekete yofiira ndi yakuda akukwera pa mpira wofiira lalanje womwe umagwirizanitsidwa ndi chingwe cha buluu\n",
            "H-311\t-0.29966795444488525\t▁ m t s i k a n a ▁ w i n a ▁ y e m w e ▁ a l i ▁ n d i ▁ c h i p e w a ▁ c h a k u d i k i r i r a ▁ n d i ▁ j e k e t e ▁ y a k u d a ▁ a k u k w e r a ▁ p a f u p i ▁ n d i ▁ l a l o n j e ▁ l o m w e ▁ l i l i ▁ n d i ▁ m t s a m i t s a ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a\n",
            "D-311\t-0.29966795444488525\tmtsikana wina yemwe ali ndi chipewa chakudikirira ndi jekete yakuda akukwera pafupi ndi lalonje lomwe lili ndi mtsamitsa m mphepete mwa nyanja\n",
            "P-311\t-0.1153 -0.3950 -0.1272 -0.0282 -0.0601 -0.0307 -0.1116 -0.0919 -0.1224 -0.1063 -0.2340 -0.0703 -0.1237 -0.1092 -0.1369 -0.2722 -0.0184 -0.0338 -0.0373 -0.0860 -0.0806 -0.0766 -0.0162 -0.1262 -0.0974 -0.0221 -0.0948 -0.1711 -0.2065 -0.1960 -0.1150 -0.1045 -0.0915 -1.8594 -0.2207 -0.1077 -0.1233 -0.0543 -0.0652 -0.2231 -0.4915 -0.1505 -0.0309 -1.2006 -0.0951 -0.0825 -0.0691 -0.2151 -0.0713 -0.0885 -0.1340 -0.1947 -0.3160 -0.1331 -0.1258 -1.1737 -0.4311 -0.2180 -0.0868 -0.0557 -0.1249 -0.0786 -0.1452 -0.1283 -0.2238 -0.0802 -0.0378 -0.1307 -0.1230 -0.3161 -0.0850 -0.1679 -0.3604 -0.1370 -0.1119 -0.0438 -0.1134 -0.1077 -0.8031 -0.1216 -0.8839 -0.5197 -0.0409 -0.0539 -0.0920 -0.2323 -0.0644 -0.1145 -0.1026 -0.3748 -0.6882 -0.0788 -0.6509 -0.5689 -1.1718 -0.0957 -0.1195 -0.3245 -1.4681 -0.3292 -0.0118 -0.1185 -0.0822 -0.5760 -0.1863 -0.8059 -0.0862 -0.1140 -0.7007 -0.1598 -0.0956 -0.1645 -0.8761 -1.8872 -0.0225 -0.2839 -0.3025 -0.3479 -1.2029 -0.4343 -0.1792 -0.1620 -0.9242 -0.5330 -2.3817 -1.1142 -0.0562 -0.5881 -0.3231 -0.2619 -0.0091 -0.1894 -0.1564 -0.3865 -0.4195 -0.1283 -0.1799 -2.0828 -0.5709 -0.3638 -0.1522 -0.0268 -0.0781 -0.2843\n",
            " 23% 3/13 [00:09<00:29,  2.94s/it, wps=746]T-133\tana anayi avala ngati zidole ndi ovina pa siteji pamene ana ena awiri ovala ngati anthu ochita zisudzo amaimitsidwa zingwe\n",
            "H-133\t-0.37815144658088684\t▁ a n a ▁ a n a y i ▁ o v a l a ▁ m a ▁ j i n z i ▁ o l i m b i d w a ▁ n d i ▁ m a s i k e t i ▁ p a m e n e ▁ a n a ▁ e n a ▁ a w i r i ▁ o v a l a ▁ j e k e t e ▁ l a m t u n d u ▁ w o c h i t a ▁ z i t h u n z i ▁ a m a y i m i t s i d w a ▁ z i n g w e\n",
            "D-133\t-0.37815144658088684\tana anayi ovala ma jinzi olimbidwa ndi masiketi pamene ana ena awiri ovala jekete lamtundu wochita zithunzi amayimitsidwa zingwe\n",
            "P-133\t-0.1202 -0.1525 -0.0968 -0.7753 -0.0983 -0.1055 -0.0785 -0.2814 -0.0446 -0.0725 -0.1094 -0.1749 -0.3219 -0.1183 -0.1052 -0.1335 -0.1067 -0.2186 -0.7793 -0.9178 -0.3474 -0.7205 -0.6847 -0.2479 -0.0590 -0.0971 -1.8397 -1.1624 -0.0742 -0.3476 -0.1183 -0.5775 -0.7680 -0.0778 -0.1606 -0.1557 -0.8193 -0.1052 -0.0616 -0.2308 -0.2866 -0.8214 -2.2312 -0.6096 -1.4566 -0.0353 -0.1940 -0.0365 -0.0951 -1.1095 -0.1339 -0.4501 -0.0598 -0.0335 -0.0260 -0.0922 -0.5138 -0.1262 -0.2624 -0.4147 -1.4428 -0.0730 -0.0930 -0.1010 -0.2268 -0.0815 -0.2640 -0.0489 -0.1083 -0.0857 -0.2848 -0.1462 -0.1318 -0.1135 -0.1274 -0.0897 -1.6840 -0.4367 -0.6590 -0.1552 -0.0084 -0.1233 -0.0840 -0.2935 -0.3777 -2.1367 -0.5590 -0.2135 -0.0699 -0.1380 -1.8944 -0.1163 -0.1448 -0.3436 -0.8547 -0.0362 -0.0649 -0.0693 -0.3793 -0.0778 -0.0607 -0.0984 -1.7093 -1.0786 -0.0392 -0.0635 -0.0187 -0.0561 -0.1421 -0.8106 -0.2363 -0.1207 -1.1992 -0.7027 -1.4396 -0.2174 -0.7732 -0.1966 -0.1935 -0.1913 -0.0358 -0.1076 -0.3089 -0.4258 -0.1545 -0.7287 -0.8475 -0.1461 -0.0584 -0.2054\n",
            "T-223\tgulu la anthu anayi likuyang ana pamene mwamuna wina wovala malaya otuwa akugwira chingwe cha trapeze chomwe chili panthambi yamtengo\n",
            "H-223\t-0.2616780698299408\t▁ g a l u ▁ a t a t u ▁ a n a y i ▁ a l i ▁ n d i ▁ k u y a n g ▁ a n a ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o t u w a ▁ a k u g w i r a ▁ c h i t h u n z i ▁ c h o m w e ▁ c h i l i ▁ p a m t e n g o ▁ p a m t e n g o\n",
            "D-223\t-0.2616780698299408\tgalu atatu anayi ali ndi kuyang ana pamene mwamuna wina wovala malaya otuwa akugwira chithunzi chomwe chili pamtengo pamtengo\n",
            "P-223\t-0.1153 -0.5842 -0.1144 -0.1645 -0.3443 -0.1042 -0.2340 -2.6848 -0.2253 -0.9323 -0.0568 -0.0960 -0.3033 -0.5070 -0.2197 -0.0596 -0.0689 -0.1040 -1.3456 -0.5855 -0.1267 -0.1317 -0.2594 -0.2195 -0.0814 -0.2423 -0.8853 -0.2772 -0.3187 -0.0997 -0.0553 -0.7709 -0.0857 -0.1340 -0.0550 -0.1409 -0.1079 -0.7369 -0.1412 -0.2107 -0.0856 -0.1861 -0.0504 -0.1084 -0.2747 -0.1695 -0.1232 -0.0459 -0.0582 -0.0488 -0.1105 -0.1307 -0.0137 -0.1027 -0.0723 -0.1111 -0.1363 -0.0916 -0.0951 -0.0443 -0.1210 -0.1042 -0.1275 -0.1075 -0.0914 -0.1075 -0.0605 -0.1293 -0.0257 -0.1359 -0.0793 -0.7760 -1.3072 -0.2212 -0.0857 -0.1494 -0.1327 -0.1643 -0.0475 -0.1161 -1.9466 -0.0325 -0.0769 -0.0798 -0.2490 -0.1075 -0.0416 -0.0751 -0.0912 -0.2448 -0.4327 -0.0869 -0.0372 -0.0680 -0.0514 -0.1767 -0.0090 -0.0624 -0.0444 -0.3597 -0.0371 -0.1417 -0.1222 -0.5162 -0.0772 -0.1841 -0.3077 -0.0625 -0.1130 -0.1041 -0.1212 -0.2583 -1.3055 -0.3455 -0.0556 -0.1170 -0.0188 -0.3913 -1.4828 -0.1328 -0.4482 -1.5007 -0.0521 -0.0798 -0.0431 -0.0152 -0.8469\n",
            "T-15\tmwamuna wa magalasi akuda jekete lakuda ndi malaya amizere yopingasa yoyera ndi yofiira akuloza chinachake ataima m mbali mwa msewu\n",
            "H-15\t-0.28388845920562744\t▁ m w a m u n a ▁ w o v a l a ▁ m a t h a l a u z a ▁ a k u d a ▁ c h a k u d y a ▁ n d i ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y o p a n g a ▁ p a m b a l i ▁ y o y e r a ▁ n d i ▁ y o f i i r a ▁ a k u l o z a ▁ c h i n a c h a k e ▁ m ▁ m b a l i ▁ m w a ▁ m s e w u\n",
            "D-15\t-0.28388845920562744\tmwamuna wovala mathalauza akuda chakudya ndi malaya amizeremizere yopanga pambali yoyera ndi yofiira akuloza chinachake m mbali mwa msewu\n",
            "P-15\t-0.1125 -0.0812 -0.0343 -0.1085 -0.0440 -0.0831 -0.1114 -0.0976 -0.1044 -0.0329 -1.7112 -1.4036 -0.1088 -0.1194 -0.1338 -0.1054 -0.4400 -0.1027 -0.9495 -0.0312 -0.1056 -0.1160 -0.1191 -0.0563 -0.3768 -0.0828 -0.1239 -0.4315 -0.1356 -0.1008 -0.4083 -0.2045 -0.1116 -1.5807 -0.1507 -0.2377 -0.0467 -0.1640 -0.0273 -0.3029 -0.0952 -0.1235 -1.7969 -0.1091 -0.0841 -0.2972 -0.3905 -0.1421 -0.9592 -0.0979 -0.0731 -0.1069 -0.0751 -0.1007 -0.4315 -0.0589 -0.4329 -0.0283 -0.0486 -0.0207 -1.3948 -0.0157 -0.1041 -0.0499 -0.0481 -0.0434 -0.1010 -0.4167 -0.7631 -0.1945 -0.0857 -0.6122 -0.2456 -0.1382 -0.1340 -2.2787 -0.1370 -0.8365 -1.4591 -0.1035 -0.0763 -0.5596 -0.1467 -0.0581 -0.1607 -0.5868 -0.1004 -0.0494 -0.0936 -0.1075 -0.3741 -0.0945 -0.0978 -0.1825 -0.1796 -0.0810 -0.3811 -0.0535 -0.1969 -0.0289 -0.1501 -0.1047 -0.7202 -0.0413 -0.1497 -1.0511 -0.3894 -2.3501 -0.4967 -0.0883 -0.0615 -0.0560 -0.2010 -0.4848 -0.1050 -0.1031 -0.0841 -0.0925 -0.0259 -0.0139 -0.1295 -0.5835 -0.1688 -0.0673 -0.7689 -0.0670 -0.0489 -0.0851 -0.1514 -0.2120 -0.1035 -0.0865 -0.2131 -0.3794 -0.2488 -0.0224 -0.0665 -0.0385 -0.2089\n",
            "T-110\tmwana wamng ono wanyamula mtanga wa mazira a isitala amitundu yowala bwino ndipo akutola lapinki paudzu\n",
            "H-110\t-0.34922686219215393\t▁ m w a n a ▁ w a m n g ▁ o n o ▁ w a n y a m u l a ▁ m p a n d a ▁ w a m k a z i ▁ a t a v a l a ▁ t ▁ s h i r t ▁ y a m i t u n d u ▁ y o w a l a ▁ n d i ▁ b u l u u ▁ n d i p o ▁ w a k u d a ▁ a l i ▁ p a u d z u\n",
            "D-110\t-0.34922686219215393\tmwana wamng ono wanyamula mpanda wamkazi atavala t shirt yamitundu yowala ndi buluu ndipo wakuda ali paudzu\n",
            "P-110\t-0.1105 -0.0889 -0.1447 -0.1243 -0.0358 -0.1045 -0.1414 -0.0916 -0.3335 -0.1325 -0.0334 -0.1215 -0.0844 -0.0920 -0.0325 -0.0325 -0.1729 -0.0860 -0.5356 -1.7802 -0.0210 -0.0971 -0.0976 -0.0328 -0.0695 -0.0989 -0.1076 -0.2281 -0.8603 -0.4830 -0.0264 -0.1675 -0.1337 -0.1487 -0.1335 -0.1321 -0.6827 -1.0008 -0.2572 -0.3932 -0.0673 -0.1453 -0.7082 -0.3804 -0.0893 -1.2384 -0.1798 -0.0912 -0.1203 -0.0941 -1.3107 -0.9803 -0.0674 -0.2648 -0.8222 -0.1007 -0.0173 -0.1391 -1.1808 -0.7282 -1.7349 -0.1793 -0.1360 -0.0788 -0.2382 -0.0597 -0.0447 -0.1745 -0.0966 -0.1338 -0.1890 -0.1325 -0.0577 -0.1150 -0.1222 -2.0275 -0.0754 -0.1105 -0.3176 -2.3974 -0.2961 -0.2251 -0.8174 -0.0920 -0.1292 -0.3117 -0.0995 -0.0754 -0.2423 -0.0529 -0.1109 -0.7695 -0.1983 -1.1011 -0.2479 -0.2546 -0.1282 -0.4491 -0.3423 -0.7451 -1.1920 -0.2155 -1.3538 -0.1986 -1.3154 -0.3222 -0.0348 -0.0549 -0.0924\n",
            "T-255\tbambo wina wazaka zapakati akukhala m malo ogwirira ntchito m mafakitale akuwerenga nyuzipepala\n",
            "H-255\t-0.33810803294181824\t▁ b a m b o ▁ w i n a ▁ w a z a k e ▁ z a p a k a t i ▁ a k u k h a l a ▁ m ▁ m a l o ▁ o f i i r a ▁ n d i ▁ c h i d o l e ▁ m ▁ m a d z i ▁ a k u g w e d e z a ▁ k u m b u y o ▁ k w a k e\n",
            "D-255\t-0.33810803294181824\tbambo wina wazake zapakati akukhala m malo ofiira ndi chidole m madzi akugwedeza kumbuyo kwake\n",
            "P-255\t-0.1148 -0.4869 -0.0933 -0.0438 -0.0493 -0.0572 -0.1009 -0.0779 -0.1105 -0.0542 -0.1424 -0.1124 -0.0468 -0.8075 -0.6167 -0.0818 -0.0695 -0.1494 -0.1268 -0.2472 -0.1189 -0.3717 -0.1138 -0.0378 -0.1292 -0.0923 -0.0423 -0.1553 -0.2067 -0.3410 -0.1525 -0.0557 -1.5554 -0.1509 -0.0975 -0.1277 -0.1116 -0.3680 -0.5944 -1.3506 -0.0774 -0.6453 -0.1385 -0.1025 -0.0487 -1.7548 -0.3002 -0.1153 -0.0306 -0.2885 -0.1217 -1.0321 -0.0988 -0.1042 -0.1527 -0.9696 -0.1261 -0.0594 -0.2284 -0.0813 -0.1561 -0.2479 -0.1563 -0.9577 -0.2015 -0.3252 -0.0845 -2.5460 -0.1281 -0.0908 -0.1012 -0.1732 -1.0721 -0.1390 -0.1609 -0.1118 -0.2859 -0.4585 -0.2490 -0.3553 -0.4095 -0.1261 -1.9739 -0.1474 -0.8330 -0.6238 -0.3342 -0.0478 -0.1523 -0.2049 -1.1288 -0.5767 -0.1388 -1.2320 -0.0217 -0.2676\n",
            "T-366\tamuna awiri ovala ma jekete achikasu amtundu wa neon akwera pamahatchi awiri abulauni mumsewu pafupi ndi bedi la maluwa achikasu owala\n",
            "H-366\t-0.345150351524353\t▁ a m u n a ▁ a w i r i ▁ o v a l a ▁ m a t h a l a u z a ▁ a c h i k a s u ▁ n d i ▁ k a m t u n d u ▁ w a ▁ n y u m b a ▁ a k u y e r a ▁ p a m a t s i k a ▁ a w i r i ▁ a k u y a n g ▁ a n a ▁ p a f u p i ▁ n d i ▁ m a t s o g o l o ▁ a c h i k a s u\n",
            "D-366\t-0.345150351524353\tamuna awiri ovala mathalauza achikasu ndi kamtundu wa nyumba akuyera pamatsika awiri akuyang ana pafupi ndi matsogolo achikasu\n",
            "P-366\t-0.1159 -0.1453 -0.0451 -0.0845 -0.0745 -0.1045 -0.0998 -0.1292 -0.4575 -0.0966 -0.0626 -0.0751 -0.1009 -0.0320 -0.0614 -0.1065 -0.0692 -0.1385 -0.1076 -0.1247 -0.1002 -2.9659 -0.0189 -0.0944 -0.1687 -0.1157 -0.0648 -0.2844 -0.0898 -0.0918 -0.7000 -0.4874 -0.1281 -0.0616 -0.4283 -0.1458 -0.0554 -0.1474 -0.0898 -0.8564 -0.2174 -0.1343 -0.1757 -1.4675 -0.1025 -0.3291 -0.3020 -0.0793 -0.0685 -0.0348 -0.0489 -0.0817 -0.0307 -0.1434 -0.5201 -0.5796 -0.6112 -0.3462 -0.1365 -0.2182 -0.2834 -0.1166 -0.5654 -0.2329 -0.7179 -0.3080 -0.3067 -1.4407 -0.1847 -0.1159 -0.2442 -0.1244 -0.2042 -0.1349 -2.0367 -0.6263 -0.1086 -0.3186 -0.5824 -0.5694 -0.3378 -1.2359 -0.0785 -0.0654 -0.0697 -0.0841 -0.6824 -0.6135 -0.0924 -2.2583 -0.2928 -0.1481 -0.2654 -0.0801 -0.1203 -0.0761 -0.7916 -0.0925 -1.3517 -0.1253 -0.2683 -0.2487 -0.0470 -0.0677 -0.0958 -0.0279 -0.0647 -0.1265 -0.0803 -0.8708 -0.0648 -2.5470 -1.0612 -0.9397 -0.0494 -0.1039 -0.0527 -0.3689 -0.1559 -0.4869 -1.4656 -0.0582 -0.0756 -0.1796 -0.2047 -0.0517 -0.0217 -1.3562\n",
            "T-259\tmzimayi wovala malaya otuwa ndipo ali ndi kachikwama kofiira atakhala pa benchi ya paki yobiriwira akuwerenga nyuzipepala\n",
            "H-259\t-0.2678717076778412\t▁ m z i m a y i ▁ w o v a l a ▁ m a l a y a ▁ o t u w a ▁ n d i p o ▁ w a k u d a ▁ n d i ▁ k a c h i k w a m a ▁ k o f i i r a ▁ a t a k h a l a ▁ p a ▁ b e n c h i ▁ y a ▁ p a k a t i ▁ y o b i r i w i r a ▁ a k u w e r e n g a ▁ m ▁ m p h e p e t e ▁ m w a ▁ z i p e w a\n",
            "D-259\t-0.2678717076778412\tmzimayi wovala malaya otuwa ndipo wakuda ndi kachikwama kofiira atakhala pa benchi ya pakati yobiriwira akuwerenga m mphepete mwa zipewa\n",
            "P-259\t-0.1144 -0.0398 -0.1853 -0.1243 -0.1030 -0.0826 -0.0424 -0.1087 -0.0823 -0.0792 -0.0687 -0.1065 -0.1262 -0.0791 -0.1210 -0.0970 -0.0762 -0.1027 -0.0653 -0.1310 -0.0328 -0.1235 -0.0873 -0.0411 -0.0568 -0.0937 -0.0128 -0.0775 -0.0967 -0.0951 -0.0805 -0.0950 -1.0253 -0.1327 -0.0748 -1.6264 -0.1198 -1.2440 -0.6111 -0.0637 -0.3368 -0.1106 -0.0308 -0.0610 -0.0926 -0.8672 -0.7752 -0.5963 -0.3503 -0.0673 -0.0427 -0.0570 -0.1205 -0.1162 -0.0532 -0.1245 -0.1092 -0.6333 -0.2074 -0.2649 -0.0734 -0.1453 -0.0365 -0.2022 -0.1381 -0.2580 -0.0749 -0.0968 -0.1069 -0.1160 -0.1118 -0.0443 -0.1306 -0.0891 -0.0138 -0.1108 -1.4388 -1.0252 -0.0488 -0.0535 -0.0412 -0.1238 -0.1241 -0.0822 -0.0321 -0.8357 -0.8750 -0.5421 -0.1860 -2.3286 -0.5505 -0.1397 -0.0462 -0.0760 -1.1976 -0.0536 -0.0738 -0.0445 -0.0441 -0.1015 -0.0123 -0.0760 -0.0435 -0.1011 -0.1644 -0.1387 -0.1190 -0.1100 -0.3856 -0.3074 -0.2606 -0.1559 -0.1954 -0.0803 -0.1210 -0.1285 -0.4849 -1.1045 -1.1691 -0.8653 -0.0609 -0.0928 -0.4806 -0.0559 -0.0248 -0.0316 -0.1736 -0.1683 -0.0960 -0.1154 -0.3245 -3.3594 -0.0656 -0.0985 -0.3934 -0.4468 -0.1047 -0.2928\n",
            "T-315\tmtsikana wa ku asia wovala nsonga ya pinki ndi yakuda ya mizere yakuda akuyenda pafupi ndi mtsikanayo pamutu wotuwa\n",
            "H-315\t-0.33823803067207336\t▁ m t s i k a n a ▁ w o y e r a ▁ w o v a l a ▁ s u t i ▁ y a ▁ b u l u u ▁ n d i ▁ y a k u d a ▁ n d i ▁ y a k u d a ▁ a k u j a m b u l a ▁ k u y e n d a ▁ p a f u p i ▁ n d i ▁ k a t u n d u ▁ w a ▁ t h u k u l u ▁ w a ▁ m u t u ▁ w a k e\n",
            "D-315\t-0.33823803067207336\tmtsikana woyera wovala suti ya buluu ndi yakuda ndi yakuda akujambula kuyenda pafupi ndi katundu wa thukulu wa mutu wake\n",
            "P-315\t-0.1165 -0.0304 -0.0807 -0.0526 -0.0437 -0.0304 -0.1255 -0.0733 -0.1487 -0.1030 -1.3507 -0.2644 -0.9746 -0.0772 -0.0923 -0.1213 -0.1193 -0.2670 -0.0512 -0.0439 -0.1172 -0.0951 -0.1153 -0.0906 -0.4443 -3.0351 -0.1692 -0.2276 -0.0773 -0.0149 -0.1998 -0.3459 -0.4259 -1.4197 -0.1333 -0.3526 -0.1085 -0.0877 -0.0853 -0.0632 -0.1043 -0.1063 -0.0586 -0.1920 -0.1055 -0.1526 -0.0459 -0.3974 -0.0997 -0.9267 -0.4165 -0.1234 -0.0918 -1.7012 -0.3304 -1.3511 -0.1371 -0.0395 -0.4757 -0.1076 -0.1284 -0.0561 -0.1095 -0.3515 -0.0904 -0.1565 -0.0958 -0.1418 -0.0854 -0.4754 -0.1026 -0.4378 -1.0330 -0.4212 -0.1665 -0.1867 -0.0949 -0.1444 -0.0971 -2.0050 -0.1590 -0.0977 -0.0359 -0.0345 -0.0409 -0.0877 -0.0570 -0.0667 -0.0965 -0.1086 -0.9666 -0.2130 -2.2259 -0.4382 -0.1320 -0.9343 -0.0287 -0.0826 -0.1837 -0.1288 -0.8141 -0.6348 -0.5583 -0.0489 -1.1043 -0.0647 -1.2295 -0.1284 -0.1200 -1.0805 -0.1638 -0.6144 -0.7758 -0.5253 -0.0999 -0.0232 -0.1646 -0.0168 -0.1787 -1.0415 -0.3581 -0.2823\n",
            "T-387\tmwamuna wovala malaya oyera ndi magalasi adzuwa ndi mwamuna wovala malaya akuda ndi magalasi adzuwa amakhala patebulo ndi mabotolo anayi amowa\n",
            "H-387\t-0.2207002192735672\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ m a g a l a s i ▁ a d z u w a ▁ n d i ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ n d i ▁ m a g a l a s i ▁ a c h i k a s u ▁ a t a k h a l a ▁ p a m p a n d o ▁ w o v a l a ▁ m a l a y a ▁ o t u w a\n",
            "D-387\t-0.2207002192735672\tmwamuna wovala malaya oyera ndi magalasi adzuwa ndi mwamuna wovala malaya akuda ndi magalasi achikasu atakhala pampando wovala malaya otuwa\n",
            "P-387\t-0.1225 -0.1450 -0.0780 -0.0900 -0.0718 -0.0661 -0.0957 -0.1133 -0.1123 -0.0751 -0.1905 -0.0616 -0.1259 -0.0925 -0.1385 -0.1129 -0.0617 -0.1250 -0.0690 -0.1271 -0.0431 -0.1195 -0.0985 -0.0536 -0.0808 -0.1078 -0.0547 -0.1066 -0.1081 -0.0148 -0.0814 -0.1266 -0.0843 -0.0114 -0.1401 -0.0966 -0.1309 -0.0629 -0.1209 -0.0479 -0.0430 -0.0814 -0.1471 -1.5776 -0.0409 -0.0326 -0.0877 -0.1008 -0.0950 -0.5840 -0.0514 -0.0994 -0.1176 -0.0823 -0.4668 -0.1058 -0.1350 -0.0820 -0.0457 -0.1328 -0.1150 -0.0672 -0.1152 -0.0248 -0.1258 -0.0887 -0.1335 -0.1185 -0.0910 -0.1147 -0.0570 -0.1367 -0.0161 -0.1081 -0.0831 -0.3856 -0.4103 -0.0911 -0.1009 -0.2186 -0.1043 -0.0305 -0.0863 -0.0923 -0.1600 -0.1176 -0.2422 -0.9396 -0.1362 -0.1420 -0.2156 -0.0500 -0.0447 -0.0737 -0.1412 -3.5138 -0.1374 -0.0538 -0.1495 -0.0884 -0.0432 -0.0664 -0.0698 -0.4938 -0.5591 -0.0788 -0.7749 -0.1254 -0.1770 -0.0673 -0.1377 -0.0702 -0.2481 -0.1659 -0.2330 -0.9473 -0.5659 -0.1040 -0.0078 -0.8556 -0.1374 -0.0770 -1.4824 -2.0635 -0.0827 -0.0955 -0.1155 -0.1875 -0.1950 -0.0877 -0.5260 -1.4353 -0.0451 -0.0882 -0.2296 -0.6870 -0.2252 -0.0787 -0.0346 -0.0610 -0.3978\n",
            "T-244\tbrunette wamkazi atavala malaya ofiira akugwiritsa ntchito zodzoladzola kwa mwamuna wa brunette ndi maso ake otsekedwa komanso mu malaya ofiira\n",
            "H-244\t-0.29892194271087646\t▁ m n y a m a t a ▁ w a m k a z i ▁ a t a v a l a ▁ m a l a y a ▁ o f i i r a ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ z o z u n g u l a ▁ z o k o n a ▁ k o m a n s o ▁ m w a m u n a ▁ w a ▁ m a s e k e t i ▁ o s e k e d w a ▁ k u m a s o ▁ k w a k e\n",
            "D-244\t-0.29892194271087646\tmnyamata wamkazi atavala malaya ofiira akugwiritsa ntchito zozungula zokona komanso mwamuna wa maseketi osekedwa kumaso kwake\n",
            "P-244\t-0.1053 -0.1218 -1.0584 -0.1064 -0.1366 -0.0895 -0.0926 -0.0470 -0.0935 -0.1155 -0.4820 -0.2669 -0.5606 -0.0506 -0.1684 -0.0495 -0.1361 -0.0958 -0.1115 -0.0739 -0.0890 -0.5049 -0.0956 -0.0900 -0.1180 -0.1000 -0.0489 -0.0804 -0.0230 -0.1240 -0.0255 -0.1031 -0.0911 -0.0201 -0.7596 -0.0774 -0.1000 -0.0404 -0.1865 -0.1087 -0.1473 -0.0777 -0.1464 -0.0649 -0.0497 -0.0734 -0.0597 -0.3351 -0.1837 -0.2559 -0.1186 -0.1341 -0.0544 -0.0529 -0.0232 -0.0947 -0.0625 -0.0091 -0.0366 -0.0999 -0.1307 -0.0716 -2.5371 -0.9008 -0.0613 -0.0484 -0.2142 -0.0735 -0.4163 -0.3157 -0.2214 -0.1148 -0.8985 -0.3020 -0.0999 -1.3393 -0.1512 -0.7400 -0.6059 -0.2193 -0.2044 -0.5209 -0.2518 -0.0239 -0.0814 -0.6627 -1.1157 -0.1415 -0.0410 -0.3253 -0.0434 -0.1395 -0.1299 -1.0112 -0.2523 -1.3101 -0.4669 -0.4418 -0.2614 -0.6194 -0.7100 -0.3895 -0.0540 -0.4205 -0.0951 -0.0823 -0.3944 -0.0971 -0.4234 -0.1287 -0.9582 -0.0459 -0.1106 -0.1370 -0.5255 -0.1511 -0.0589 -0.9543 -0.2549 -0.0198 -0.1480 -1.0276 -1.5634 -0.1695 -1.5763 -0.0263 -1.1068\n",
            "T-141\tanthu awiri akuuluka akuuluka kuchokera pachoulukira chofiira choyera ndi chakuda chokhala ndi thambo lamtambo wabuluu kumbuyo kwawo\n",
            "H-141\t-0.29889151453971863\t▁ a n t h u ▁ a w i r i ▁ a k u k h a l a ▁ p a t e b u l o ▁ k u c h o k e r a ▁ c h o f i i r a ▁ c h o f i i r a ▁ c h o y e r a ▁ n d i ▁ c h a k u d y a ▁ c h o k h a l a ▁ n d i ▁ c h a b u l u u ▁ w a m a t a b w a ▁ k u m b u y o ▁ k w a w o\n",
            "D-141\t-0.29889151453971863\tanthu awiri akukhala patebulo kuchokera chofiira chofiira choyera ndi chakudya chokhala ndi chabuluu wamatabwa kumbuyo kwawo\n",
            "P-141\t-0.1163 -0.1384 -0.1523 -0.0160 -0.0466 -0.0580 -0.1008 -0.1003 -0.4152 -0.1030 -0.0469 -0.0996 -0.0889 -0.1369 -0.1585 -0.1293 -1.4887 -1.4376 -0.1310 -0.1309 -0.1230 -0.0944 -0.1695 -0.1073 -2.8661 -0.3252 -0.0527 -0.0226 -0.1918 -0.1028 -0.1073 -1.9960 -0.3417 -0.1549 -0.0435 -0.0297 -0.0141 -0.0156 -0.0210 -0.0770 -0.1217 -0.2057 -0.0454 -1.9559 -0.6589 -0.0632 -0.2736 -0.0315 -0.1332 -0.1250 -0.0222 -0.0414 -0.1236 -0.4899 -0.0901 -0.2445 -0.0410 -0.2098 -0.1169 -0.0922 -0.0429 -1.1216 -1.0987 -0.2146 -0.1399 -0.1257 -0.0965 -0.0447 -0.1000 -0.1454 -0.1590 -0.0484 -0.0648 -0.3727 -0.1529 -0.0805 -0.0456 -0.3665 -0.1718 -0.1072 -0.0555 -0.0595 -1.8880 -0.0657 -0.0719 -0.0977 -0.0781 -0.1161 -0.0990 -0.0369 -0.0558 -0.1028 -0.1511 -1.8394 -0.1271 -0.7576 -0.9185 -0.4870 -0.0785 -0.1821 -0.1098 -0.1385 -0.2702 -0.2592 -0.4395 -0.2478 -0.1277 -0.4563 -0.1627 -0.1816 -0.0840 -0.1766 -1.7125 -0.0542 -0.4764 -0.4086 -0.0619 -0.0788 -0.0381 -0.3744 -0.1005 -0.9901 -0.0979 -1.0214 -0.0578 -0.5286\n",
            "T-29\twosewera mpira wovala yunifolomu yobiriwira akuyesa kugwira mpira pomwe mdani wake atavala yunifomu yabuluu akuyesa kumuletsa\n",
            "H-29\t-0.2905334234237671\t▁ w o s e w e r a ▁ m p i r a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ a k u y e n d a ▁ k u m b u y o ▁ n d i ▁ k o m a n s o ▁ a t a k h a l a ▁ p a t e b u l o ▁ l o m w e ▁ l i k u y e s a ▁ k u m b u y o ▁ k w a k e\n",
            "D-29\t-0.2905334234237671\twosewera mpira wovala yunifolomu yobiriwira akuyenda kumbuyo ndi komanso atakhala patebulo lomwe likuyesa kumbuyo kwake\n",
            "P-29\t-0.1165 -0.0504 -0.6913 -0.0867 -0.4571 -0.0185 -0.1385 -0.0520 -0.1275 -0.1111 -0.0373 -0.1150 -0.0321 -0.0423 -0.1023 -0.1765 -0.0972 -0.1546 -0.1472 -0.1127 -0.0762 -0.1305 -0.1235 -0.1280 -0.0247 -0.0243 -0.0431 -0.0238 -0.0196 -0.2211 -0.0950 -0.0093 -0.1207 -0.0967 -0.0337 -2.2779 -0.4673 -0.0493 -0.0431 -0.1057 -0.0121 -0.0769 -0.0394 -0.1334 -0.1405 -0.1238 -0.0503 -0.1927 -0.7594 -0.3569 -0.4697 -0.0372 -0.9036 -0.1155 -0.6922 -0.2826 -0.4023 -0.0251 -0.3893 -0.0108 -0.1196 -0.1021 -0.6676 -0.0653 -0.1406 -0.6741 -1.3348 -0.5808 -0.1805 -0.1694 -0.3596 -1.3479 -0.1733 -0.0883 -0.2680 -0.4204 -0.0880 -1.3520 -0.3203 -0.1106 -0.0513 -0.1482 -0.0875 -0.1319 -0.1135 -2.8432 -0.2710 -0.0869 -0.1291 -0.0423 -0.0354 -0.1108 -0.3252 -1.3266 -0.4340 -0.2353 -0.0501 -0.0990 -0.1620 -0.1037 -0.3874 -0.0448 -1.5446 -0.5266 -0.9809 -0.1582 -0.2856 -0.2787 -0.1900 -0.1298 -0.3221 -0.0612 -0.0293 -0.0854 -1.1984 -0.1335 -0.2699 -0.0897 -0.6849 -0.1101 -0.0992\n",
            "T-284\tazimayi awiri ovala malaya akuda amakhala pamadesiki amatabwa m chipinda choyera chokhala ndi denga lotchingidwa komanso kuwala kochepa\n",
            "H-284\t-0.3004300892353058\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u t h a m a n g a ▁ p a m a d z i ▁ a m a t h a l a u z a ▁ o m w e ▁ a l i ▁ n d i ▁ c h i p e w a ▁ c h o y e r a ▁ n d i ▁ c h o k h a l a ▁ n d i ▁ m b a l e ▁ k u t s o g o l o ▁ k w a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-284\t-0.3004300892353058\tmayi wina wovala malaya oyera akuthamanga pamadzi amathalauza omwe ali ndi chipewa choyera ndi chokhala ndi mbale kutsogolo kwa chipale chofewa\n",
            "P-284\t-0.1064 -0.3906 -0.0975 -0.0628 -0.0999 -0.1065 -0.6447 -0.1576 -0.3638 -0.1144 -0.1051 -0.1282 -0.1012 -0.0821 -0.1096 -0.0844 -0.1146 -0.0892 -0.0731 -0.1041 -0.0739 -0.1293 -0.0424 -0.1216 -0.0852 -0.3805 -1.9865 -0.2525 -0.0454 -0.1116 -0.1110 -0.5479 -0.0264 -0.1036 -1.3245 -0.0424 -0.1129 -0.0966 -0.0940 -0.0306 -0.1326 -0.1278 -0.0767 -0.0218 -0.1151 -0.1448 -0.2488 -0.8770 -0.8421 -0.0554 -0.1310 -0.6556 -0.4891 -0.1291 -0.3416 -1.0443 -0.1578 -0.3434 -0.1161 -0.0865 -0.7576 -0.0785 -0.1355 -0.8168 -0.4874 -0.0867 -0.1175 -0.0826 -0.1671 -1.0829 -0.0932 -0.1079 -0.1944 -0.1081 -0.1213 -0.1095 -0.2245 -0.0516 -0.1082 -0.8654 -0.5688 -0.0687 -0.0793 -0.1293 -0.0352 -0.0479 -0.0683 -0.5673 -0.0536 -0.0663 -0.1111 -0.1314 -2.3116 -0.1014 -0.1028 -0.1173 -2.2912 -0.0743 -0.1107 -0.4478 -0.3917 -0.1431 -0.0318 -0.1421 -0.0869 -0.6835 -0.0575 -0.1432 -0.0870 -0.8835 -0.9218 -0.1405 -0.3245 -1.6091 -0.1350 -0.1384 -0.4546 -0.7459 -0.2371 -0.0652 -0.0178 -0.1152 -0.0801 -0.1812 -0.0983 -0.0345 -0.1313 -0.1071 -0.2253 -2.4688 -0.0861 -0.1023 -1.3618 -0.3629 -0.3233 -0.1350 -0.1006 -0.3515 -0.0872 -0.0624 -0.8640 -0.0466 -0.0417 -0.0750 -0.4080\n",
            "T-213\tmkazi watsitsi lopaka utoto wabulauni ndi wabulauni wanyamula mkono wake pa mwamuna amene wanyamula kapu\n",
            "H-213\t-0.33545640110969543\t▁ m k a z i ▁ w a t s i t s i ▁ l o p a k a ▁ u t o t o ▁ w a g w i r a ▁ n d i ▁ w a b u l a u n i ▁ w a n y a m u l a ▁ m k o n o ▁ w a m k e d w a ▁ p a m e n e ▁ m w a m u n a ▁ a k u y a n g ▁ a n a\n",
            "D-213\t-0.33545640110969543\tmkazi watsitsi lopaka utoto wagwira ndi wabulauni wanyamula mkono wamkedwa pamene mwamuna akuyang ana\n",
            "P-213\t-0.1274 -0.1378 -0.2928 -0.1348 -0.0425 -0.0553 -0.1246 -0.0064 -0.2334 -0.9598 -1.1307 -0.0918 -0.0131 -0.1339 -0.0647 -0.1188 -0.0226 -0.0853 -0.9807 -0.1331 -0.3031 -0.1194 -0.4437 -2.0067 -0.1859 -0.6299 -0.2327 -0.0998 -0.1762 -0.1788 -0.2291 -0.7313 -0.0640 -0.0874 -0.1060 -0.1654 -0.1818 -0.4830 -0.3292 -0.0883 -0.2937 -0.6632 -0.2524 -0.6279 -0.1605 -0.1104 -0.0856 -0.0559 -0.0254 -0.0431 -0.1082 -0.1483 -0.2122 -0.6115 -0.3828 -0.1016 -0.0398 -0.1161 -0.0764 -0.1179 -0.1135 -1.1064 -0.4251 -0.2238 -0.0744 -0.0710 -0.1632 -0.2302 -0.2216 -0.6091 -0.5684 -0.6488 -1.8777 -0.9145 -0.0805 -0.1482 -0.6555 -0.1957 -0.1314 -1.4623 -0.0687 -0.0622 -0.1038 -1.7342 -0.9063 -0.1206 -0.1179 -0.0280 -0.1269 -0.1065 -0.3277 -1.1912 -0.5580 -0.9082 -1.1169 -0.1743 -0.1278 -0.2047 -0.2841 -0.0971 -0.0780 -0.1545 -0.0689\n",
            "T-28\twosewera mpira wa basketball wovala yunifolomu yoyera yobiriwira ndi yachikasu wangopanga basiketi pamasewera\n",
            "H-28\t-0.30666014552116394\t▁ w o s e w e r a ▁ m p i r a ▁ w o t s e t s e r e k a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o y e r a ▁ n d i ▁ y o y e r a ▁ n d i ▁ k a c h i k w a s u ▁ p a k h o m a ▁ l a ▁ p a n j i n g a ▁ p a m a s e w e r a\n",
            "D-28\t-0.30666014552116394\twosewera mpira wotsetsereka wovala yunifolomu yoyera ndi yoyera ndi kachikwasu pakhoma la panjinga pamasewera\n",
            "P-28\t-0.1114 -0.9197 -0.1394 -0.1134 -0.0639 -0.0232 -0.0691 -0.0302 -0.1246 -0.1045 -0.1483 -0.1622 -0.0641 -0.0378 -0.1123 -0.1044 -0.4793 -1.1302 -0.8734 -0.1793 -0.1726 -1.1747 -0.0771 -0.1045 -0.0929 -0.1950 -0.0317 -0.3538 -0.1493 -0.6082 -1.0290 -0.1336 -0.1453 -0.0742 -0.1046 -0.1366 -0.1562 -0.0237 -0.0564 -0.1911 -0.0631 -0.0657 -0.3018 -0.1295 -0.0093 -0.0725 -0.1137 -0.0219 -0.3438 -0.0442 -0.1579 -0.0560 -0.1249 -0.1112 -0.1257 -0.0875 -0.1046 -0.1155 -1.2901 -0.1047 -0.2394 -0.0942 -0.0474 -0.1148 -0.1114 -0.6702 -0.1662 -0.1025 -0.2849 -1.1294 -0.4982 -0.5312 -0.0921 -0.0700 -0.1248 -0.9677 -0.0863 -0.5832 -0.1160 -0.1200 -2.1317 -0.3437 -0.8981 -0.1967 -0.1715 -0.1825 -0.1965 -0.1230 -0.6049 -0.1829 -0.1903 -2.9315 -0.2721 -0.5343 -1.4032 -0.1542 -0.9532 -0.0537 -0.1304 -0.2101 -0.2551 -0.1519 -0.6652 -0.3810 -0.0434 -0.3989 -0.0521 -0.0578 -0.0520 -0.1256 -0.3967\n",
            "T-383\tbambo wina akuwoloka msewu pakati pa galimoto yowala kwambiri ndi taxi yachikasu yokhala ndi basiketi yomangidwa ndi zingwe zonyamulira katundu wake\n",
            "H-383\t-0.3497938811779022\t▁ b a m b o ▁ w i n a ▁ a k u g u l u ▁ l o k h a l a ▁ p a n s i ▁ p a ▁ c h i p a l e ▁ c h o t u w a ▁ n d i ▁ w a n y a m u l a ▁ c h i p a t a ▁ c h o k h a l a ▁ n d i ▁ j e k e t e ▁ y o k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ z i n y a l a l a\n",
            "D-383\t-0.3497938811779022\tbambo wina akugulu lokhala pansi pa chipale chotuwa ndi wanyamula chipata chokhala ndi jekete yokhala ndi chipale chofewa ndi zinyalala\n",
            "P-383\t-0.1090 -0.0334 -0.1311 -0.0357 -0.0604 -0.0703 -0.0932 -0.0666 -0.0725 -0.0791 -0.1262 -0.1034 -1.7227 -0.0481 -0.1055 -1.9230 -0.5330 -0.2215 -0.3241 -0.1340 -0.5711 -0.1157 -0.5075 -0.5132 -0.0932 -0.2012 -0.0796 -0.1006 -1.0608 -0.1228 -0.5082 -0.1514 -0.0478 -0.0751 -0.6041 -0.1550 -0.1266 -2.1566 -0.1882 -0.0486 -0.2678 -0.0856 -1.3227 -0.0746 -0.0787 -0.4331 -0.1434 -0.0983 -1.1066 -0.3795 -0.0192 -0.0939 -0.0984 -0.4998 -0.1247 -0.0732 -0.1239 -1.4295 -0.4731 -1.4593 -0.8385 -0.1583 -0.0403 -0.1029 -0.0910 -0.1000 -0.1023 -0.2225 -0.0777 -0.1021 -1.3717 -0.1316 -0.5291 -0.0999 -0.8216 -0.0733 -0.0656 -0.8722 -0.1743 -0.1070 -0.0980 -0.2100 -0.1449 -0.1320 -0.2252 -0.0796 -0.0857 -0.1853 -2.0476 -0.2406 -0.1653 -0.2252 -0.0419 -0.0873 -0.0982 -0.3303 -0.1957 -0.8769 -0.0522 -0.1017 -0.0983 -0.1189 -0.0826 -0.0568 -0.1002 -0.1179 -0.1258 -2.1977 -0.0990 -0.1488 -0.1163 -0.2391 -0.6289 -0.4212 -0.0698 -0.6048 -0.1002 -0.0234 -1.2350 -0.1286 -0.6657 -0.1077 -0.1514 -0.1172 -0.0721 -0.0848 -0.0811 -0.0441 -0.3595 -1.8554 -0.2901 -0.1071 -0.3259 -0.4998 -0.7570 -0.1733 -2.0050\n",
            "T-67\tmwamuna wamfupi wotuwa wokhala ndi mikwingwirima yakuda pafupi ndi pamwamba pa lamba akunyamula zolemera\n",
            "H-67\t-0.37536323070526123\t▁ m w a m u n a ▁ w o p h i k i d w a ▁ w a k h a l a ▁ n d i ▁ m i p i r i ▁ y o y e r a ▁ n d i ▁ m a n j a ▁ p a f u p i ▁ n d i ▁ p a m w a m b a ▁ p a ▁ k u l a n k h u l a ▁ z o y e r a\n",
            "D-67\t-0.37536323070526123\tmwamuna wophikidwa wakhala ndi mipiri yoyera ndi manja pafupi ndi pamwamba pa kulankhula zoyera\n",
            "P-67\t-0.1101 -0.1060 -0.1568 -0.1028 -0.7349 -0.0427 -0.0744 -0.1166 -0.1163 -0.1841 -0.5483 -1.1951 -1.1291 -0.1684 -0.1086 -0.5485 -0.5685 -0.0352 -0.0720 -0.1289 -1.4168 -0.5379 -0.1794 -0.0398 -0.1264 -0.2917 -0.1145 -0.1308 -0.2871 -0.1382 -0.1072 -0.1051 -0.2782 -0.1096 -1.0917 -0.2487 -0.1028 -1.1729 -0.1600 -1.0143 -1.1080 -0.5089 -0.1563 -0.1533 -0.1840 -0.1400 -1.3663 -0.1013 -0.1035 -0.1889 -0.1461 -0.0858 -0.2011 -0.0354 -0.1014 -0.0806 -2.4773 -0.1808 -0.1772 -0.0389 -0.0439 -0.0596 -0.1125 -0.0580 -0.0525 -0.1060 -0.2235 -2.0100 -0.7913 -0.1715 -1.0955 -0.0736 -0.0264 -0.1912 -0.5050 -0.0958 -0.4430 -0.1224 -0.4155 -0.6754 -0.6398 -2.6063 -0.3126 -0.2227 -0.6871 -0.0572 -0.0499 -0.0326 -0.1607 -0.2496 -0.5141 -0.0572 -1.2448 -0.1217 -0.2338 -0.0889 -0.4230\n",
            "T-276\twapolisi wamkazi akumwetulira atanyamula nkhwangwa yabuluu ndikuvala st patrick s day memorabilis akuyenda pamaso pa anthu osonkhana\n",
            "H-276\t-0.3851584196090698\t▁ w a p o l i s i ▁ w a m k a z i ▁ a k u m w e t u l i r a ▁ a t a n y a m u l a ▁ n k h o n d o ▁ y a ▁ b u l u u ▁ n d i p o ▁ w a v a l a ▁ c h i p e w a ▁ c h a k e ▁ n d i ▁ m o d z i ▁ a t a g w i r i t s a ▁ p a m a s o ▁ p a ▁ a n t h u ▁ o t u w a\n",
            "D-276\t-0.3851584196090698\twapolisi wamkazi akumwetulira atanyamula nkhondo ya buluu ndipo wavala chipewa chake ndi modzi atagwiritsa pamaso pa anthu otuwa\n",
            "P-276\t-0.1126 -0.2994 -2.3241 -1.5883 -0.2769 -0.0354 -0.0523 -0.0966 -0.2948 -0.0980 -0.4441 -0.6023 -0.8357 -0.0284 -0.2530 -0.0321 -0.0780 -0.1218 -0.0699 -0.1022 -0.0756 -1.8085 -0.0823 -0.0643 -0.0019 -0.0267 -0.0477 -0.0473 -0.0465 -0.1175 -0.1396 -0.3732 -0.0315 -0.1183 -0.1243 -0.0189 -0.0878 -0.0325 -0.0476 -0.0738 -0.1107 -0.1067 -1.7683 -1.9384 -0.0344 -0.1284 -0.5043 -0.4307 -0.0437 -0.1421 -0.0511 -0.1098 -0.6643 -0.0553 -0.4185 -0.0557 -0.0438 -0.0402 -0.0827 -0.2477 -0.0858 -0.0827 -0.9531 -0.0676 -0.1146 -0.2226 -0.7166 -0.3727 -0.1412 -0.1082 -0.1175 -0.1127 -0.9337 -0.0957 -0.1190 -0.6417 -0.8730 -0.1224 -0.0922 -0.1314 -0.6923 -0.1031 -0.4583 -2.5744 -0.2474 -0.1010 -1.7723 -0.0823 -0.0741 -0.1578 -0.6586 -0.2775 -1.7214 -1.1283 -0.0387 -0.0982 -0.1506 -1.5568 -0.1153 -0.8858 -0.0383 -0.0386 -0.1369 -0.7241 -0.8826 -0.0429 -0.6017 -0.0850 -1.2741 -0.1590 -0.2161 -0.1215 -0.3566 -0.0160 -0.0832 -1.1838 -0.1976 -0.2026 -1.1001 -0.5230 -0.0084 -0.1067 -0.0784 -0.3491 -0.6162 -2.4018 -0.4904 -0.4266 -0.1685 -0.3535\n",
            "T-193\tamuna awiri omwe ali muofesi yomasuka ndipo onse akuyang ana makompyuta awo ndipo wina wakweza mapazi awo pa desiki\n",
            "H-193\t-0.3682764768600464\t▁ a m u n a ▁ a w i r i ▁ o m w e ▁ a l i ▁ m u m s e w u ▁ a m t s i k a n a ▁ n d i p o ▁ m n y a m a t a ▁ k u m e n y a ▁ m p i r a ▁ n d i p o ▁ w i n a ▁ n d i p o ▁ w i n a ▁ a k u y a n g ▁ a n a ▁ k u t i ▁ a g e t s i\n",
            "D-193\t-0.3682764768600464\tamuna awiri omwe ali mumsewu amtsikana ndipo mnyamata kumenya mpira ndipo wina ndipo wina akuyang ana kuti agetsi\n",
            "P-193\t-0.1227 -0.0855 -0.1355 -0.0456 -0.0829 -0.1137 -0.0950 -0.1659 -0.1048 -0.1308 -0.0422 -0.1090 -0.1210 -0.0600 -0.5279 -0.5264 -0.1112 -0.0926 -0.0657 -0.0443 -0.0644 -0.1276 -0.1870 -1.0882 -0.5271 -0.4818 -0.2594 -0.0485 -0.0339 -0.1118 -0.4083 -0.2568 -2.8690 -0.1915 -0.2205 -0.7402 -0.1153 -0.2683 -0.1277 -0.1570 -0.0423 -0.0203 -0.0820 -0.9897 -0.0282 -0.1145 -0.4493 -0.7209 -0.0860 -0.1367 -0.1667 -0.0719 -0.0522 -0.1570 -0.1027 -1.3899 -0.2957 -0.1148 -1.5632 -0.0779 -0.3982 -0.0943 -0.1191 -2.6127 -0.6508 -0.1120 -0.2878 -0.5389 -0.1762 -0.5776 -0.0907 -0.1067 -1.7243 -0.0351 -0.1096 -0.3823 -0.2682 -0.0489 -0.1246 -0.1158 -1.6279 -0.0616 -0.1010 -0.4424 -0.0596 -0.0941 -0.4607 -0.9834 -0.0609 -0.1475 -0.2073 -1.3619 -0.0376 -0.0869 -1.3419 -0.1135 -0.1054 -0.3307 -0.0946 -0.1020 -0.0622 -0.3869 -0.1660 -1.4206 -0.1506 -1.0033 -0.8709 -0.1263 -0.5692 -2.1323 -0.4364 -0.4911 -0.1137 -0.1687 -0.1298\n",
            "T-236\tgalu woyera watsitsi lopiringizika wavala chomangira n kumaonera m madzi galu wina wakuda ndi wabulauni\n",
            "H-236\t-0.32066789269447327\t▁ g a l u ▁ w o y e r a ▁ w a t s i t s i ▁ l o p i n k i z i r i t a ▁ w a v a l a ▁ c h o v a l a ▁ c h a m a n j a ▁ k u m a w o n e r a ▁ m ▁ m a d z i ▁ w i n a ▁ w a k u d a ▁ n d i ▁ w o j a m b u l a\n",
            "D-236\t-0.32066789269447327\tgalu woyera watsitsi lopinkizirita wavala chovala chamanja kumawonera m madzi wina wakuda ndi wojambula\n",
            "P-236\t-0.1053 -0.4058 -0.0940 -0.0507 -0.1452 -0.1017 -0.0795 -0.2593 -0.0434 -0.1070 -0.0722 -0.1226 -0.1134 -0.0609 -0.2710 -1.6185 -0.0199 -0.0768 -0.0891 -0.0251 -0.0618 -0.0907 -0.3032 -0.0723 -0.4077 -0.2002 -0.5386 -0.4711 -0.0478 -0.2503 -0.1092 -1.0894 -0.6054 -1.1487 -0.4936 -0.2352 -0.3738 -0.3065 -0.0548 -0.1779 -0.0793 -0.1332 -0.1272 -0.0392 -0.0834 -0.4369 -0.4917 -0.0895 -0.1013 -0.1414 -0.1154 -0.0677 -0.0957 -0.9306 -0.9901 -0.2460 -0.8455 -0.0630 -0.4421 -0.1072 -0.7495 -0.2515 -0.6467 -0.2611 -0.2715 -0.2781 -0.4442 -0.0596 -1.7340 -0.4599 -0.1422 -0.6115 -0.2404 -0.0607 -0.0533 -0.8424 -0.0932 -0.0746 -0.0840 -1.2960 -0.1722 -0.1201 -0.1457 -0.1284 -0.9500 -0.1078 -0.4779 -0.1393 -0.1939 -0.1193 -0.2871 -1.1645 -0.2332 -0.0762 -0.1345 -0.1468 -1.0999 -2.0742 -0.0982 -0.0242 -0.0636 -0.0563 -0.0583 -0.0842 -0.3342\n",
            "T-280\tbambo wina wovala malaya ofiira amizeremizere akutsamira pampando wa galimoto yake n kumaseweretsa malaya a jekete\n",
            "H-280\t-0.3311985731124878\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ a m i z e r e m i z e r e ▁ a k u t s a m i r a ▁ n d i ▁ a n t h u ▁ a l i ▁ n d i ▁ k u m a s e w e r e t s a ▁ k u m a n j a ▁ k w a k e\n",
            "D-280\t-0.3311985731124878\tmwamuna wovala malaya ofiira amizeremizere akutsamira ndi anthu ali ndi kumaseweretsa kumanja kwake\n",
            "P-280\t-0.1192 -1.4632 -2.4483 -0.1172 -0.3793 -0.0841 -0.1148 -0.1264 -0.1265 -0.2320 -0.0522 -0.8357 -0.1142 -0.0752 -0.1235 -0.1025 -1.2332 -0.0815 -0.2307 -0.1405 -0.1165 -0.1340 -0.0896 -0.0133 -0.0289 -0.0864 -0.1905 -0.3083 -0.2210 -0.0952 -0.2450 -0.1805 -0.0681 -0.0625 -0.0406 -0.0451 -0.0304 -0.1889 -0.0139 -0.0586 -0.0505 -0.0343 -0.0394 -0.0934 -0.2816 -0.1085 -0.0948 -0.7526 -0.1759 -0.0896 -0.3307 -0.1193 -0.0519 -0.1023 -0.0993 -1.0089 -0.2284 -1.1834 -0.4826 -1.0366 -0.4036 -0.0217 -0.0486 -0.1013 -0.0766 -0.8623 -1.4090 -0.0697 -0.1543 -0.7618 -0.2031 -0.1415 -0.5864 -0.5084 -1.0312 -0.0744 -0.2200 -1.0003 -0.1898 -0.3953 -0.0475 -0.0889 -0.5994 -0.0311 -0.0753 -0.1522 -0.1465 -1.2327 -0.4586 -0.1938 -0.1902 -1.6802 -0.7991 -0.1082 -0.1833 -0.6709 -0.5894 -0.4182 -0.1616 -0.0524 -0.5309\n",
            "T-281\tmunthu wovala chovala chonyezimira amachotsa m mphepete mwa msewu pogwiritsa ntchito chowuzira\n",
            "H-281\t-0.35388752818107605\t▁ m u n t h u ▁ w o v a l a ▁ c h o v a l a ▁ c h o f i i r a ▁ a m a t h a m a n g i t s a ▁ m p h e p e t e ▁ m w a ▁ m s e w u ▁ p a f u p i ▁ n d i ▁ c h i t h u n z i\n",
            "D-281\t-0.35388752818107605\tmunthu wovala chovala chofiira amathamangitsa mphepete mwa msewu pafupi ndi chithunzi\n",
            "P-281\t-0.1152 -0.0897 -0.1173 -0.1074 -0.0237 -0.0540 -0.1227 -0.1309 -0.1017 -0.0631 -0.1400 -0.1163 -0.0695 -0.1094 -0.1072 -0.6602 -0.0921 -0.9825 -0.1307 -0.0779 -0.0579 -0.1224 -0.1031 -0.0756 -0.1048 -2.0266 -1.2504 -0.2807 -0.1716 -0.0504 -0.1578 -0.1071 -0.3833 -0.0550 -0.0859 -1.9424 -0.4625 -0.1255 -0.1234 -0.1007 -0.1142 -0.0677 -0.1498 -0.1829 -0.1862 -0.0795 -0.1159 -0.0929 -2.4811 -0.3743 -0.2416 -0.0735 -0.1990 -0.0271 -0.1491 -0.0855 -0.7946 -0.1196 -0.1222 -0.1380 -0.7502 -0.5432 -0.1887 -0.1246 -0.0583 -0.2567 -1.9112 -0.2155 -0.9819 -0.0571 -0.3700 -0.1028 -0.2319 -0.5027 -0.4199 -0.1407 -0.1221 -1.7754 -0.1535 -0.1373 -2.5461 -0.8046 -0.0404 -0.7146 -0.1379 -0.1074 -0.4003\n",
            "T-16\tbambo akugwira gitala ndikugwira ntchito pa betbook ya asus pomwe bambo wina amagwiritsa ntchito apple netbook pambali pake\n",
            "H-16\t-0.39809295535087585\t▁ b a m b o ▁ a k u m e t a ▁ c h i t a l a ▁ n d i ▁ z o g w i r a ▁ n t c h i t o ▁ y a k e ▁ y a c h i k a s u ▁ p a m e n e ▁ w o v a l a ▁ m a g w i r i t s a ▁ n t c h i t o ▁ p a b w a l o ▁ l o m w e ▁ l i l i ▁ p a m b a l i ▁ p a k e\n",
            "D-16\t-0.39809295535087585\tbambo akumeta chitala ndi zogwira ntchito yake yachikasu pamene wovala magwiritsa ntchito pabwalo lomwe lili pambali pake\n",
            "P-16\t-0.1100 -0.3394 -0.1352 -0.0438 -0.0273 -0.0681 -0.1044 -1.1747 -0.0207 -0.1282 -0.2936 -0.1134 -0.3094 -0.2305 -0.1405 -1.2252 -0.0618 -0.0469 -0.1650 -0.5334 -1.0611 -0.4438 -0.1588 -1.1782 -0.0883 -0.0808 -0.1844 -0.1750 -0.4247 -0.6247 -1.2135 -0.3157 -0.0775 -0.4327 -0.1155 -0.1981 -0.1492 -0.0141 -0.0796 -0.0734 -0.0570 -0.0284 -0.1078 -0.4141 -0.3533 -1.6059 -0.2009 -0.0640 -1.6881 -0.5623 -1.7643 -0.1197 -0.0904 -1.1474 -0.1829 -0.0114 -0.2291 -0.0932 -0.5905 -0.6631 -0.4852 -0.0230 -0.0749 -0.0587 -0.0779 -2.5064 -0.7685 -1.5222 -0.1827 -0.1770 -0.1109 -0.1056 -0.8788 -0.0735 -1.1018 -0.5540 -0.0655 -0.4440 -0.0727 -0.0274 -0.1853 -0.1212 -0.1011 -0.1678 -0.0095 -0.0305 -0.1306 -0.0532 -0.0464 -0.0218 -0.0822 -0.5473 -0.4245 -2.9736 -0.8497 -0.1057 -0.0538 -0.1152 -0.1315 -0.1318 -2.3443 -0.7917 -1.0395 -0.0823 -0.2331 -0.2796 -0.0742 -1.0531 -0.0560 -0.2117 -0.0564 -0.1110 -1.3991 -0.6868 -0.0848 -0.0603 -0.2857 -0.6102 -0.1398 -0.1386 -0.9655 -0.2577 -0.0755\n",
            "T-22\twosewera mpira wachimuna wamwamuna wovala yunifolomu yakuda akuyesa kuletsa wosewera mpira wachimuna atavala yunifolomu yoyera\n",
            "H-22\t-0.25609490275382996\t▁ w o s e w e r a ▁ m p i r a ▁ w a c h i n y a m u l a ▁ m w a n a ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ y u n i f o l o m u ▁ y a k u d a ▁ a k u y e s a ▁ k u l e t s a ▁ k w a ▁ m p i r a ▁ w a c h i m u n a ▁ w i n a ▁ a t a v a l a ▁ z o y e r a\n",
            "D-22\t-0.25609490275382996\twosewera mpira wachinyamula mwana wamng ono wovala yunifolomu yakuda akuyesa kuletsa kwa mpira wachimuna wina atavala zoyera\n",
            "P-22\t-0.1061 -0.2148 -0.0482 -0.2024 -0.0874 -0.0724 -0.0859 -0.0470 -0.1260 -0.1191 -0.0155 -0.0227 -0.0892 -0.0316 -0.0745 -0.1344 -0.0812 -0.0909 -0.2376 -0.1221 -0.0474 -0.7623 -0.0332 -0.0839 -0.0536 -0.3933 -0.1206 -0.1820 -0.1045 -0.4097 -0.0373 -0.1250 -1.8378 -0.0910 -0.1567 -0.1578 -0.3219 -1.0506 -0.1748 -0.2480 -0.1370 -0.1423 -0.0244 -0.0707 -0.1659 -0.1207 -0.0602 -0.2714 -0.1374 -0.0777 -0.1239 -0.1284 -0.1499 -0.0336 -0.0154 -0.0521 -0.0204 -0.0184 -0.0301 -0.0589 -0.0277 -0.0105 -0.1161 -0.0990 -0.0885 -0.1419 -0.1834 -0.1664 -0.1998 -0.1272 -0.8568 -0.0614 -0.0990 -0.2017 -0.0777 -0.2959 -0.2733 -0.0917 -0.0518 -0.0517 -1.5609 -0.2587 -1.1076 -0.0605 -0.2282 -0.0787 -1.5409 -0.2193 -0.2312 -0.3699 -0.4395 -0.0368 -0.1277 -0.1002 -0.1016 -0.1475 -0.0412 -0.1259 -1.1866 -0.0741 -0.0456 -0.7778 -0.1110 -0.1221 -0.8978 -0.1900 -0.5836 -1.5208 -0.1319 -0.0848 -0.1630 -0.5267 -0.0166 -0.1092 -0.7817 -0.0980 -0.0352 -0.1309 -0.3219 -3.0138 -0.6667 -0.0907 -0.0464 -0.0554 -0.0765 -0.1723\n",
            " 31% 4/13 [00:11<00:22,  2.53s/it, wps=871]T-129\tgulu la anthu likuimirira ndi kumvetsera mmodzi wa gululo m dera la miyala lozunguliridwa ndi nyumba ndi mitengo\n",
            "H-129\t-0.3503485918045044\t▁ g u l u ▁ l a ▁ a n t h u ▁ l i k u i m i r i r a ▁ n d i ▁ k u m b u y o ▁ m o d z i ▁ w a u k u l u ▁ m u m l e n g a l e n g a ▁ p a z u n g u l i r i d w a ▁ n d i ▁ m i t e n g o ▁ i n a\n",
            "D-129\t-0.3503485918045044\tgulu la anthu likuimirira ndi kumbuyo modzi waukulu mumlengalenga pazunguliridwa ndi mitengo ina\n",
            "P-129\t-0.1143 -0.0436 -0.0538 -0.0750 -0.0592 -0.1007 -0.0412 -0.1013 -0.0997 -0.0971 -0.0345 -0.0216 -0.0648 -0.1025 -0.0757 -0.1230 -0.1286 -0.0707 -0.0819 -1.9860 -0.4108 -0.2856 -0.3155 -0.5933 -0.0737 -0.1132 -0.1633 -0.2415 -0.3447 -0.1396 -0.4589 -0.6975 -0.1719 -0.4007 -1.1785 -0.2712 -0.0559 -0.1562 -0.1595 -1.1722 -0.2809 -0.9483 -0.0608 -0.0713 -0.0911 -0.8841 -0.1220 -1.5689 -0.0399 -0.1128 -0.0465 -0.3635 -0.1056 -0.6956 -1.6340 -0.5849 -1.0906 -0.0404 -1.0112 -0.2743 -0.2290 -0.0204 -0.3041 -0.5086 -0.1938 -0.1962 -0.2773 -1.1653 -0.1665 -0.4912 -0.7398 -0.0192 -0.0657 -0.0419 -0.0599 -0.0546 -0.0497 -0.0415 -0.0572 -0.0668 -0.1299 -0.1337 -0.0190 -0.0769 -0.0849 -0.1026 -1.3843 -1.5001 -0.1924 -0.0843 -0.0557 -0.1163 -0.0188 -0.3302 -0.9314 -0.6824 -0.9823 -1.8548\n",
            "T-82\tosewera mpira achikazi anayi akuyesera kumenya mpira pogwiritsa ntchito mitu yawo nthawi imodzi pamasewera ovuta\n",
            "H-82\t-0.334323912858963\t▁ o s e w e r a ▁ m p i r a ▁ a c h i k a z i ▁ a n a y i ▁ a k u y e s e r a ▁ k u m b u y o ▁ k w a ▁ m p i r a ▁ w o g w i r i t s a ▁ n t c h i t o ▁ y a w o ▁ m ▁ m a d z i ▁ p a n j i n g a ▁ y a w o\n",
            "D-82\t-0.334323912858963\tosewera mpira achikazi anayi akuyesera kumbuyo kwa mpira wogwiritsa ntchito yawo m madzi panjinga yawo\n",
            "P-82\t-0.1171 -0.7059 -0.1239 -0.0545 -0.0251 -0.1078 -0.0628 -0.0977 -0.0930 -0.0838 -0.1580 -0.0784 -0.0456 -0.1141 -0.1162 -1.1308 -0.1818 -0.0793 -0.0714 -1.0230 -0.2532 -0.1313 -0.0409 -0.1167 -0.0955 -1.3187 -0.1507 -0.0735 -0.0497 -0.1281 -0.2771 -0.3490 -0.0687 -0.2106 -0.1638 -0.1502 -0.0445 -0.0243 -0.1437 -0.1062 -0.6548 -0.1147 -0.3129 -0.4853 -1.0887 -0.0089 -0.1304 -0.1039 -0.3495 -0.2096 -0.4706 -0.5999 -1.1675 -0.4267 -0.1714 -0.0476 -0.4654 -0.1532 -1.3557 -0.5312 -0.7105 -0.0254 -0.0671 -0.1247 -0.1318 -0.0314 -0.1332 -0.1322 -0.1513 -0.0227 -0.1226 -0.0193 -0.0786 -0.0637 -0.0198 -0.0230 -0.0863 -2.0460 -0.2517 -1.0590 -0.0525 -0.2798 -0.7848 -0.3646 -0.0744 -0.5026 -0.5789 -0.1265 -0.0673 -0.1795 -1.4476 -0.1611 -1.0475 -0.6936 -0.2233 -2.0637 -0.0354 -0.1680 -0.3461 -1.1904 -0.4753 -0.8163 -0.2423 -0.3336\n",
            "T-38\tazimayi atatu achikulire ali m chipinda chochezera chokongoletsedwa pa khirisimasi kope la vaio ndilofunika kwambiri\n",
            "H-38\t-0.3556457459926605\t▁ a z i m a y i ▁ a t a t u ▁ a c h i k u l i r e ▁ a l i ▁ m ▁ c h i p a n d a ▁ c h o s e w e r a ▁ c h o k o n g o l e t s e r a ▁ p a k i ▁ p a ▁ s i t e j i ▁ y a ▁ k h o p e ▁ y a w o ▁ n d i ▁ k a m e r a\n",
            "D-38\t-0.3556457459926605\tazimayi atatu achikulire ali m chipanda chosewera chokongoletsera paki pa siteji ya khope yawo ndi kamera\n",
            "P-38\t-0.1057 -0.2420 -0.0229 -0.0718 -0.0755 -0.0900 -0.0177 -0.1154 -0.0776 -0.1159 -0.1024 -0.0970 -0.1564 -0.0569 -0.0702 -0.1609 -0.4611 -0.0625 -0.0500 -0.2981 -0.1201 -0.1510 -0.0469 -0.0419 -0.0877 -0.1088 -0.1495 -0.7870 -0.1070 -0.1006 -1.1141 -0.0624 -0.2175 -0.0534 -0.1611 -0.0180 -0.1226 -0.0442 -0.0196 -0.4057 -0.1184 -0.0418 -0.0906 -0.5884 -0.9415 -0.1825 -1.1109 -0.0544 -0.1549 -0.1469 -0.1304 -0.0926 -0.0777 -2.0380 -1.2320 -0.2690 -0.5686 -0.1426 -0.1132 -0.0406 -0.0455 -0.0292 -0.0463 -0.0739 -1.2011 -0.1511 -0.1708 -0.0765 -0.1766 -0.6856 -0.6435 -0.2008 -0.6783 -0.1918 -0.4683 -0.8023 -0.4388 -0.2967 -0.9838 -0.6745 -0.0168 -0.1300 -0.4742 -0.1507 -0.8011 -0.5726 -1.3032 -0.0726 -1.1729 -0.2658 -0.1186 -0.9937 -0.2418 -1.9793 -0.2044 -0.1697 -1.0279 -0.0869 -0.0772 -0.1749 -1.7716 -0.3885 -0.3535 -1.8465 -0.0361 -0.2430 -0.8415\n",
            "T-127\tmtsikana yemwe wavala kansalu kansalu kabuluu akuvala mahula pa siteji yokhala ndi zibaluni kumbuyo kwake\n",
            "H-127\t-0.3072708249092102\t▁ m t s i k a n a ▁ y e m w e ▁ w a v a l a ▁ k a b u d u l a ▁ w o k h a l a ▁ n s a l u ▁ a k u w u l u k a ▁ m a s i t e p e ▁ a ▁ s i t e j i ▁ y o k h a l a ▁ n d i ▁ z i p a l e ▁ k u m b u y o ▁ k w a k e\n",
            "D-127\t-0.3072708249092102\tmtsikana yemwe wavala kabudula wokhala nsalu akuwuluka masitepe a siteji yokhala ndi zipale kumbuyo kwake\n",
            "P-127\t-0.1124 -0.2892 -0.0538 -0.0212 -0.0828 -0.0544 -0.1033 -0.1269 -0.1085 -0.3148 -0.2274 -0.0195 -0.0493 -0.0293 -0.1029 -0.0848 -0.0379 -0.1111 -0.0353 -0.1271 -0.0740 -0.1088 -0.1157 -0.8617 -0.1216 -0.8885 -0.0857 -0.1051 -0.1729 -0.5133 -0.3314 -0.1421 -2.6007 -0.1992 -0.1314 -0.1770 -0.1164 -0.0829 -0.1154 -0.1127 -0.2819 -1.0630 -0.0762 -0.4582 -0.0553 -0.1164 -0.2051 -0.1790 -0.1031 -3.0798 -0.6133 -0.1862 -0.1861 -0.0446 -0.0955 -0.1215 -0.3192 -0.0895 -1.7562 -0.1255 -0.0452 -0.1090 -0.4404 -0.0848 -0.1235 -0.7654 -0.5451 -2.5234 -0.9211 -0.3270 -0.1988 -0.2562 -0.0307 -0.1428 -1.5224 -0.0317 -0.9184 -0.0200 -0.1056 -0.1410 -0.1161 -0.1058 -0.1760 -0.0348 -0.1120 -0.1070 -0.9995 -0.0729 -0.3382 -0.1921 -0.7231 -0.4779 -0.0795 -0.6356 -0.2544 -0.1220 -0.0102 -0.0503 -0.0279 -0.0345 -0.2954 -0.0064 -0.0286 -0.0879 -0.1203 -0.0496 -0.0629\n",
            "T-35\tbambo wina ataimirira yekha pansi pa mtengo pa kapinga n kupukuta m maso poganizira za chitukuko cha nyumbayo\n",
            "H-35\t-0.36686262488365173\t▁ b a m b o ▁ w i n a ▁ a t a i m i r i r a ▁ p a n j i n g a ▁ n d i ▁ k a m t e n g o ▁ k a p e n a ▁ k u t i ▁ a k u t h a m a n g i t s a ▁ c h i n t h u ▁ c h a c h i k u l u ▁ c h a ▁ m b a l e\n",
            "D-35\t-0.36686262488365173\tbambo wina ataimirira panjinga ndi kamtengo kapena kuti akuthamangitsa chinthu chachikulu cha mbale\n",
            "P-35\t-0.1079 -1.7886 -0.1061 -0.0312 -0.0539 -0.0758 -0.0935 -0.0887 -0.0506 -0.2331 -0.1156 -0.1045 -0.0802 -0.1504 -0.0811 -0.6839 -0.1168 -0.2506 -0.6618 -0.1087 -0.2624 -0.1019 -0.1110 -0.3689 -0.1539 -0.6694 -0.4512 -0.1508 -0.5119 -0.1618 -0.1026 -0.1429 -0.7940 -0.1849 -0.0850 -1.1837 -0.7341 -0.0657 -0.2349 -0.3493 -1.0831 -0.0407 -0.0754 -0.4934 -0.1045 -0.1276 -0.1931 -0.7156 -1.0121 -0.0269 -0.4689 -0.1590 -0.1258 -0.1344 -0.1541 -1.1095 -0.0837 -0.2389 -2.1004 -0.2728 -0.2548 -0.6509 -0.1016 -0.3059 -0.0790 -0.0727 -0.6802 -0.2953 -0.0489 -0.0220 -0.0908 -0.0696 -0.5218 -0.0848 -0.0561 -2.7209 -0.2142 -0.0750 -0.0231 -0.1813 -0.3442 -0.0638 -0.1131 -2.6083 -0.1125 -0.0526 -0.0495 -0.3119 -0.5103 -0.0552 -0.4745 -1.6980 -0.1106 -0.3314 -0.4443 -0.5264 -0.3346 -0.0789 -0.1393 -0.2677 -1.3541\n",
            "T-230\tkamnyamata kakang ono kamene kali pa sileyi yobiriwira amadutsa paphiri la chipale chofewa dzuwa likamalowa\n",
            "H-230\t-0.31144264340400696\t▁ k a m n y a m a t a ▁ k a k a n g ▁ o n o ▁ k a m e n e ▁ k a m e t a l i ▁ p a ▁ c h i d o l e ▁ c h o b i r i w i r a ▁ a m a d u t s a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ c h i w a m a\n",
            "D-230\t-0.31144264340400696\tkamnyamata kakang ono kamene kametali pa chidole chobiriwira amadutsa pa chipale chofewa ndi chiwama\n",
            "P-230\t-0.1143 -0.1057 -0.2177 -0.0416 -0.1277 -0.1977 -0.1093 -0.0536 -0.1013 -0.0260 -0.1311 -0.1131 -0.0165 -0.0999 -0.2864 -0.1230 -0.0643 -0.0209 -0.0876 -0.0458 -0.0370 -0.0521 -0.1340 -0.2436 -0.2012 -1.5510 -0.1198 -0.0672 -0.1403 -0.1000 -0.2758 -0.1363 -0.1375 -0.1464 -0.7112 -0.2994 -0.3492 -0.0758 -0.2057 -0.2123 -0.1143 -1.4957 -0.7208 -0.1141 -0.0651 -1.3726 -0.1311 -0.9179 -0.4121 -0.1151 -1.2808 -0.1144 -0.8902 -0.4182 -0.0369 -0.0632 -0.0568 -0.0106 -0.0470 -0.0751 -0.1304 -0.1553 -0.6688 -0.0820 -0.0713 -1.5814 -1.1875 -0.0974 -0.5830 -0.1394 -0.1510 -0.1174 -0.1988 -1.9404 -0.0637 -0.1542 -0.0936 -0.0768 -0.1850 -0.0940 -0.0690 -0.0508 -0.0595 -0.0645 -0.0678 -0.0555 -0.1332 -0.0687 -0.0729 -0.2599 -0.0605 -0.0722 -0.0973 -0.1860 -1.9055 -0.1007 -0.4525 -1.2169 -1.0414 -0.2793 -0.2755 -1.6746\n",
            "T-395\tmunthu wovala malaya achikasu akugwira ntchito pa chinthu chokhala ndi mawaya ofiira ndi akuda omwe amatuluka pachivundikiro choyera\n",
            "H-395\t-0.2660597562789917\t▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ n d i ▁ c h i d o l e ▁ c h o k h a l a ▁ n d i ▁ c h o k h a l a ▁ n d i ▁ m a l o ▁ o f i i r a ▁ n d i ▁ a n t h u ▁ a w i r i ▁ a m a t u l u k a ▁ m ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-395\t-0.2660597562789917\tmunthu wovala malaya achikasu ndi chidole chokhala ndi chokhala ndi malo ofiira ndi anthu awiri amatuluka m chipale chofewa\n",
            "P-395\t-0.1176 -0.1045 -0.1310 -0.0567 -0.0276 -0.0843 -0.0849 -0.1114 -0.0995 -0.0737 -0.1035 -0.1388 -0.0768 -0.1335 -0.1011 -0.0606 -0.1049 -0.1010 -0.1212 -0.0460 -0.1219 -0.0906 -0.1812 -0.0176 -0.0412 -0.0656 -0.0210 -0.1369 -0.0564 -0.0503 -0.0743 -1.5046 -0.2853 -0.1393 -0.1284 -2.2727 -0.0727 -0.0646 -1.0590 -0.1663 -0.0702 -0.2240 -0.0958 -0.1433 -0.0712 -0.1906 -1.8716 -0.2265 -0.1054 -0.3095 -0.1360 -0.1121 -0.0422 -0.0707 -0.1126 -0.1072 -0.2045 -0.0552 -0.3953 -0.0649 -0.0782 -0.0989 -0.0695 -0.1249 -0.1109 -0.0450 -0.0494 -0.1337 -0.0995 -0.0417 -0.0756 -0.9134 -0.8461 -0.3354 -0.1716 -0.0639 -0.0433 -0.1362 -0.1034 -0.1657 -0.1318 -0.7770 -0.0367 -0.1189 -0.1307 -0.5055 -0.8183 -0.3246 -0.2703 -0.0958 -0.0745 -0.4915 -1.2613 -0.9265 -0.0494 -0.1273 -0.0787 -0.4941 -0.4561 -0.0971 -0.6908 -0.2555 -1.5972 -0.0413 -0.0192 -0.0858 -0.0843 -0.4874 -0.5355 -0.2248 -0.0530 -0.0968 -1.6167 -0.4296 -0.4786 -0.1052 -0.0743 -0.0096 -0.0673 -0.0290 -0.6107 -0.4414 -0.0516 -0.2288 -0.9332\n",
            "T-250\tamuna aku asia amakhala osalowerera ndale ngati akuyembekezera chinachake bambo wina akulankhula pa foni yake\n",
            "H-250\t-0.39476990699768066\t▁ a m u n a ▁ a k u y a n g ▁ a n a ▁ m a k a z i ▁ o s a m b i r a ▁ m ▁ m b u y o ▁ l a ▁ n g a t i ▁ a n g a t i ▁ a k u y e n d e z e k e r a ▁ c h i n a c h a k e ▁ m ▁ m b a l i ▁ m w a ▁ k u m b u y o ▁ k w a k e\n",
            "D-250\t-0.39476990699768066\tamuna akuyang ana makazi osambira m mbuyo la ngati angati akuyendezekera chinachake m mbali mwa kumbuyo kwake\n",
            "P-250\t-0.1117 -0.2682 -0.0660 -0.0728 -0.0679 -0.0860 -0.0912 -0.1127 -1.6158 -0.1646 -0.7474 -2.9182 -0.0952 -0.2489 -0.0896 -0.0875 -0.0682 -0.2418 -0.0929 -0.3516 -0.7377 -0.2371 -0.5164 -1.1531 -0.2181 -0.0856 -0.0782 -0.0925 -0.0968 -0.4027 -0.0641 -0.0651 -0.0680 -0.1029 -0.1113 -0.3352 -0.7304 -1.8056 -0.8248 -1.7645 -0.4881 -0.3909 -0.0672 -1.8392 -0.3728 -0.2411 -0.7648 -0.9000 -0.1233 -0.2363 -0.0851 -0.0676 -1.4700 -1.0815 -0.7145 -0.1534 -0.6639 -0.1930 -0.1049 -0.4371 -0.3430 -0.1188 -0.9372 -0.4692 -0.5579 -0.0283 -0.1607 -1.4889 -0.1722 -0.6023 -0.0726 -0.0736 -0.0954 -0.1064 -0.7154 -0.1347 -0.3595 -0.2035 -0.0644 -0.0693 -0.0599 -0.0979 -0.0318 -0.0674 -0.0828 -0.4516 -0.7476 -0.6672 -0.5991 -0.1013 -0.5975 -0.1254 -0.0834 -0.9624 -0.0221 -0.2658 -0.1752 -0.6818 -0.3435 -0.7890 -0.2482 -0.3869 -0.0276 -0.1008 -0.1642 -0.1344 -0.1269 -0.1500 -0.4791 -0.4894 -0.3030\n",
            "T-251\tgalu watsitsi lalitali akuthamanga pa udzu kulowera ku kamera lilime lake likulendewera pakamwa potsegula\n",
            "H-251\t-0.35208579897880554\t▁ g a l u ▁ w a ▁ t s i t s i ▁ l a l i t a l i ▁ a k u t h a m a n g a ▁ p a ▁ u d z u ▁ l o y e r a ▁ p a m e n e ▁ e n a ▁ a t a y i m i r i r a ▁ n d i ▁ g u l u ▁ l a ▁ a m a k h a l a ▁ p a ▁ m a s e w e r a\n",
            "D-251\t-0.35208579897880554\tgalu wa tsitsi lalitali akuthamanga pa udzu loyera pamene ena atayimirira ndi gulu la amakhala pa masewera\n",
            "P-251\t-0.1013 -0.0238 -0.1011 -0.0783 -0.0606 -0.0863 -0.0203 -0.2490 -0.4541 -1.3084 -0.0388 -0.0885 -0.0652 -0.0379 -0.0751 -0.0763 -0.0520 -0.1401 -0.0232 -0.0595 -0.0220 -0.1189 -0.0125 -0.0613 -0.1279 -0.8086 -0.2466 -0.0941 -2.3147 -0.1642 -0.1133 -0.0612 -0.1007 -0.0488 -0.0351 -0.1146 -0.0788 -0.3773 -0.2350 -1.2988 -0.4439 -0.4942 -0.0826 -0.0259 -0.0918 -0.8996 -0.0873 -2.0574 -0.0310 -0.0407 -0.1166 -0.1192 -1.6735 -0.1478 -0.2501 -0.0632 -0.1998 -0.0447 -0.0883 -2.5780 -0.1674 -0.0724 -0.0937 -0.1367 -0.5686 -0.1934 -1.5561 -1.2887 -0.2680 -0.0910 -0.2753 -0.0883 -0.0916 -0.0917 -0.0984 -1.3665 -0.3838 -0.1789 -0.6968 -1.0838 -0.1714 -0.1001 -0.0904 -0.1065 -0.1316 -0.3685 -0.1472 -0.4406 -1.5951 -0.6366 -0.6038 -1.3648 -0.1257 -0.1996 -0.1429 -0.1296 -0.0649 -0.1404 -0.6124 -0.4982 -0.8188 -0.0458 -0.2634 -0.5684 -0.1217 -0.1473 -0.3650 -0.1235\n",
            "T-137\tmunthu m ngalawa yobiriwira amapalasa m mabwinja atanyamula nkhafi ndipo atavala pamwamba pa lalanje ndi wakuda\n",
            "H-137\t-0.401898592710495\t▁ m u n t h u ▁ m ▁ g a l a w o ▁ l i l i ▁ n d i ▁ m p i r a ▁ a m a k h a l a ▁ p a ▁ m p a n d o ▁ w i n a ▁ a t a n y a m u l a ▁ c h i n a c h a k e ▁ n d i p o ▁ a t a v a l a ▁ p a m w a m b a ▁ p a ▁ n j i n g a ▁ y a k u d a\n",
            "D-137\t-0.401898592710495\tmunthu m galawo lili ndi mpira amakhala pa mpando wina atanyamula chinachake ndipo atavala pamwamba pa njinga yakuda\n",
            "P-137\t-0.1154 -0.0959 -0.0859 -0.0878 -0.0510 -0.0434 -0.0809 -0.1340 -0.1952 -0.4149 -1.3722 -0.1086 -0.0930 -0.6628 -1.0338 -0.6873 -0.0730 -2.0644 -0.2849 -0.6250 -0.1208 -0.0902 -0.5599 -0.1121 -0.1447 -0.1295 -0.3300 -0.3888 -0.3679 -0.0329 -0.0821 -0.1311 -0.2068 -0.3608 -0.0744 -1.3018 -0.2486 -0.1131 -0.1499 -0.1191 -0.1282 -0.9813 -0.1153 -1.0331 -1.2829 -1.0836 -0.5201 -0.3629 -0.3698 -0.5237 -0.1024 -1.2049 -0.0681 -0.1232 -0.1596 -0.1469 -1.0825 -0.2532 -0.0673 -2.0273 -0.0385 -0.0563 -0.0348 -0.0900 -0.0591 -0.1110 -0.0941 -1.7448 -0.1335 -0.0865 -1.1759 -0.9855 -0.8739 -0.0861 -0.0883 -0.1471 -0.0767 -0.0711 -0.2950 -0.2069 -0.0945 -0.9030 -0.0758 -0.1123 -0.9682 -0.3993 -0.0901 -0.1363 -0.0950 -0.0547 -0.1223 -0.0976 -2.2460 -0.2563 -0.2989 -0.6133 -0.1165 -0.1542 -0.0695 -0.1172 -0.0796 -0.1453 -0.1425 -0.3456 -0.8623 -0.1721 -0.9818 -0.7204 -0.1735 -0.0918 -0.1722 -0.6514 -0.1980 -1.9826 -1.0582 -0.0958 -0.2282 -0.8362\n",
            "T-161\tkatswiri wankhondo yemwe ali kutsogolo akuponya ntchafu ya mdani wakeyo pamene khamu la anthu ndi oweruza akuonera chapatali\n",
            "H-161\t-0.40358948707580566\t▁ m t s i k a n a ▁ w a m k u l u ▁ y e m w e ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ c h o z u n g u l i r a ▁ c h a m t e n g o ▁ p a m e n e ▁ a n t h u ▁ o m w e ▁ a l i ▁ n d i ▁ t s i t s i ▁ l o y e r a ▁ a t a k h a l a ▁ p a t e b u l o\n",
            "D-161\t-0.40358948707580566\tmtsikana wamkulu yemwe ali kutsogolo kwa chozungulira chamtengo pamene anthu omwe ali ndi tsitsi loyera atakhala patebulo\n",
            "P-161\t-0.0968 -3.0198 -0.5444 -0.1139 -0.0753 -0.1486 -0.0789 -0.1172 -0.1441 -0.0860 -0.1417 -0.1295 -0.4196 -0.1725 -1.2111 -0.4431 -0.5337 -0.1094 -1.0809 -0.0420 -0.1940 -0.0161 -0.0611 -0.0954 -0.2001 -0.0686 -0.0772 -0.1355 -0.0592 -0.6241 -0.1869 -0.3634 -0.0385 -0.0537 -0.0525 -0.0468 -0.0562 -0.1179 -0.1625 -0.3470 -0.0909 -0.1038 -0.3333 -0.0652 -2.2650 -1.3726 -0.3674 -0.0082 -0.1204 -0.0446 -0.1003 -0.0351 -0.0764 -0.1144 -0.1364 -0.7410 -0.1162 -0.2704 -1.7510 -0.6235 -0.9558 -0.0272 -0.7622 -0.0326 -0.1033 -0.5613 -0.2418 -0.1747 -0.0518 -0.0306 -0.0229 -0.0826 -2.1757 -0.6440 -0.1239 -0.0397 -0.1484 -0.0798 -2.0776 -0.6507 -0.1112 -0.0634 -0.0801 -0.0918 -1.6922 -0.1002 -0.1236 -0.6376 -0.0655 -0.0688 -0.1557 -2.3735 -0.3597 -0.8689 -0.5527 -0.2772 -0.1940 -0.0483 -0.0346 -1.0690 -0.5058 -0.1323 -0.0504 -0.0962 -0.1536 -2.1778 -0.5630 -0.1179 -2.1813 -0.6496 -0.1053 -0.0393 -0.1010 -0.1643 -0.2006 -0.1396 -2.1129 -1.0447 -0.1536 -0.0924 -0.0951 -0.0744 -0.3346\n",
            "T-390\tanyamata awiri m modzi wovala malaya abuluu ndi m modzi wa malaya akuda akuvina pamaso pa gulu loimba komanso achikulire angapo\n",
            "H-390\t-0.28639519214630127\t▁ a n y a m a t a ▁ a w i r i ▁ m m o d z i ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m m o d z i ▁ w a ▁ m a l a y a ▁ a k u d a ▁ a k u t h a m a n g a ▁ p a m a s o ▁ p a ▁ k u l u ▁ o y i m a ▁ k u m a n s o ▁ a c h i k u l i r a\n",
            "D-390\t-0.28639519214630127\tanyamata awiri mmodzi wovala malaya abuluu ndi mmodzi wa malaya akuda akuthamanga pamaso pa kulu oyima kumanso achikulira\n",
            "P-390\t-0.1107 -0.1238 -0.0447 -0.0693 -0.1151 -0.0747 -0.1041 -0.0413 -0.1118 -0.1109 -0.0884 -0.0525 -0.0949 -0.0516 -0.0955 -0.1041 -0.2543 -0.6139 -0.4730 -0.0996 -0.0353 -0.0927 -0.0757 -0.1375 -0.0463 -0.0836 -0.1041 -0.0653 -0.1355 -0.1069 -0.0576 -0.1198 -0.0467 -0.1559 -0.0471 -0.1633 -0.0800 -0.2280 -0.1066 -0.1386 -0.0445 -0.1024 -0.0299 -0.0846 -0.0391 -0.0595 -0.0910 -0.0980 -0.1548 -1.4218 -0.1890 -0.0463 -0.1090 -0.0575 -0.0724 -0.0505 -0.5622 -1.1056 -1.0140 -0.4691 -0.3766 -0.1508 -0.0165 -0.1286 -0.0872 -0.1387 -0.1275 -0.1000 -0.1154 -0.1824 -0.0986 -0.1353 -0.1307 -0.1168 -2.2824 -0.1697 -0.1125 -0.1591 -0.1378 -0.0892 -0.2461 -0.5851 -0.0839 -0.0450 -0.1292 -0.8721 -0.2926 -0.0690 -0.0411 -0.0699 -0.3715 -0.1852 -0.1717 -1.1642 -0.8598 -0.5460 -0.5504 -0.7911 -1.3592 -0.8913 -0.2668 -0.0974 -0.6568 -0.1354 -0.8965 -0.4080 -0.5954 -0.2711 -0.4584 -1.6593 -0.0270 -0.0708 -0.2776 -1.3889 -0.1027 -0.1746 -0.1321 -0.1316 -0.0156 -0.1681 -0.0628 -0.4916 -1.8961\n",
            "T-319\tmwamuna wovala jekete lamasewera wokhala ndi tsitsi lalitali lofiirira ndi magalasi akutenga chidwi ndi ojambula angapo\n",
            "H-319\t-0.2366403490304947\t▁ m w a m u n a ▁ w o v a l a ▁ j e k e t e ▁ a m a s e w e r a ▁ o k h a l a ▁ n d i ▁ t s i t s i ▁ l a l i t a l i ▁ l o f i i r i r a ▁ n d i ▁ m a g a l a s i ▁ a k u d i k i r i d w a ▁ n d i ▁ m a n j a ▁ a k u y a n g ▁ a n a\n",
            "D-319\t-0.2366403490304947\tmwamuna wovala jekete amasewera okhala ndi tsitsi lalitali lofiirira ndi magalasi akudikiridwa ndi manja akuyang ana\n",
            "P-319\t-0.1108 -0.1251 -0.0313 -0.1026 -0.1854 -0.0793 -0.0779 -0.1143 -0.1008 -0.0658 -0.4325 -0.0403 -0.1125 -0.0661 -0.1170 -0.1003 -0.1628 -0.3254 -0.1114 -0.1155 -0.0166 -0.1410 -0.1004 -1.7610 -0.1522 -0.0708 -0.2102 -0.1119 -0.0236 -0.1493 -0.0750 -0.1038 -0.1242 -0.8256 -0.0776 -0.0947 -0.1138 -0.0808 -0.1086 -0.1000 -0.0323 -0.0528 -0.1166 -0.0976 -1.6114 -0.0423 -0.0358 -0.0415 -0.0521 -0.0918 -0.0773 -0.3187 -0.1596 -0.1141 -0.0536 -0.0518 -0.0803 -0.0197 -0.0576 -0.1316 -0.5491 -0.0736 -0.0838 -0.0383 -0.0967 -0.0410 -0.4785 -0.0330 -0.1337 -0.1140 -0.8498 -0.1495 -0.0965 -0.1815 -0.2557 -0.0850 -0.2915 -0.2702 -0.0877 -0.1130 -0.0213 -0.0298 -0.0815 -0.2024 -0.0888 -0.1286 -0.5475 -0.9941 -0.6725 -0.0248 -0.2205 -0.3637 -1.8868 -0.0312 -0.1340 -0.1233 -0.6059 -0.1170 -0.0985 -0.1892 -0.5614 -0.7809 -0.4441 -0.1354 -0.0843 -0.3710 -1.2648 -0.0991 -0.5938 -1.7744 -0.0986 -0.1001 -0.0881 -0.1313 -0.0916 -0.0571 -0.1145 -0.2931\n",
            "T-282\tachinyamata asanu ndi mmodzi akujambula chithunzi m sitima yapansi panthaka\n",
            "H-282\t-0.3892377018928528\t▁ a n y a m a t a ▁ a t a t s a m i r a ▁ m ▁ m o d z i ▁ a k u g w i r a ▁ n t c h i t o ▁ z i n t h u ▁ z a k e ▁ a m a k h a l a ▁ p a n s i\n",
            "D-282\t-0.3892377018928528\tanyamata atatsamira m modzi akugwira ntchito zinthu zake amakhala pansi\n",
            "P-282\t-0.1120 -0.2080 -0.1116 -0.1013 -0.0978 -0.0486 -0.0910 -0.0398 -0.1080 -0.1226 -0.1219 -0.5794 -0.2044 -0.3936 -0.5775 -0.0999 -1.4890 -0.1681 -0.1053 -0.1117 -0.1544 -0.3825 -1.3570 -0.1322 -0.3421 -0.1736 -0.1408 -0.0648 -0.1117 -0.7556 -0.0527 -0.0966 -1.3585 -0.1754 -0.1356 -0.0804 -0.1199 -0.1397 -0.7038 -0.0131 -0.1750 -0.1274 -0.1410 -0.0067 -0.1713 -0.1018 -1.1499 -0.5394 -0.5429 -0.2161 -0.2241 -0.0819 -0.1523 -1.5856 -0.3566 -1.0780 -0.8269 -0.1033 -1.4076 -1.5327 -0.1026 -1.9948 -0.6592 -0.1871 -0.2068 -0.1249 -0.1628 -0.7538 -0.1357 -0.9248 -0.3448 -0.0920 -0.8227\n",
            "T-348\tmunthu akusuzumira pazipangizo zake zowonera zinthu akuyang ana chinachake m chizimezime\n",
            "H-348\t-0.3558260500431061\t▁ m u n t h u ▁ a k u z u n g u l i r a ▁ z i p a n g o ▁ z i z a k e ▁ z o w o n e r a ▁ n d i ▁ n t h u ▁ a k u y a n g ▁ a n a ▁ c h i n a c h a k e ▁ c h a ▁ m i z e r e\n",
            "D-348\t-0.3558260500431061\tmunthu akuzungulira zipango zizake zowonera ndi nthu akuyang ana chinachake cha mizere\n",
            "P-348\t-0.1077 -0.1176 -0.0966 -0.0788 -0.0297 -0.0370 -0.0603 -0.1395 -0.1065 -0.1343 -0.0826 -1.8266 -0.0919 -0.1419 -0.5854 -0.3846 -0.1434 -0.0566 -0.0324 -0.1108 -0.1126 -1.4262 -0.0236 -0.2524 -0.1255 -1.5595 -0.0638 -0.2422 -0.1244 -0.0412 -0.3234 -1.5597 -1.0225 -0.6379 -0.0631 -0.1399 -0.0139 -0.6268 -1.0530 -0.3696 -0.0500 -0.0886 -0.9772 -0.1361 -0.1587 -0.7370 -1.9023 -0.0980 -0.1993 -1.2626 -0.5720 -0.1077 -0.3567 -0.2614 -0.9374 -0.1130 -0.1139 -0.0132 -0.0900 -0.0637 -0.0474 -0.1248 -0.0829 -0.0868 -0.1189 -0.1254 -0.0398 -0.0823 -0.1634 -0.4035 -0.2921 -0.0366 -0.0499 -0.0804 -0.0790 -0.0237 -0.2928 -0.5448 -0.0799 -0.4740 -0.6340 -1.8369 -0.8240 -0.8885 -0.6356 -0.1021 -0.0321 -0.7473\n",
            "T-391\tbambo wina wovala thukuta la buluu komanso mwana wovala sweti yofinya akuyenda molunjika mumzinda womwe munadzaza anthu\n",
            "H-391\t-0.27685093879699707\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ t h u k u t a ▁ l a ▁ b u l u u ▁ k o m a n s o ▁ m w a n a ▁ w o v a l a ▁ s u t i ▁ y o f i i r a ▁ a k u y e n d a ▁ m u m z i n d a ▁ w o m w e ▁ u l i ▁ m o d z a z a ▁ a n t h u\n",
            "D-391\t-0.27685093879699707\tbambo wina wovala thukuta la buluu komanso mwana wovala suti yofiira akuyenda mumzinda womwe uli modzaza anthu\n",
            "P-391\t-0.1121 -0.0151 -0.1058 -0.0486 -0.0383 -0.0843 -0.0935 -0.0571 -0.0865 -0.0792 -0.1224 -0.1147 -0.0377 -0.1135 -0.1459 -0.1392 -0.1274 -0.1168 -0.1035 -0.1372 -0.0826 -0.0744 -0.0349 -0.0454 -0.0400 -0.0808 -0.1080 -1.3523 -0.0852 -0.2871 -1.8309 -0.1888 -0.1164 -0.0594 -0.0420 -0.0927 -1.5732 -0.1044 -0.0215 -0.0798 -0.0231 -0.0216 -0.0264 -0.0848 -0.0408 -1.6512 -0.1595 -0.3171 -0.1069 -0.1309 -0.0344 -0.1844 -0.2432 -0.1313 -0.0747 -0.1093 -0.1112 -0.2342 -1.4908 -0.1349 -0.0446 -0.0958 -0.0976 -0.3390 -0.0275 -0.0683 -0.3574 -0.1610 -0.2351 -0.1242 -0.2493 -0.1671 -0.1509 -1.0568 -0.0807 -0.0555 -0.0394 -0.1062 -0.1139 -0.0634 -0.1829 -0.1854 -0.5019 -0.0603 -0.1014 -0.0089 -0.0779 -0.1013 -1.7656 -0.1423 -1.0245 -0.0501 -0.0813 -0.1236 -2.0632 -1.2273 -0.1413 -0.0911 -0.2148 -0.2588 -0.3039 -0.0225 -0.5895 -0.6729 -0.1112 -0.2889 -1.1506 -0.8584 -0.2627 -0.0414 -0.0804 -1.0980\n",
            "T-289\tbanja lina likuyang ana anyamata awiri aang ono akuwasonyeza chinthu kunja kwa barani pamene atsikana aang ono awiri aima cham mbali\n",
            "H-289\t-0.37145671248435974\t▁ m n y a m a t a ▁ a k u y a n g ▁ a n a ▁ m n y a m a t a ▁ w i n a ▁ a k u m w e t u l i r a ▁ k u w a t s o g o l o ▁ n d i ▁ c h i n t h u ▁ p a m e n e ▁ m p a n d a ▁ w i n a ▁ p a m e n e ▁ m k a z i ▁ a k u y a n g ▁ a n a ▁ m ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-289\t-0.37145671248435974\tmnyamata akuyang ana mnyamata wina akumwetulira kuwatsogolo ndi chinthu pamene mpanda wina pamene mkazi akuyang ana m chipale chofewa\n",
            "P-289\t-0.1044 -0.6836 -1.9492 -0.3508 -0.1102 -0.1341 -0.1056 -0.1577 -0.0997 -0.1205 -0.7442 -0.2729 -0.0913 -0.0167 -0.1625 -0.0417 -0.1053 -0.0971 -0.0983 -0.0495 -0.2077 -0.1199 -0.2906 -2.1381 -0.0289 -0.1512 -0.2338 -0.0981 -0.0210 -0.0863 -0.0861 -0.2736 -0.1262 -0.7696 -0.1122 -0.1245 -0.3122 -0.5003 -0.0801 -0.9916 -0.3224 -0.5545 -0.0656 -0.2077 -0.0219 -0.0579 -0.0385 -0.1144 -0.1235 -1.1384 -1.3028 -1.4228 -0.1589 -0.9323 -0.0790 -0.3652 -0.0757 -0.7537 -0.4418 -0.9951 -0.1095 -0.5009 -0.1141 -0.0887 -0.1172 -0.2485 -0.0515 -0.0856 -1.0273 -0.0258 -0.0430 -0.0329 -0.0973 -1.1463 -0.2327 -1.9420 -1.2069 -0.0687 -0.0636 -0.0823 -1.1734 -0.7482 -0.4687 -0.1722 -0.0824 -0.2490 -0.0918 -0.5536 -0.1478 -0.0815 -0.1028 -0.2251 -0.3834 -0.1921 -0.5921 -0.2383 -0.0693 -0.0405 -0.0822 -1.8393 -0.9704 -0.0917 -0.3167 -0.0611 -0.0789 -1.1824 -1.1054 -0.1364 -1.9359 -0.2426 -0.0557 -0.0315 -0.0800 -0.0935 -0.0401 -0.1884 -0.1548 -1.9226 -0.9412 -1.4772 -0.1033 -0.4433 -0.1268 -0.2043 -0.0584 -0.0380 -0.2307 -0.0750 -0.0892 -0.3559 -0.1849 -0.5061 -0.1366 -0.1144 -0.1359\n",
            "T-100\tazimayi awiri wina atavala mpango ndipo wina atavala chipewa chachikulu akugunda chakudya chomwe chili patebulo lachikale lokhala ndi malaya amatabwa\n",
            "H-100\t-0.26486554741859436\t▁ a z i m a y i ▁ a w i r i ▁ w i n a ▁ a t a v a l a ▁ m p a n g o ▁ n d i p o ▁ w i n a ▁ a t a v a l a ▁ c h i p e w a ▁ c h a c h i k u l u ▁ a k u d a ▁ c h a k u d a ▁ c h o m w e ▁ c h i l i ▁ p a t e b u l o ▁ l a c h i k a s u ▁ l o k h a l a ▁ n d i ▁ m a t a l a\n",
            "D-100\t-0.26486554741859436\tazimayi awiri wina atavala mpango ndipo wina atavala chipewa chachikulu akuda chakuda chomwe chili patebulo lachikasu lokhala ndi matala\n",
            "P-100\t-0.1127 -0.0863 -1.0169 -0.0993 -0.0342 -0.1062 -0.0277 -0.0731 -0.0747 -0.0821 -0.0079 -0.1016 -0.0573 -0.1084 -0.0780 -3.0692 -0.1323 -0.1124 -0.1367 -0.1041 -0.0773 -0.0127 -0.0952 -0.0618 -0.0963 -0.0866 -0.1073 -0.1007 -0.1628 -0.0640 -0.3616 -0.0935 -1.0677 -0.1069 -0.0902 -0.7006 -0.0535 -0.0685 -0.0290 -0.0402 -0.0851 -0.6440 -0.0458 -0.0519 -0.1533 -0.1415 -0.2537 -0.0202 -0.0896 -0.0435 -0.1137 -0.0875 -0.1139 -0.1040 -0.6320 -0.1216 -0.0603 -0.6294 -0.0250 -0.0395 -0.1005 -0.1165 -0.0148 -0.0587 -0.0839 -1.3650 -0.1541 -0.0558 -0.0611 -0.1252 -0.0462 -0.1486 -0.1173 -0.1839 -0.0677 -0.1223 -0.8747 -0.1513 -0.1187 -0.8174 -0.1226 -0.3073 -0.3679 -0.0996 -0.5464 -0.2447 -0.0985 -0.0777 -0.0905 -0.9284 -0.1847 -0.8267 -0.1600 -0.1067 -0.0280 -0.0575 -0.0496 -0.0600 -0.0752 -0.0969 -0.1227 -0.1022 -2.6491 -0.1300 -0.0625 -0.0458 -0.0587 -0.0312 -0.0720 -0.2514 -0.2957 -1.9842 -0.0670 -0.0508 -0.0329 -0.2125 -1.2822 -0.0745 -0.0716 -0.2610 -1.1771 -0.1241 -0.2214 -0.1284 -0.0631 -0.1595 -0.0850 -0.0774 -0.1232 -0.1302 -0.1573 -0.0577 -0.0529 -1.0873 -0.2039 -1.2952 -0.2909 -1.3934\n",
            "T-197\tmunthu wovala chovala chabulauni ndi chipewa chachikulu chooneka ngati koloko atakhala pamasitepe okhala ndi mbale za zinthu zofiira\n",
            "H-197\t-0.266388863325119\t▁ m u n t h u ▁ w o v a l a ▁ c h o v a l a ▁ c h a ▁ b u l a u n i ▁ n d i ▁ c h i p e w a ▁ c h a c h i k u l i r e ▁ k u t s o g o l o ▁ k w a ▁ c h i k w a n g w a n i ▁ p a k a t i ▁ p a ▁ m u m s e w u ▁ w o k h a l a ▁ n d i ▁ z o f i i r a\n",
            "D-197\t-0.266388863325119\tmunthu wovala chovala cha bulauni ndi chipewa chachikulire kutsogolo kwa chikwangwani pakati pa mumsewu wokhala ndi zofiira\n",
            "P-197\t-0.1122 -0.1421 -0.1200 -0.0701 -0.0288 -0.0832 -0.0942 -0.1353 -0.0573 -0.0929 -0.1543 -0.1125 -0.1093 -0.1267 -0.0994 -0.0457 -0.0704 -0.1677 -0.0346 -0.1046 -0.1029 -0.1317 -0.0945 -0.0166 -0.0652 -0.1068 -1.1312 -0.1842 -0.3934 -0.0836 -0.3253 -0.1607 -0.0727 -0.1196 -0.0972 -0.4346 -0.0724 -0.1278 -0.1346 -0.0894 -0.0647 -0.0595 -0.0621 -0.1189 -0.0308 -0.0994 -0.1055 -0.0067 -0.0406 -0.1494 -0.1443 -0.0779 -0.0591 -0.0409 -0.0961 -0.0146 -1.5300 -0.3841 -0.6961 -0.1128 -1.0590 -0.3918 -0.5488 -0.1372 -0.0416 -0.0187 -0.1393 -0.0948 -0.0490 -0.1069 -0.3428 -0.0347 -0.1748 -0.1040 -1.5396 -0.0991 -0.0713 -0.7770 -0.1332 -0.8429 -2.8515 -0.0262 -0.1254 -0.2669 -0.8278 -0.0783 -0.0949 -0.8683 -0.2882 -1.3591 -0.1705 -0.1416 -0.3975 -0.1036 -0.1294 -0.2238 -0.1726 -0.5195 -2.7206 -0.2560 -0.1616 -0.4907 -0.1265 -0.0250 -0.1366 -0.1746 -0.1813 -0.0960 -0.1094 -0.1436 -0.1033 -0.1961 -0.0976 -0.0601 -0.0505 -0.0861 -0.0772 -0.2095 -0.5457 -0.9233 -0.0539 -0.0811 -0.0511 -0.2515 -0.7389\n",
            "T-43\tbambo yemwe wavala juzi jinzi ndi bereti yobiriwira amagonera pogwiritsira ntchito makina opangira makina\n",
            "H-43\t-0.322048544883728\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ j e a n s ▁ n d i ▁ c h i p e w a ▁ n d i ▁ j e k e t e ▁ y o f i i r a ▁ a m a k w e r a ▁ p a m e n e ▁ a k u k w e r a ▁ c h i n t h u ▁ c h o m a n g i d w a ▁ m ▁ m a n j a ▁ m w a k e\n",
            "D-43\t-0.322048544883728\tbambo wina wovala jeans ndi chipewa ndi jekete yofiira amakwera pamene akukwera chinthu chomangidwa m manja mwake\n",
            "P-43\t-0.1084 -0.2297 -0.1216 -0.0291 -0.0383 -0.0416 -0.1422 -0.0723 -0.0657 -0.1241 -0.1244 -0.1151 -0.1695 -0.4914 -0.0541 -0.1101 -0.0820 -0.1048 -0.1017 -0.6456 -0.6118 -0.2909 -0.0288 -0.0304 -0.1514 -1.5820 -0.1516 -0.0739 -0.1330 -2.1279 -0.1377 -0.0918 -2.0187 -0.1840 -0.1332 -0.1700 -0.1696 -0.9659 -0.0770 -0.1042 -0.2893 -1.1305 -0.5813 -0.1011 -0.0393 -0.0618 -0.0518 -0.0825 -0.2794 -0.0816 -0.4645 -0.0520 -0.2501 -0.0386 -0.2099 -0.1165 -0.2355 -0.5111 -0.0811 -0.8459 -1.9920 -1.3023 -0.0627 -0.2606 -0.1322 -0.3606 -0.9148 -0.2436 -0.3331 -0.0616 -0.0403 -0.1070 -0.6607 -0.2637 -0.1495 -1.4478 -0.3125 -0.2073 -0.1044 -0.1031 -0.1105 -1.0334 -0.0727 -0.0635 -0.4381 -0.1139 -0.0961 -0.0553 -0.1080 -0.4638 -0.0558 -0.1538 -0.0488 -0.3320 -0.0173 -0.4711 -0.1281 -1.5616 -0.0826 -0.1117 -0.1525 -0.4877 -0.9323 -0.1488 -0.1173 -0.8730 -0.0442 -0.0801 -1.1342 -0.3299 -0.2099 -0.1095 -0.0574 -0.0246 -0.0469\n",
            "T-357\tamuna awiri omwe akuthamanga ndi zizindikiro zokhala ndi manambala pamalaya awo akuyesa kulumpha chipika chomwe chili panjira yawo\n",
            "H-357\t-0.2986125349998474\t▁ a m u n a ▁ a w i r i ▁ o m w e ▁ a k u t h a m a n g a ▁ m ▁ m a d z i ▁ n d i ▁ z i k o ▁ z o k h a l a ▁ n d i ▁ m a n j a ▁ a m b a l a m b a ▁ p a ▁ m a l a y a ▁ o y e r a ▁ a k u i k a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-357\t-0.2986125349998474\tamuna awiri omwe akuthamanga m madzi ndi ziko zokhala ndi manja ambalamba pa malaya oyera akuika chipale chofewa\n",
            "P-357\t-0.1134 -0.0856 -0.1078 -0.1319 -0.0704 -0.0966 -0.0897 -0.0993 -0.0362 -0.1693 -0.0555 -0.1155 -0.1065 -0.1056 -0.2022 -0.0565 -0.0607 -0.0822 -0.0463 -0.8779 -0.0543 -2.8018 -0.0980 -0.0790 -0.0499 -0.0868 -0.0341 -0.0386 -0.1221 -0.0675 -0.9538 -0.1324 -0.3954 -0.0893 -0.2331 -0.1357 -0.0455 -0.1004 -0.0265 -0.0725 -0.0845 -0.1313 -0.0828 -0.1034 -1.1381 -0.2750 -0.2276 -0.1341 -0.1015 -0.0252 -0.1340 -0.1524 -0.0845 -0.1130 -0.0904 -0.0500 -0.0798 -0.0919 -0.1234 -0.3304 -0.2497 -1.2616 -0.1247 -0.1143 -0.0915 -0.5506 -1.0772 -0.2398 -0.3277 -0.0727 -0.1228 -1.2319 -0.7378 -0.1811 -0.1339 -0.3388 -0.1362 -0.9853 -0.5572 -0.1138 -0.1497 -0.7379 -0.0454 -0.1725 -0.0704 -0.1188 -1.5563 -0.0754 -0.3057 -0.1095 -0.1013 -0.6590 -0.0765 -0.0940 -1.1712 -1.9009 -0.5206 -0.0755 -0.0949 -0.0878 -0.2930 -0.7517 -0.2493 -0.3646 -0.1878 -0.0631 -0.0105 -0.0828 -0.0293 -0.4478 -0.3513 -0.0177 -0.0817 -2.4604\n",
            "T-80\tosewera mpira akusewera masewero ausiku ndipo mpira uli mmwamba pomwe matimu awiriwa akumenyera nkhondo\n",
            "H-80\t-0.34599101543426514\t▁ o s e w e r a ▁ m p i r a ▁ a k u s e w e r a ▁ m a s e w e r a ▁ o t s e t s e r a ▁ p a w o ▁ n d i p o ▁ m p i r a ▁ w i n a ▁ m ▁ m b a l i ▁ m w a c h i m u n z i r o ▁ a w i r i ▁ a k u m e n y a\n",
            "D-80\t-0.34599101543426514\tosewera mpira akusewera masewera otsetsera pawo ndipo mpira wina m mbali mwachimunziro awiri akumenya\n",
            "P-80\t-0.1159 -0.4459 -0.0669 -0.0683 -0.0156 -0.1015 -0.0533 -0.1082 -0.1191 -0.1743 -0.0127 -0.0916 -0.0420 -0.1009 -0.1165 -0.1604 -0.0257 -0.0908 -0.0690 -0.0504 -0.0493 -0.1195 -0.0523 -0.1024 -0.1108 -0.1083 -0.2011 -0.1118 -0.1219 -0.0458 -0.0586 -0.0617 -0.1122 -0.1425 -0.1037 -1.5025 -0.3523 -0.0788 -0.9896 -0.0993 -0.0319 -0.0387 -0.9447 -0.2064 -2.9019 -0.2695 -1.5418 -0.3969 -0.3229 -0.2679 -0.1710 -0.1095 -0.1907 -0.0530 -0.1158 -0.4903 -0.8797 -0.2234 -0.1500 -0.1057 -0.1690 -0.4767 -0.3376 -0.1007 -0.1319 -0.1184 -1.7405 -0.0765 -0.2723 -1.9055 -0.1034 -1.2254 -0.6867 -0.1250 -0.0223 -0.1660 -0.1659 -1.3107 -0.1086 -0.0710 -0.8651 -0.8199 -0.4872 -2.2970 -0.1056 -0.4828 -0.3747 -0.1559 -0.4600 -0.2438 -0.2041 -0.0326 -0.0812 -0.1204 -0.5570 -0.2011 -0.1145 -0.6986 -0.1881 -0.0683 -0.0563 -0.1531 -1.5909\n",
            "T-202\tmtsikana wina wamng ono atavala pinki akuyang ana wina yemwenso atavala pinki adalumpha pa trampoline\n",
            "H-202\t-0.29263371229171753\t▁ m t s i k a n a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a k u y a n g ▁ a n a ▁ m p a n d a ▁ w i n a ▁ a k u y e n d a ▁ m ▁ m i s e w u ▁ y e m w e ▁ a t a v a l a ▁ t h a l a u z a ▁ l a b u l u u\n",
            "D-202\t-0.29263371229171753\tmtsikana wina wovala malaya apinki akuyang ana mpanda wina akuyenda m misewu yemwe atavala thalauza labuluu\n",
            "P-202\t-0.1292 -0.2736 -0.0355 -0.0330 -0.0388 -0.0405 -0.1019 -0.0847 -0.1208 -0.1193 -0.0729 -0.0644 -0.1053 -0.1073 -0.1049 -0.0693 -0.8477 -2.2949 -0.1171 -0.1337 -0.1166 -0.1096 -0.0525 -0.2767 -0.4615 -0.1250 -0.0812 -0.0911 -0.0799 -0.8369 -0.3768 -0.0766 -0.0256 -0.0246 -0.0354 -0.1198 -0.0973 -0.0233 -0.0971 -1.2562 -0.1455 -0.0848 -0.0517 -0.0764 -0.0912 -0.0811 -0.1433 -0.1023 -0.9015 -2.7075 -1.0980 -0.0704 -0.0573 -0.0875 -0.1097 -0.0683 -0.0510 -0.1375 -0.1221 -0.1181 -0.7277 -0.6078 -0.0636 -0.0537 -1.8374 -0.1586 -0.0579 -0.0943 -0.1189 -0.2518 -0.7962 -0.3825 -0.2108 -0.5625 -0.6269 -0.2164 -0.0779 -0.0790 -1.1028 -0.2007 -0.0372 -0.0483 -0.2125 -0.0974 -0.1010 -0.3089 -0.1482 -0.6185 -0.1077 -0.0725 -0.1208 -0.0891 -1.1732 -0.7726 -0.2093 -0.5010 -0.1350 -0.0740 -0.3409 -0.0943 -0.1511 -0.1350 -0.2123 -1.1589 -0.0695 -0.0718 -0.2493 -0.0552 -0.7406\n",
            "T-121\tbambo wina atavala suti ya njinga yamoto yophimbidwa akukhala panjinga yamoto akukweza dzanja lake\n",
            "H-121\t-0.25909993052482605\t▁ b a m b o ▁ w i n a ▁ a t a v a l a ▁ s u t i ▁ y a ▁ n j i n g a ▁ y a m o t o ▁ y a m o t o ▁ n d i p o ▁ a k u k h a l a ▁ p a n j i n g a ▁ y a m o t o ▁ k u k w e z a ▁ n j a n j i\n",
            "D-121\t-0.25909993052482605\tbambo wina atavala suti ya njinga yamoto yamoto ndipo akukhala panjinga yamoto kukweza njanji\n",
            "P-121\t-0.1185 -0.0551 -0.1135 -0.0310 -0.0553 -0.0592 -0.1061 -0.0812 -0.0814 -0.1088 -0.1394 -0.1129 -0.3280 -0.0357 -0.0977 -0.0449 -0.0992 -0.1055 -0.1037 -0.1129 -0.2393 -0.0299 -0.0174 -0.0445 -0.0878 -0.0182 -0.2360 -0.7581 -0.5636 -0.4351 -0.6963 -0.0931 -0.2127 -0.1078 -0.1506 -0.0019 -0.1213 -0.1053 -0.0138 -0.0112 -0.0164 -0.1302 -0.1565 -0.2392 -1.9730 -0.2507 -0.0329 -0.0619 -0.1940 -0.7864 -0.0552 -0.1021 -0.5068 -0.0602 -0.1021 -0.1274 -0.1158 -0.2090 -0.2390 -1.3692 -0.1399 -0.1575 -0.1232 -0.0834 -2.3954 -0.1368 -0.1607 -0.1965 -0.1547 -0.0813 -0.1145 -0.0956 -0.1190 -0.0834 -0.0879 -1.4172 -0.0211 -0.0768 -0.0916 -0.1620 -1.7311 -0.1411 -0.5185 -0.3212 -0.0550 -0.0464 -0.1714 -0.1467 -0.9445 -0.0689 -0.2257 -0.2460 -0.0572 -0.6261 -0.7541\n",
            "T-70\twoimba wina wamkazi atavala diresi lakuda akukokera maikolofoni pamene oimba atatu akuimba zoimbira za zingwe\n",
            "H-70\t-0.3652157783508301\t▁ w o y i m b a ▁ w i n a ▁ w a m k a z i ▁ a t a v a l a ▁ t h a l a u z a ▁ l a k u d a ▁ a k u j a m b u l a ▁ m a i k o l o f o n i ▁ p a m e n e ▁ w a m n y a m a t a ▁ w i n a ▁ a k u j a m b u l i r a ▁ z i n g w e ▁ z a z i k u l u\n",
            "D-70\t-0.3652157783508301\twoyimba wina wamkazi atavala thalauza lakuda akujambula maikolofoni pamene wamnyamata wina akujambulira zingwe zazikulu\n",
            "P-70\t-0.1079 -0.3298 -0.1812 -0.2229 -0.4537 -0.2520 -0.1798 -0.1532 -0.1088 -0.1101 -0.0777 -0.0676 -0.1223 -0.0991 -0.2134 -1.4395 -1.0170 -0.0694 -0.1702 -0.3572 -0.1199 -0.1122 -0.0864 -0.0328 -0.1031 -0.0630 -0.1073 -0.0952 -0.0990 -0.1002 -2.3809 -1.0202 -0.0786 -0.4415 -0.1247 -0.2293 -0.1694 -0.1762 -0.1122 -0.3771 -0.2947 -0.6167 -0.2216 -0.0695 -0.1549 -0.1048 -0.1665 -0.0713 -0.1355 -2.5218 -0.0795 -0.0882 -0.3988 -0.0702 -0.1099 -0.1803 -0.1169 -2.5103 -0.1261 -1.1366 -0.0728 -0.0804 -0.0429 -0.0133 -0.3483 -0.0242 -0.1451 -0.0573 -0.1110 -0.5435 -0.1660 -0.2929 -0.0429 -0.0737 -0.0663 -0.0873 -1.0382 -0.6880 -1.0116 -2.3363 -0.1554 -0.1005 -0.0390 -0.6108 -0.0266 -0.0815 -0.1079 -0.4949 -0.4163 -0.4015 -0.1111 -0.1088 -0.1750 -0.6232 -0.1236 -2.9609 -0.1398 -0.1328 -0.0105 -0.7526 -0.0943 -0.8187 -0.6206 -0.1067 -0.1614 -0.0640 -0.2464 -0.8971 -1.0508 -0.3251 -0.1392 -0.7612 -0.0089 -0.2295 -0.1103 -0.0519 -1.3729 -0.5153 -0.1176 -0.2029 -0.5457\n",
            "T-186\tmayi wina akuliza piyano yopakidwa malo pafupi ndi bambo wina amene waimirira n kumaimba chojambulira chamatabwa\n",
            "H-186\t-0.32903650403022766\t▁ m a y i ▁ w i n a ▁ a k u g w i r a ▁ n t c h i t o ▁ y o p a n g i d w a ▁ n d i p o ▁ m w a m b a ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w i n a ▁ w a i m i r i r a ▁ k u m b a l i ▁ c h i n g w e ▁ c h o f i i r a ▁ c h a m a t a b w a\n",
            "D-186\t-0.32903650403022766\tmayi wina akugwira ntchito yopangidwa ndipo mwamba pafupi ndi bambo wina waimirira kumbali chingwe chofiira chamatabwa\n",
            "P-186\t-0.1212 -0.0610 -0.0789 -0.0308 -0.0783 -0.0933 -0.0335 -0.0801 -0.0639 -0.1072 -0.1062 -0.1420 -0.1454 -0.0836 -2.6412 -0.1366 -0.0677 -0.1163 -0.5736 -0.1053 -1.4843 -0.7488 -0.4413 -0.2556 -0.0980 -0.1044 -0.1572 -0.0819 -0.0497 -1.3567 -1.0138 -0.1836 -0.0430 -0.1108 -0.0765 -0.0954 -0.0186 -0.1085 -0.1391 -0.2378 -0.0854 -0.0595 -0.4221 -0.0624 -0.1080 -2.0855 -0.6207 -0.1400 -0.4726 -1.0754 -0.1196 -0.1322 -0.4029 -0.1367 -0.0704 -0.0610 -0.0358 -0.0533 -0.0976 -0.0517 -0.1247 -0.0752 -0.1567 -1.8819 -0.2390 -0.1815 -0.0779 -0.0587 -0.1294 -0.0260 -0.0632 -0.1024 -0.1172 -0.1894 -0.4327 -0.1806 -0.1809 -0.1469 -0.2601 -0.0964 -0.0532 -0.0228 -0.1083 -0.0998 -0.0371 -0.0804 -0.0596 -0.6507 -0.6201 -0.1423 -0.0600 -0.0974 -0.3650 -0.0679 -0.9945 -0.8738 -1.0589 -0.3083 -0.3200 -0.1210 -0.0055 -0.0747 -0.1416 -2.1010 -1.2454 -0.2380 -0.0363 -0.1440 -0.2293 -1.4834 -0.0730 -0.5008 -1.6257 -0.1892 -1.7130 -0.1186 -0.3527 -0.0108 -0.0667 -0.3092\n",
            "T-111\twosewera wa dodgers adangomenya tag yachitatu baseman mumasewera oyandikira kwambiri\n",
            "H-111\t-0.3877798020839691\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ j e k e t e ▁ a t a n y a m u l a ▁ n y a n j a ▁ y a c h i t a t u ▁ m ▁ m a d z i ▁ k u m a s e w e r a ▁ o y e r a ▁ n d i ▁ m p i r a\n",
            "D-111\t-0.3877798020839691\twosewera mpira wa jekete atanyamula nyanja yachitatu m madzi kumasewera oyera ndi mpira\n",
            "P-111\t-0.1171 -0.0588 -0.0442 -0.2970 -0.0316 -0.0260 -0.0974 -0.0535 -0.1122 -0.1131 -1.7047 -1.8089 -0.1374 -0.0799 -0.0797 -0.1226 -0.5667 -0.2144 -0.4179 -0.6492 -0.3769 -1.8982 -0.2052 -0.0320 -0.4741 -0.1114 -0.2797 -1.8378 -0.0983 -0.4659 -0.0784 -0.2908 -0.0570 -0.1113 -0.1008 -0.2031 -0.1068 -2.2250 -0.6843 -0.2642 -1.1731 -0.1531 -0.1001 -0.1327 -0.1115 -0.1504 -1.2275 -0.0857 -0.0963 -0.0779 -0.1061 -0.2391 -0.0822 -0.1626 -0.5976 -0.2383 -0.6239 -0.5246 -0.4062 -0.3295 -0.1083 -0.1165 -2.7629 -0.1865 -0.0280 -0.5524 -0.0906 -0.4022 -0.0622 -0.0712 -0.0378 -0.0979 -0.1051 -0.6695 -0.8698 -0.1797 -0.2344 -0.0904 -0.1558 -0.1044 -0.0361 -0.0837 -0.1435 -1.8389 -0.6585 -0.3322 -0.0540 -0.0710 -1.1168\n",
            "T-32\tmnyamata wovala epuloni yoyera ali ndi manja m chipinda chochezeramo komanso m chipinda chamivi pomwe mnyamata wabuluu akuyang ana\n",
            "H-32\t-0.30944982171058655\t▁ m n y a m a t a ▁ w o v a l a ▁ t h u k u t a ▁ l o y e r a ▁ a l i ▁ n d i ▁ m a n j a ▁ a k e ▁ m ▁ c h i p i n d a ▁ c h o t s e t s e r a ▁ k u m a n z i ▁ n d i p o ▁ m c h i n d a ▁ w a m n g ▁ o n o ▁ w a k u y a n g ▁ a n a\n",
            "D-32\t-0.30944982171058655\tmnyamata wovala thukuta loyera ali ndi manja ake m chipinda chotsetsera kumanzi ndipo mchinda wamng ono wakuyang ana\n",
            "P-32\t-0.1071 -0.1006 -0.0207 -0.0510 -0.1202 -0.0661 -0.0952 -0.0244 -0.1062 -0.1035 -0.2027 -0.0851 -0.1852 -0.1277 -0.0834 -0.1143 -0.0999 -0.1472 -0.8647 -0.1040 -0.4669 -0.2029 -0.5707 -0.2479 -0.1165 -0.6110 -0.1179 -0.0311 -0.2153 -0.0609 -0.0990 -0.1051 -0.6589 -0.0864 -0.0732 -0.1042 -0.2353 -0.0699 -0.0859 -0.0828 -0.1116 -0.1252 -1.6255 -0.0315 -0.0772 -0.1156 -0.5930 -0.7499 -1.1884 -0.0763 -1.7188 -0.4430 -0.2017 -0.0498 -0.1885 -0.5782 -0.1115 -0.2271 -0.0454 -0.1120 -0.0957 -0.0368 -0.0588 -0.2835 -0.3059 -0.0846 -0.0521 -0.2299 -0.0342 -0.2495 -0.0397 -0.5073 -0.1787 -1.5022 -0.1564 -0.5866 -0.1080 -0.1529 -1.4544 -0.8647 -0.2813 -0.1642 -0.2250 -0.0788 -0.9066 -0.0552 -0.1181 -0.1004 -1.3919 -0.1145 -0.5398 -0.7057 -0.1951 -0.1142 -0.2190 -0.6979 -1.7623 -0.3258 -0.5283 -0.2723 -0.1383 -0.0301 -0.0301 -0.0715 -0.1538 -0.4174 -1.9041 -0.9429 -0.1687 -0.2686 -0.1097 -0.0525 -0.1305 -0.0987 -0.0882 -0.0432 -0.1295 -0.5381\n",
            "T-126\tgulu la ana ang onoang ono amaliseche akusamba pafupi ndi zitsulo zazikulu ndi ndowa zachikasu\n",
            "H-126\t-0.30851131677627563\t▁ g u l u ▁ l a ▁ a n a ▁ a n g ▁ o n o a n g ▁ o n o ▁ a t a n y a m u l a ▁ m a ▁ j e k e t e ▁ a k u s a m b a ▁ p a f u p i ▁ n d i ▁ c h i t s u l o ▁ c h a z i k u l u ▁ n d i ▁ z a c h i k a s u\n",
            "D-126\t-0.30851131677627563\tgulu la ana ang onoang ono atanyamula ma jekete akusamba pafupi ndi chitsulo chazikulu ndi zachikasu\n",
            "P-126\t-0.1264 -0.2665 -0.0963 -0.0845 -0.0874 -0.1165 -0.0417 -0.0862 -0.5186 -0.1379 -0.4363 -0.1066 -0.1582 -0.2359 -1.7700 -0.8440 -1.1418 -0.0866 -0.0700 -0.0533 -0.2567 -0.0845 -0.0440 -0.2057 -0.0388 -0.0243 -0.0517 -0.2487 -0.0851 -0.7215 -0.1278 -0.9213 -0.0410 -0.1441 -0.0432 -0.0701 -0.0622 -0.1856 -0.1012 -0.5325 -0.1105 -1.2153 -1.5665 -0.0703 -0.7352 -0.0792 -0.0294 -0.1777 -0.1021 -1.7997 -0.2719 -0.1173 -0.6872 -0.1631 -0.2148 -0.0312 -0.1872 -0.0932 -0.2122 -0.1394 -0.7846 -0.0443 -0.0230 -0.0696 -0.1336 -0.0400 -0.0702 -0.1134 -0.1293 -0.9730 -0.1196 -0.0593 -0.6043 -0.8930 -0.1860 -0.0356 -0.0480 -0.0831 -0.5939 -0.0998 -0.1395 -0.9981 -0.0505 -1.0025 -0.0703 -0.4131 -0.1256 -0.1152 -0.0728 -0.0313 -0.1141 -0.1625 -3.1160 -0.3894 -0.0192 -0.0918 -0.0567 -0.4233 -0.1456 -0.0406 -0.0861 -0.2428\n",
            "T-275\tmwamuna wovala zovala zakuda ndi magalasi adzuwa akukwera njinga yamapiri kudutsa m nkhalango pafupi ndi mtsinje\n",
            "H-275\t-0.28112348914146423\t▁ m w a m u n a ▁ w o v a l a ▁ z o v a l a ▁ z o v a l a ▁ z a k u d a ▁ n d i ▁ m a t h a l a u z a ▁ a c h i k a s u ▁ a k u k w e r a ▁ n j i n g a ▁ y a m a t a b w a ▁ n d i ▁ c h a m t u n d u ▁ w a f u p i ▁ n d i ▁ c h i n t h u\n",
            "D-275\t-0.28112348914146423\tmwamuna wovala zovala zovala zakuda ndi mathalauza achikasu akukwera njinga yamatabwa ndi chamtundu wafupi ndi chinthu\n",
            "P-275\t-0.1186 -0.1983 -0.2382 -0.0861 -0.0972 -0.1562 -0.0725 -0.1223 -0.1217 -0.0962 -0.0700 -0.0553 -0.1207 -0.1220 -0.1240 -0.1050 -0.8917 -0.1074 -0.1254 -0.1084 -0.0989 -0.1191 -0.0988 -0.0765 -0.2048 -0.8816 -0.1065 -0.1072 -0.1221 -0.1056 -0.2212 -0.0853 -0.1563 -0.0858 -0.0329 -0.1004 -0.1101 -0.1401 -0.1112 -0.0729 -0.0925 -0.0691 -0.1434 -0.4799 -0.3291 -0.0775 -0.0661 -0.1144 -0.0514 -0.4470 -0.0668 -0.1075 -0.1204 -0.8529 -0.1682 -0.0878 -1.2604 -1.3346 -0.1068 -0.0701 -0.0752 -0.1388 -0.1349 -0.0676 -0.2911 -0.0997 -0.1316 -0.0430 -0.1065 -0.0997 -2.4967 -0.7763 -0.0891 -0.0613 -0.0992 -0.1173 -0.1162 -0.1044 -0.1592 -0.1152 -0.1005 -1.0813 -0.5952 -0.3306 -0.0838 -0.3307 -0.1417 -0.8555 -0.1437 -0.2273 -0.2723 -0.6143 -0.1953 -0.1071 -1.9429 -0.8623 -0.1119 -0.1383 -0.1447 -0.0228 -0.2260 -0.3949 -0.2244 -2.3302 -0.1778 -0.4151 -0.1968 -0.2705 -0.2770 -0.1371 -0.1130 -0.0960 -1.7608 -0.1192 -0.0932 -0.4024 -0.0147 -0.1201 -0.0655 -0.4545\n",
            "T-149\tmnyamata wina wovala malaya amizeremizere yabuluu akugona pa udzu kutsogolo kwa tebulo lofiira ndipo akuwerenga buku\n",
            "H-149\t-0.277311235666275\t▁ m n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a ▁ b u l u u ▁ w a k u d a ▁ k u t s o g o l o ▁ k w a ▁ u d z u ▁ w o k h a l a ▁ n d i ▁ b u l u u ▁ n d i p o ▁ w a k u y a n g ▁ a n a ▁ k u m b u y o\n",
            "D-149\t-0.277311235666275\tmnyamata wina wovala malaya amizeremizere ya buluu wakuda kutsogolo kwa udzu wokhala ndi buluu ndipo wakuyang ana kumbuyo\n",
            "P-149\t-0.1138 -0.0742 -0.0583 -0.0439 -0.1135 -0.0553 -0.0984 -0.0239 -0.1077 -0.1009 -0.0907 -0.0673 -0.0964 -0.1073 -0.1157 -0.0677 -0.0676 -0.0554 -0.1185 -0.0889 -0.1257 -0.1054 -0.0316 -0.1168 -0.0403 -0.1163 -0.0451 -0.1136 -0.0879 -0.1268 -0.4916 -0.0494 -0.1569 -0.0644 -0.0256 -0.0865 -0.0488 -0.0183 -0.0463 -0.0984 -0.0338 -0.0773 -0.1064 -0.0791 -0.1090 -0.2442 -0.0734 -0.3812 -0.0778 -0.1101 -0.0315 -0.0739 -0.2090 -0.2206 -0.3307 -0.7108 -0.4058 -0.3146 -0.1111 -2.4965 -0.3055 -0.3663 -0.0413 -0.0631 -0.0283 -0.1201 -0.0618 -0.0987 -0.1252 -0.1652 -0.0667 -0.1009 -0.1169 -3.4458 -0.4945 -0.0317 -0.0787 -0.0886 -1.0639 -0.1352 -0.2923 -1.4266 -0.3466 -0.1866 -0.1253 -0.0882 -0.2105 -0.0677 -0.1131 -0.3139 -1.2612 -0.7922 -0.2183 -2.0991 -0.0798 -0.0872 -0.6291 -0.0901 -0.1624 -0.7498 -0.0576 -0.0912 -0.8255 -0.2388 -0.3310 -0.1824 -1.6869 -0.1929 -0.2571 -0.0631 -0.0799 -0.0836 -0.1023 -0.2853 -0.3710 -0.7382 -0.0413 -1.0091 -0.3516 -0.0494 -0.1729 -0.0866 -0.6153\n",
            "T-81\tbambo wina wachikulire yemwe anavala malaya abuluu komanso mathalauza obiriwira atakhala patebulo ndi makina ojambulira kumbuyo kwake\n",
            "H-81\t-0.24061475694179535\t▁ b a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ k o m a n s o ▁ m a t h a l a u z a ▁ o b i r i w i r a ▁ a t a k h a l a ▁ p a t e b u l o ▁ n d i ▁ m a t h a l a u z a ▁ o g u l i r a ▁ c h a c h i k a s u\n",
            "D-81\t-0.24061475694179535\tbambo wina wachikulire wina yemwe wavala malaya abuluu komanso mathalauza obiriwira atakhala patebulo ndi mathalauza ogulira chachikasu\n",
            "P-81\t-0.1192 -0.0544 -0.1418 -0.0317 -0.0465 -0.0676 -0.1087 -0.0545 -0.0607 -0.0742 -0.1240 -0.1039 -0.0247 -0.5856 -0.0968 -0.0552 -0.0426 -0.0983 -0.0728 -0.0728 -0.0816 -0.0576 -0.0565 -0.0976 -0.8060 -1.7261 -0.1816 -0.0742 -0.2260 -0.1167 -0.0222 -0.0220 -0.0488 -0.0996 -0.0861 -1.6155 -0.1305 -0.1304 -0.1366 -0.1138 -0.1213 -0.1238 -0.0732 -0.1061 -0.2972 -0.1363 -0.0298 -0.1115 -0.0903 -0.2696 -0.0583 -0.0723 -0.0457 -0.1143 -0.0168 -0.0845 -0.9681 -0.3131 -0.0585 -0.0916 -0.0195 -0.0383 -0.0259 -0.0905 -0.2053 -0.1848 -0.3246 -0.0328 -0.0723 -0.2977 -0.1324 -0.0385 -0.0483 -0.1590 -0.1239 -0.0621 -2.1280 -0.0395 -0.0367 -0.0703 -0.0292 -0.0634 -0.0357 -0.1123 -0.1354 -0.2856 -0.0196 -0.0873 -1.2111 -0.0714 -0.1246 -0.0892 -0.1265 -0.1024 -0.0227 -0.1092 -0.5517 -0.1665 -0.0347 -0.0466 -0.0566 -0.0319 -0.0934 -0.1791 -0.0743 -0.1013 -0.1229 -0.1037 -0.0832 -2.4413 -0.1787 -0.0800 -0.3785 -0.1380 -0.0270 -0.0630 -0.0973 -0.1324 -1.0745 -2.6233 -0.1126 -0.0993 -0.0304 -0.1543 -0.1366 -0.2943 -0.5491 -0.0931 -1.1081 -1.6739 -0.0770 -0.0555 -0.1605 -0.8734 -0.2224 -0.0673 -0.5731\n",
            " 38% 5/13 [00:13<00:18,  2.30s/it, wps=1012]T-347\tgulu la achichepere aimirira mumsewu kutsogolo kwa khoma la njerwa lokhala ndi chipata chachitali chamatabwa\n",
            "H-347\t-0.2745896279811859\t▁ g u l u ▁ l a ▁ a c h i c h e p e r e ▁ a l i ▁ m u m s e w u ▁ k u t s o g o l o ▁ k w a ▁ k h o m a ▁ l a ▁ n j e r w a ▁ k o k h a l a ▁ n d i ▁ c h i t a l i ▁ c h a k e ▁ c h a ▁ m a t a b w a\n",
            "D-347\t-0.2745896279811859\tgulu la achichepere ali mumsewu kutsogolo kwa khoma la njerwa kokhala ndi chitali chake cha matabwa\n",
            "P-347\t-0.1110 -0.0334 -0.0550 -0.1293 -0.1217 -0.0987 -0.0348 -0.1367 -0.1261 -0.1870 -0.0350 -0.0701 -0.1114 -1.2527 -0.0872 -0.3802 -0.1552 -0.4272 -0.0716 -0.0622 -0.1373 -0.1383 -1.1734 -0.2097 -0.1319 -0.2431 -0.8956 -0.0778 -0.0578 -0.1251 -0.0799 -0.0568 -0.1007 -1.5915 -0.1084 -0.2614 -0.0317 -0.0577 -0.0135 -0.0662 -0.0545 -0.0673 -0.1281 -0.0429 -0.0411 -0.1415 -0.1788 -0.6446 -0.6213 -0.1483 -0.0401 -0.0426 -0.1597 -0.1762 -0.7229 -0.6134 -0.5033 -0.0335 -0.0496 -0.0476 -0.0465 -0.0745 -0.1178 -1.3674 -0.4361 -0.0482 -0.0997 -0.1016 -0.0674 -0.1110 -0.0725 -0.0528 -0.1034 -0.1496 -0.0900 -0.0800 -0.0771 -0.0836 -0.9581 -0.9093 -0.9483 -0.1157 -0.1718 -0.0151 -0.0745 -0.1107 -1.1586 -0.4440 -0.1518 -0.1409 -0.1099 -0.1346 -0.7478 -1.1034 -0.0972 -2.3995 -0.1101 -0.2963 -0.0150 -0.0488 -0.5911\n",
            "T-411\tazimayi awiri anayimirira atagwirana manja pamalo pomwe pali anthu ambiri mayi wina akudutsa ndipo mwamuna akuima chapatali\n",
            "H-411\t-0.31247806549072266\t▁ a z i m a y i ▁ a w i r i ▁ a i m i r i r a ▁ n d i ▁ a t a y i m a ▁ a t a n y a m u l a ▁ p a n j a ▁ p a m e n e ▁ a n t h u ▁ e n a ▁ n d i ▁ m a y i ▁ w i n a ▁ a k u m b u y o ▁ n d i p o ▁ m w a m u n a ▁ a k u y a n g ▁ a n a\n",
            "D-411\t-0.31247806549072266\tazimayi awiri aimirira ndi atayima atanyamula panja pamene anthu ena ndi mayi wina akumbuyo ndipo mwamuna akuyang ana\n",
            "P-411\t-0.1169 -0.0777 -0.1080 -0.0869 -0.0677 -0.1057 -0.0294 -0.1146 -0.0929 -0.1145 -0.0550 -0.0900 -0.0593 -0.0944 -0.0893 -0.1071 -3.3218 -0.0708 -0.0755 -0.1956 -0.0792 -0.0444 -0.1024 -0.1229 -1.3912 -0.2216 -0.0986 -0.1011 -0.1425 -0.7221 -0.1021 -1.4562 -0.1347 -0.7895 -0.7008 -0.0912 -0.4802 -0.3367 -0.0869 -0.3881 -0.0806 -0.0992 -0.0520 -0.2046 -0.0479 -0.1143 -0.1020 -1.5731 -0.1458 -0.3182 -0.0306 -0.0860 -0.1637 -0.3339 -1.4528 -0.4201 -0.0612 -0.0877 -0.0445 -0.1159 -1.8372 -0.2163 -0.1069 -0.0539 -0.1263 -0.1047 -1.5472 -0.1699 -0.1090 -0.1252 -0.5325 -0.0605 -0.1193 -0.3672 -0.0899 -0.1880 -0.3157 -0.0742 -0.0877 -0.5755 -0.0275 -0.0564 -0.1284 -0.2076 -1.2313 -0.1085 -0.1082 -0.6290 -0.2650 -1.1134 -0.0820 -0.1271 -0.1257 -0.2472 -0.0479 -0.1088 -1.2310 -0.0496 -0.1194 -0.1156 -0.3889 -0.1541 -0.1320 -0.1036 -0.0690 -0.1336 -0.1479 -1.2071 -1.1477 -0.2404 -0.3035 -0.1533 -0.1900 -0.3510 -0.2042 -0.0937 -0.0830 -0.1503 -0.7950\n",
            "T-24\tmtsikana wovala yunifolomu yobiriwira ndi msungwana wovala yunifolomu yoyera atanyamula timitengo ta lacrosse\n",
            "H-24\t-0.2550242245197296\t▁ m t s i k a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ y o b i r i w i r a ▁ n d i ▁ m t s i k a n a ▁ w o v a l a ▁ y u n i f o l o m u ▁ a t a n y a m u l a ▁ m t e n g o ▁ w o k h a l a ▁ p a ▁ s i t e j i\n",
            "D-24\t-0.2550242245197296\tmtsikana wovala yunifolomu yobiriwira ndi mtsikana wovala yunifolomu atanyamula mtengo wokhala pa siteji\n",
            "P-24\t-0.1131 -0.0302 -0.0654 -0.0319 -0.0373 -0.0242 -0.1190 -0.0542 -0.1336 -0.1237 -0.2486 -0.0985 -1.6551 -0.1256 -0.0950 -0.1331 -0.1116 -0.0968 -0.0212 -0.0329 -0.0378 -0.0095 -0.0299 -0.1248 -0.0431 -0.0140 -0.0831 -0.1166 -0.2252 -0.1019 -0.7847 -0.0892 -0.0376 -0.1527 -0.0214 -0.1189 -0.0504 -0.1218 -0.1316 -0.1014 -0.4399 -0.0715 -0.1499 -0.0989 -0.5544 -0.2084 -0.0276 -0.1227 -0.8826 -0.0316 -0.1254 -0.1535 -0.0342 -0.4011 -1.1410 -0.1220 -0.1243 -0.1289 -0.1215 -0.3276 -0.0281 -0.0142 -0.0449 -0.0308 -0.0512 -0.0272 -0.0790 -0.0300 -0.0142 -0.1160 -2.6672 -0.2203 -0.1088 -0.2720 -0.0319 -0.0730 -0.0283 -0.0961 -0.0494 -0.1111 -0.0933 -0.8659 -1.9199 -0.3301 -0.0341 -0.1829 -0.0217 -0.1319 -0.2762 -0.3504 -1.1404 -0.1859 -0.1283 -0.0476 -0.1197 -0.1232 -1.2640 -0.1566 -1.0529 -0.5382 -0.6990 -0.1983 -0.6262 -1.2602 -0.0373 -0.1413\n",
            "T-297\tmwana amatsamira pachionetsero chopangidwa ndi pulasitiki wabuluu ndi wachikasu pamene wamkulu akuyang ana\n",
            "H-297\t-0.3824525773525238\t▁ a n y a m a t a ▁ a s a n u ▁ a k u y e n d e t s e r a ▁ n d i ▁ c h i s o t i ▁ c h o k h a l a ▁ n d i ▁ t h u p i ▁ l a c h i k u l u ▁ n d i p o ▁ w a c h i k a s u ▁ k a m e n e ▁ w a c h i k u l u ▁ a k u y a n g ▁ a n a\n",
            "D-297\t-0.3824525773525238\tanyamata asanu akuyendetsera ndi chisoti chokhala ndi thupi lachikulu ndipo wachikasu kamene wachikulu akuyang ana\n",
            "P-297\t-0.1070 -0.6455 -0.0726 -0.3633 -0.0936 -0.0788 -0.0871 -0.2161 -0.1899 -0.1212 -0.2030 -0.2756 -0.1071 -0.2486 -0.2221 -0.1667 -0.7011 -0.4114 -0.2562 -1.9625 -0.0579 -1.4548 -0.0491 -0.8707 -0.0166 -0.0557 -0.3083 -0.6297 -0.2009 -0.1371 -1.8466 -0.1577 -0.1068 -0.2347 -0.2930 -0.1424 -0.3143 -0.1219 -0.2015 -0.1408 -0.2098 -0.1243 -0.4712 -0.0847 -0.0659 -0.7554 -0.1425 -0.1556 -0.0635 -0.2794 -0.1047 -0.0856 -0.1992 -0.1312 -0.4056 -0.7658 -0.9389 -0.4346 -1.2860 -0.5511 -0.1227 -0.5851 -0.1143 -0.2835 -0.1130 -0.0460 -1.3929 -1.1662 -0.1894 -0.0532 -0.0835 -3.3651 -0.1041 -0.1300 -0.4948 -0.1168 -0.0887 -0.5365 -0.1878 -0.0619 -0.0645 -0.0461 -0.2510 -0.2242 -0.0102 -0.0450 -0.0788 -1.7833 -1.2774 -0.8691 -0.5744 -0.2954 -0.2038 -0.0943 -1.3396 -0.2158 -0.2232 -0.0630 -0.0605 -0.0336 -1.2896 -0.0159 -0.2855 -0.1622 -1.9352 -0.8752 -0.2474 -0.0541 -0.2266 -0.0300 -0.3093 -0.1075 -0.0825 -0.0310 -0.1309 -0.4682\n",
            "T-165\tbambo wina wovala kabudula woyera komanso pamwamba pa wetsuit wakwera pabwalo losambira lachikasu lowala kwambiri\n",
            "H-165\t-0.3671325147151947\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ k a b u d u l a ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ c h i k w a m a ▁ p a m w a m b a ▁ p a ▁ t s u k o ▁ l a ▁ m u n t h u ▁ w a c h i s a n u ▁ n d i ▁ t ▁ s h i r t ▁ y a c h i k a s u ▁ l o w a l a ▁ k w a m b i r i\n",
            "D-165\t-0.3671325147151947\tbambo wina wovala kabudula woyera wokhala ndi chikwama pamwamba pa tsuko la munthu wachisanu ndi t shirt yachikasu lowala kwambiri\n",
            "P-165\t-0.1135 -1.9275 -0.5692 -0.3196 -0.1082 -0.1359 -0.1217 -0.0897 -0.2114 -0.0898 -0.1399 -0.1149 -0.1227 -0.0821 -0.2328 -0.1475 -0.1721 -0.1178 -0.0953 -2.9259 -0.0760 -0.0815 -0.0804 -0.0327 -0.1190 -0.1077 -0.0931 -0.1392 -0.0271 -0.0694 -0.0721 -0.0910 -0.0577 -0.0950 -0.1315 -0.7206 -0.2710 -0.5264 -0.1882 -0.1049 -0.1200 -0.1206 -0.1101 -0.8637 -0.7391 -0.0998 -0.1294 -0.5542 -0.1452 -0.4184 -2.5002 -0.1839 -0.0847 -0.0714 -0.1635 -0.1265 -0.2008 -0.1099 -1.7717 -0.6144 -0.0794 -0.0659 -0.0492 -0.0967 -0.1052 -0.8104 -0.1144 -0.2730 -0.8040 -1.3892 -0.3461 -0.7743 -1.3212 -0.0802 -0.8561 -0.2414 -0.2521 -1.6941 -0.8856 -0.2885 -0.1123 -0.1936 -0.0696 -0.0913 -0.0455 -0.2123 -1.9085 -0.1012 -0.0485 -0.8655 -0.1067 -0.0666 -0.0385 -0.1398 -0.2424 -0.0885 -0.1037 -0.2854 -0.3556 -2.2881 -0.1829 -0.1920 -0.6057 -0.2685 -0.0277 -0.1277 -0.5512 -0.8087 -0.2190 -0.2946 -0.0873 -0.1373 -0.4637 -0.3640 -0.0444 -0.1159 -2.5564 -0.0990 -0.2566 -0.2608 -0.0985 -0.1038 -0.4781 -1.0454 -0.4923 -0.1019 -0.0618 -0.0899 -0.0203 -0.1142 -0.0559 -0.1961\n",
            "T-157\tmayi wina atakwera njinga akuimitsidwa pafupi ndi bambo wina amene wakhala pampando atanyamula taipi pachifuwa chake\n",
            "H-157\t-0.2523938715457916\t▁ m a y i ▁ w i n a ▁ a t a k w e r a ▁ n j i n g a ▁ k u d u t s i d w a ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w i n a ▁ w a k h a l a ▁ p a m p a n d o ▁ a t a n y a m u l a ▁ c h i p i n d a ▁ c h a c h i k a s u ▁ w a k e\n",
            "D-157\t-0.2523938715457916\tmayi wina atakwera njinga kudutsidwa pafupi ndi bambo wina wakhala pampando atanyamula chipinda chachikasu wake\n",
            "P-157\t-0.1143 -0.0748 -0.0951 -0.0270 -0.0934 -0.0759 -0.2034 -0.0820 -0.0750 -0.1323 -0.1083 -0.1443 -0.1041 -0.1041 -0.2583 -1.6692 -0.2637 -0.1607 -0.0907 -0.1269 -0.0370 -0.0761 -0.0495 -0.0404 -0.0313 -0.0958 -0.1159 -1.7100 -0.1063 -2.2817 -0.5430 -0.0941 -0.0719 -0.8117 -0.2897 -0.0538 -0.1085 -0.1162 -0.3728 -0.1885 -0.0646 -0.0732 -0.1040 -0.0530 -0.0943 -0.0274 -0.0763 -0.0974 -0.1620 -0.2931 -0.1061 -0.2541 -0.0322 -0.0120 -0.0953 -0.0345 -0.0298 -0.0366 -0.1325 -0.1025 -0.4535 -0.1732 -0.2874 -0.0833 -0.1467 -0.1359 -0.1037 -0.1033 -0.1657 -0.1136 -0.1852 -0.0799 -0.1689 -0.0279 -0.0121 -0.0259 -0.0990 -1.3338 -0.1094 -0.1033 -0.7010 -0.0054 -0.0998 -0.0280 -0.0473 -0.0581 -0.1068 -0.1041 -0.7658 -0.0850 -0.0789 -1.3507 -0.2939 -1.0851 -0.1226 -0.1049 -0.1205 -0.0189 -0.0576 -0.1797 -1.1877 -0.0639 -0.0825 -0.1110 -1.7808 -0.3157 -0.0339 -0.4121 -0.8690 -0.2120 -0.8374 -0.1184 -0.0916\n",
            "T-316\tbambo wina wovala suti atakhala pampando pomwe pali nyali m mbali mwake ndipo kutsogolo kwake kuli nyimbo akuyimba cello\n",
            "H-316\t-0.3288083076477051\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ s u t i ▁ a t a k h a l a ▁ p a m p a n d o ▁ w o m w e ▁ p a l i ▁ n y a l i ▁ n d i ▁ m a l i ▁ n d i p o ▁ o t s o g o l o ▁ k w a k e ▁ a l i ▁ n d i ▁ m b a l e\n",
            "D-316\t-0.3288083076477051\tbambo wina wovala suti atakhala pampando womwe pali nyali ndi mali ndipo otsogolo kwake ali ndi mbale\n",
            "P-316\t-0.1156 -0.0402 -0.1005 -0.0415 -0.0606 -0.0697 -0.1121 -0.0389 -0.0648 -0.0919 -0.1285 -0.1162 -0.0335 -0.5762 -0.0407 -0.1337 -0.1142 -0.1148 -0.1036 -0.6614 -0.0409 -0.0458 -0.0420 -0.0935 -0.7620 -0.0524 -0.1068 -0.0878 -0.0660 -0.1028 -0.1314 -0.1161 -0.1186 -0.0209 -0.1028 -0.3166 -0.0422 -0.1655 -0.0290 -0.0160 -0.0283 -0.1232 -1.1679 -0.1884 -0.7124 -0.0490 -0.1345 -0.1130 -1.7509 -0.1584 -0.1279 -0.0453 -0.1437 -0.2833 -1.4767 -0.1105 -0.1689 -0.0839 -0.1098 -0.6279 -0.2202 -0.1504 -0.1607 -0.2314 -0.3533 -1.6374 -0.5029 -0.1708 -1.1547 -0.1135 -0.1662 -0.8419 -0.0358 -0.0946 -0.8895 -1.7358 -0.2059 -0.9820 -0.0195 -0.2028 -0.0593 -0.5522 -0.1331 -1.6470 -0.0974 -0.1546 -0.9341 -0.2326 -0.1473 -0.2785 -0.7587 -0.0679 -0.1281 -1.1154 -0.1684 -0.2190 -0.1376 -0.2537 -0.1508 -0.0818 -0.3796 -1.0924 -2.3870\n",
            "T-4\tpali mwamuna wina wovala zofiira ndi ana awiri akuyang ana gudumu lalikulu lozungulira komanso lamitundumitundu\n",
            "H-4\t-0.3104400634765625\t▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ z o f i i r a ▁ n d i ▁ a l a n j e ▁ a k u y a n g ▁ a n a ▁ k u t u ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ z u n g u l i r a ▁ z o k o n g o l a ▁ m ▁ m u n t h u\n",
            "D-4\t-0.3104400634765625\tmwamuna wina wovala zofiira ndi alanje akuyang ana kutu ali kutsogolo kwa zungulira zokongola m munthu\n",
            "P-4\t-0.1006 -1.1603 -0.1608 -0.1082 -0.0978 -0.0589 -0.1020 -0.1278 -0.1242 -0.0467 -0.1181 -0.0754 -0.1232 -0.1130 -0.0621 -0.0784 -0.0419 -0.1142 -0.0993 -0.1120 -0.1076 -0.2001 -0.0534 -0.5820 -0.0771 -0.1312 -0.0809 -0.2633 -0.0935 -0.3062 -0.0896 -0.0949 -0.0845 -0.3392 -2.8407 -0.2220 -1.0120 -0.2487 -0.2028 -0.0831 -0.4162 -0.1645 -0.2592 -0.0222 -0.4253 -0.0348 -0.2832 -0.0847 -0.1086 -0.0594 -0.1415 -0.0876 -0.2604 -0.0844 -1.1227 -0.2018 -0.1939 -0.8449 -0.1876 -0.0754 -0.1784 -0.2116 -0.2931 -1.0606 -1.7192 -0.3751 -0.0177 -0.1326 -0.0434 -0.2927 -0.1235 -0.1051 -0.0700 -0.1698 -0.1246 -0.6442 -0.5021 -0.0938 -0.0215 -0.0491 -0.0771 -0.0715 -0.1444 -0.2529 -0.1502 -0.7072 -0.2864 -1.4756 -0.2084 -0.1581 -0.5810 -0.1253 -0.1397 -0.8563 -0.2948 -0.7510 -1.8973 -0.4428 -0.7982 -0.2006 -0.0480 -0.0767 -0.0746 -1.0436\n",
            "T-422\tanthu anayi akhala pamipando ya buluu ndi yobiriwira pamene munthu wachisanu anakhala pambali akuyang ana pansi pa mtengo wofiyira wotambalala\n",
            "H-422\t-0.2785126864910126\t▁ a n t h u ▁ a n a y i ▁ a t a k h a l a ▁ p a m e n e ▁ a b u l u u ▁ n d i ▁ o b i r i w i r a ▁ p a m e n e ▁ m u n t h u ▁ w a c h i s a n u ▁ a t a k h a l a ▁ p a m p a n d a ▁ w i n a ▁ a l i ▁ n d i ▁ m p a n d a ▁ w o f i i r a ▁ a t a v a l a\n",
            "D-422\t-0.2785126864910126\tanthu anayi atakhala pamene abuluu ndi obiriwira pamene munthu wachisanu atakhala pampanda wina ali ndi mpanda wofiira atavala\n",
            "P-422\t-0.1062 -0.0749 -0.1088 -0.0400 -0.1519 -0.0669 -0.0791 -1.1421 -0.2731 -0.1913 -0.0131 -0.1354 -0.0730 -0.1409 -1.0514 -0.1170 -0.2437 -0.0741 -0.1147 -0.0773 -0.1034 -0.0961 -0.0700 -0.0999 -0.1223 -0.9997 -0.1017 -0.1288 -0.0865 -0.2060 -3.3058 -0.0734 -0.0924 -0.0440 -0.0311 -0.0871 -0.1218 -0.0815 -0.0676 -0.2218 -1.1536 -0.0907 -0.0588 -0.0339 -0.0844 -0.0216 -0.0523 -0.0504 -0.0978 -0.1412 -0.3152 -0.1419 -0.3090 -0.0994 -0.0524 -0.0518 -0.1007 -0.1851 -1.2188 -0.0517 -0.0298 -0.0774 -0.0755 -0.0920 -0.0577 -0.3197 -0.2553 -0.0591 -0.0428 -0.2911 -0.1032 -0.0228 -0.1786 -0.0907 -0.9265 -0.7590 -0.0924 -1.1679 -0.2110 -0.1176 -0.0396 -0.1392 -0.0949 -0.0448 -0.1233 -0.1567 -0.9760 -0.2303 -0.0620 -0.0883 -0.1248 -0.1008 -0.6811 -0.0601 -0.1319 -0.0967 -0.1015 -1.6454 -1.2798 -0.2248 -0.0868 -0.1799 -0.0373 -0.0766 -0.1066 -1.3920 -0.1593 -0.3676 -0.0735 -0.1561 -0.4463 -0.1059 -0.0335 -0.5208 -0.6485 -0.0397 -0.0654 -0.0716 -0.1709 -0.3921 -1.5528 -0.1772 -0.1071 -0.3530 -0.0997 -0.0567 -0.1091 -1.9655\n",
            "T-241\tmwamuna wa turbaned ndi apolisi awiri aima kutsogolo kwa denga loyera ndi mulu wa matumba otaya zinyalala\n",
            "H-241\t-0.37795382738113403\t▁ m w a m u n a ▁ w o v a l a ▁ j i n z i ▁ a k u k h a l a ▁ p a m i z e r e ▁ a k u t h a m a n g a ▁ k u t s o g o l o ▁ n d i ▁ a w i r i ▁ n d i ▁ m u l u ▁ w a ▁ m a d z i ▁ o t u w a ▁ n d i ▁ m i y a l a\n",
            "D-241\t-0.37795382738113403\tmwamuna wovala jinzi akukhala pamizere akuthamanga kutsogolo ndi awiri ndi mulu wa madzi otuwa ndi miyala\n",
            "P-241\t-0.1180 -0.0617 -0.0421 -0.1254 -0.5537 -0.0681 -0.0924 -0.1210 -0.1199 -0.2585 -0.9161 -0.9539 -0.1192 -0.1157 -0.1141 -0.1063 -1.1512 -1.6038 -0.0405 -0.4957 -0.0952 -0.0694 -0.1905 -0.4874 -0.2932 -0.4002 -1.0681 -0.1262 -0.0898 -0.1791 -0.1106 -0.1043 -0.1153 -2.7129 -0.2608 -0.5377 -1.2072 -0.0432 -0.0678 -0.2779 -0.3613 -0.4841 -0.1003 -1.6922 -0.1889 -0.1007 -0.2298 -0.0875 -0.1910 -0.0246 -1.4912 -0.1257 -0.7084 -0.0967 -0.0667 -0.2876 -0.0232 -0.0120 -0.0932 -0.0854 -0.0789 -0.1133 -1.3976 -0.0351 -0.1026 -0.1671 -1.7454 -0.2262 -0.7019 -0.0948 -0.0788 -0.0840 -0.3214 -0.0394 -0.1019 -0.0951 -0.1826 -0.6086 -1.6964 -0.0786 -0.0817 -0.0720 -0.1457 -0.4038 -0.4964 -0.2527 -1.2656 -0.3688 -0.0356 -0.1731 -0.8345 -0.1526 -0.2575 -0.1115 -0.0807 -0.5310 -1.0426 -0.2054 -0.0630 -0.1147 -0.9737 -1.2349 -0.9174 -0.1902 -0.0194 -0.0952 -0.3072\n",
            "T-302\tatsikana angapo ali pagulu ndipo wina akumwetulira pomwe dzuwa likuwalira kumaso kwake\n",
            "H-302\t-0.42218759655952454\t▁ m w a m u n a ▁ y e k h a s i ▁ a t a n y a m u l a ▁ k h o k a ▁ l a l i k u l u ▁ n d i ▁ d o t h i ▁ n d i p o ▁ m e n e ▁ a w i r i ▁ n d i ▁ z u w a ▁ k u m b u y o ▁ k w a k e\n",
            "D-302\t-0.42218759655952454\tmwamuna yekhasi atanyamula khoka lalikulu ndi dothi ndipo mene awiri ndi zuwa kumbuyo kwake\n",
            "P-302\t-0.1125 -0.7757 -0.7515 -0.1133 -0.0769 -0.1189 -0.1207 -0.3407 -0.1548 -2.0469 -0.1745 -0.3550 -0.0108 -0.1133 -1.4044 -0.1377 -0.1014 -0.1109 -0.9266 -0.1286 -0.2010 -0.2853 -0.0987 -0.0408 -0.3697 -0.0716 -0.1314 -0.1246 -0.2741 -1.8893 -0.2081 -0.7638 -0.9196 -0.1510 -0.3206 -0.5547 -0.4018 -0.0819 -0.2828 -0.0494 -0.0200 -0.1021 -0.1255 -0.3527 -0.0609 -0.1097 -0.2957 -1.5483 -0.5072 -0.3255 -1.0078 -0.1024 -0.2200 -1.6813 -0.2084 -0.2337 -1.1282 -0.0456 -0.1168 -0.7001 -0.6927 -0.1045 -0.1162 -0.1730 -0.3041 -1.8489 -0.3694 -0.0400 -0.0839 -0.1227 -1.5152 -0.1206 -0.1212 -0.4700 -0.1258 -1.1290 -1.2448 -0.1277 -0.2230 -1.3050 -0.2798 -0.3029 -0.1738 -0.1767 -0.0601 -0.0788 -0.2176 -0.4757 -0.1475 -0.1132 -2.0325 -0.0695 -0.7105\n",
            "T-245\tazimayi awiri a ku asia akulankhula komanso kumwa zakumwa patebulo laling ono lozungulira\n",
            "H-245\t-0.3203096091747284\t▁ a z i m a y i ▁ a w i r i ▁ a k u ▁ a s i a ▁ a k u l a n k h u l a ▁ k u m a s o ▁ m w a n a ▁ k u m a n z a ▁ t e b u l o ▁ l a l i k u l u ▁ l a ▁ a n t h u ▁ o m w e ▁ a m a z u n g u l i r a\n",
            "D-245\t-0.3203096091747284\tazimayi awiri aku asia akulankhula kumaso mwana kumanza tebulo lalikulu la anthu omwe amazungulira\n",
            "P-245\t-0.1179 -0.1177 -0.0158 -0.0684 -0.0370 -0.1043 -0.0138 -0.0846 -0.0995 -0.1384 -0.0668 -0.1204 -0.0443 -0.0960 -0.0911 -0.1208 -0.1906 -0.1254 -1.7441 -0.1964 -0.1501 -0.0699 -0.1227 -0.0864 -0.1340 -0.0505 -0.1200 -0.2021 -0.1059 -0.4247 -0.0251 -0.0686 -0.0508 -0.0368 -0.1237 -0.1321 -0.4741 -0.3585 -0.1895 -0.0996 -0.4334 -0.0216 -0.0788 -2.0025 -0.5469 -0.1395 -1.0151 -0.1105 -0.1613 -0.4838 -0.0927 -0.1472 -0.2086 -1.2552 -0.0657 -0.3417 -0.1794 -1.5770 -0.0850 -0.1763 -0.0737 -0.0695 -0.0480 -0.1081 -0.3098 -0.5213 -0.1592 -0.0999 -1.4411 -0.4995 -0.0383 -0.3725 -0.2188 -0.4641 -0.3079 -0.6900 -0.3481 -0.3569 -2.1886 -0.0705 -0.1132 -0.1551 -1.1803 -1.4468 -0.3890 -0.2097 -0.1196 -1.3147 -0.5405 -0.0843 -1.7731 -0.1225 -0.0495 -0.0418 -0.0235 -0.0369 -0.0553 -0.0350 -0.1313 -0.0822\n",
            "T-235\tana akusewera m makwalala wina atanyamula mfuti pamene mkazi wachikulire akudutsa\n",
            "H-235\t-0.337128609418869\t▁ a n a ▁ a k u s e w e r a ▁ m ▁ m a p o ▁ w i n a ▁ w a v a l a ▁ m a l a y a ▁ o t c h i ▁ p a m e n e ▁ m k a z i ▁ w a c h i k a s u ▁ a k u d i k i r e\n",
            "D-235\t-0.337128609418869\tana akusewera m mapo wina wavala malaya otchi pamene mkazi wachikasu akudikire\n",
            "P-235\t-0.1262 -0.0896 -0.0481 -0.1855 -0.0768 -0.1464 -0.3360 -0.1098 -0.0772 -0.1046 -0.0404 -0.1273 -0.0722 -0.0910 -0.1203 -0.0454 -0.2173 -0.1197 -0.1419 -2.3959 -1.0390 -0.3094 -0.7916 -0.0899 -0.1309 -0.1111 -0.2618 -0.7550 -0.4347 -0.5822 -0.1456 -0.0858 -0.1242 -0.1101 -0.2735 -0.2702 -0.7853 -0.1557 -0.1010 -0.1005 -0.0773 -0.3520 -0.2437 -2.1563 -0.1155 -0.0452 -1.2127 -0.0591 -0.1298 -0.0551 -0.0210 -0.0719 -0.0599 -0.0970 -0.3405 -0.3599 -0.1371 -0.0426 -0.0540 -0.1082 -1.8734 -0.2340 -0.6360 -0.0463 -0.0661 -0.1046 -0.1312 -0.4590 -0.0306 -0.3288 -1.3573 -0.5365 -0.0832 -0.1539 -1.2094 -0.2000 -0.0272 -0.2966 -1.1833 -0.9450\n",
            "T-151\twosewera mpira watimu yachikasu akudumphira osewera awiri a timu ya buluu pomwe osewera ena akuthamangira kumbali\n",
            "H-151\t-0.3163256347179413\t▁ m t s i k a n a ▁ w o v a l a ▁ t ▁ s h i r t ▁ y a c h i k a s u ▁ n d i ▁ m p i r a ▁ w o s e w e r a ▁ w o s e w e r a ▁ a ▁ b u l u u ▁ n d i ▁ w o y e r a ▁ p o m w e ▁ m a s e w e r a ▁ a k u t h a m a n g i r a ▁ k u m b u y o\n",
            "D-151\t-0.3163256347179413\tmtsikana wovala t shirt yachikasu ndi mpira wosewera wosewera a buluu ndi woyera pomwe masewera akuthamangira kumbuyo\n",
            "P-151\t-0.1161 -1.8563 -0.2396 -0.0487 -0.5657 -0.2861 -0.1755 -0.1357 -0.1017 -0.0936 -0.5414 -0.7675 -0.4440 -0.4581 -0.1419 -0.1279 -0.0992 -0.1694 -0.0984 -0.5279 -0.0559 -0.1463 -0.0378 -0.0239 -0.1135 -0.0018 -0.2357 -0.3303 -0.1230 -0.0815 -0.0817 -0.1329 -0.0176 -0.1562 -0.0744 -1.4061 -0.1843 -0.1274 -0.1960 -0.9952 -0.2077 -0.4049 -0.0751 -0.1278 -0.1282 -0.5351 -0.3168 -0.6718 -0.1470 -0.0322 -0.1316 -0.0973 -0.1023 -0.1329 -1.1399 -0.0814 -1.2344 -0.1411 -0.0678 -0.1610 -0.0956 -0.1346 -0.1356 -0.3832 -1.3300 -0.8936 -0.4236 -0.0658 -0.1843 -0.0229 -0.0641 -0.8392 -0.0922 -0.0919 -0.3377 -3.2370 -0.2988 -0.1569 -0.2573 -0.1428 -0.0961 -0.1240 -0.9716 -0.0805 -0.0843 -0.0633 -0.1044 -0.0712 -0.8111 -0.8836 -0.2497 -0.0714 -0.0179 -0.2284 -0.0408 -0.0940 -0.1267 -0.5283 -0.7400 -0.0901 -0.0961 -0.0600 -0.0884 -0.0209 -0.0761 -0.0599 -0.1101 -0.0693 -0.3962 -0.0722 -0.3167 -2.0396 -0.1119 -0.2048 -0.2392 -0.4543 -0.0221 -0.0427 -1.0453\n",
            "T-11\tmwamuna atavala nsonga ya thanki ndi mkazi atavala pamwamba pa bikini akuvina limodzi panja ndi nyali kutsogolo kwa anthu owonerera\n",
            "H-11\t-0.32961389422416687\t▁ m w a m u n a ▁ a t a v a l a ▁ n s o n g a ▁ y a ▁ t h a n k i ▁ n d i ▁ m k a z i ▁ a t a v a l a ▁ m w a m b a ▁ p a f u p i ▁ n d i ▁ m n y a m a t a ▁ w i n a ▁ n d i ▁ k a z i ▁ k u t s o g o l o ▁ k w a ▁ n y u m b i r i\n",
            "D-11\t-0.32961389422416687\tmwamuna atavala nsonga ya thanki ndi mkazi atavala mwamba pafupi ndi mnyamata wina ndi kazi kutsogolo kwa nyumbiri\n",
            "P-11\t-0.1062 -0.0651 -0.0326 -0.1245 -0.0704 -0.0574 -0.0749 -0.1322 -0.1037 -0.4683 -0.0233 -0.1100 -0.0331 -0.1016 -0.0816 -0.1156 -0.0966 -1.0151 -0.0842 -0.0773 -0.6955 -0.1334 -0.1204 -0.1110 -0.9518 -0.1303 -0.4741 -0.7013 -0.2658 -0.6961 -0.0778 -0.6641 -0.1177 -0.1428 -1.4304 -0.3470 -0.0919 -0.1581 -1.1547 -0.1541 -0.1301 -0.0474 -0.0582 -0.0954 -0.2279 -0.0397 -0.0845 -0.4890 -0.0963 -0.1084 -0.1453 -0.1065 -0.2182 -2.3184 -0.1525 -0.1461 -0.0768 -0.2698 -0.0780 -0.0572 -0.1002 -1.7454 -0.5025 -0.0363 -0.0592 -0.1008 -0.0597 -0.4628 -0.0865 -0.1341 -0.5193 -1.9611 -1.4906 -0.1311 -0.0933 -0.1547 -0.0472 -0.0577 -0.0897 -0.5341 -1.9138 -0.1284 -0.1328 -0.1094 -0.2772 -0.0467 -0.0818 -0.2977 -2.4298 -0.5136 -0.4817 -0.1958 -0.4359 -0.6533 -0.2081 -0.8065 -0.0402 -0.0914 -0.0189 -0.0712 -0.0416 -0.0471 -0.1844 -0.1511 -0.0218 -0.0977 -0.1041 -0.9545 -0.3849 -0.4291 -0.1688 -0.1028 -0.9211 -0.1312 -0.5212 -0.1355\n",
            "T-155\tmwana atakutidwa ndi utoto amakhala pakati pa thireyi za utoto wamitundumitundu wothira bwino ndi utoto\n",
            "H-155\t-0.36218777298927307\t▁ m w a n a ▁ a k u t i d w a ▁ n d i ▁ n t h u ▁ p a m w a m b a ▁ a t a v a l a ▁ t ▁ s h i r t ▁ y o t u w a ▁ p a m i t u n d u m i t u n d u ▁ w o t h i r a ▁ n d i ▁ m a f u n d e\n",
            "D-155\t-0.36218777298927307\tmwana akutidwa ndi nthu pamwamba atavala t shirt yotuwa pamitundumitundu wothira ndi mafunde\n",
            "P-155\t-0.1010 -0.0886 -0.0151 -0.1386 -0.0418 -0.1176 -0.1037 -0.1055 -0.1310 -0.1133 -0.6890 -0.9596 -1.8287 -0.2069 -0.0948 -0.0825 -0.1700 -0.0744 -0.1624 -0.1799 -2.0549 -0.6618 -0.0826 -0.4749 -0.2891 -1.2254 -0.1144 -0.0602 -1.2281 -0.1231 -0.0313 -0.0498 -0.1259 -0.1285 -0.6893 -0.2413 -0.0924 -0.6492 -0.1301 -0.1539 -0.0996 -0.1004 -1.6432 -0.2918 -0.3139 -0.0767 -0.3991 -0.0245 -0.0654 -0.1160 -0.5561 -1.6443 -0.3646 -0.1161 -0.0898 -0.0702 -0.1468 -1.5476 -0.1219 -0.1041 -0.5718 -0.0266 -0.1088 -0.0483 -0.0128 -0.0611 -1.0465 -0.1017 -0.0574 -0.0405 -0.0360 -0.0232 -0.0639 -0.1275 -0.7236 -0.2444 -0.2736 -1.6969 -0.0930 -0.1777 -0.1010 -0.1427 -1.1606 -0.0974 -0.0713 -0.1524 -0.4634 -0.0828 -2.1811 -0.1477 -1.1878 -0.0749 -0.0527 -0.6911\n",
            "T-254\tmtsikana wovala chovala choyera akuseweretsa thovu pamene mayi ndi mwana wake wamkazi amaimirira pambali\n",
            "H-254\t-0.231480211019516\t▁ m t s i k a n a ▁ w o v a l a ▁ c h o v a l a ▁ c h o y e r a ▁ a k u s e w e r a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y o m w e ▁ i m a d z i ▁ n d i ▁ m k a z i ▁ a t a i m i r i r a ▁ p a m b a l i\n",
            "D-254\t-0.231480211019516\tmtsikana wovala chovala choyera akusewera kutsogolo kwa nyumba yomwe imadzi ndi mkazi ataimirira pambali\n",
            "P-254\t-0.1114 -0.0341 -0.2213 -0.0240 -0.0459 -0.0579 -0.1141 -0.0746 -0.1273 -0.0952 -0.0274 -0.0945 -0.0410 -0.1499 -0.1387 -0.1329 -0.1089 -0.0609 -0.0741 -0.3160 -0.0283 -0.0863 -0.0947 -0.1259 -0.1130 -0.0279 -0.0958 -0.1203 -0.0473 -0.0881 -0.0601 -0.1060 -0.1286 -0.0951 -0.1047 -0.1198 -0.1366 -0.0497 -0.1167 -0.0584 -0.1672 -0.2187 -0.1238 -1.8478 -0.1065 -0.1171 -0.4699 -0.2331 -0.0240 -0.1410 -0.0675 -0.3928 -0.1215 -1.0756 -0.0403 -0.1039 -0.0773 -1.2578 -0.0705 -0.1553 -0.0409 -0.1778 -0.1097 -0.1908 -0.2601 -0.8720 -0.3001 -0.2581 -0.1139 -0.1036 -0.3775 -0.8132 -0.1892 -1.3586 -1.0300 -0.0520 -0.1039 -0.3121 -0.1255 -0.1019 -0.1116 -0.7062 -0.1311 -0.1174 -0.0193 -0.0750 -0.0844 -0.1156 -1.2273 -0.0859 -0.8963 -0.0348 -0.4430 -0.0812 -0.0786 -0.0277 -0.0923 -0.2106 -0.1161 -0.1262 -0.3281 -0.4523 -0.0800 -0.0435 -0.1226 -1.1733\n",
            "T-301\twosewera wa hockey amaletsa kuwombera kwa wosewera yemwe amapikisana naye momwe osewera ena amawonera\n",
            "H-301\t-0.34359827637672424\t▁ w o s e w e r a ▁ w o k w e r a ▁ n j i n g a ▁ y a k u d a ▁ w o s e w e r a ▁ w o s e w e r a ▁ a ▁ m a p i k i s a n o ▁ o m w e ▁ e n a ▁ a k u s e w e r a ▁ m a w o n e r e r a\n",
            "D-301\t-0.34359827637672424\twosewera wokwera njinga yakuda wosewera wosewera a mapikisano omwe ena akusewera mawonerera\n",
            "P-301\t-0.1144 -0.0768 -0.0596 -0.0316 -0.0396 -0.0410 -0.1095 -0.0720 -0.1234 -0.1243 -0.2740 -0.7906 -1.7828 -1.0976 -0.1271 -0.1574 -0.1161 -0.1066 -0.9565 -2.0720 -0.2466 -0.2003 -0.0839 -0.1309 -0.1214 -1.3544 -0.0972 -0.1535 -0.0934 -0.4679 -0.3514 -0.1009 -1.3980 -0.1574 -0.1424 -0.0435 -0.0529 -0.1211 -0.0898 -0.2009 -0.1761 -0.4150 -0.1023 -0.4731 -0.0526 -0.0632 -0.0878 -0.0847 -0.5636 -0.1503 -0.5038 -0.8318 -0.1704 -0.2653 -0.4216 -0.1056 -0.2442 -0.0350 -0.2649 -0.1324 -0.0280 -0.0751 -0.1214 -0.8723 -0.4204 -0.4022 -0.1417 -0.0805 -1.4003 -0.2332 -0.0630 -0.1107 -0.2768 -1.5819 -1.1056 -1.0021 -0.0330 -0.0543 -0.0755 -0.0621 -0.2277 -0.1603 -0.3573 -0.2099 -0.2360 -0.5425 -0.2515 -0.1403 -1.0204 -1.1203 -0.1279 -0.1246 -0.2711\n",
            "T-62\tmtsikana wina watsitsi lakuda nambala five twenty eight wovala zofiira ndi zoyera akukonzekera kuponya mfuti\n",
            "H-62\t-0.24419961869716644\t▁ m t s i k a n a ▁ w i n a ▁ w a t s i t s i ▁ l a k u d a ▁ w o v a l a ▁ m a l a y a ▁ o t u w a ▁ n d i ▁ c h i p e w a ▁ z o f i i r a ▁ n d i ▁ z o y e r a ▁ a k u k o n z e k e r a ▁ k u t s o g o l o\n",
            "D-62\t-0.24419961869716644\tmtsikana wina watsitsi lakuda wovala malaya otuwa ndi chipewa zofiira ndi zoyera akukonzekera kutsogolo\n",
            "P-62\t-0.1134 -0.0286 -0.0802 -0.0380 -0.0507 -0.0341 -0.1152 -0.0945 -0.1189 -0.1176 -0.0235 -0.0918 -0.0794 -0.1473 -0.1053 -0.0148 -0.7098 -0.1981 -0.0140 -0.0683 -0.0214 -0.0163 -0.0634 -0.0863 -0.1716 -0.1067 -0.0471 -0.0670 -0.1718 -0.2037 -0.0890 -2.0340 -0.1613 -1.5237 -0.1196 -0.1342 -0.1054 -0.1092 -0.1109 -0.2470 -0.5287 -0.3449 -0.0514 -0.1030 -0.0787 -0.6319 -1.0511 -0.4273 -0.4983 -0.6558 -0.1377 -0.0558 -0.1278 -0.1483 -0.3824 -2.1273 -0.1257 -0.1165 -0.0878 -0.1374 -0.1031 -0.1683 -0.1237 -1.4073 -0.0590 -0.1034 -0.0666 -0.1311 -0.0378 -0.1991 -0.1069 -0.3574 -0.0729 -0.1046 -0.1267 -0.0239 -0.0527 -0.0802 -0.0770 -0.0348 -0.1101 -0.0926 -0.1349 -0.0385 -0.1620 -0.1088 -0.2466 -0.1959 -0.0098 -0.0754 -0.0283 -0.0362 -0.0822 -0.0871 -0.1389 -0.0641 -0.0787 -1.0355 -2.0092 -0.0513 -0.0622 -0.1820 -0.1560 -0.1181 -1.2488\n",
            "T-48\tmunthu amene wavala juzi wanyamula nsana n kuyenda pafupi ndi kamtsikana kovala chikwama akukankha ngolo\n",
            "H-48\t-0.3504614233970642\t▁ m u n t h u ▁ w a n y a m u l a ▁ c h i p a l e ▁ c h o n y a m u l a ▁ m s a n a ▁ w i n a ▁ a k u y e n d a ▁ p a n s i ▁ n d i p o ▁ a t a v a l a ▁ c h i k w a m a ▁ k u t h a m a n g o\n",
            "D-48\t-0.3504614233970642\tmunthu wanyamula chipale chonyamula msana wina akuyenda pansi ndipo atavala chikwama kuthamango\n",
            "P-48\t-0.1058 -0.2430 -0.0689 -0.0542 -0.0327 -0.0417 -0.1014 -0.1192 -0.2350 -0.3838 -2.6940 -0.1014 -0.1378 -0.0418 -0.4352 -0.0769 -0.0931 -0.1113 -0.1429 -0.0453 -0.1678 -1.4347 -0.1139 -0.6563 -0.0460 -0.0735 -0.5645 -0.1039 -0.0367 -1.9511 -0.0313 -0.0902 -0.3719 -0.1513 -0.0778 -0.1269 -0.1255 -1.1204 -0.9783 -0.3279 -0.1006 -0.2197 -0.1086 -1.1954 -0.1125 -0.1085 -0.1099 -0.1265 -0.6082 -0.0717 -0.1854 -0.1325 -0.1794 -0.0579 -0.0425 -0.1149 -0.1309 -0.1880 -0.1373 -0.6635 -0.1545 -0.0553 -0.1522 -0.7013 -0.1402 -0.1203 -1.0321 -0.0595 -0.1257 -1.7114 -0.3957 -0.4325 -0.6950 -0.1290 -0.0794 -0.1264 -0.1021 -0.2532 -0.0894 -0.0841 -0.0667 -0.1140 -0.0973 -0.0675 -0.1037 -0.1128 -0.9169 -0.5026 -2.3978 -0.4068 -0.1341 -0.1768 -0.3446 -0.1094 -0.1044 -1.7327 -1.5585\n",
            "T-333\tmayi wina anawerenga pepala ndi zakumwa kuchokera mu kapu ya khofi kutsogolo kwa chithunzi chojambula zithunzi\n",
            "H-333\t-0.33120670914649963\t▁ m a y i ▁ w i n a ▁ a n a y e n d a ▁ p a n j i n g a ▁ z a k u d y a ▁ k u c h o k e r a ▁ m ▁ k a z i ▁ k u t s o g o l o ▁ k w a ▁ c h i t h u n z i ▁ c h o j a m b u l a ▁ z i n t h u\n",
            "D-333\t-0.33120670914649963\tmayi wina anayenda panjinga zakudya kuchokera m kazi kutsogolo kwa chithunzi chojambula zinthu\n",
            "P-333\t-0.1027 -1.2791 -0.1052 -0.0362 -0.0824 -0.0839 -0.4799 -0.0634 -0.0776 -0.1251 -0.1358 -0.0890 -1.4349 -0.2003 -0.3070 -1.2320 -0.1485 -0.0921 -0.1166 -0.1247 -0.2194 -0.2073 -2.9381 -0.7614 -0.6580 -0.5327 -0.0756 -0.1038 -0.2000 -0.4447 -0.1413 -0.5182 -0.1025 -0.6643 -0.2541 -0.1470 -0.1324 -1.0497 -0.0586 -0.5016 -0.0564 -0.0827 -0.0126 -0.0203 -0.0492 -0.1002 -0.0947 -2.0023 -0.5718 -0.5921 -0.2407 -1.2372 -0.2976 -0.1248 -2.0853 -0.1309 -0.9874 -0.5265 -0.0546 -0.0588 -0.0727 -0.0811 -0.1234 -0.1103 -0.2031 -0.1453 -0.1147 -0.1540 -0.0318 -0.0553 -0.0817 -0.3219 -0.6776 -0.0189 -0.0700 -0.0118 -0.0420 -0.3346 -0.0347 -0.0514 -0.6816 -0.2836 -0.0848 -0.1823 -0.0220 -0.0321 -0.0622 -0.1032 -0.9632 -0.1938 -0.0547 -0.7900 -0.0342 -0.0344 -0.0429 -0.1410\n",
            "T-243\tanthu awiri akuyang ana njinga zamoto ziwiri zofiira pamalo pomwe pali zojambula zachipembedzo pakhoma\n",
            "H-243\t-0.27888643741607666\t▁ a n t h u ▁ a w i r i ▁ a k u y a n g ▁ a n a ▁ n j i n g a ▁ z a m o t o ▁ z i n t h u ▁ z o f i i r i r a ▁ p a m a l o ▁ o m w e ▁ p a l i ▁ z o j a m b u l i t s a ▁ z o p i r i k i r a\n",
            "D-243\t-0.27888643741607666\tanthu awiri akuyang ana njinga zamoto zinthu zofiirira pamalo omwe pali zojambulitsa zopirikira\n",
            "P-243\t-0.1063 -0.0752 -0.0671 -0.0566 -0.0946 -0.0920 -0.0966 -0.1224 -0.0480 -0.1305 -0.0636 -0.1079 -0.1066 -0.0932 -0.0318 -0.1232 -0.0300 -0.2825 -0.0480 -0.0610 -0.0959 -0.0747 -0.0341 -0.1395 -0.1105 -0.8640 -0.4216 -0.0445 -0.0668 -0.2550 -0.1041 -0.1214 -0.0142 -0.1092 -0.1785 -0.6527 -0.0140 -0.1461 -0.1158 -0.2150 -0.1674 -0.9053 -0.3684 -0.0071 -0.0616 -0.1029 -0.1683 -0.0460 -0.0119 -0.0584 -0.1079 -0.0488 -1.7951 -0.0562 -0.1128 -0.1110 -0.4660 -0.6401 -0.1782 -0.0976 -0.0690 -0.4549 -0.0838 -0.1018 -1.1711 -0.5317 -0.1051 -0.0975 -0.7076 -0.2611 -1.6004 -0.0972 -0.1525 -0.4973 -0.1374 -0.3425 -0.0872 -0.0600 -0.0140 -0.0525 -0.0420 -1.2147 -0.8215 -0.1049 -0.1164 -0.0692 -0.0685 -0.4935 -1.4538 -0.4781 -1.4758 -0.1013 -0.6764 -0.2703 -0.8475 -0.0953 -0.9726\n",
            "T-218\twosewera amayang ana mpira wa tenisi womwe adagunda ukuwuluka pomwe gulu limayang ana\n",
            "H-218\t-0.37379172444343567\t▁ w o s e w e r a ▁ a m a y a n g ▁ a n a ▁ m p i r a ▁ w o v a l a ▁ t ▁ s h i r t ▁ w o m w e ▁ a t a g w i r a ▁ n t c h i t o ▁ k u m w e t u l i r a ▁ n d i ▁ m a l a y a\n",
            "D-218\t-0.37379172444343567\twosewera amayang ana mpira wovala t shirt womwe atagwira ntchito kumwetulira ndi malaya\n",
            "P-218\t-0.1227 -0.0998 -0.0752 -0.7853 -0.3656 -0.0213 -0.1074 -0.0590 -0.0985 -0.1154 -1.4804 -0.2361 -0.1171 -0.1988 -0.4703 -0.1088 -0.2724 -0.1192 -0.0788 -0.1099 -0.1674 -0.1456 -0.4548 -0.4324 -0.0711 -0.1238 -0.0994 -0.1926 -0.0682 -3.0864 -0.3946 -0.1318 -0.0980 -0.1376 -0.1061 -0.2958 -0.3621 -0.1012 -0.0641 -0.2803 -0.0364 -0.0476 -0.1554 -0.9933 -0.1322 -0.8430 -0.1162 -0.1565 -0.1275 -0.1325 -0.9857 -0.1211 -0.8146 -1.5808 -0.1017 -0.4151 -0.1865 -0.1740 -1.2759 -1.0562 -1.5256 -0.5286 -0.8927 -0.0980 -0.2564 -0.1067 -0.5253 -0.6665 -0.3662 -1.6198 -0.0839 -0.1116 -0.0205 -0.0366 -0.3107 -0.5428 -0.1213 -0.3187 -0.2771 -0.0523 -0.1031 -0.1073 -0.0663 -0.2086 -1.7405 -0.4240 -0.2702 -0.0975 -0.4814\n",
            "T-233\tbambo wina wovala t sheti yabuluu akupachika chinthu padenga lalitali mopanda chitetezo ataima pansanjika ya lift\n",
            "H-233\t-0.34883183240890503\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ t ▁ s h i r t ▁ y a ▁ b u l u u ▁ a k u k h a l a ▁ c h i n t h u ▁ p a ▁ c h i n t h u ▁ p a l i ▁ n d i p o ▁ a l i ▁ p o p a n d a ▁ c h i t e t e z o ▁ p a ▁ s k a t e b o a r d\n",
            "D-233\t-0.34883183240890503\tbambo wina wovala t shirt ya buluu akukhala chinthu pa chinthu pali ndipo ali popanda chitetezo pa skateboard\n",
            "P-233\t-0.1210 -0.0301 -0.1110 -0.0528 -0.0496 -0.0542 -0.1063 -0.0672 -0.0785 -0.0884 -0.1188 -0.1154 -0.0342 -0.0634 -0.0362 -0.1263 -0.1345 -0.1176 -0.1059 -0.6004 -0.0674 -0.1625 -0.0268 -0.2450 -0.0270 -0.0135 -0.1290 -0.0135 -0.0727 -0.6982 -0.2206 -0.2577 -0.0701 -0.0414 -0.0264 -0.0787 -0.1088 -0.2671 -0.0779 -0.5711 -0.7533 -0.1265 -0.1952 -0.1343 -0.0984 -0.2488 -0.0482 -0.0795 -1.9934 -0.2844 -0.0392 -0.0521 -0.1301 -0.1194 -0.1195 -1.1062 -0.4064 -0.1062 -0.0783 -1.9402 -0.5154 -0.0310 -0.0726 -0.1161 -0.5593 -0.1274 -2.2975 -0.0673 -0.1358 -0.7023 -0.1656 -0.1481 -1.6743 -0.0393 -0.0940 -1.0879 -0.4239 -0.0821 -0.1189 -0.2348 -1.8865 -0.1588 -0.1842 -0.1017 -0.0198 -0.1325 -0.1265 -0.3065 -0.0839 -0.0741 -0.3277 -1.9625 -0.3653 -0.2024 -0.1909 -0.0343 -0.0802 -0.8509 -0.1283 -1.1819 -1.5510 -2.1045 -0.0802 -0.0634 -0.2883 -0.8379 -0.0965 -0.1129 -0.0417 -0.2947 -2.7098\n",
            "T-312\tbambo wina atanyamula msana paphewa lake ndipo ananyamula ndodo ndi manja awiri akudutsa m madzi a mumtsinje wamatope\n",
            "H-312\t-0.3081444799900055\t▁ b a m b o ▁ w i n a ▁ a t a n y a m u l a ▁ m s a n a ▁ p a k e ▁ w a k e ▁ n d i p o ▁ a t a n y a m u l a ▁ n d i ▁ m a n j a ▁ a l i ▁ n d i ▁ d z a n j a ▁ l i m o d z i ▁ a m u m s e w u\n",
            "D-312\t-0.3081444799900055\tbambo wina atanyamula msana pake wake ndipo atanyamula ndi manja ali ndi dzanja limodzi amumsewu\n",
            "P-312\t-0.1039 -0.1767 -0.0997 -0.0329 -0.1060 -0.0699 -0.0945 -0.1065 -0.0752 -0.0694 -0.1227 -0.1021 -0.0564 -0.0227 -0.0927 -0.0904 -0.0095 -0.0646 -0.0388 -0.0627 -0.0611 -0.0980 -0.1003 -0.2124 -0.1884 -0.7391 -0.0340 -0.1393 -0.1019 -1.3112 -0.1341 -0.7319 -0.1582 -0.2009 -2.2612 -0.2941 -0.6444 -0.1663 -0.1521 -0.1174 -0.0693 -0.0803 -0.8546 -0.0545 -0.0917 -0.5710 -1.9022 -0.1105 -0.0320 -0.0071 -0.0881 -0.0420 -0.0534 -0.0419 -0.1096 -0.1008 -1.4818 -0.0826 -0.3694 -0.1728 -1.6335 -0.2715 -0.2390 -0.0265 -0.0886 -0.0939 -0.1922 -0.9516 -0.0663 -0.1258 -0.2634 -0.0531 -0.1223 -0.1391 -1.6474 -0.0899 -0.1357 -0.1135 -0.0658 -0.1093 -0.0907 -0.1334 -2.1097 -0.1859 -0.0604 -0.0704 -0.0537 -0.0557 -0.1060 -0.3587 -0.6228 -0.5131 -0.2052 -0.5628 -0.5169 -0.3117 -0.0188 -2.0347\n",
            "T-162\tbambo wina wovala sweti yakuda akuponya mivi molunjika pa bolodi la mivi yomwe ili pakhoma pafupi ndi nsalu yofiira\n",
            "H-162\t-0.3272632956504822\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ j e k e t e ▁ l a c h i k a s u ▁ a k u k w e r a ▁ n j i n g a ▁ y a m o t o ▁ p a f u p i ▁ n d i ▁ t h a b w a ▁ l o m w e ▁ l i l i ▁ p a f u p i ▁ n d i ▁ k h o m a ▁ l o f i i r a ▁ n d i ▁ l o f i i r a\n",
            "D-162\t-0.3272632956504822\tbambo wina wovala jekete lachikasu akukwera njinga yamoto pafupi ndi thabwa lomwe lili pafupi ndi khoma lofiira ndi lofiira\n",
            "P-162\t-0.1194 -0.0257 -0.0983 -0.0451 -0.0309 -0.0679 -0.1197 -0.0692 -0.1076 -0.0679 -0.1052 -0.1041 -0.0432 -0.0951 -0.0550 -0.0893 -0.1107 -0.0954 -0.0931 -2.8316 -0.4984 -0.3723 -0.0991 -0.0556 -0.1392 -0.0947 -0.2620 -0.1880 -0.5836 -0.1173 -0.0810 -0.6094 -0.9148 -0.3528 -0.1269 -0.1144 -0.1133 -0.0579 -0.1023 -0.9732 -0.7388 -0.1745 -0.0859 -0.0915 -0.1071 -1.7075 -1.3847 -0.1364 -0.0274 -0.1319 -0.0702 -0.1334 -0.1003 -0.0889 -0.8951 -0.0328 -0.0666 -0.0885 -0.1763 -1.2205 -0.1556 -1.2671 -0.0819 -0.0604 -0.0580 -0.1017 -0.0357 -0.0886 -0.1030 -0.2660 -1.2387 -0.2843 -0.4744 -1.2294 -1.1698 -0.6422 -0.1517 -0.4606 -0.4201 -0.8887 -0.1083 -0.2861 -0.0977 -0.1623 -0.1093 -0.0650 -0.0966 -0.1362 -1.6101 -0.1258 -0.5336 -0.0766 -0.0548 -0.0366 -0.0796 -0.0852 -0.1587 -0.0865 -0.1751 -0.4004 -1.2447 -0.0631 -0.0899 -0.3876 -0.1436 -0.5076 -0.1898 -1.3493 -0.0592 -0.0789 -0.0232 -0.6918 -1.3032 -0.0935 -0.0571 -0.1007 -0.0838 -1.7220 -0.3791 -0.6261 -0.0348 -0.0915 -0.0185 -0.1277 -0.0900\n",
            "T-10\tamuna awiri ayimirira pafupi ndi msika wa pike place pomwe banja lakumbuyo likujambula chithunzi chaukwati\n",
            "H-10\t-0.40396803617477417\t▁ a m u n a ▁ a w i r i ▁ a i m i r i r a ▁ p a f u p i ▁ n d i ▁ k a u w o n e t s e d w a ▁ k o m a n s o ▁ a n j a ▁ k u m b u y o ▁ k u t i ▁ c h i t h u n z i\n",
            "D-10\t-0.40396803617477417\tamuna awiri aimirira pafupi ndi kauwonetsedwa komanso anja kumbuyo kuti chithunzi\n",
            "P-10\t-0.1112 -0.1644 -0.1219 -0.1218 -0.0752 -0.0833 -0.0913 -0.1176 -0.2839 -0.1872 -0.0382 -0.1213 -0.1016 -0.0957 -3.3201 -0.0482 -0.0851 -0.2069 -0.0689 -0.0489 -0.1067 -0.1022 -0.0609 -0.1108 -0.9918 -0.0931 -0.0535 -0.0622 -0.1160 -0.0216 -0.0769 -0.1108 -0.1201 -1.0379 -0.1235 -1.3941 -0.4681 -0.1097 -0.8497 -0.3340 -0.4231 -0.8393 -0.1123 -0.7870 -0.1181 -0.6219 -0.1439 -0.6844 -0.6325 -0.1917 -0.9706 -0.0293 -1.2892 -0.1222 -0.0789 -0.8628 -0.8556 -1.0201 -0.0927 -0.1260 -0.5619 -0.2093 -1.2748 -0.0111 -0.0388 -0.0244 -0.0742 -0.0944 -0.1112 -1.0614 -1.5102 -0.1945 -0.1100 -0.8553 -0.0576 -0.4212 -2.0606 -0.0587 -0.0525 -0.0733 -0.0312 -0.0419 -2.7634\n",
            "T-143\tanthu awiri akwera pamwamba pa makwerero pamene mwamuna wina wovala buluu waima kuseri kwa makwerero apakati\n",
            "H-143\t-0.30754610896110535\t▁ a n t h u ▁ a w i r i ▁ a k u y e r a ▁ p a m w a m b a ▁ p a ▁ m a k w e r e r o ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ w a i m a ▁ k u t s e g u l i r i d w a ▁ k w a ▁ m a k w e r e r o\n",
            "D-143\t-0.30754610896110535\tanthu awiri akuyera pamwamba pa makwerero pamene mwamuna wina waima kutseguliridwa kwa makwerero\n",
            "P-143\t-0.1091 -0.1270 -0.0379 -0.0382 -0.1479 -0.0922 -0.0960 -0.1239 -0.3004 -0.1173 -0.0551 -0.1328 -0.1012 -0.1702 -0.1273 -0.1656 -0.1727 -2.1367 -1.2364 -0.1419 -0.0931 -0.1203 -0.1226 -0.4849 -0.1485 -0.1096 -0.0334 -0.0215 -0.1044 -0.0922 -0.0590 -0.1543 -0.2256 -0.4622 -0.2747 -1.7416 -0.2313 -0.0483 -0.0915 -0.8532 -0.2832 -0.0950 -0.1265 -0.0917 -0.1641 -0.2902 -0.0913 -0.0835 -0.0670 -0.1137 -0.1265 -0.0241 -0.1242 -0.0812 -0.0575 -0.0450 -0.1345 -0.1183 -0.0346 -0.0425 -0.0503 -0.1329 -0.1421 -0.5295 -0.3712 -2.6056 -0.1014 -0.0861 -0.0895 -0.3724 -0.0446 -0.6386 -0.0120 -0.5998 -0.6550 -0.2156 -0.8178 -0.6504 -0.8041 -0.8163 -0.2555 -0.0342 -0.0982 -0.1240 -0.3708 -0.1866 -0.1341 -1.4106 -0.2193 -0.1532 -0.4463 -0.7002 -0.0702 -0.0830 -0.8238 -0.2966 -0.2289 -1.4723\n",
            "T-296\tmayi wina wovala malaya ofiira ndi tsitsi lakuda atakhala pampando akumwetulira mtsikana wovala t shirt ya hello kitty\n",
            "H-296\t-0.29994744062423706\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ s h e t i ▁ y a k u d a ▁ a t a k h a l a ▁ p a m p a n d o ▁ a k u m e n y a ▁ m u m s e w u ▁ w o k h a l a ▁ n d i ▁ c h i p e w a ▁ c h o t c h e t e z a\n",
            "D-296\t-0.29994744062423706\tmayi wina wovala malaya ofiira ndi sheti yakuda atakhala pampando akumenya mumsewu wokhala ndi chipewa chotcheteza\n",
            "P-296\t-0.1116 -0.0453 -0.0953 -0.0283 -0.1177 -0.1097 -0.0553 -0.2166 -0.0668 -0.1072 -0.1067 -0.1137 -0.0447 -0.1698 -0.1209 -0.0734 -0.1174 -0.1040 -0.0425 -0.1232 -0.0507 -0.1207 -0.0382 -0.1166 -0.0923 -0.0364 -0.0225 -0.0727 -0.3124 -0.0807 -0.1595 -0.1034 -0.0246 -0.0669 -0.1518 -0.0931 -0.4750 -1.6115 -1.7245 -0.4193 -0.1359 -0.1467 -0.1190 -0.0990 -0.0606 -0.0519 -0.0358 -0.1287 -0.1201 -0.1533 -0.1052 -0.0998 -0.0568 -0.0278 -0.0983 -0.0781 -0.1038 -0.0888 -0.0898 -0.1154 -0.2703 -0.2824 -0.2453 -0.0294 -0.0131 -0.0302 -0.0889 -1.1189 -0.2768 -0.0979 -0.3541 -0.1435 -0.6051 -0.7865 -0.4623 -0.1170 -0.6543 -2.1054 -0.4079 -0.0962 -0.1530 -0.2224 -0.0570 -0.1408 -1.5076 -0.8774 -0.3704 -0.1085 -0.1559 -0.0740 -0.1143 -0.0724 -0.0251 -0.2777 -0.1781 -0.0905 -0.5151 -0.0838 -0.2594 -1.5916 -1.4318 -0.0546 -0.1120 -0.2326 -0.1208 -0.0843 -0.2843 -0.9774 -1.3765 -0.1107 -0.3348 -0.9846 -1.0411 -1.3695 -1.2070 -0.3535\n",
            "T-25\tmnyamata wina wovala malaya achikasu wakwera bulu womangidwa pangolo atanyamula anyamata awiri achikasu mumsewu\n",
            "H-25\t-0.26838451623916626\t▁ m n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ w a k u d a ▁ n d i p o ▁ w o m a n g i d w a ▁ p a m p a n d o ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a t a v a l a ▁ j e k e t e ▁ l a c h i k a s u\n",
            "D-25\t-0.26838451623916626\tmnyamata wina wovala malaya achikasu wakuda ndipo womangidwa pampando wovala malaya abulauni atavala jekete lachikasu\n",
            "P-25\t-0.1134 -0.0836 -0.1561 -0.0417 -0.1216 -0.0528 -0.0933 -0.0185 -0.0984 -0.1151 -0.1295 -0.0533 -0.0807 -0.1137 -0.1078 -0.0811 -0.0700 -0.2001 -0.1260 -0.0876 -0.1231 -0.1111 -0.0411 -0.1491 -0.0599 -0.1261 -0.0345 -0.1005 -0.0915 -0.1469 -0.0423 -0.0478 -0.0913 -0.0157 -0.1447 -0.0208 -0.0662 -0.1011 -0.2898 -0.2233 -0.7234 -2.2020 -0.1698 -0.1242 -0.1268 -1.4922 -0.0695 -0.0950 -0.4388 -0.1308 -0.1014 -0.2969 -1.2599 -0.4118 -0.2547 -0.0801 -0.5662 -0.0441 -0.0830 -0.0202 -0.1427 -0.1210 -0.4624 -0.1164 -0.2198 -1.0377 -0.2672 -0.0798 -0.0736 -0.2926 -0.0930 -0.1121 -0.8507 -0.4023 -0.1176 -0.0942 -0.1255 -0.0998 -0.1428 -0.1804 -0.4235 -0.1414 -0.0693 -0.1286 -0.0656 -0.1218 -2.8477 -0.3574 -0.0834 -1.3545 -0.0704 -0.0662 -0.0600 -0.0939 -0.1197 -1.2086 -0.1480 -2.2520 -0.1107 -0.0864 -0.1430 -0.1007 -0.5068 -0.2070 -0.4697 -0.2350 -0.0207 -0.1635 -0.1153 -0.9993 -0.1854 -0.2010 -0.1985 -0.0981 -0.3505 -0.1385 -0.0227 -0.0586 -0.2205\n",
            "T-103\tbambo wina wadazi akuyesera kumenya mpira wa basketball pamasewera pomwe anthu ali pamalopo akuwonera\n",
            "H-103\t-0.29381272196769714\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ z i d a ▁ a k u y e s e r a ▁ k u m e n y a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ p a m a s e w e r a ▁ a ▁ m a l o ▁ o t u w a ▁ a k u w o n e r a\n",
            "D-103\t-0.29381272196769714\tbambo wina wovala zida akuyesera kumenya mpira wa basketball pamasewera a malo otuwa akuwonera\n",
            "P-103\t-0.1095 -0.1144 -0.1060 -0.0355 -0.0804 -0.0832 -0.1080 -0.0704 -0.0667 -0.0683 -0.1421 -0.1079 -0.0835 -0.4504 -0.1598 -0.1411 -0.1174 -0.1143 -0.0977 -1.0582 -0.2482 -2.6610 -0.1202 -0.1107 -0.3456 -0.0585 -0.0889 -0.4180 -0.2587 -0.0622 -0.1225 -0.0360 -0.1056 -0.0996 -0.4683 -0.2063 -0.3042 -0.9994 -0.0754 -0.0583 -0.1088 -0.2043 -0.0798 -0.1296 -0.0748 -0.0665 -0.1226 -0.1227 -0.0760 -0.1459 -0.3637 -0.4530 -0.2284 -0.0542 -0.6478 -0.0797 -0.0132 -0.0724 -0.1531 -0.1099 -0.9229 -0.1530 -0.5376 -0.2037 -0.8216 -0.0930 -0.1907 -0.7779 -0.0500 -0.0549 -0.0295 -0.1391 -0.0938 -0.7160 -0.2917 -0.9049 -0.3478 -0.9693 -0.4347 -0.1350 -0.3610 -1.5766 -0.1942 -0.1707 -0.1024 -0.3161 -0.1086 -0.1030 -0.1213 -2.6887 -0.2358 -0.1153 -0.0484 -0.1745 -0.1217 -0.4322\n",
            "T-209\tbambo wina wovala uta wopangidwa ndi dola imodzi ndipo wavala magalasi akuyang ana mu kamera\n",
            "H-209\t-0.3047182261943817\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ t h u k u t a ▁ l a k u t h a n d i d w a ▁ n d i ▁ b o t o l o ▁ l a ▁ p i n k i ▁ n d i p o ▁ w a v a l a ▁ m a t h a l a u z a ▁ a k u y a n g ▁ a n a ▁ m u ▁ k a m e r a\n",
            "D-209\t-0.3047182261943817\tbambo wina wovala thukuta lakuthandidwa ndi botolo la pinki ndipo wavala mathalauza akuyang ana mu kamera\n",
            "P-209\t-0.1148 -0.1107 -0.0771 -0.1661 -0.0312 -0.0888 -0.1278 -0.1650 -0.1132 -0.0959 -0.1149 -0.1271 -0.0955 -0.1009 -0.1346 -0.1195 -0.0798 -0.0973 -0.1041 -1.6813 -0.0572 -0.3780 -0.0617 -0.0510 -0.0140 -0.0790 -0.1099 -0.0493 -0.2786 -2.1804 -0.3611 -1.3266 -0.2297 -0.1697 -0.3609 -0.0659 -0.0865 -1.1599 -0.1392 -0.0836 -0.1406 -0.2536 -0.0407 -0.1938 -0.2848 -1.4190 -1.1741 -1.2509 -0.3123 -0.0458 -0.3541 -0.0905 -0.2090 -0.9793 -0.7455 -2.0315 -0.2426 -0.1221 -0.0230 -0.0704 -0.1103 -0.8969 -0.1336 -0.0629 -0.1651 -0.0621 -0.0999 -1.0538 -1.1072 -0.4177 -0.1269 -0.0807 -0.0991 -0.0977 -0.4550 -0.0857 -1.9411 -0.0485 -0.0794 -0.0923 -0.0966 -0.0180 -0.2243 -0.0941 -0.0736 -0.2064 -0.3954 -0.1218 -0.0771 -0.1527 -0.0379 -0.1829 -0.0709 -0.0838 -0.0598 -0.1405 -0.3054 -0.3373 -0.6314 -0.2669 -0.1887 -0.1950 -0.1259 -0.1231 -0.0427 -0.1016 -0.0634\n",
            " 46% 6/13 [00:15<00:14,  2.11s/it, wps=1117]T-92\tbambo amene akusuta ndudu aima ndi mwamuna wina kutsogolo kwa ndudu m chikwama chowonetsera\n",
            "H-92\t-0.2909485697746277\t▁ b a m b o ▁ a m e n e ▁ a k u s u t a ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ n d i ▁ m w a m u n a ▁ w i n a ▁ k u t s o g o l o ▁ k w a ▁ m a c h i k w a n g w a n i ▁ c h o s e w e r a\n",
            "D-92\t-0.2909485697746277\tbambo amene akusuta ndi gulu la anthu ndi mwamuna wina kutsogolo kwa machikwangwani chosewera\n",
            "P-92\t-0.1066 -0.3797 -0.1453 -0.0459 -0.0354 -0.0432 -0.1164 -0.4320 -1.1008 -0.0445 -0.1174 -0.0542 -0.1373 -0.0816 -0.1290 -0.1073 -1.4711 -0.2191 -0.4424 -0.2458 -0.1122 -0.6321 -0.0421 -1.3615 -0.1902 -2.1706 -0.1090 -0.3072 -0.0386 -0.1098 -0.1143 -0.1059 -0.1746 -0.1969 -0.0452 -0.0864 -0.0737 -0.0698 -0.1132 -2.3310 -0.0861 -0.0716 -0.1683 -0.0745 -0.2261 -0.1314 -0.0433 -0.0916 -0.0487 -0.1158 -0.1076 -0.3256 -0.0382 -0.0557 -0.1171 -0.1073 -1.5162 -0.0748 -0.1394 -0.0333 -0.0293 -0.0096 -0.0783 -0.0473 -0.0696 -0.1062 -0.5862 -0.0178 -0.1027 -0.0990 -0.1701 -1.9197 -0.9380 -0.1761 -0.1594 -0.4474 -0.0868 -0.0883 -2.1486 -0.3494 -0.0306 -0.0844 -0.0324 -0.0642 -0.2551 -0.1743 -0.1045 -0.0520 -0.9822 -0.1178 -0.0512 -0.1955 -0.0927 -0.0999 -0.2615\n",
            "T-71\tmayi wamng ono wa brunette wakhala pansi atanyamula mwana yemwe akutafuna mphete yamitundu yosiyanasiyana\n",
            "H-71\t-0.30150631070137024\t▁ m a y i ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ j e k e t e ▁ l o k h a l a ▁ n d i ▁ a t s i k a n a ▁ a m a y e n d a ▁ p a m e n e ▁ a k u j a m b u l a ▁ m i t e n g o ▁ y o s i y a n a s i y a n a\n",
            "D-71\t-0.30150631070137024\tmayi wamng ono wovala jekete lokhala ndi atsikana amayenda pamene akujambula mitengo yosiyanasiyana\n",
            "P-71\t-0.1041 -0.1559 -0.1384 -0.0649 -0.1166 -0.0996 -0.0381 -0.1730 -0.2729 -0.1728 -0.0622 -0.0690 -0.1495 -0.1021 -0.0631 -0.1337 -0.1030 -0.5979 -0.0980 -0.0961 -0.1484 -0.1171 -0.1049 -0.9228 -1.6702 -0.0804 -0.1059 -0.0230 -0.0682 -0.0873 -0.9970 -0.2075 -0.7003 -0.2138 -0.0961 -0.1181 -0.0973 -0.0976 -0.1140 -0.4995 -0.1159 -0.0764 -2.7759 -0.2804 -0.3649 -0.2473 -1.1286 -0.1887 -0.0896 -0.0984 -0.1112 -0.4554 -0.1398 -0.2778 -0.1724 -0.1320 -0.1763 -0.1060 -0.1006 -0.1052 -0.2334 -0.0951 -2.2195 -0.2013 -0.0382 -0.0772 -0.0767 -1.1384 -0.1438 -0.1080 -1.1397 -0.0895 -0.1237 -0.2277 -0.0635 -0.0745 -0.2028 -0.0805 -1.4368 -1.7806 -0.5723 -0.0275 -0.0801 -0.3778 -0.0945 -0.1283 -0.0379 -0.9853 -0.6227 -0.0863 -0.0131 -0.1015 -0.0822 -0.1007 -0.0458 -0.0228 -0.0090 -0.1166 -0.0645 -0.0727 -0.8366\n",
            "T-346\tmtsikana wovala magalasi agwire mtsikana wa msinkhu womwewo atavala thukuta lofiira ndi magalasi achikasu\n",
            "H-346\t-0.32133081555366516\t▁ m t s i k a n a ▁ w o v a l a ▁ m a g a l a s i ▁ a ▁ b u l a u n i ▁ a k u w a l a ▁ m a d z i ▁ k u w o n e k e r a ▁ t a v a l a ▁ t h u k u t a ▁ l a ▁ o f i i r a ▁ n d i ▁ m a g a l a s i ▁ a c h i k a s u\n",
            "D-346\t-0.32133081555366516\tmtsikana wovala magalasi a bulauni akuwala madzi kuwonekera tavala thukuta la ofiira ndi magalasi achikasu\n",
            "P-346\t-0.1223 -0.4778 -0.0129 -0.1082 -0.0398 -0.0362 -0.1284 -0.0707 -0.1466 -0.1122 -0.0349 -0.1139 -0.0648 -0.1472 -0.0986 -0.1311 -0.1068 -0.0559 -0.1195 -1.0991 -0.3670 -0.0778 -0.1305 -0.0168 -0.0490 -0.0867 -0.0736 -0.8176 -0.4500 -0.4511 -0.0781 -0.1561 -0.6435 -0.0797 -0.1011 -0.1123 -0.3398 -0.2580 -0.1278 -2.0028 -0.1796 -0.2827 -0.2231 -0.1370 -0.1247 -1.8201 -2.2208 -0.1504 -0.0628 -0.1276 -0.8483 -0.0718 -0.4196 -0.1398 -0.0946 -0.0742 -0.8587 -1.4457 -0.0797 -0.1015 -0.1027 -1.7152 -0.9494 -0.1591 -0.1466 -0.1075 -0.1461 -0.1012 -0.3729 -0.6057 -0.1566 -0.2464 -0.0667 -0.0350 -0.1045 -0.1122 -0.2111 -0.1958 -0.7969 -1.5933 -0.0631 -0.0710 -0.0913 -0.0327 -0.2193 -0.1076 -0.0461 -0.0684 -0.1067 -0.1446 -0.0534 -0.1366 -1.1640 -0.2121 -0.1832 -0.1699 -0.0253 -0.0414 -0.3630 -0.9310 -2.2291 -0.1829 -0.1105 -0.2297 -0.1616 -0.0261 -0.3968 -0.1024\n",
            "T-30\twosewera mpira wa jersey yobiriwira akulandira mpira pamene wosewera mpira wa jersey yoyera wagona pansi\n",
            "H-30\t-0.311105340719223\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ j e a n s ▁ y o b i r i w i r a ▁ a k u l a n k h u l a ▁ n d i ▁ m p i r a ▁ p a m e n e ▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ j e r s e y ▁ y o k o n g o l a ▁ m ▁ m a d z i\n",
            "D-30\t-0.311105340719223\twosewera mpira wa jeans yobiriwira akulankhula ndi mpira pamene wosewera mpira wa jersey yokongola m madzi\n",
            "P-30\t-0.1061 -0.1430 -0.0686 -0.0368 -0.8786 -0.0267 -0.1064 -0.0467 -0.1034 -0.1080 -0.0197 -0.1150 -0.0872 -0.0558 -0.1235 -0.1620 -0.0678 -0.2477 -0.2464 -0.5886 -0.1276 -1.7614 -0.1028 -0.1531 -0.1430 -0.2197 -0.3609 -1.7988 -0.0588 -0.0587 -0.0798 -0.0146 -0.0498 -0.0432 -0.0931 -0.1298 -0.1457 -0.0934 -0.1048 -0.9651 -1.8191 -0.0223 -0.1884 -0.1249 -0.1619 -0.0694 -0.1180 -0.1174 -0.0999 -0.0664 -0.0971 -0.1454 -0.8233 -0.0875 -0.1239 -0.0679 -0.1161 -0.1394 -0.5224 -0.1435 -0.2134 -0.8615 -0.0444 -0.0442 -0.0980 -0.4555 -0.6876 -0.1067 -0.3502 -0.0088 -0.1927 -0.0333 -0.1154 -0.1199 -0.9185 -0.1389 -0.0743 -0.0494 -0.1139 -0.1489 -0.1235 -0.2336 -0.2514 -2.1320 -0.0750 -0.3219 -1.5061 -0.2464 -0.3549 -0.1187 -0.6518 -0.1495 -0.8269 -0.6742 -0.1447 -0.8784 -0.1024 -0.1009 -0.7492 -0.3904 -1.0037 -1.0363 -1.0290 -0.3625 -0.2493 -0.0556 -0.0650 -0.0944\n",
            "T-112\tmayi wachikulire wakhala patebulo atavala blazer yofiirira kudikirira mbale yake ya pasitala\n",
            "H-112\t-0.28355544805526733\t▁ m a y i ▁ w a c h i k u l i r e ▁ w a k h a l a ▁ p a t e b u l o ▁ a t a v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ k u d i k i r i r a ▁ m ▁ b a l e ▁ y a c h i k a s u\n",
            "D-112\t-0.28355544805526733\tmayi wachikulire wakhala patebulo atavala malaya ofiira ndi kudikirira m bale yachikasu\n",
            "P-112\t-0.1086 -0.0569 -0.0598 -0.0479 -0.0750 -0.0862 -0.0430 -0.1749 -0.0494 -0.0594 -0.0809 -0.1164 -0.0646 -0.1902 -0.0705 -0.0538 -0.0281 -0.1262 -1.6705 -0.2559 -0.0986 -0.0549 -0.1081 -0.0697 -0.1147 -0.1293 -0.1133 -0.1107 -0.7005 -0.0867 -0.0109 -0.0308 -0.0831 -0.0810 -0.1026 -2.5422 -0.0042 -0.0904 -0.0308 -0.1028 -0.1208 -0.1038 -0.1151 -0.1429 -0.1081 -0.8036 -0.1691 -0.1062 -0.1531 -0.0860 -0.1108 -1.1620 -0.0551 -0.1951 -0.0492 -0.5354 -0.1149 -1.0384 -0.1353 -0.0897 -1.2127 -0.5240 -0.2066 -0.6162 -0.6670 -0.0499 -0.0253 -0.0708 -0.0744 -0.0444 -0.1045 -0.1600 -0.1366 -0.6326 -0.4529 -0.1141 -0.5861 -0.4865 -0.1749 -0.0521 -0.1138 -2.1382 -0.1096 -0.0963 -0.4924 -0.1137 -0.1147 -0.6055 -1.5825\n",
            "T-169\tgulu la amuna linakwera galimoto ya buluu m chipululu itanyamula zikwama zipewa makwerero ndi zinthu zina\n",
            "H-169\t-0.39287519454956055\t▁ g u l u ▁ l a ▁ a m u n a ▁ l i n a ▁ l i k u y a n g ▁ a n a ▁ m u t u ▁ m u ▁ c h i u b u ▁ n d i ▁ g a l i m o t o ▁ y a ▁ m a s i t a l a ▁ m a s i t e p e ▁ o f i i r a ▁ n d i ▁ z i n t h u\n",
            "D-169\t-0.39287519454956055\tgulu la amuna lina likuyang ana mutu mu chiubu ndi galimoto ya masitala masitepe ofiira ndi zinthu\n",
            "P-169\t-0.1235 -0.0465 -0.0739 -0.0846 -0.0756 -0.0982 -0.0367 -0.0937 -0.1142 -0.2900 -0.1179 -0.0192 -0.0769 -0.1214 -0.1100 -0.0492 -0.0673 -0.4496 -0.1009 -0.2098 -0.1325 -0.1685 -0.1982 -0.0936 -0.0267 -0.2367 -0.1226 -0.0961 -0.1093 -0.1122 -0.1113 -0.2106 -0.1048 -0.5767 -0.5812 -0.9163 -0.0390 -0.0758 -1.3973 -1.5536 -0.8905 -0.7797 -0.0928 -0.1031 -2.1983 -1.2064 -0.1549 -0.0895 -0.9820 -0.3545 -0.0835 -0.5960 -1.3329 -0.3942 -0.0499 -1.1480 -0.0662 -0.0254 -0.0655 -0.5822 -0.1216 -0.2783 -0.1428 -1.8137 -0.5765 -0.2356 -0.2903 -0.1287 -0.5631 -0.1624 -0.9759 -0.1103 -0.1979 -1.2972 -1.0042 -0.2849 -0.4523 -0.6306 -0.0844 -0.3295 -0.0539 -0.1297 -1.6412 -1.0047 -0.9019 -0.1004 -0.0353 -0.5278 -0.2914 -0.1052 -0.0551 -0.0739 -0.1173 -0.2863 -0.1272 -1.4404 -1.2849 -0.0494 -0.0498 -0.9142\n",
            "T-55\tmnyamata akanyamula ndi kunyamula mfuti ya makina mnyamata wamkulu pang ono kuposa iye akuveka chipewa pamutu pake\n",
            "H-55\t-0.39802077412605286\t▁ m n y a m a t a ▁ a t a n y a m u l a ▁ n d i ▁ k o n y a m u l a ▁ m f u t i ▁ y a ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ w o m w e ▁ a k u g w i r i t s a ▁ n t c h i t o ▁ k a k u m w a ▁ k w a k e\n",
            "D-55\t-0.39802077412605286\tmnyamata atanyamula ndi konyamula mfuti ya m mphepete mwa nyanja womwe akugwiritsa ntchito kakumwa kwake\n",
            "P-55\t-0.1145 -0.1339 -0.0416 -0.0432 -0.1155 -0.1141 -0.0986 -0.0529 -0.1047 -0.1046 -0.3636 -0.7712 -0.1013 -0.7509 -0.0737 -0.0798 -0.0694 -0.0885 -0.0649 -0.0977 -0.1109 -0.2504 -0.2025 -0.1820 -0.2209 -0.3915 -1.6573 -0.2297 -0.1527 -0.0975 -0.1438 -0.1123 -0.0590 -0.1197 -0.1132 -0.1108 -3.5728 -0.1632 -0.9867 -0.0623 -0.1250 -0.0913 -0.0909 -0.6883 -0.0589 -1.7136 -0.8609 -0.8704 -0.0913 -0.7046 -0.3994 -0.2162 -0.0155 -0.1425 -0.0705 -0.0656 -0.0790 -0.1842 -0.0932 -0.1090 -0.0376 -0.1143 -0.3689 -0.0594 -0.0948 -0.1103 -1.0990 -1.4079 -0.1915 -0.1668 -0.0904 -0.1297 -0.9350 -0.6090 -0.0953 -1.7718 -0.0622 -0.6260 -0.1475 -1.3522 -0.1550 -0.8706 -0.1298 -0.0728 -2.4532 -0.0876 -0.0387 -0.1029 -0.0659 -0.0945 -0.1588 -0.1322 -1.7603 -0.4619 -2.1349 -0.8048 -0.3341 -0.7527 -0.9271 -0.2424 -0.9957 -0.5213 -0.1653 -0.1420 -0.0309 -0.0911\n",
            "T-98\tanthu asanu adadikirira pamzere pomwe bambo wovala jekete labuluu akulipira ndalama\n",
            "H-98\t-0.3529209494590759\t▁ a n t h u ▁ a s a n u ▁ a t a g w i r a ▁ n t c h i t o ▁ p a m z e r e ▁ p o m w e ▁ m a d z i ▁ a t a v a l a ▁ j e k e t e ▁ l a b u l u u ▁ a w i r i ▁ a k u m b i r a n a\n",
            "D-98\t-0.3529209494590759\tanthu asanu atagwira ntchito pamzere pomwe madzi atavala jekete labuluu awiri akumbirana\n",
            "P-98\t-0.1067 -0.1657 -0.0783 -0.0364 -0.1987 -0.0859 -0.0869 -0.1696 -0.4527 -0.0954 -0.0128 -0.1054 -0.0899 -0.3082 -0.7397 -0.1167 -3.4565 -0.6208 -0.0968 -0.1330 -0.8063 -0.1146 -1.3295 -0.1461 -0.0969 -0.1266 -0.1062 -0.2211 -0.2878 -0.0961 -0.2210 -0.1876 -0.4290 -0.0660 -0.1898 -0.0679 -0.1876 -0.1265 -0.2681 -0.7752 -0.1406 -0.0289 -0.0990 -0.0757 -0.8933 -0.2419 -2.7103 -0.0396 -0.0623 -0.1045 -0.7230 -0.3787 -0.2672 -0.3225 -0.0901 -0.0891 -0.1202 -0.0874 -0.3637 -0.1885 -0.4500 -0.1559 -0.0049 -0.2204 -0.1017 -0.4236 -0.6240 -1.5451 -0.0997 -0.0665 -0.1006 -0.0415 -0.1171 -0.5142 -1.9894 -0.1273 -0.0297 -0.1182 -0.1952 -0.3099 -0.2134 -0.1201 -1.4536 -0.9472 -0.9248 -0.0543 -0.1450 -0.0854 -0.1064 -0.4457\n",
            "T-170\tkhamu lalikulu la anthu ena okhala ndi mbendera zobiriwira zoyera ndi zofiirira zamizeremizere\n",
            "H-170\t-0.2554306387901306\t▁ k h a m u ▁ l a l i k u l u ▁ l a ▁ a n t h u ▁ o k h a l a ▁ n d i ▁ m i t e n g o ▁ y o b i r i w i r a ▁ n d i ▁ z o y e r a ▁ z o f i i r a ▁ n d i ▁ z o f i i r a ▁ z a m i z e r e\n",
            "D-170\t-0.2554306387901306\tkhamu lalikulu la anthu okhala ndi mitengo yobiriwira ndi zoyera zofiira ndi zofiira zamizere\n",
            "P-170\t-0.1054 -0.1035 -1.6013 -0.1138 -0.0466 -0.0860 -0.0711 -0.0338 -0.2158 -0.2380 -0.1075 -0.0526 -0.0580 -0.0290 -0.0792 -0.1186 -0.2075 -0.2923 -0.1219 -0.0824 -0.0173 -0.0211 -0.0819 -0.1250 -0.1196 -3.2236 -0.0393 -0.1108 -0.1119 -0.0758 -0.1012 -0.0912 -0.0458 -0.0529 -0.0940 -0.0902 -0.9376 -0.7717 -1.8038 -0.0512 -0.0518 -0.1782 -0.3520 -0.0925 -0.4438 -0.7390 -1.4091 -0.0447 -0.0352 -0.0817 -0.0441 -0.0465 -0.0357 -0.1105 -0.1251 -1.3519 -0.1226 -0.0544 -0.1182 -0.1217 -0.0370 -0.7338 -0.0828 -0.0413 -0.1348 -0.0898 -0.2558 -0.0835 -0.0722 -0.0630 -0.1193 -0.0245 -0.1493 -0.0845 -0.3607 -0.0609 -0.1081 -0.0911 -0.0167 -0.4822 -0.1918 -0.0566 -0.0856 -0.0262 -0.5788 -0.1353 -0.7467 -0.1445 -0.2846 -0.6345 -0.6370 -0.0729 -0.0440 -0.0375 -0.2093\n",
            "T-130\tmwamuna wavala malaya ofiira pamene mkazi waima naye ali ndi mikwingwirima yofiirira m tsitsi lake\n",
            "H-130\t-0.2709790766239166\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ p a m e n e ▁ m k a z i ▁ w o k h a l a ▁ n d i ▁ m a y i ▁ w i n a ▁ y e m w e ▁ a l i ▁ n d i ▁ m a f i r i ▁ y o f i i r a\n",
            "D-130\t-0.2709790766239166\tmwamuna wovala malaya ofiira pamene mkazi wokhala ndi mayi wina yemwe ali ndi mafiri yofiira\n",
            "P-130\t-0.1249 -0.0703 -0.0354 -0.1038 -0.0628 -0.0575 -0.0648 -0.0991 -0.1198 -0.1666 -0.0813 -0.6769 -0.1428 -0.0929 -0.1357 -0.1072 -0.0468 -0.1115 -0.0419 -0.1265 -0.0615 -0.1287 -0.1016 -0.0147 -0.0490 -0.0358 -0.0578 -0.0515 -0.1404 -0.1086 -1.7379 -0.0976 -0.1007 -0.1132 -0.0769 -0.0489 -0.0791 -0.0605 -0.3698 -0.1077 -0.0205 -0.0536 -0.1065 -0.0253 -1.6779 -0.5536 -0.0495 -0.1226 -0.1352 -0.1666 -0.1168 -0.1334 -0.1346 -0.0980 -0.1164 -0.1453 -0.1274 -0.4952 -0.0994 -0.0884 -1.0836 -0.1610 -0.0703 -0.1175 -0.3619 -0.9051 -0.1594 -0.0491 -0.1179 -0.1410 -0.0884 -0.1760 -1.4728 -0.1001 -0.1236 -0.7275 -0.2422 -0.1104 -0.1225 -0.3768 -0.1898 -0.7714 -0.5351 -1.6128 -0.2343 -0.2900 -0.5246 -0.1250 -0.0339 -0.0586 -0.3209 -0.0333 -0.1383 -3.4205\n",
            "T-270\tatsikana omwe anavala yunifolomu ya broncos yofiira ndi yoyera anatsetsereka pa udzu pamene ankagwira mpira wofewa wachikasu\n",
            "H-270\t-0.30593055486679077\t▁ k a m t s i k a n a ▁ k a k a n g ▁ o n o ▁ k o v a l a ▁ y u n i f o l o m u ▁ y o f i i r a ▁ y o f i i r a ▁ n d i ▁ y o y e r a ▁ a t a n s e ▁ p a ▁ u d z u ▁ p a m e n e ▁ m p i r a ▁ w o f i i r a ▁ m p i r a ▁ w a c h i k a s u\n",
            "D-270\t-0.30593055486679077\tkamtsikana kakang ono kovala yunifolomu yofiira yofiira ndi yoyera atanse pa udzu pamene mpira wofiira mpira wachikasu\n",
            "P-270\t-0.1136 -1.4293 -0.2147 -0.5491 -0.0320 -0.0837 -0.0447 -0.0478 -0.1542 -0.0843 -0.1350 -0.0911 -1.4736 -0.2589 -1.4797 -0.0811 -0.0811 -0.2348 -0.1103 -0.1000 -0.0587 -0.2434 -0.1020 -0.4342 -0.0622 -0.2292 -0.0908 -0.0996 -0.1199 -0.0942 -0.4615 -0.3946 -0.0342 -0.0465 -0.0685 -0.0269 -0.1791 -0.0441 -0.0109 -0.1373 -0.1054 -0.0405 -0.5158 -0.1763 -0.0506 -0.1772 -0.0426 -0.1648 -0.0831 -1.4326 -0.0292 -0.0505 -0.0710 -0.2659 -0.0488 -0.2012 -0.0963 -2.4204 -0.0481 -0.1040 -0.1095 -0.0714 -0.0370 -0.0728 -0.0869 -0.1083 -0.1276 -0.1015 -0.1690 -1.4661 -0.7020 -0.7465 -0.9177 -0.0484 -0.3162 -1.0777 -0.1801 -1.9627 -0.7865 -0.5327 -0.0800 -0.0532 -0.0610 -0.3287 -0.1595 -0.2254 -0.0840 -0.0546 -0.0453 -0.0904 -2.4241 -0.6795 -0.2640 -0.1163 -0.1054 -0.1309 -0.1331 -0.2778 -0.6658 -0.0798 -0.1312 -0.0407 -0.1494 -0.1396 -1.4632 -0.1690 -0.0535 -0.0423 -0.1093 -0.2061 -0.0489 -0.5572 -1.3573 -0.0963 -0.0545 -0.0771 -0.0976 -0.1174 -0.0791 -0.1815\n",
            "T-216\tmnyamata wina wa ku asia wovala jekete la pinki ndi lakuda akuyenda ndi mtsikana mu jekete ya bulauni\n",
            "H-216\t-0.2939225137233734\t▁ m n y a m a t a ▁ w i n a ▁ w a k u ▁ a s i a ▁ w o v a l a ▁ j e k e t e ▁ l a ▁ t ▁ s h i r t ▁ y a k u d a ▁ a k u g w i r a ▁ n t c h i t o ▁ n d i ▁ c h i t h u n z i ▁ c h a ▁ b u l a u n i\n",
            "D-216\t-0.2939225137233734\tmnyamata wina waku asia wovala jekete la t shirt yakuda akugwira ntchito ndi chithunzi cha bulauni\n",
            "P-216\t-0.1052 -0.5624 -0.0466 -0.0321 -0.1106 -0.0417 -0.0848 -0.0193 -0.1006 -0.1161 -0.1137 -0.0938 -0.0648 -0.1298 -0.1120 -0.0351 -0.2558 -0.2723 -0.2010 -0.2730 -1.4673 -0.8638 -0.3450 -0.1613 -0.1434 -0.0331 -0.1608 -0.1332 -0.1126 -0.0835 -0.1050 -0.0929 -0.0703 -0.0511 -0.0492 -0.0685 -0.0075 -0.0862 -0.0925 -0.1381 -0.1023 -0.3642 -1.6401 -1.4801 -0.6084 -0.0774 -0.2685 -0.0445 -0.0303 -0.1130 -1.5961 -0.2195 -0.5625 -0.1270 -0.0516 -0.1091 -0.1305 -0.5499 -0.1113 -0.1289 -2.0373 -0.0604 -0.0416 -0.0407 -0.7273 -0.1118 -0.2460 -0.0583 -0.0707 -0.1001 -0.0670 -0.0205 -0.2159 -0.0771 -0.6334 -0.1233 -0.1001 -0.1537 -2.2444 -0.1346 -0.2125 -1.3268 -1.0586 -0.1241 -0.1548 -0.3634 -0.0533 -0.1697 -0.4035 -0.1083 -0.4847 -0.2805 -0.1335 -0.4355 -0.0591 -0.5735 -0.1238 -0.0665 -0.0939 -0.5503\n",
            "T-246\tmayi akuphunzitsa kalasi yovina yopangidwa ndi ana ang onoang ono atanyamula masilafu okongola\n",
            "H-246\t-0.3033013939857483\t▁ m a y i ▁ a k u p h u n z i t s a ▁ g a l a s i ▁ l o b i r i w i r a ▁ n d i p o ▁ a n t h u ▁ a t a k h a l a ▁ p a m w a m b a ▁ p a ▁ m n y a m a t a ▁ w a n y a m u l a ▁ m a s i k o ▁ o k o n g o l a\n",
            "D-246\t-0.3033013939857483\tmayi akuphunzitsa galasi lobiriwira ndipo anthu atakhala pamwamba pa mnyamata wanyamula masiko okongola\n",
            "P-246\t-0.1061 -0.0642 -0.1268 -0.0455 -0.1141 -0.0977 -0.0989 -0.0556 -0.0969 -1.6018 -0.5097 -0.4298 -0.9410 -0.0442 -0.0874 -0.2060 -0.0323 -0.0839 -0.1067 -2.9521 -0.4899 -0.0663 -0.4283 -0.0135 -0.0502 -0.0928 -2.2789 -0.0525 -1.8356 -0.0885 -0.0708 -0.0856 -0.0292 -0.0683 -0.0586 -0.0847 -0.1527 -0.1766 -0.1144 -0.1015 -0.7105 -0.0783 -0.1233 -0.3412 -0.1745 -0.1936 -0.0953 -0.0668 -0.1133 -0.2768 -2.1899 -0.1178 -0.1047 -0.0355 -0.1384 -0.0611 -0.1186 -0.1027 -0.1053 -0.1166 -0.2160 -0.0768 -0.1085 -0.0503 -0.5478 -0.1370 -0.0874 -0.0270 -0.1201 -0.1431 -0.4745 -1.7143 -0.1358 -0.1252 -0.0176 -0.0922 -0.0187 -0.1086 -0.0892 -1.0192 -0.5878 -0.8310 -0.2185 -0.1040 -0.0557 -0.3386 -0.0651 -0.1173 -0.1033 -0.8344 -0.4194 -0.3038 -0.3222 -0.6436 -0.1975 -0.3735 -0.2871 -0.5821 -0.2970 -0.0391 -0.0354 -0.0375 -0.0648 -0.1042 -0.1710\n",
            "T-76\tgalu wonyezimira ali ndi lilime likulendewera kukamwa uku akuthamanga pa udzu\n",
            "H-76\t-0.36143040657043457\t▁ g a l u ▁ w a m i z i r a ▁ a l i ▁ n d i ▁ m i y e n d o ▁ i k u l e n d e w e r a ▁ k a m w a ▁ k a k u t h a m a n g a ▁ p a m a l o ▁ o u d z u\n",
            "D-76\t-0.36143040657043457\tgalu wamizira ali ndi miyendo ikulendewera kamwa kakuthamanga pamalo oudzu\n",
            "P-76\t-0.1169 -0.5065 -0.1535 -0.0584 -0.0988 -0.1093 -0.0243 -0.2394 -0.7020 -0.2529 -0.3111 -1.2237 -1.2064 -0.1515 -0.1297 -0.8283 -0.3048 -0.0786 -0.1330 -0.0417 -0.0502 -0.0804 -0.0834 -0.4173 -0.2929 -1.3915 -0.0771 -0.2289 -0.0847 -0.7548 -0.1229 -0.3594 -0.0839 -0.0798 -1.5411 -0.2473 -0.5762 -0.3768 -0.0464 -0.4258 -0.0281 -0.0287 -0.1213 -0.1613 -0.1667 -0.4968 -0.6957 -0.6802 -0.1170 -0.1590 -0.4204 -0.8889 -0.9992 -0.1337 -0.2531 -0.3858 -0.0997 -0.0927 -0.0892 -0.0401 -0.0304 -0.1061 -0.1625 -0.5135 -0.1009 -0.8437 -0.4864 -0.6819 -0.1581 -0.4866 -0.1450 -2.2109 -0.8586 -0.3726 -0.1979 -0.0647\n",
            "T-139\tbambo wina wovala zitunda zamitundumitundu akusefukira pabwalo loyera la mafunde pamadzi\n",
            "H-139\t-0.27867957949638367\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ j i n z i ▁ y a k u d a ▁ n d i ▁ m u n t h u ▁ a k u t u l u t s e t s e r a ▁ p a b w a l o ▁ l o y e r a ▁ l a ▁ m a f u n d e ▁ p a m a d z i\n",
            "D-139\t-0.27867957949638367\tbambo wina wovala jinzi yakuda ndi munthu akutulutsetsera pabwalo loyera la mafunde pamadzi\n",
            "P-139\t-0.1005 -0.3941 -0.0902 -0.0278 -0.1427 -0.1009 -0.1102 -0.1261 -0.0600 -0.0905 -0.1320 -0.1057 -0.0325 -0.1043 -0.2008 -0.1296 -0.0903 -0.1269 -0.1031 -1.1812 -0.6825 -0.0415 -0.6764 -0.1757 -0.0980 -1.9468 -0.1116 -1.0088 -0.1227 -0.1424 -0.1221 -0.1006 -0.9195 -0.2450 -0.4440 -0.2006 -0.8054 -0.2873 -0.4809 -0.0385 -0.0661 -0.0414 -0.1080 -0.3122 -0.0349 -0.0949 -1.7049 -0.3333 -0.0822 -0.0298 -0.2330 -0.0670 -0.1023 -1.2376 -0.1223 -0.0384 -0.0312 -0.1631 -0.1076 -0.9933 -0.1442 -0.7120 -0.0576 -0.0682 -0.0400 -0.0370 -0.0992 -0.0464 -0.7567 -0.0488 -0.1540 -0.0283 -0.0924 -0.1037 -0.8463 -0.5636 -0.5379 -0.1628 -0.1176 -0.5381 -0.0449 -0.0378 -0.0258 -0.0078 -0.2051 -1.1003 -0.1091 -0.3433 -0.0765 -0.3777 -0.1011 -0.0793 -0.2505\n",
            "T-6\tmtsikana wina wovala mkanjo wa pinki akutulutsa bulangete pansi pa kamnyamata komwe kanali\n",
            "H-6\t-0.2887052893638611\t▁ m t s i k a n a ▁ w i n a ▁ w o v a l a ▁ m k a n j o ▁ w a p i n k i ▁ a t a t u ▁ n d i ▁ t s i t s i ▁ l a l i t a l i ▁ p a n s i ▁ p a ▁ k h a m u ▁ l a ▁ a n y a m a t a ▁ a t a n y a m u l a\n",
            "D-6\t-0.2887052893638611\tmtsikana wina wovala mkanjo wapinki atatu ndi tsitsi lalitali pansi pa khamu la anyamata atanyamula\n",
            "P-6\t-0.1188 -0.1325 -0.0422 -0.0768 -0.0448 -0.0335 -0.1112 -0.0731 -0.1211 -0.1287 -0.0428 -0.0910 -0.1019 -0.1416 -0.0971 -0.0263 -0.0671 -0.0784 -0.1426 -0.0787 -0.1092 -0.0955 -0.0419 -0.5959 -0.2288 -0.0729 -0.0418 -0.1647 -0.0854 -0.0839 -0.4955 -2.1743 -0.1211 -0.0197 -0.1455 -0.0466 -0.1472 -0.3141 -0.9388 -0.1378 -0.9532 -0.1811 -0.1851 -1.5693 -0.0413 -0.1213 -0.5388 -0.5174 -0.2774 -0.8225 -0.1621 -0.0980 -0.3578 -0.0656 -0.0309 -0.2313 -0.4248 -0.2054 -0.3453 -0.0968 -0.1701 -0.3413 -0.1304 -0.3982 -0.1214 -0.1489 -0.3478 -0.0624 -0.1197 -0.0278 -0.1479 -0.5592 -1.7197 -0.8297 -0.7153 -0.0855 -0.0549 -0.0797 -0.0815 -0.0995 -0.1356 -0.1450 -0.2530 -0.8200 -0.1010 -0.0507 -0.1293 -0.0412 -0.0679 -0.4970 -1.0063 -0.3117 -0.0797 -1.7322 -0.3786 -0.1196 -0.1384 -0.0704 -0.0594 -0.1586 -1.5861\n",
            "T-210\tamuna awiri osowa pokhala akutsamira pa khoma la njerwa ndi kunyamula chikwangwani\n",
            "H-210\t-0.33437579870224\t▁ a m u n a ▁ a w i r i ▁ o t s o g o l a ▁ a k u t h a m a n g i r a ▁ p a k h o m a ▁ l a ▁ n j e r w a ▁ n d i ▁ k u n y a m u l a ▁ k w a ▁ n k h o n i\n",
            "D-210\t-0.33437579870224\tamuna awiri otsogola akuthamangira pakhoma la njerwa ndi kunyamula kwa nkhoni\n",
            "P-210\t-0.1253 -0.0693 -0.2339 -0.0894 -0.0614 -0.2338 -0.1139 -0.0935 -0.0865 -0.1247 -0.0566 -0.1084 -0.1022 -0.1463 -2.1677 -0.1822 -0.8512 -0.7613 -0.1475 -0.0838 -0.9024 -0.1030 -0.5544 -1.0898 -0.2020 -0.9026 -0.2347 -0.1099 -0.3407 -0.1249 -0.0373 -0.1567 -0.3371 -0.1107 -0.0915 -0.1016 -1.9438 -0.1755 -0.4250 -1.0475 -0.0117 -0.0844 -0.1022 -0.1471 -1.4780 -0.2766 -0.7130 -0.0317 -0.4234 -0.0929 -0.1321 -0.0396 -0.1156 -0.1387 -0.0337 -0.0507 -0.1100 -0.3058 -0.6849 -0.1376 -0.1163 -0.1454 -0.0740 -0.1230 -0.0789 -0.0784 -0.1125 -0.1200 -1.5889 -0.5001 -0.1173 -0.7240 -0.2841 -0.1537 -0.0725 -0.1416 -0.3251 -1.6668 -0.0536\n",
            "T-91\tpabwalo lotchingidwa ndi mpanda ndi nyumba yoyera kumbuyo galu woyera akudumpha m mwamba pafupi ndi galu wabulauni\n",
            "H-91\t-0.29408812522888184\t▁ k a m w a n a ▁ k o c h i t i k i r a ▁ n d i ▁ m p a n d a ▁ y e m w e ▁ a l i ▁ n d i ▁ a k u y e n d a ▁ k u m b u y o ▁ a w i r i ▁ a k u d u m p h a ▁ m ▁ m w a m b a ▁ p a f u p i ▁ n d i ▁ g a l u ▁ w a b u l a u n i\n",
            "D-91\t-0.29408812522888184\tkamwana kochitikira ndi mpanda yemwe ali ndi akuyenda kumbuyo awiri akudumpha m mwamba pafupi ndi galu wabulauni\n",
            "P-91\t-0.1048 -0.7641 -0.6000 -0.4435 -0.3494 -0.1029 -0.1343 -0.1297 -0.1161 -0.0810 -0.1700 -0.4421 -0.1075 -0.0409 -0.4766 -0.1158 -1.4880 -1.3240 -0.7696 -0.1602 -0.1029 -0.1672 -0.2016 -0.1201 -0.3811 -1.6369 -0.0548 -0.5236 -0.0390 -0.0266 -0.1370 -0.1133 -1.3143 -0.5387 -0.0635 -0.0227 -0.1040 -0.0853 -0.3668 -0.2575 -0.0710 -0.1163 -0.1584 -0.0912 -0.1099 -0.1430 -2.9073 -0.5855 -0.2728 -0.5894 -0.0970 -0.3019 -0.1180 -0.3391 -0.1001 -1.5719 -0.2164 -0.5633 -0.0587 -0.0848 -0.0146 -0.0891 -0.0809 -0.5364 -1.3075 -0.1631 -0.0877 -0.1132 -0.0860 -0.2250 -0.5424 -0.1059 -0.0772 -0.1229 -0.0164 -0.0424 -0.0472 -0.0797 -0.1335 -0.9441 -0.2124 -0.3903 -0.7664 -0.1204 -0.0323 -0.0162 -0.1189 -0.0828 -0.1206 -0.0896 -0.6949 -0.0339 -0.0406 -0.0482 -0.1239 -0.0196 -0.1022 -0.1046 -0.1189 -0.1671 -0.2390 -0.0649 -0.3854 -0.2372 -0.0786 -0.4020 -0.5912 -0.0468 -0.0612 -0.1242 -0.0223 -0.0388 -0.0725 -0.2694\n",
            "T-248\tatsikana awiri atanyamula manja awo mtsikana atavala malaya abuluu ndi lamba wakuda kumtunda kwake\n",
            "H-248\t-0.2522762715816498\t▁ a t s i k a n a ▁ a w i r i ▁ a t a n y a m u l a ▁ m a n j a ▁ a w o ▁ a k u d z i k a ▁ m a d z i ▁ a t a v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m p a n d a ▁ w a k u d a\n",
            "D-248\t-0.2522762715816498\tatsikana awiri atanyamula manja awo akudzika madzi atavala malaya abuluu ndi mpanda wakuda\n",
            "P-248\t-0.1119 -0.1403 -0.0669 -0.0629 -0.0616 -0.0176 -0.1320 -0.0422 -0.1345 -0.1053 -0.0790 -0.0404 -0.1004 -0.0477 -0.1285 -0.1040 -0.0792 -0.0814 -0.1110 -0.3193 -0.0143 -0.0913 -0.0489 -0.0621 -0.0545 -0.1052 -0.1146 -0.2125 -0.2393 -0.2842 -0.4728 -0.0984 -0.0942 -0.1016 -0.0636 -0.2427 -0.0763 -1.0178 -0.1912 -0.0963 -2.0309 -0.2150 -0.1217 -0.0126 -0.1186 -0.7251 -1.2412 -0.6746 -1.1726 -0.2294 -0.0610 -0.1035 -0.1805 -0.0636 -0.1224 -0.0721 -0.1031 -0.1008 -0.1235 -0.1006 -0.1583 -0.1212 -0.0899 -0.1109 -0.0790 -0.1027 -0.0753 -0.4099 -0.8446 -0.1885 -0.0576 -0.1955 -0.0286 -0.1037 -1.4040 -0.0720 -0.0996 -0.1540 -1.4693 -0.3415 -0.2847 -0.0458 -0.0623 -0.1886 -0.1137 -0.5381 -0.1444 -0.8128 -0.2225 -0.0529 -0.1101 -1.3065\n",
            "T-304\tgalu woyera wokhala ndi mawanga akuda akuthamanga m munda wokutidwa ndi chipale chofewa\n",
            "H-304\t-0.24022361636161804\t▁ g a l u ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ m w a m u n a ▁ a k u d u m p h a ▁ k u t h a m a n g a ▁ m ▁ m u n d a ▁ w a k u d a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-304\t-0.24022361636161804\tgalu woyera wokhala ndi mwamuna akudumpha kuthamanga m munda wakuda ndi chipale chofewa\n",
            "P-304\t-0.1045 -0.0675 -0.1175 -0.0568 -0.1064 -0.0948 -0.0713 -0.0520 -0.0545 -0.1245 -0.0404 -0.0908 -0.1130 -1.1538 -0.2435 -0.0152 -0.1160 -0.0985 -0.0670 -0.1122 -0.0992 -0.2974 -0.9231 -0.0905 -0.1298 -0.0667 -0.4365 -0.1282 -0.5834 -1.3587 -0.1204 -0.1697 -0.1082 -0.2589 -0.0306 -0.0622 -1.0032 -0.6280 -0.2179 -0.0753 -0.0244 -0.1182 -0.1486 -0.7467 -0.1473 -0.1383 -0.1655 -0.1041 -0.0465 -0.1002 -0.0534 -0.0660 -0.1197 -0.0766 -0.2447 -0.6086 -1.5936 -1.0858 -0.1733 -0.0437 -0.1078 -0.1028 -0.0798 -0.7325 -1.1166 -0.1711 -0.0469 -1.5902 -0.1215 -0.0337 -0.1204 -0.1224 -0.0934 -0.1275 -0.0777 -0.1115 -0.2755 -0.3130 -0.0528 -0.0257 -0.0873 -0.0887 -0.0823 -0.0232 -0.0072 -0.0272 -0.0203 -0.0884 -0.0393\n",
            "T-273\tagalu atatu ovala majuzi achikuda amathamanga paudzu ali ndi makwerero ndi manja kumbuyo\n",
            "H-273\t-0.3029387593269348\t▁ a g a l u ▁ a t a t u ▁ a t u ▁ o v a l a ▁ m a ▁ j u z i ▁ a c h i k u l u ▁ a t a m a n g a ▁ p a m a l o ▁ o z u n g u l i r a ▁ n d i ▁ m a p e p u l o ▁ n d i ▁ m a n j a ▁ a k u m b u y o\n",
            "D-273\t-0.3029387593269348\tagalu atatu atu ovala ma juzi achikulu atamanga pamalo ozungulira ndi mapepulo ndi manja akumbuyo\n",
            "P-273\t-0.1059 -0.1028 -0.5281 -0.0890 -0.0812 -0.1150 -0.0965 -0.1792 -0.0486 -0.0944 -0.0218 -0.0323 -0.0754 -0.4024 -0.0914 -1.4820 -0.0997 -0.3295 -0.0488 -0.1162 -0.0984 -0.1242 -0.1068 -0.0531 -0.1085 -0.5062 -0.2935 -0.0517 -0.0594 -0.2194 -0.0669 -0.6443 -1.0849 -0.0849 -0.0781 -0.0723 -0.1233 -1.4516 -0.3423 -0.1307 -0.1881 -0.4501 -0.1201 -0.7594 -0.1789 -0.8940 -0.1922 -0.1251 -0.1260 -0.1286 -0.1297 -0.2715 -0.2787 -1.3264 -0.3011 -0.0854 -0.6025 -0.2354 -0.1010 -0.0301 -0.1294 -0.0648 -0.2619 -0.0558 -0.3998 -0.7989 -0.1558 -0.7310 -0.3090 -0.1474 -0.1297 -0.0553 -0.0561 -0.7633 -0.1766 -1.9705 -0.3865 -0.2430 -0.0493 -0.2147 -0.8845 -0.0705 -0.0953 -0.0926 -0.1793 -0.0787 -1.2806 -0.0258 -0.0902 -0.7068 -0.6735 -0.0887 -0.2655 -1.4184 -0.1967 -0.0303 -0.0421 -0.0874 -0.2199\n",
            "T-214\tmwamuna ndi mnzake wamkazi akuwonera kuwombera kwake pamene akusewera mpira wa pong\n",
            "H-214\t-0.32224392890930176\t▁ m w a m u n a ▁ n d i ▁ m t s i k a n a ▁ w a ▁ m k a z i ▁ a k u w o n e r a ▁ k u t s o g o l o ▁ k w a ▁ m p h e p e t e ▁ a k u s e w e r a ▁ m p i r a w o\n",
            "D-214\t-0.32224392890930176\tmwamuna ndi mtsikana wa mkazi akuwonera kutsogolo kwa mphepete akusewera mpirawo\n",
            "P-214\t-0.1083 -0.0646 -0.0809 -0.1012 -0.0513 -0.0617 -0.0845 -0.1219 -0.1331 -0.0888 -0.0518 -0.1263 -0.0649 -0.5047 -0.0968 -0.1872 -0.2817 -0.1394 -0.0976 -0.3572 -0.0971 -0.1077 -0.2081 -0.1668 -1.3933 -1.7175 -0.1516 -0.1014 -0.0259 -0.0643 -0.1165 -0.0936 -0.0980 -0.1046 -0.3334 -0.1536 -0.5103 -0.0337 -0.4235 -0.1281 -0.1150 -2.0494 -0.1133 -1.0438 -1.2717 -0.0313 -0.0521 -0.0898 -0.0472 -0.0807 -0.0896 -0.1539 -0.0153 -0.1258 -0.1721 -0.5572 -2.2735 -0.5631 -0.0709 -0.1713 -0.0628 -0.0570 -0.0551 -0.0675 -0.6805 -0.6775 -0.1578 -1.1094 -0.0288 -0.0662 -0.0772 -0.0422 -0.1032 -0.1085 -0.1121 -0.3418 -0.0537 -0.0357 -0.0814 -3.7217 -0.2141 -0.6499\n",
            "T-60\tmayi wina wachikulire wovala magalasi apinki wanyamula magazini awiri mumsewu wodutsa anthu ambiri\n",
            "H-60\t-0.22259722650051117\t▁ m a y i ▁ w i n a ▁ w a c h i k u l i r e ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ m w a n a ▁ w a n y a m u l a ▁ z i n y a l a l i ▁ m ▁ m o d z i ▁ w o d u t s a ▁ a n t h u ▁ a m b i r i\n",
            "D-60\t-0.22259722650051117\tmayi wina wachikulire wovala malaya ofiira ndi mwana wanyamula zinyalali m modzi wodutsa anthu ambiri\n",
            "P-60\t-0.1033 -0.0822 -0.0824 -0.0311 -0.0998 -0.1033 -0.0444 -0.0763 -0.0656 -0.1100 -0.1023 -0.0222 -0.1034 -0.1066 -0.0448 -0.0724 -0.0270 -0.0865 -0.0888 -0.1022 -0.0573 -0.0278 -0.1018 -0.0873 -0.0394 -0.0528 -0.1163 -0.0893 -0.1270 -0.1041 -0.1474 -0.1110 -1.8247 -0.1374 -0.1469 -0.1231 -0.0794 -1.9676 -0.2248 -0.0488 -0.0995 -0.0742 -0.1422 -0.1139 -0.1856 -0.1403 -0.0568 -0.0948 -0.6787 -0.2960 -0.1466 -0.2725 -0.0950 -0.1161 -0.5201 -0.1789 -1.4102 -0.5321 -0.0796 -0.1172 -0.1185 -0.1171 -0.1304 -0.1150 -0.1899 -0.0501 -0.2341 -0.9876 -0.0807 -0.0319 -0.6602 -0.0662 -0.9712 -0.1605 -0.4092 -0.6384 -0.0541 -0.5736 -0.0966 -0.1085 -0.3251 -0.1131 -0.9137 -0.1480 -0.3576 -0.1506 -0.0334 -0.1858 -0.1130 -0.1541 -0.4820 -0.3329 -0.0417 -0.0769 -0.0515 -0.3827 -0.1640 -0.1537 -0.1627 -0.0382 -0.0378 -0.0787 -0.1179\n",
            "T-329\tbambo wina wokalamba wovala malaya akuda akudula nkhuni pogwiritsa ntchito macheka amagetsi\n",
            "H-329\t-0.3389047086238861\t▁ b a m b o ▁ w i n a ▁ w o k h a l a ▁ m ▁ m b a l i ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u d u m p h a ▁ n d i p o ▁ m t s i k a n a ▁ m ▁ c h i p i k a ▁ a m a d z i\n",
            "D-329\t-0.3389047086238861\tbambo wina wokhala m mbali wovala malaya akuda akudumpha ndipo mtsikana m chipika amadzi\n",
            "P-329\t-0.1108 -0.0422 -0.1196 -0.0352 -0.0614 -0.0559 -0.1144 -0.0832 -0.0647 -0.0573 -0.1223 -0.1050 -0.1385 -0.1394 -0.0167 -0.4207 -0.1097 -0.0506 -0.1044 -0.1158 -1.6098 -0.1040 -1.3887 -0.0895 -0.1118 -0.0517 -0.8824 -0.0991 -0.8957 -0.1026 -0.0395 -0.1393 -0.1399 -0.1262 -0.1035 -0.1508 -0.0966 -0.0898 -0.1310 -0.0471 -0.1144 -0.0876 -0.1520 -0.4312 -0.0951 -0.0599 -0.1005 -0.0859 -0.3266 -0.2199 -0.1373 -0.5214 -1.1001 -1.1100 -0.1175 -0.0407 -0.2652 -0.1526 -1.1791 -0.9420 -0.1870 -1.6151 -0.0293 -0.0908 -0.9578 -1.4419 -0.0978 -0.3454 -0.0780 -0.1709 -0.0416 -0.2215 -0.2605 -0.5909 -0.6554 -0.6877 -0.0658 -0.1590 -2.0672 -0.6252 -0.0569 -0.1304 -0.2218 -1.3192 -0.2701 -0.0618 -1.6219 -0.4332 -0.0573 -0.2341\n",
            "T-389\tanthu ena ovala malaya abuluu akuimirira ndi zilembo zazikulu zomasulira mawu akuti krunch\n",
            "H-389\t-0.30091896653175354\t▁ a n t h u ▁ e n a ▁ o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u i m i r i r a ▁ n d i ▁ z i d a ▁ z a z i k u l u ▁ z a z i k u l u ▁ z o m w e ▁ z i l i ▁ m ▁ m a w u ▁ a k u c h i t i k a\n",
            "D-389\t-0.30091896653175354\tanthu ena ovala malaya abuluu akuimirira ndi zida zazikulu zazikulu zomwe zili m mawu akuchitika\n",
            "P-389\t-0.1145 -0.1143 -0.0760 -0.0184 -0.0455 -0.0735 -0.1031 -0.7112 -0.0409 -0.0731 -0.1551 -0.1288 -0.0872 -0.0985 -0.0865 -0.1323 -0.1166 -0.1389 -0.1020 -0.0643 -0.1281 -0.0255 -0.1285 -0.0912 -0.3084 -0.6109 -0.0735 -0.0598 -0.0699 -0.0198 -0.0880 -0.1003 -0.2855 -0.1204 -0.7143 -0.0312 -0.3533 -0.2222 -0.2388 -0.0379 -0.1230 -0.1027 -0.5611 -0.0946 -0.0881 -0.0962 -0.1949 -0.1422 -1.2880 -0.2400 -0.1125 -0.3295 -0.3305 -1.1765 -0.1203 -0.6219 -0.1766 -0.0245 -0.1521 -0.1381 -0.1100 -0.7387 -0.3982 -0.0667 -0.2846 -0.1152 -0.0706 -0.1042 -0.1019 -0.8474 -0.0892 -0.0600 -2.1807 -0.2176 -0.1077 -0.6542 -0.1368 -0.2487 -0.1380 -0.1517 -1.0650 -0.8829 -0.0981 -0.3693 -1.8602 -0.9840 -0.2641 -0.5012 -0.1245 -0.3594 -1.1107 -0.0827 -0.3466 -0.2257 -0.2345 -0.9064 -0.2884 -0.6627\n",
            "T-176\tanthu awiri ovala mwansangala atayima pa chipale chofewa pamene utsi ukutuluka m mwamba\n",
            "H-176\t-0.25443071126937866\t▁ a n t h u ▁ a w i r i ▁ o v a l a ▁ m a s a n g a l a l a ▁ a t a n y a m u l a ▁ c h i p a l e ▁ c h o f e w a ▁ p a m e n e ▁ m t s i k a n a\n",
            "D-176\t-0.25443071126937866\tanthu awiri ovala masangalala atanyamula chipale chofewa pamene mtsikana\n",
            "P-176\t-0.1082 -0.1134 -0.1424 -0.0267 -0.0810 -0.1117 -0.0977 -0.1026 -0.5792 -0.0966 -0.0410 -0.0994 -0.1214 -0.2227 -0.1162 -0.1111 -0.0703 -0.1195 -0.1064 -0.1440 -0.1760 -0.2872 -0.6008 -0.8736 -0.3152 -0.1020 -0.0939 -0.1190 -0.3668 -0.1126 -0.3289 -0.0628 -0.1262 -0.0903 -1.0525 -0.4190 -0.5010 -0.0520 -0.6828 -0.0521 -0.1479 -0.1096 -0.0223 -0.0586 -0.0747 -0.0436 -0.1121 -0.0787 -0.0195 -0.0619 -0.0100 -0.0829 -0.0309 -0.0063 -0.0858 -0.0372 -0.1347 -0.1555 -0.2864 -0.1726 -0.2213 -0.0570 -0.0617 -0.1019 -0.1323 -2.5802 -0.5238 -0.1889 -0.0582 -0.0440 -0.3924 -0.3726 -0.4449 -2.8911\n",
            "T-410\tmnyamata wina wovala malaya amizeremizere yakuda ndi yoyera akutsamira pa udzu pamene magalimoto akudutsa pafupi ndi msewu\n",
            "H-410\t-0.1669216752052307\t▁ m n y a m a t a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a k u d a ▁ n d i ▁ y o y e r a ▁ a k u t s a m i r a ▁ p a m e n e ▁ m a g a l i m o t o ▁ a k u d u t s a ▁ p a f u p i ▁ n d i ▁ m s e w u\n",
            "D-410\t-0.1669216752052307\tmnyamata wina wovala malaya amizeremizere yakuda ndi yoyera akutsamira pamene magalimoto akudutsa pafupi ndi msewu\n",
            "P-410\t-0.1062 -0.0757 -0.0609 -0.0407 -0.1176 -0.0720 -0.1030 -0.0235 -0.1097 -0.1058 -0.1182 -0.0715 -0.0818 -0.1137 -0.1043 -0.0740 -0.0472 -0.0494 -0.1208 -0.0956 -0.1203 -0.0991 -0.0295 -0.1139 -0.0909 -0.1156 -0.0858 -0.1174 -0.0856 -0.1999 -0.1742 -0.1223 -0.2995 -0.0671 -0.0279 -0.0765 -0.0842 -0.0728 -0.1264 -0.1400 -0.0309 -0.1424 -0.0775 -1.6431 -0.1552 -0.1578 -0.1019 -0.0558 -0.1997 -0.1062 -0.0343 -0.0679 -0.1128 -0.0985 -0.3231 -0.1231 -0.1080 -0.1280 -0.1026 -0.1290 -0.1015 -0.4291 -0.0901 -0.1401 -0.1599 -0.0467 -0.1133 -0.1601 -0.0560 -0.0442 -0.1395 -0.0697 -0.0141 -0.1288 -0.5147 -0.2357 -0.1102 -0.1695 -0.1031 -0.1372 -1.5669 -0.5931 -0.1303 -0.1015 -0.1236 -0.0690 -0.0242 -0.0116 -0.0382 -0.0896 -0.3252 -0.0933 -0.1017 -0.1100 -0.3607 -0.0737 -0.1208 -0.0987 -0.1028 -1.2184 -0.1329 -0.2660 -0.0653 -0.0534 -0.0614 -0.2051 -0.0295 -0.0981 -0.1239 -0.0854 -0.4873 -0.9703 -0.0565 -0.0618 -0.0304 -0.4803\n",
            "T-49\tgalu wonyezimira woyera ndi wabulauni akudumpha pa chinthu china n kunyamula mpira m kamwa mwake\n",
            "H-49\t-0.2712036073207855\t▁ g a l u ▁ w o n y e z i m i r a ▁ w o y e r a ▁ n d i ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ c h i n a c h a k e ▁ m ▁ n y a n j a ▁ y a k e\n",
            "D-49\t-0.2712036073207855\tgalu wonyezimira woyera ndi wabulauni akuthamanga chinachake m nyanja yake\n",
            "P-49\t-0.1096 -0.4472 -0.1286 -0.0539 -0.0596 -0.0975 -0.0281 -1.0152 -1.8643 -0.0570 -0.0880 -0.1721 -0.0409 -0.0528 -0.0355 -0.1188 -0.1747 -0.1197 -0.0634 -0.2099 -0.1064 -0.0663 -0.0986 -0.1044 -0.1240 -0.0620 -0.1094 -0.1006 -0.1252 -0.0298 -0.6299 -2.2359 -0.0933 -0.0779 -0.1186 -0.0291 -0.0237 -0.0322 -0.1126 -0.2250 -0.1525 -0.0955 -0.4946 -0.2007 -0.2173 -0.3141 -0.1598 -0.0594 -0.2213 -0.5070 -0.1077 -0.1181 -0.0845 -0.0837 -0.1508 -0.8990 -0.1523 -0.1027 -0.1821 -0.1160 -0.4377 -0.1366 -0.6316 -0.8783 -0.5221 -0.0949 -0.1111 -0.1824 -0.0711 -0.1499 -0.2607 -0.7612 -0.3637 -0.2615 -0.2608 -1.6268\n",
            "T-84\tmunthu wadazi ameneyu yemwe akuoneka kuti wagona wakhala patebulo pa laibulale\n",
            "H-84\t-0.4065161943435669\t▁ m u n t h u ▁ w a z a i m i r i r a ▁ m ▁ m i y e n d e t s o ▁ a k u w o n e k a ▁ k u t s o g o l o ▁ k w a ▁ k a t e b u l o ▁ p a l i ▁ n d i ▁ m b a l i\n",
            "D-84\t-0.4065161943435669\tmunthu wazaimirira m miyendetso akuwoneka kutsogolo kwa katebulo pali ndi mbali\n",
            "P-84\t-0.1076 -0.0764 -0.1112 -0.0827 -0.0284 -0.0748 -0.0764 -0.1224 -0.2909 -0.1848 -1.5091 -0.1036 -1.2017 -0.7855 -0.0899 -0.2377 -0.0777 -0.1397 -0.1008 -0.2168 -0.3894 -1.4186 -0.5117 -0.7496 -0.7654 -0.0817 -0.4442 -0.2390 -0.1842 -1.6752 -1.0730 -1.7330 -0.0637 -0.2307 -0.1932 -0.1285 -0.7727 -0.0946 -0.0791 -0.0676 -0.0786 -0.0858 -0.0816 -0.4385 -0.0800 -0.0789 -0.3496 -0.1802 -0.0644 -0.0720 -0.0701 -0.0705 -0.1009 -0.1222 -0.7019 -0.1461 -0.2309 -0.1357 -0.4868 -2.2005 -0.0350 -0.8400 -0.1075 -0.0692 -0.0371 -0.1922 -0.4155 -0.1225 -1.3187 -0.0487 -0.2237 -2.2656 -0.4110 -0.2733 -0.1914 -2.3381 -0.3897 -0.0964 -0.0749 -0.3056 -0.8832\n",
            "T-360\tmayi akuyang ana mokayikira yemwe akumujambula iye ndi atsikana atatu omwe ali panja\n",
            "H-360\t-0.37378472089767456\t▁ m a y i ▁ a k u y a n g ▁ a n a ▁ m ▁ k a m w a ▁ i l i ▁ n d i ▁ a n t h u ▁ e n a ▁ a k u j a m b u l a ▁ p i r i ▁ a t a t s i k a n a ▁ k u m e n y a ▁ p a n j a\n",
            "D-360\t-0.37378472089767456\tmayi akuyang ana m kamwa ili ndi anthu ena akujambula piri atatsikana kumenya panja\n",
            "P-360\t-0.1190 -0.0679 -0.1277 -0.0398 -0.1160 -0.1052 -0.1461 -0.0410 -0.0881 -0.0367 -0.1548 -0.0548 -0.1186 -0.1015 -0.0940 -0.0911 -0.1443 -0.1491 -0.0712 -0.6570 -0.6688 -0.2308 -0.6932 -0.0628 -0.3539 -0.1713 -1.5508 -0.9144 -0.1775 -0.1205 -0.6093 -0.0596 -0.1597 -0.1114 -0.7120 -1.3333 -0.6660 -0.0908 -0.1490 -0.0962 -0.7140 -0.0728 -0.0973 -0.1080 -0.2077 -0.0533 -0.0787 -0.9652 -0.0769 -0.0349 -0.0368 -0.0528 -0.0408 -0.1142 -0.0955 -1.8598 -0.1854 -1.8305 -0.7335 -0.0694 -0.7770 -0.1161 -0.7654 -1.5562 -0.4775 -0.6110 -0.0231 -0.1099 -0.1730 -0.1134 -0.1253 -1.4856 -0.1747 -0.1931 -0.1413 -0.1537 -0.3280 -0.1535 -0.1756 -2.2306 -0.2305 -1.1656 -0.0844 -0.2160 -1.3089\n",
            "T-47\tamuna awiri ogwira ntchito akuima pamalo okonzera njinga yemwe ali kutsogolo ali ndi chida m manja mwake\n",
            "H-47\t-0.3188386857509613\t▁ a m u n a ▁ a w i r i ▁ o k w e r a ▁ n t c h i t o ▁ a k u y e n d a ▁ m ▁ m a l o ▁ o k o n z e k e r a ▁ n j i n g a ▁ y a i k u l u ▁ y e m w e ▁ a l i ▁ n d i ▁ c h i k w a m a ▁ m ▁ m a n j a ▁ m w a k e\n",
            "D-47\t-0.3188386857509613\tamuna awiri okwera ntchito akuyenda m malo okonzekera njinga yaikulu yemwe ali ndi chikwama m manja mwake\n",
            "P-47\t-0.1039 -0.1992 -0.0705 -0.0640 -0.0797 -0.0934 -0.0940 -0.5006 -0.0422 -0.1526 -0.0476 -0.1091 -0.1097 -0.0533 -0.7817 -0.1544 -0.0448 -0.1848 -0.1132 -0.0938 -0.0186 -1.5785 -0.1105 -0.0760 -0.0597 -0.0184 -0.0312 -0.0934 -1.7703 -0.0649 -0.0807 -0.2162 -1.0636 -0.1831 -0.1481 -0.1055 -0.1254 -0.6472 -0.7402 -0.0848 -0.1046 -1.3520 -0.1246 -0.0818 -0.0971 -0.3165 -0.7020 -0.0446 -0.4991 -0.0236 -0.9779 -2.2323 -0.0672 -0.0850 -0.1157 -0.2350 -0.2141 -0.1571 -0.0824 -0.0785 -0.0878 -0.1497 -0.0489 -0.2023 -0.6544 -0.8663 -0.2758 -0.4486 -1.3049 -0.1084 -0.1969 -1.0281 -0.0703 -0.0161 -0.0519 -0.0892 -0.3881 -0.0857 -0.1035 -0.1106 -0.0324 -0.0835 -0.0945 -0.1485 -0.1369 -0.0870 -0.0764 -2.3923 -0.1895 -0.0874 -0.6323 -0.0859 -0.3173 -1.2094 -0.4695 -0.4721 -0.7220 -0.1722 -0.0076 -0.0805 -2.1078 -0.1197 -0.0154 -0.0980 -0.0350 -0.0365 -0.0183\n",
            "T-261\tazimayi angapo amavala zovala za kum mawa kwa golide zabuluu zachikasu ndi zofiira ndipo akuvina\n",
            "H-261\t-0.27818936109542847\t▁ a z i m a y i ▁ a n a y i ▁ a t a v a l a ▁ m a g a l a s i ▁ o v a l a ▁ z a k u m w a ▁ w a i m a ▁ n d i ▁ z a b u l u u ▁ z a c h i k a s u ▁ n d i ▁ z o f i i r a ▁ p a k h o m a\n",
            "D-261\t-0.27818936109542847\tazimayi anayi atavala magalasi ovala zakumwa waima ndi zabuluu zachikasu ndi zofiira pakhoma\n",
            "P-261\t-0.1010 -0.1481 -0.1038 -0.0738 -0.0366 -0.0860 -0.0522 -0.1055 -0.0875 -0.0824 -1.5879 -0.3346 -0.4426 -0.0750 -0.0981 -0.1944 -0.0576 -0.2536 -0.9697 -0.1141 -0.1351 -0.1147 -0.1004 -0.3310 -0.3288 -1.0084 -0.1575 -0.0868 -0.0867 -0.2207 -0.1143 -0.0655 -0.5978 -0.0958 -0.1256 -0.1718 -0.1201 -0.1055 -0.0562 -0.0874 -0.9603 -0.0841 -0.2522 -1.0876 -0.1242 -0.0872 -0.8361 -0.1246 -2.4660 -0.4416 -0.0701 -0.0556 -0.5779 -0.1167 -0.1790 -0.1641 -0.2832 -0.1039 -1.9946 -0.1891 -0.0758 -0.0616 -0.0413 -0.0822 -0.0781 -0.1254 -0.0241 -0.0449 -0.0687 -0.0516 -0.1510 -0.0135 -0.0501 -0.0892 -0.0222 -0.1285 -0.1598 -0.3555 -0.1489 -0.1773 -0.0768 -0.0587 -0.0519 -0.0520 -0.3432 -0.4092 -1.4364 -0.1103 -0.4881 -0.4546 -0.6303 -0.2469 -0.3545 -0.1751\n",
            "T-78\tmwamuna wovala magalasi ndi malaya oyera olembedwa dzina lakuti jim akumwetulira\n",
            "H-78\t-0.2759932577610016\t▁ m w a m u n a ▁ w o v a l a ▁ m a g a l a s i ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ o l i m b i t s i d w a ▁ n d i ▁ m a t e n g a ▁ a d z i n j i ▁ a k u m w e t u l i r a\n",
            "D-78\t-0.2759932577610016\tmwamuna wovala magalasi ndi malaya oyera olimbitsidwa ndi matenga adzinji akumwetulira\n",
            "P-78\t-0.1229 -0.0758 -0.0826 -0.1013 -0.0676 -0.0706 -0.0892 -0.0969 -0.1221 -0.0945 -0.1125 -0.1230 -0.1282 -0.0802 -0.1190 -0.0938 -0.1559 -0.1432 -0.1644 -0.1304 -0.0921 -0.1147 -0.0327 -0.0451 -0.0719 -0.0479 -0.0407 -0.1296 -0.1381 -0.0375 -0.1076 -0.1538 -0.1263 -0.0295 -0.1176 -0.0860 -0.0838 -0.0329 -0.1260 -0.0439 -0.1004 -0.1104 -0.6695 -1.0382 -0.9799 -0.0282 -0.0577 -0.6517 -0.1992 -0.0732 -1.4848 -0.3368 -0.1197 -0.0979 -0.1121 -1.5987 -0.1953 -0.1257 -0.1377 -0.2260 -0.5519 -1.6932 -0.5398 -0.2380 -0.2013 -0.4473 -0.1313 -0.5209 -0.6110 -0.0421 -0.1449 -0.1780 -1.6716 -0.1931 -0.7870 -0.5900 -0.0894 -0.1963 -1.9599 -0.1823 -0.4117 -0.0047 -0.0430 -0.0350 -0.0397 -0.0430 -0.0872 -0.4786\n",
            "T-104\tmtsikana wofiirira wovala chovala chofiirira komanso nsapato zofiira kudumpha ali m galimoto yapansi panthaka\n",
            "H-104\t-0.2717136740684509\t▁ m t s i k a n a ▁ w i n a ▁ w o v a l a ▁ c h o v a l a ▁ c h o f i i r a ▁ k o m a n s o ▁ n s a p a t o ▁ z o f i i r a ▁ a k u d u m p h a ▁ n d i ▁ m a g a l i m o t o ▁ a k u y a n g ▁ a n a ▁ p a n s i\n",
            "D-104\t-0.2717136740684509\tmtsikana wina wovala chovala chofiira komanso nsapato zofiira akudumpha ndi magalimoto akuyang ana pansi\n",
            "P-104\t-0.1119 -1.7851 -0.0625 -0.1419 -0.0474 -0.0335 -0.0973 -0.0776 -0.1043 -0.1374 -0.0667 -0.8902 -0.3544 -0.1056 -0.1292 -0.0464 -0.1062 -0.0391 -0.1189 -0.1176 -0.1222 -0.1071 -0.0370 -0.0716 -0.1082 -0.0143 -0.0900 -0.0819 -0.1394 -0.1139 -0.0131 -0.0517 -0.0962 -0.2195 -0.0563 -0.1698 -0.0406 -0.3641 -0.1184 -0.4436 -0.6906 -0.0271 -0.0711 -0.0554 -0.0296 -0.0605 -0.0915 -2.3918 -0.1622 -1.4044 -0.1267 -0.0878 -0.0125 -0.0536 -0.0951 -0.0143 -1.5073 -0.0689 -0.0722 -0.0902 -0.0381 -0.1582 -0.1187 -0.6958 -1.5645 -0.1737 -0.1287 -0.0978 -0.0787 -0.0795 -0.0323 -0.1944 -0.1305 -2.2793 -0.0942 -0.1449 -0.1213 -0.0349 -0.1284 -0.0984 -0.1031 -0.0582 -0.0319 -0.0205 -0.0755 -0.0245 -0.0337 -0.1050 -0.3072 -1.9013 -1.1178 -0.3958 -0.1252 -0.0427 -1.1072 -0.1181 -0.0904 -0.0321 -0.2867 -0.4321 -0.1948 -0.1497 -0.1961 -0.0753 -0.0290 -1.2103\n",
            "T-415\tgalu wabulauni wokhala ndi kolala yofiirira akuyang ana kumanzere ndi thambo loyera la buluu kumbuyo kwake\n",
            "H-415\t-0.2528398931026459\t▁ g a l u ▁ w a k u d a ▁ w o k h a l a ▁ n d i ▁ k o l a l a ▁ y o f i i r a ▁ a k u y a n g ▁ a n a ▁ k u m a n z e r e ▁ n d i ▁ a n t h u ▁ o y e r a ▁ a m u n a ▁ k u m b u y o ▁ k w a k e\n",
            "D-415\t-0.2528398931026459\tgalu wakuda wokhala ndi kolala yofiira akuyang ana kumanzere ndi anthu oyera amuna kumbuyo kwake\n",
            "P-415\t-0.1040 -0.9423 -0.1104 -0.0546 -0.0975 -0.0917 -0.0528 -0.1318 -0.2615 -0.1395 -0.6064 -0.0808 -0.0990 -0.3611 -0.0798 -0.0242 -0.0592 -0.1064 -0.0478 -0.1154 -0.1092 -0.0240 -0.1258 -0.0859 -0.1729 -1.0751 -0.4533 -0.7370 -0.1599 -0.2753 -0.0944 -0.1277 -0.8813 -0.0934 -0.1081 -0.0482 -0.1587 -0.0364 -0.6697 -0.1183 -0.0691 -0.0472 -0.1185 -0.0165 -0.1821 -0.0384 -0.1430 -0.0748 -0.0896 -0.0634 -0.1350 -0.0867 -0.2473 -0.1188 -0.1527 -0.0866 -0.2388 -0.2276 -0.4015 -0.0420 -0.0568 -0.0666 -0.1698 -0.1353 -0.0887 -0.2520 -0.8094 -2.1574 -0.0292 -0.0368 -0.1103 -0.0782 -0.7462 -0.0460 -0.1208 -0.0583 -0.1167 -0.1259 -0.3951 -0.2598 -2.6001 -0.7663 -1.4355 -0.1924 -1.2077 -0.0830 -0.0879 -0.0736 -0.0705 -0.0197 -0.0432 -0.3761 -0.0051 -0.0254 -0.0983 -0.0611 -0.0492 -0.0232\n",
            "T-159\tmwamuna wayima kumbuyo ndi desiki ndipo pali mbali ya galimoto yofiyira yomwe ili pamwamba pamutu pake\n",
            "H-159\t-0.3258066177368164\t▁ m w a m u n a ▁ w a i m a ▁ k u m b u y o ▁ n d i ▁ s i t e j i ▁ n d i p o ▁ a l i ▁ n d i ▁ g a l i m o t o ▁ y a k e ▁ y o f i i r a ▁ y o m w e ▁ i l i ▁ p a m w a m b a ▁ p a ▁ t h u p i\n",
            "D-159\t-0.3258066177368164\tmwamuna waima kumbuyo ndi siteji ndipo ali ndi galimoto yake yofiira yomwe ili pamwamba pa thupi\n",
            "P-159\t-0.1170 -0.1369 -0.0280 -0.1211 -0.1144 -0.0571 -0.0839 -0.1295 -0.1702 -1.6712 -0.6160 -0.4058 -0.1014 -0.1650 -0.1036 -0.0504 -0.0867 -0.5476 -0.1130 -0.1160 -0.0560 -0.0300 -0.0950 -0.2210 -0.1174 -0.1313 -0.1004 -1.2378 -0.1560 -0.2376 -2.0161 -1.1544 -0.0214 -0.1535 -0.2971 -0.0732 -0.0995 -0.2129 -0.0321 -0.1224 -1.7681 -0.8899 -0.0599 -0.0981 -0.7066 -0.1017 -0.1116 -0.1952 -1.1994 -0.1044 -0.0637 -0.0595 -0.0212 -0.0696 -0.0128 -0.0365 -0.1250 -0.0208 -0.5714 -1.8179 -0.3760 -0.1024 -0.0128 -0.3526 -0.0304 -0.0949 -0.2998 -0.0395 -0.1274 -0.1257 -0.3926 -2.4356 -0.1412 -0.0404 -0.0977 -0.0937 -0.1297 -1.0721 -0.0776 -0.1354 -0.0225 -0.1066 -0.0983 -0.3315 -0.0976 -0.0145 -0.1215 -0.1264 -0.1445 -0.0104 -0.1037 -0.2406 -0.8922 -0.3814 -1.8020 -0.2101 -0.2310 -1.2837\n",
            "T-164\twonyamula golide ataima panja pachipale chofewa ndipo munthu waima ndi ma ski ndi mitengo\n",
            "H-164\t-0.31479594111442566\t▁ w o j a m b u l a ▁ n d i ▁ k u d i k i r i r a ▁ p a n j a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ n d i ▁ n y u m b a ▁ y o m w e ▁ i l i ▁ n d i ▁ m a d z i ▁ n d i ▁ m i t e n g o\n",
            "D-164\t-0.31479594111442566\twojambula ndi kudikirira panja pa chipale chofewa ndi nyumba yomwe ili ndi madzi ndi mitengo\n",
            "P-164\t-0.1165 -1.0911 -0.1226 -0.7068 -0.0479 -0.0877 -0.0499 -0.0607 -0.0965 -0.1444 -0.1452 -1.6445 -0.0777 -0.0747 -0.1637 -1.7033 -0.0942 -2.5337 -0.3130 -0.3402 -0.1820 -0.8503 -0.0391 -0.4466 -0.1028 -0.2002 -0.7411 -0.1160 -1.0476 -0.4575 -0.2467 -0.1707 -0.0269 -0.1234 -0.3540 -0.0583 -0.1290 -0.0639 -0.0435 -0.0734 -0.0250 -0.1060 -0.0621 -0.0349 -0.1177 -0.0513 -0.0543 -0.3928 -0.0517 -0.2161 -0.1948 -0.2779 -0.1973 -0.0833 -0.1973 -1.6902 -0.0550 -0.0568 -0.2035 -0.0732 -0.1861 -0.1660 -0.2795 -0.2044 -0.2074 -0.1119 -0.0938 -0.0960 -0.2435 -1.6513 -0.0604 -0.0882 -0.5459 -0.0548 -0.0821 -0.0786 -0.0515 -0.0898 -1.5262 -0.4075 -0.0551 -0.2119 -0.4628 -0.0665 -0.0723 -0.1274 -0.3998 -0.6146 -0.6648 -0.1426 -0.0604 -0.6665 -0.1163 -0.4761\n",
            "T-189\tmnyamata wovala chisoti panjinga akuwuluka mumlengalenga pamene akukwera pakati pa mapiri afumbi ndi mtsinje kumbuyo kwake\n",
            "H-189\t-0.31515127420425415\t▁ m n y a m a t a ▁ w o v a l a ▁ c h i s o t i ▁ a k u d a ▁ a k u w u l u k a ▁ m l e n g a l e n g a ▁ a k u g w i r a ▁ n t c h i t o ▁ p a k a t i ▁ p a ▁ a f u p i ▁ n d i ▁ m t s i k a n a ▁ w a k e\n",
            "D-189\t-0.31515127420425415\tmnyamata wovala chisoti akuda akuwuluka mlengalenga akugwira ntchito pakati pa afupi ndi mtsikana wake\n",
            "P-189\t-0.1031 -0.1114 -0.0760 -0.0408 -0.1003 -0.0501 -0.1026 -0.0480 -0.1170 -0.1163 -0.0864 -0.0806 -0.0529 -0.1262 -0.1090 -0.1087 -0.1046 -0.7943 -0.0754 -0.0763 -0.1533 -0.0276 -0.0081 -0.0393 -0.0803 -0.9787 -0.7608 -0.2158 -0.4451 -0.1253 -0.1068 -0.1477 -0.1836 -0.2240 -3.0139 -0.2398 -0.1564 -0.0717 -0.0356 -0.1220 -0.0934 -0.0544 -1.3138 -0.0873 -0.1457 -0.0462 -0.0934 -0.0410 -0.0326 -0.0177 -0.0639 -0.0830 -0.1137 -0.6061 -0.6492 -0.1006 -1.4073 -0.0796 -0.8917 -0.0762 -0.1891 -0.1467 -1.7218 -0.0720 -0.1196 -0.2090 -0.1200 -0.3185 -0.1457 -0.1110 -0.0387 -0.1166 -1.1813 -0.0948 -0.8798 -0.0568 -0.1142 -0.1531 -0.0913 -0.1369 -1.7269 -0.3421 -0.0921 -1.2132 -0.1111 -0.0886 -0.0380 -0.0735 -0.1111 -0.0671 -0.2885 -1.2097 -0.0919 -0.0577 -1.2567 -0.3210 -0.0956 -0.1114 -0.5829 -0.0723 -0.1367 -2.3307 -0.4526 -0.2746\n",
            "T-258\tanthu angapo akhala mozungulira kukoka matebulo okhala ndi zinthu zamaofesi pamwamba pake\n",
            "H-258\t-0.3797416388988495\t▁ a n t h u ▁ a n g a p o ▁ a t a k h a l a ▁ m o z u n g u l i r a ▁ k o m a n t i d w a ▁ n d i ▁ g a l u ▁ n d i ▁ z i n t h u ▁ z o f i i r a ▁ z a m a w o n a ▁ p a m w a m b a\n",
            "D-258\t-0.3797416388988495\tanthu angapo atakhala mozungulira komantidwa ndi galu ndi zinthu zofiira zamawona pamwamba\n",
            "P-258\t-0.1077 -0.1306 -0.0473 -0.0314 -0.0457 -0.0677 -0.1003 -0.1141 -0.0880 -0.0274 -0.0913 -0.0277 -0.0456 -0.0767 -0.1660 -2.1626 -0.1141 -0.1994 -0.0353 -0.1149 -0.0553 -0.1095 -0.1183 -0.3144 -1.3681 -0.0691 -0.0981 -0.0338 -0.0482 -0.0437 -0.0561 -0.0510 -0.0449 -0.1117 -0.1467 -0.2109 -2.3045 -0.2315 -0.0872 -0.5052 -0.6929 -1.4365 -0.9442 -0.1306 -0.1404 -0.1108 -0.7498 -0.2294 -0.2568 -0.3316 -1.0983 -0.1586 -0.0584 -0.5932 -0.1458 -1.1825 -0.0659 -0.1342 -0.1539 -0.0155 -0.0923 -1.4205 -0.4823 -0.0625 -0.1410 -0.1119 -0.0067 -0.2428 -1.2334 -0.6422 -0.4038 -0.5207 -0.4010 -0.1269 -1.6346 -0.1668 -0.8088 -0.2235 -1.2534 -0.5749 -1.0471 -0.6441 -0.7023 -0.0597 -0.0946 -0.4416 -1.2963 -0.1044 -0.2969 -0.0281 -0.0902 -1.1497\n",
            "T-318\tkamera imayang ana pansi mkati mwa chubu chobiriwira pamene mwana akutsetsereka\n",
            "H-318\t-0.3142065405845642\t▁ k a m n y a m a t a ▁ k a k a n g ▁ o n o ▁ k a ▁ z i n t h u ▁ k a c h i n g w a ▁ c h o b i r i w i r a ▁ k a m e r a ▁ a k u s e w e r e t s e r e k a\n",
            "D-318\t-0.3142065405845642\tkamnyamata kakang ono ka zinthu kachingwa chobiriwira kamera akuseweretsereka\n",
            "P-318\t-0.1202 -0.0501 -0.1547 -0.0367 -2.2555 -0.0476 -0.1265 -0.0644 -0.1010 -0.1129 -0.0989 -0.1071 -0.2313 -0.3034 -0.3694 -0.6228 -0.0669 -0.0612 -0.2476 -0.1335 -0.0793 -0.1892 -0.1309 -0.0323 -0.2952 -0.2831 -1.6592 -0.0571 -0.6449 -0.0752 -0.1652 -0.1146 -0.1117 -1.3164 -0.3559 -1.4113 -0.0505 -0.1450 -1.3911 -0.0488 -0.1353 -0.6761 -0.1889 -0.0072 -0.0622 -0.1117 -0.5234 -0.0473 -0.0411 -0.0749 -0.0415 -0.0417 -0.0475 -0.1382 -0.1530 -0.8640 -1.2321 -0.1305 -0.6930 -0.3266 -0.1065 -0.1907 -0.8703 -0.3601 -0.0735 -0.1122 -0.0530 -1.2014 -0.0542 -0.1162 -0.2885 -0.4203 -0.0363 -0.1201 -0.3319 -0.5825 -0.1298 -0.1641 -0.2061\n",
            " 54% 7/13 [00:17<00:11,  1.98s/it, wps=1228]T-373\tanthu angapo ali papaki akuwonera masewera a chess omwe akuseweredwa ndi zidutswa zazikulu\n",
            "H-373\t-0.3457629978656769\t▁ a n t h u ▁ a w i r i ▁ a k h a l a ▁ p a n s i ▁ a k u w o n e t s e r a ▁ m a s e w e r a ▁ o m w e ▁ a k u s e w e r a ▁ n d i ▁ z i d z a ▁ z a z i k u l u\n",
            "D-373\t-0.3457629978656769\tanthu awiri akhala pansi akuwonetsera masewera omwe akusewera ndi zidza zazikulu\n",
            "P-373\t-0.1052 -0.1243 -0.1508 -0.0716 -0.1015 -0.1026 -0.0957 -0.2169 -2.9541 -0.2236 -0.1981 -0.0930 -0.1098 -0.3138 -1.8049 -1.0620 -0.1446 -0.0589 -0.1397 -0.1127 -0.0720 -0.1204 -2.2443 -1.1827 -0.0861 -0.0882 -0.3584 -0.0723 -0.1045 -0.1512 -0.1531 -0.1504 -0.2953 -1.3241 -0.0889 -0.1367 -0.0290 -0.1468 -0.1103 -0.1616 -0.0607 -0.7075 -0.1555 -0.0612 -0.0761 -0.0859 -0.3950 -0.1396 -0.8557 -0.1239 -1.0193 -0.0817 -0.1200 -2.0171 -0.3938 -0.1675 -0.5404 -0.0321 -0.7495 -0.0504 -0.1788 -0.1505 -0.1224 -0.2060 -0.1184 -0.1674 -0.0885 -0.7494 -0.0589 -0.5405 -1.0056 -0.5181 -0.2147 -0.0557 -0.0930 -0.4357 -0.1105 -0.0404 -0.1051 -0.0289 -0.0699 -0.2012\n",
            "T-207\tmtsikana akuyang ana mnyamata wa blond akugwedezeka pampando ndi nyumba zowonekera kumbuyo kwake\n",
            "H-207\t-0.36698174476623535\t▁ m t s i k a n a ▁ a k u y a n g ▁ a n a ▁ m n y a m a t a ▁ w a ▁ b l o n d ▁ a k u d e z e k a ▁ p a m t e n g o ▁ n d i ▁ m b a l i ▁ n d i ▁ z o k o n g o l a ▁ k u m b u y o\n",
            "D-207\t-0.36698174476623535\tmtsikana akuyang ana mnyamata wa blond akudezeka pamtengo ndi mbali ndi zokongola kumbuyo\n",
            "P-207\t-0.1214 -1.6062 -0.8000 -1.4943 -0.0783 -0.0586 -0.0924 -0.0496 -0.1283 -0.1352 -0.1594 -0.0278 -0.1110 -0.0355 -0.7617 -0.0462 -0.4263 -0.0946 -0.0940 -0.0583 -0.1501 -0.1232 -0.9096 -0.8266 -0.1116 -0.1414 -0.1296 -0.0831 -0.0038 -0.1473 -0.1013 -0.1110 -0.2069 -0.3410 -0.6456 -0.6571 -0.2197 -0.6303 -0.2569 -0.2243 -0.0628 -0.1625 -0.2112 -1.3363 -1.8568 -0.7781 -0.0380 -0.0155 -0.1421 -0.1028 -1.1633 -0.1192 -1.0082 -0.8628 -0.1510 -0.1939 -0.2349 -0.0852 -0.1136 -0.2091 -0.0244 -0.0747 -0.2241 -1.8393 -0.2022 -0.1266 -0.2090 -0.1334 -0.0938 -1.7507 -0.0903 -0.1284 -0.2113 -1.8006 -0.3067 -0.7904 -0.3375 -0.1417 -0.2328 -0.1355 -0.1078 -0.2482 -0.5177 -0.0441 -0.2025 -0.1101 -0.1940 -0.0518 -0.1392 -0.0429 -1.6367\n",
            "T-185\tmunthu wovala mathalauza akuda ndi kusindikiza pamwamba pa ski mumlengalenga pamwamba pa chipale chofewa\n",
            "H-185\t-0.264731228351593\t▁ m u n t h u ▁ w o v a l a ▁ m a t h a l a u z a ▁ n d i ▁ k u s i n d i k i z a ▁ p a m w a m b a ▁ p a ▁ s i t i m e n g a ▁ p a m w a m b a ▁ p a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-185\t-0.264731228351593\tmunthu wovala mathalauza ndi kusindikiza pamwamba pa sitimenga pamwamba pa chipale chofewa\n",
            "P-185\t-0.1166 -0.1755 -0.7156 -0.0277 -0.0220 -0.0621 -0.0727 -0.1154 -0.0961 -0.0646 -0.1369 -0.1285 -0.0874 -0.1243 -0.1175 -0.2728 -0.1104 -0.6270 -0.0082 -0.0970 -0.1854 -0.1274 -0.0184 -0.0251 -0.0664 -0.1176 -1.3185 -0.0496 -0.1421 -0.2767 -2.3079 -0.1923 -0.6165 -0.0906 -1.6074 -0.3912 -0.2217 -0.0636 -0.0556 -0.0911 -0.1596 -0.2810 -1.4294 -0.1678 -0.0850 -0.1439 -0.1041 -0.1053 -0.1751 -0.1814 -0.1205 -0.0282 -0.1436 -0.0787 -0.1962 -0.3786 -0.0827 -0.7834 -0.6810 -1.0656 -1.3588 -0.6872 -0.1799 -0.1954 -0.4707 -0.1448 -0.1001 -1.6535 -0.1142 -0.0496 -0.2700 -0.1103 -0.1158 -0.0215 -0.1342 -0.0751 -0.1591 -0.0977 -0.2095 -0.0679 -0.0831 -0.0265 -0.0346 -0.0939 -0.0080 -0.0768 -0.0231 -0.0208 -0.0375 -0.0366 -0.0842 -0.0810\n",
            "T-182\tmwamuna wovala malaya abuluu akukwera mwala pamene anthu kumbuyo kwake atavala malaya ofiira akuonera\n",
            "H-182\t-0.2592037320137024\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u k w e r a ▁ m a l a y a ▁ a m i t u n d u ▁ y o v a l a ▁ m a l a y a ▁ o f i i r a ▁ o f i i r a ▁ a k u w o n e r a\n",
            "D-182\t-0.2592037320137024\tmwamuna wovala malaya abuluu akukwera malaya amitundu yovala malaya ofiira ofiira akuwonera\n",
            "P-182\t-0.1152 -0.1555 -0.0279 -0.1226 -0.2775 -0.0556 -0.0649 -0.1204 -0.1131 -0.0750 -0.1072 -0.0462 -0.1486 -0.1014 -0.1346 -0.0964 -0.0271 -0.1164 -0.0691 -0.1279 -0.0674 -0.1161 -0.0904 -0.2202 -0.2554 -0.1974 -0.0599 -0.0665 -0.0250 -0.0813 -0.1479 -0.0692 -0.1040 -0.2213 -0.1947 -0.1277 -0.0652 -0.1315 -0.1210 -0.3123 -1.4551 -0.5043 -0.2217 -0.6011 -0.0995 -0.0704 -0.2743 -0.4943 -0.0916 -1.4449 -0.2745 -0.0722 -0.0247 -0.0687 -0.2019 -0.0316 -0.1385 -3.0600 -0.1633 -0.0738 -0.1266 -0.0931 -1.7825 -0.1401 -1.4546 -0.1264 -0.0720 -0.1024 -0.0601 -0.0489 -0.1007 -0.0409 -0.0716 -0.0429 -0.2548 -0.1040 -1.1346 -0.5702 -0.0500 -0.0784 -0.0442 -0.2407 -0.1386 -0.3752 -0.2268 -0.1121 -0.4710 -0.2217 -0.0730 -0.1193 -0.1450 -0.1177 -1.2230\n",
            "T-309\tmayi wovala malaya oyera akuyang ana mayi yemwe wakhala pafupi naye yemwe akupanga nkhope yoseketsa\n",
            "H-309\t-0.27081868052482605\t▁ m a y i ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u y a n g ▁ a n a ▁ m a y i ▁ w a k h a l a ▁ p a f u p i ▁ n d i ▁ m a y i ▁ w i n a ▁ w a k u d a ▁ p a m a s i t e p e ▁ o f i i r a\n",
            "D-309\t-0.27081868052482605\tmayi wovala malaya oyera akuyang ana mayi wakhala pafupi ndi mayi wina wakuda pamasitepe ofiira\n",
            "P-309\t-0.1162 -0.3935 -0.0913 -0.0306 -0.0792 -0.1000 -0.0701 -0.2680 -0.0666 -0.1133 -0.0850 -0.1232 -0.1039 -0.0532 -0.1254 -0.0672 -0.1112 -0.0333 -0.1299 -0.1080 -0.0264 -0.0646 -0.1005 -0.0512 -0.0944 -0.1085 -0.6739 -0.1563 -0.1064 -0.3369 -0.1863 -0.1470 -0.1095 -0.0723 -0.1064 -0.1347 -0.0948 -0.1443 -0.2330 -0.1820 -1.2287 -1.3021 -0.0940 -0.0589 -0.1537 -0.7913 -0.2019 -0.0986 -0.0969 -0.1151 -0.1256 -0.0720 -0.1368 -0.1986 -0.0345 -0.0628 -0.0461 -0.0761 -0.0263 -0.2777 -0.1113 -0.0880 -0.6986 -1.5856 -0.4697 -0.3277 -0.1137 -0.3296 -0.1953 -0.0939 -0.1126 -0.0892 -1.0677 -0.1804 -0.6473 -0.1953 -0.3441 -0.0998 -0.1329 -1.8591 -0.0920 -0.1047 -1.2269 -0.3707 -1.5999 -0.1371 -0.0465 -0.0425 -0.1549 -0.4595 -0.5459 -1.0528 -0.4000 -0.2163 -0.1608 -0.2428 -0.0781\n",
            "T-156\tana amasewera mumchenga wozunguliridwa ndi mchenga wokhala ndi mazenera ambiri ngati otsegula\n",
            "H-156\t-0.34189286828041077\t▁ a n a ▁ a s e w e r a ▁ m ▁ c h i p i n d o ▁ w o z u n g u l i r a ▁ n d i ▁ m c h e n g o ▁ w a k h a l a ▁ n d i ▁ m a s e w e r a ▁ a m b i r i ▁ a m b i r i ▁ k u t s o g o l o ▁ k w a k e\n",
            "D-156\t-0.34189286828041077\tana asewera m chipindo wozungulira ndi mchengo wakhala ndi masewera ambiri ambiri kutsogolo kwake\n",
            "P-156\t-0.1096 -0.0934 -0.0972 -0.1309 -0.0934 -0.1902 -0.8141 -0.4618 -0.0900 -0.1362 -0.0677 -0.1119 -0.1348 -0.2094 -0.3711 -0.2140 -0.0598 -0.3615 -1.9363 -0.8133 -0.1447 -0.6962 -1.2248 -0.0883 -1.7024 -0.2566 -0.3511 -0.0322 -0.0396 -0.0243 -0.0338 -0.0604 -0.0652 -0.1164 -0.2396 -0.1343 -0.4802 -0.0505 -0.1481 -0.1158 -0.1413 -2.4058 -0.0998 -0.3124 -0.1063 -0.0657 -0.3507 -0.1062 -0.0971 -0.5021 -1.3271 -0.0436 -0.1372 -0.1845 -0.1266 -0.1623 -0.1433 -0.0610 -0.0961 -0.0843 -0.0746 -0.1031 -0.2219 -0.6176 -0.0676 -0.0431 -0.0346 -0.1144 -0.1019 -0.1271 -0.7236 -0.3387 -0.1371 -0.0380 -0.0868 -0.1565 -0.5417 -1.4760 -0.7250 -0.0947 -0.3123 -0.1276 -0.2862 -2.1931 -0.1299 -0.4452 -0.0394 -0.7730 -0.1033 -0.0843 -0.0764 -0.1478 -0.5014 -0.1956 -0.1351 -0.1629 -3.0355 -0.1366 -0.0831\n",
            "T-295\tmbalame yotuwa ya m madzi yokhala ndi zizindikiro zakuda ndi zoyera ikuuluka pafupi ndi madzi\n",
            "H-295\t-0.31102296710014343\t▁ m a y i ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ s i t i ▁ y o k h a l a ▁ n d i ▁ z i n t h u ▁ z o f i i r a ▁ n d i ▁ z o y e r a ▁ n d i ▁ z a k u m b u y o ▁ p a f u p i ▁ n d i ▁ m a d z i\n",
            "D-295\t-0.31102296710014343\tmayi wina yemwe wavala siti yokhala ndi zinthu zofiira ndi zoyera ndi zakumbuyo pafupi ndi madzi\n",
            "P-295\t-0.1000 -2.1159 -0.1983 -0.0729 -0.0894 -0.0887 -0.3887 -0.2352 -0.1593 -0.1122 -0.1328 -0.9169 -0.0977 -0.2991 -0.0192 -0.1633 -0.0845 -1.0689 -0.1111 -0.9751 -0.1383 -0.0841 -0.1085 -0.1103 -0.9315 -0.4539 -1.2000 -0.1576 -0.1559 -0.0786 -0.0685 -0.2592 -0.0241 -0.1226 -0.0814 -0.1128 -0.1080 -0.0177 -0.0949 -0.0845 -0.0992 -1.0005 -0.0981 -1.2871 -0.2837 -0.2007 -0.0820 -0.0980 -0.9551 -0.4804 -1.1977 -0.0556 -0.1043 -0.0296 -0.2987 -0.0944 -0.6971 -0.1470 -0.1081 -0.1066 -0.5712 -0.5403 -0.2320 -0.1019 -0.0774 -0.1316 -0.0807 -0.5092 -0.1254 -0.1007 -0.2739 -0.0610 -1.4356 -0.2036 -0.1095 -0.8774 -0.8296 -0.0512 -0.1619 -0.2473 -0.1369 -0.4106 -0.1115 -0.1630 -0.0239 -0.0283 -0.0730 -0.2094 -0.0175 -0.1655 -0.1095 -0.1259 -0.1202 -0.0905 -2.4266 -0.1607 -0.0780 -0.0624\n",
            "T-407\tmnyamata watsitsi lakuda wovala malaya abuluu mpango wobiriwira ndi magalasi akupanga mbale pagudumu ladothi\n",
            "H-407\t-0.22001725435256958\t▁ m n y a m a t a ▁ w a t s i t s i ▁ l a k u d a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ w o b i r i w i r a ▁ n d i ▁ m a g a l a s i ▁ a k u y a n g ▁ a n a ▁ k u d u m p h a\n",
            "D-407\t-0.22001725435256958\tmnyamata watsitsi lakuda wovala malaya abuluu wobiriwira ndi magalasi akuyang ana kudumpha\n",
            "P-407\t-0.1012 -0.1761 -0.0309 -0.0589 -0.1103 -0.0542 -0.1004 -0.0426 -0.1095 -0.1076 -0.0292 -0.3299 -0.5421 -0.0171 -0.0649 -0.0333 -0.0355 -0.0648 -0.0868 -0.1707 -0.0980 -0.0812 -0.0691 -0.0767 -0.1525 -0.0986 -0.1119 -0.0609 -0.0434 -0.1158 -0.1293 -0.1127 -0.1045 -0.0368 -0.0963 -0.0506 -0.1175 -0.0283 -0.1105 -0.0871 -0.7008 -0.1016 -0.0573 -0.0594 -0.0483 -0.0246 -0.0857 -1.7807 -0.1120 -0.0148 -0.0673 -0.0314 -0.1055 -0.0272 -0.0769 -0.0507 -0.1153 -0.1364 -0.1193 -0.0828 -0.0743 -0.1062 -0.5764 -0.1075 -0.2675 -0.1408 -0.0716 -0.3845 -0.0323 -0.0403 -0.0502 -0.2294 -0.3619 -0.1751 -3.0245 -0.1313 -0.2560 -0.1259 -0.0787 -0.1134 -0.1089 -0.1471 -0.0937 -1.8499 -0.1275 -1.0385 -0.0787 -0.0720 -0.1192 -0.0358 -0.1052 -2.2716\n",
            "T-286\tbambo wina wovala jeans ndi jekete yabuluu akuyenda m manda masana ali ndi manja m matumba\n",
            "H-286\t-0.3082306385040283\t▁ a m u n a ▁ a w i r i ▁ o v a l a ▁ c h i p e w a ▁ c h a ▁ b u l u u ▁ a k u y e n d a ▁ m ▁ m a n j a ▁ m a s o ▁ a l i ▁ n d i ▁ m a n j a ▁ a l i ▁ m ▁ m a n j a\n",
            "D-286\t-0.3082306385040283\tamuna awiri ovala chipewa cha buluu akuyenda m manja maso ali ndi manja ali m manja\n",
            "P-286\t-0.1208 -1.3572 -0.0938 -0.0783 -0.1365 -0.0967 -0.1230 -0.1732 -0.0078 -0.0933 -0.0661 -0.0966 -0.1363 -0.6913 -0.0618 -0.1026 -0.1083 -0.1044 -0.1058 -0.3979 -0.0725 -0.0848 -0.7575 -1.2843 -0.3203 -0.1398 -0.1630 -0.0479 -0.0618 -0.1443 -0.2385 -0.5303 -0.5093 -0.1693 -0.0847 -0.0229 -0.0924 -0.1300 -0.0389 -0.1231 -0.1601 -1.3069 -0.0272 -0.0211 -0.1029 -0.1249 -0.2351 -0.3057 -0.0694 -0.0881 -0.2740 -0.6397 -0.1012 -0.1072 -1.2730 -2.0940 -0.0844 -1.0846 -0.0771 -0.0727 -0.9648 -0.0430 -0.1064 -0.1304 -0.0468 -0.0811 -0.1076 -0.2447 -0.3938 -0.1599 -0.0678 -0.1032 -0.1232 -0.2235 -1.1398 -0.0486 -0.1193 -0.4596 -0.1104 -1.3511 -1.2030 -0.1492 -0.1907 -0.1100 -1.1049\n",
            "T-326\tamuna awiri achikulire akukambitsirana panja m dera lokhala ndi makoma amiyala ndi pansi\n",
            "H-326\t-0.28063318133354187\t▁ a m u n a ▁ a w i r i ▁ a c h i k u l i r e ▁ a k u k h a l a ▁ n d i ▁ z i s a n a ▁ p a n j a ▁ n d i k u k h a l a ▁ n d i ▁ m a k o m a ▁ a m i y a l a ▁ n d i ▁ m p a n s i\n",
            "D-326\t-0.28063318133354187\tamuna awiri achikulire akukhala ndi zisana panja ndikukhala ndi makoma amiyala ndi mpansi\n",
            "P-326\t-0.1041 -0.1863 -0.0949 -0.0753 -0.1030 -0.0882 -0.0876 -0.1096 -0.0360 -0.1056 -0.0593 -0.1132 -0.0889 -0.1181 -0.1604 -0.0796 -0.1048 -0.0491 -0.0707 -0.0602 -0.0770 -0.0492 -0.5229 -0.0807 -0.1371 -0.0856 -0.1386 -0.0987 -0.6719 -0.1270 -1.1568 -0.1547 -0.1456 -0.5795 -0.0749 -0.0947 -0.1729 -0.9368 -0.1054 -0.4009 -1.1352 -0.0216 -0.9705 -0.1187 -0.1483 -0.1597 -0.1759 -0.0322 -0.1079 -0.1582 -0.3046 -0.0542 -0.2432 -1.1265 -0.3457 -0.1976 -1.6317 -0.1160 -0.0655 -0.1514 -0.0847 -0.8326 -0.0927 -0.1213 -0.1240 -0.0353 -0.1011 -0.8871 -0.1117 -0.4891 -0.1219 -0.1409 -0.1111 -1.0126 -0.5818 -0.7828 -0.1735 -0.0414 -0.0855 -0.2744 -0.6227 -0.0863 -0.1030 -0.0929 -0.3830 -0.7647 -0.6856 -0.4731 -0.8973 -0.1698 -0.0839\n",
            "T-147\twokwera pa chipale chofewa akudumpha mozondoka pamalo osungiramo mapiri a terrain park\n",
            "H-147\t-0.2856467068195343\t▁ w o k w e r a ▁ p a ▁ c h i p a l e ▁ c h o f e w a ▁ k u d u m p h a ▁ m o d z i ▁ w o k h a l a ▁ p a m a s o ▁ n d i ▁ a n t h u ▁ e n a ▁ a k u y e n d a\n",
            "D-147\t-0.2856467068195343\twokwera pa chipale chofewa kudumpha modzi wokhala pamaso ndi anthu ena akuyenda\n",
            "P-147\t-0.1154 -0.1414 -0.0456 -0.0353 -0.0257 -0.0523 -0.0634 -0.1216 -0.1135 -0.0485 -0.1551 -0.3302 -0.0321 -0.1230 -0.1170 -0.0504 -0.1106 -0.1102 -0.0223 -0.0707 -0.0176 -0.0638 -0.0412 -0.1185 -0.0905 -0.0197 -0.1006 -0.1284 -0.3947 -0.0777 -0.2376 -0.0588 -0.1446 -0.0240 -0.0382 -0.0807 -0.1319 -0.1022 -1.1860 -0.4114 -0.2915 -0.6116 -0.1055 -0.2068 -0.3748 -0.3428 -0.1174 -0.1170 -0.0585 -0.1238 -0.0959 -1.6312 -0.1210 -0.4338 -0.2687 -0.5044 -0.3081 -0.0523 -0.4119 -0.0670 -0.1112 -0.2319 -1.3180 -2.6404 -0.6057 -0.0936 -0.1304 -0.0867 -0.5718 -0.2339 -0.0782 -0.1590 -0.6917 -1.1764 -0.2585 -0.3786 -0.0732 -0.6535 -0.0835 -0.2696 -1.6951\n",
            "T-242\tgalimoto yoyaka moto yofiira yayimitsidwa pafupi ndi gulu la anthu ndi ana omwe aima mumsewu\n",
            "H-242\t-0.27397584915161133\t▁ g a l i m o t o ▁ y o y e r a ▁ a m u t u ▁ y o f i i r a ▁ n d i ▁ y a i m i t s i d w a ▁ p a f u p i ▁ n d i ▁ g u l u ▁ l a ▁ a n t h u ▁ a i m a ▁ m u m s e w u\n",
            "D-242\t-0.27397584915161133\tgalimoto yoyera amutu yofiira ndi yaimitsidwa pafupi ndi gulu la anthu aima mumsewu\n",
            "P-242\t-0.1035 -0.0442 -0.0902 -0.0476 -0.1974 -0.0504 -0.0323 -0.0395 -0.0352 -0.1608 -0.0099 -1.3698 -0.0468 -0.4186 -0.2273 -0.1212 -0.1527 -2.1020 -0.6207 -1.5546 -0.2004 -0.2285 -0.0844 -0.6151 -0.0244 -0.0137 -0.0734 -0.3652 -0.0543 -0.2044 -0.1246 -1.1084 -0.0742 -0.0893 -0.1106 -0.2092 -0.1262 -0.4388 -1.5720 -0.6575 -0.3863 -0.1166 -0.0390 -0.0514 -0.0617 -0.1014 -0.1103 -0.0659 -0.3014 -0.0520 -0.0449 -0.1268 -0.0741 -0.0903 -0.0703 -0.0970 -0.1172 -0.1297 -0.0385 -0.0685 -0.1444 -0.0361 -0.0841 -0.2434 -0.1092 -0.0725 -0.0911 -0.9414 -0.0716 -0.0767 -0.0667 -0.1542 -1.0774 -1.2774 -0.0311 -0.0855 -0.2549 -0.1952 -1.8912 -0.0376 -0.0424 -0.0945 -0.0556 -0.0284 -0.1827\n",
            "T-88\tmtsikana yemwe wakhala pafupi ndi bambo yemwe wavala t shirt yoyera akudya zokazinga zachi french\n",
            "H-88\t-0.2640663981437683\t▁ m t s i k a n a ▁ y e m w e ▁ w a k h a l a ▁ p a f u p i ▁ n d i ▁ b a m b o ▁ w a ▁ m e n e ▁ w a v a l a ▁ t ▁ s h i r t ▁ y o y e r a ▁ a k u j a z i ▁ z o k h a l a ▁ n d i ▁ c h i p e w a\n",
            "D-88\t-0.2640663981437683\tmtsikana yemwe wakhala pafupi ndi bambo wa mene wavala t shirt yoyera akujazi zokhala ndi chipewa\n",
            "P-88\t-0.1189 -0.0427 -0.1388 -0.0440 -0.0651 -0.0380 -0.1190 -0.0661 -0.1212 -0.1443 -0.0862 -0.0181 -0.0173 -0.0131 -0.0542 -0.0830 -0.0323 -0.1329 -1.4510 -0.0635 -0.1021 -0.0826 -0.1121 -0.1353 -0.0689 -0.0911 -0.0982 -0.0512 -0.0218 -0.0624 -0.0776 -0.0312 -0.0633 -0.1105 -0.1058 -0.1718 -0.1961 -0.0473 -0.0172 -0.0138 -0.0839 -0.3607 -0.8831 -1.0142 -0.3541 -1.7722 -0.4428 -0.1918 -0.1487 -0.0746 -0.3114 -0.2780 -0.1325 -0.0854 -0.0965 -0.0932 -1.4981 -0.0949 -0.2778 -0.0510 -1.0343 -0.0220 -0.0209 -0.1140 -0.1069 -0.0546 -0.0639 -0.1250 -0.0299 -0.1393 -0.1071 -0.1210 -0.0500 -0.1379 -0.6184 -0.1748 -1.0303 -0.1091 -0.1330 -0.6163 -0.1439 -0.0444 -0.1401 -0.1487 -1.1876 -0.1294 -0.0945 -2.0580 -0.4491 -0.1387 -0.0714 -0.2951 -0.1162 -0.0732 -0.5878 -0.1404 -0.8154 -0.6898 -1.2552\n",
            "T-408\tmunthu wovala mofiyira komanso mathalauza obisala wapindika m chiuno ndipo manja ake ali pamtengo waukulu\n",
            "H-408\t-0.3099203109741211\t▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ k o m a n s o ▁ m a t h a l a u z a ▁ o b i r i w i r a ▁ n d i ▁ c h i n t h u ▁ n d i p o ▁ m a n j a ▁ a k e ▁ p a m t e n g o\n",
            "D-408\t-0.3099203109741211\tmunthu wovala malaya ofiira komanso mathalauza obiriwira ndi chinthu ndipo manja ake pamtengo\n",
            "P-408\t-0.1111 -0.1252 -0.0457 -0.0537 -0.0156 -0.0366 -0.0842 -0.1117 -0.0530 -0.3582 -0.0794 -0.1050 -0.0685 -0.1236 -0.1006 -0.0978 -0.0874 -4.0725 -0.1557 -0.3707 -0.1244 -0.0934 -0.1670 -0.0434 -0.0917 -0.1133 -0.0475 -0.1439 -0.1086 -0.9578 -0.7447 -0.0252 -0.0580 -0.0203 -0.0475 -0.0388 -0.0734 -2.4419 -0.1141 -0.2819 -0.1519 -0.0887 -0.0589 -0.0822 -0.0340 -0.0223 -0.0788 -0.1127 -0.4642 -1.2001 -0.0637 -0.3498 -0.1106 -0.1894 -0.4806 -0.5377 -0.0985 -0.1084 -0.0613 -0.0898 -0.0907 -0.1242 -0.8179 -0.0807 -0.0408 -0.5616 -1.8890 -0.0343 -0.0981 -0.1128 -1.4895 -0.1417 -0.0812 -1.4414 -0.0444 -0.1328 -0.2117 -0.2652 -0.2368 -0.0470 -0.4058 -0.0948 -0.5555 -0.4339 -0.0608 -0.1196 -0.1485 -0.1050 -0.1196 -0.7347 -0.4029 -0.2228 -0.0229 -0.0431 -1.6540\n",
            "T-140\tmtsikana wablond wavala chisoti chasiliva chigongono ndi zoyala pamabondo ndi rollerblades\n",
            "H-140\t-0.326012521982193\t▁ m t s i k a n a ▁ w a ▁ b l o n d ▁ w a v a l a ▁ c h i s o t i ▁ c h a c h i k a s u ▁ c h o n g o l a ▁ n d i ▁ z o y a n g ▁ a n a ▁ p a m a l o ▁ o n d o ▁ m ▁ m p h e p e t e ▁ m w a ▁ t s i t s i\n",
            "D-140\t-0.326012521982193\tmtsikana wa blond wavala chisoti chachikasu chongola ndi zoyang ana pamalo ondo m mphepete mwa tsitsi\n",
            "P-140\t-0.1113 -1.3448 -0.0308 -0.0550 -0.0677 -0.0396 -0.1039 -0.0477 -0.1135 -0.1191 -0.0234 -0.8355 -1.6479 -1.1577 -0.2446 -0.0516 -0.0252 -0.0247 -0.1454 -0.0516 -0.3047 -0.0436 -0.1444 -0.1047 -0.1278 -0.1185 -0.4215 -0.0762 -0.1047 -0.1586 -0.0165 -0.0138 -0.0549 -0.0921 -0.0347 -0.0389 -0.2056 -0.7010 -0.0809 -0.0629 -0.3201 -0.1096 -0.0278 -0.2433 -0.0899 -1.2635 -0.0431 -1.2069 -1.1771 -0.0707 -0.0357 -0.8016 -0.7577 -0.2993 -0.0763 -0.0820 -0.0857 -0.1780 -0.2462 -0.0976 -0.5223 -1.0537 -0.6926 -0.1107 -0.0532 -0.2704 -0.1058 -0.6971 -0.0953 -0.2855 -0.1650 -0.2671 -0.3945 -0.8026 -0.1511 -0.0980 -0.2573 -1.2934 -0.7578 -0.2404 -0.4690 -1.6484 -0.9019 -0.5372 -0.0428 -0.0847 -0.0907 -0.1679 -0.0994 -0.0110 -0.1402 -0.1609 -0.5799 -0.1924 -0.0977 -0.1897 -2.7592 -0.2377 -0.1537 -0.0262 -0.0398 -0.0897 -0.1859\n",
            "T-101\tgalu wabulauni wovala malaya apinki amatafuna choyera pamene galu wabulauni atavala mawotchi achikasu\n",
            "H-101\t-0.2031531035900116\t▁ g a l u ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a t a n y a m u l a ▁ c h o y e r a ▁ p a m e n e ▁ g a l u ▁ w a b u l a u n i ▁ a t a v a l a ▁ c h i p e w a ▁ c h a c h i k a s u\n",
            "D-101\t-0.2031531035900116\tgalu wamng ono wovala malaya apinki atanyamula choyera pamene galu wabulauni atavala chipewa chachikasu\n",
            "P-101\t-0.1022 -0.1397 -0.0983 -0.1021 -0.0977 -0.0892 -0.0599 -0.0857 -1.1440 -0.0643 -0.1089 -0.0868 -0.1338 -0.0733 -0.0578 -0.1409 -0.0513 -0.0418 -0.0510 -0.1261 -0.1365 -0.1305 -0.1056 -0.0323 -0.0965 -0.0991 -0.1306 -0.0674 -0.1102 -0.0757 -0.1689 -0.5604 -0.0678 -0.0288 -0.0226 -0.1288 -0.1296 -0.0691 -1.0309 -0.1186 -1.5168 -0.1151 -0.0864 -0.0734 -0.0376 -0.0705 -0.1262 -0.0996 -0.0301 -0.0636 -1.2641 -0.0914 -0.1624 -0.1483 -0.0953 -0.1335 -0.6439 -0.1216 -0.2395 -0.2985 -0.0364 -0.0524 -0.0854 -0.8316 -0.1118 -0.0758 -0.0446 -0.0928 -0.0126 -0.1244 -0.7694 -0.0745 -0.0969 -0.0915 -0.0257 -0.0223 -0.0509 -0.1146 -0.3857 -0.0506 -0.1215 -0.1997 -0.1399 -0.1344 -0.1454 -0.1050 -2.1367 -0.1207 -0.0576 -0.5341 -0.8625 -0.0501 -0.1242 -0.1532 -0.0543 -0.0867 -0.2181 -0.4886 -0.0943 -0.0599 -0.1478 -0.0876 -0.0918 -0.1260 -0.2586\n",
            "T-123\tamuna awiri m modzi wovala jekete yobiriwira ndipo m modzi wa jekete yofiira akufuna kuyatsa moto m nkhalango\n",
            "H-123\t-0.23373353481292725\t▁ a m u n a ▁ a w i r i ▁ m ▁ m o d z i ▁ w a v a l a ▁ j e k e t e ▁ y o b i r i w i r a ▁ n d i p o ▁ m m o d z i ▁ w a ▁ j e k e t e ▁ y o f i i r a ▁ a k u f u n a ▁ k u m u y a n g ▁ a n a ▁ k u m b u y o\n",
            "D-123\t-0.23373353481292725\tamuna awiri m modzi wavala jekete yobiriwira ndipo mmodzi wa jekete yofiira akufuna kumuyang ana kumbuyo\n",
            "P-123\t-0.1147 -0.1177 -0.1376 -0.0713 -0.0905 -0.0979 -0.1013 -0.1113 -0.0311 -0.1076 -0.0532 -0.1192 -0.1187 -0.0530 -0.5734 -0.0510 -0.0943 -0.0883 -0.0283 -0.1046 -0.0810 -0.0954 -0.4482 -0.0635 -0.1237 -0.0925 -0.1127 -0.1160 -0.1768 -0.2941 -0.1060 -0.0826 -0.0086 -0.1317 -0.0868 -0.4298 -0.0336 -0.1737 -0.0885 -0.0479 -0.0734 -0.0205 -0.1232 -0.0627 -0.1127 -0.1220 -0.1392 -0.0716 -0.0759 -0.4926 -0.0642 -0.1194 -0.1090 -1.2126 -0.4228 -0.0852 -0.0212 -0.0624 -0.0701 -0.1874 -0.1733 -1.6036 -1.1025 -0.1084 -0.2938 -0.0681 -0.0159 -0.1237 -0.0938 -0.3077 -0.1861 -0.0081 -0.0703 -0.1162 -0.0494 -0.1185 -0.1138 -0.0944 -0.0353 -0.1311 -0.2828 -0.1121 -0.1732 -0.4662 -0.1134 -0.4139 -0.1483 -0.6645 -0.7642 -1.3033 -0.0900 -0.7956 -0.1015 -0.0923 -0.0768 -0.0922 -0.0968 -0.1852 -2.3036 -0.4718 -0.4812 -0.4791 -0.6037 -0.0531 -0.1516 -0.7388\n",
            "T-215\tmayi wagona pansi ndi kamera ndipo mwamuna akutsamira pa iye akujambula chithunzi\n",
            "H-215\t-0.39800941944122314\t▁ m a y i ▁ w a g o n a ▁ p a ▁ c h i p a l e ▁ c h a ▁ m k a z i ▁ n d i ▁ m w a m u n a ▁ a k u t h a m a n g i t s a ▁ m ▁ n j a m b u l a ▁ z i t h u n z i\n",
            "D-215\t-0.39800941944122314\tmayi wagona pa chipale cha mkazi ndi mwamuna akuthamangitsa m njambula zithunzi\n",
            "P-215\t-0.1048 -0.3577 -0.0796 -0.0900 -0.0773 -0.1199 -0.2132 -0.2472 -1.3312 -0.4957 -0.4331 -0.1451 -0.0961 -0.0472 -0.1289 -0.8077 -0.8123 -0.0824 -0.0752 -1.3012 -0.0976 -0.6879 -0.0442 -0.0736 -0.1789 -0.0898 -0.5722 -0.4513 -0.7645 -2.8596 -0.1284 -0.1707 -0.0554 -0.1105 -0.6327 -0.1594 -0.0620 -0.6360 -0.5069 -0.1728 -0.0954 -0.0361 -0.0664 -0.0636 -0.1181 -0.1063 -0.2911 -0.4123 -0.0949 -0.0669 -1.3101 -0.1491 -0.0790 -0.4619 -0.0978 -0.0707 -0.0659 -2.0941 -0.2691 -0.0975 -0.0739 -0.4917 -0.9870 -1.0001 -0.5743 -0.0705 -2.1435 -0.2079 -0.0588 -0.1904 -0.0687 -0.1490 -2.2194 -0.3871 -0.3982 -0.3297 -0.0337 -0.0364 -0.0319 -0.0469 -1.1936\n",
            "T-247\tbanja lachiyuda likudyera limodzi chakudya chamadzulo lamlungu kuti lilambire\n",
            "H-247\t-0.3594149053096771\t▁ p a n j a ▁ l a c h i n y a m u l a ▁ l i k u d y e r a ▁ l i m o d z i ▁ y a k u d a ▁ a k u j a m b u l a ▁ m a s u l o ▁ a ▁ n g a t i ▁ n d i ▁ k u t i ▁ l a m b i r i\n",
            "D-247\t-0.3594149053096771\tpanja lachinyamula likudyera limodzi yakuda akujambula masulo a ngati ndi kuti lambiri\n",
            "P-247\t-0.1022 -0.1959 -0.1272 -0.2986 -0.7127 -0.1167 -0.1283 -0.7545 -0.2603 -0.4371 -0.0514 -0.0527 -0.3696 -0.2947 -0.5994 -0.1001 -1.0699 -0.2821 -0.4326 -0.1327 -0.4943 -0.1112 -0.0095 -0.0854 -1.3304 -1.5961 -1.0835 -0.1270 -0.1204 -0.1692 -0.3687 -0.1805 -0.0197 -0.0724 -0.1543 -0.0647 -0.0399 -0.0878 -0.3750 -0.0942 -0.6616 -0.1462 -0.1444 -0.1484 -0.1192 -1.0667 -0.1226 -0.1328 -0.3262 -0.1069 -0.0340 -0.3545 -0.0731 -0.0956 -0.1599 -0.1621 -1.3001 -0.2352 -0.8593 -0.1096 -0.3886 -0.3089 -0.0682 -0.2806 -0.7298 -1.3569 -0.4482 -0.2195 -0.2689 -0.0626 -0.1129 -1.5274 -0.0927 -0.0999 -0.2297 -1.6968 -0.3050 -0.5305 -0.0410 -0.1312 -0.4905 -2.1346 -0.0718 -0.0469 -0.0968 -0.0312 -0.1991 -0.1969\n",
            "T-118\tgalu watsitsi lagolide akuthamanga panjira yofiyira pomwe anthu amangoyang ana pafupi\n",
            "H-118\t-0.3150704503059387\t▁ g a l u ▁ w a t s i t s i ▁ l a b u l a u n i ▁ a k u t h a m a n g a ▁ p a n j i r a ▁ y o f i i r a ▁ p o m w e ▁ a n t h u ▁ e n a ▁ a k u y a n g ▁ a n a ▁ p a f u p i\n",
            "D-118\t-0.3150704503059387\tgalu watsitsi labulauni akuthamanga panjira yofiira pomwe anthu ena akuyang ana pafupi\n",
            "P-118\t-0.1039 -0.0313 -0.0970 -0.0861 -0.1062 -0.1019 -0.0150 -0.1375 -0.5730 -0.0511 -0.0848 -0.1433 -0.0229 -0.0631 -0.1056 -0.0765 -0.3940 -0.4775 -1.0211 -0.1243 -1.2235 -0.0556 -0.2135 -0.1443 -0.1134 -0.1867 -0.0400 -0.0848 -2.3216 -0.1077 -0.0944 -0.0332 -0.0952 -0.0471 -0.0781 -0.1705 -0.1084 -1.3330 -0.1671 -0.7508 -0.0350 -0.0710 -0.0574 -0.0671 -0.1309 -0.2377 -0.2243 -0.0565 -0.0538 -0.9683 -0.0563 -0.1799 -0.1264 -1.4645 -1.5376 -0.2092 -0.3189 -0.1245 -0.1002 -0.4835 -0.1613 -0.8410 -0.1050 -0.2192 -0.1193 -1.1747 -0.0411 -0.1086 -0.1071 -0.3351 -3.0729 -0.0906 -0.0685 -0.0885 -0.0723 -0.1205 -0.1143 -0.2215 -0.0736 -0.1363 -0.4379 -0.1681 -0.1158 -1.3775 -0.0416 -0.2134 -0.0784 -0.3343\n",
            "T-1\tmayi wina wakummawa atavala malaya akuda ma leggings ndi nsapato wayima panja pa sitolo yogulitsa zinthu\n",
            "H-1\t-0.3106388747692108\t▁ m a y i ▁ w i n a ▁ w a k u m w a ▁ a t a v a l a ▁ m a l a y a ▁ a k u d a ▁ n d i ▁ m a ▁ j e k e t e ▁ n d i ▁ d z a n j a ▁ l a k e ▁ p a n j a ▁ p a ▁ s i t o l o ▁ y o g u l i t s a ▁ z i n t h u\n",
            "D-1\t-0.3106388747692108\tmayi wina wakumwa atavala malaya akuda ndi ma jekete ndi dzanja lake panja pa sitolo yogulitsa zinthu\n",
            "P-1\t-0.1067 -0.1361 -0.0997 -0.0932 -0.1006 -0.1040 -0.0446 -0.0674 -0.0542 -0.1032 -0.0992 -0.0750 -0.0881 -0.8424 -0.2444 -0.0619 -0.5146 -0.1274 -0.1903 -1.6705 -0.0742 -0.1206 -0.0284 -0.0967 -0.1425 -0.1032 -0.1062 -0.1381 -0.0838 -0.0746 -0.1084 -0.0373 -0.1012 -0.0829 -0.1650 -0.7125 -0.1062 -0.1569 -0.0815 -0.0889 -0.2333 -0.0886 -0.0657 -0.2747 -1.8139 -0.0927 -1.7886 -0.4973 -0.2541 -0.6731 -0.0435 -0.0098 -0.0481 -0.1010 -1.0398 -0.1247 -0.1119 -0.2195 -1.5243 -0.0603 -0.1502 -0.7808 -0.0887 -0.1239 -0.0665 -0.2621 -0.1890 -0.5230 -0.2698 -0.0778 -1.0023 -0.1891 -1.2385 -1.0927 -0.1829 -0.1062 -0.8354 -0.2727 -0.2768 -0.2470 -0.6125 -0.2736 -0.4989 -0.0126 -0.2191 -0.2020 -0.5155 -0.1780 -2.1294 -0.2883 -0.1046 -0.0401 -0.0704 -0.0633 -0.2085 -0.6239 -0.1870 -0.8555 -0.1158 -0.0752 -0.0728 -0.0630 -0.1134\n",
            "T-364\tmkwati ndi mkwatibwi kudumphira wina ndi mzake manja atatambasula\n",
            "H-364\t-0.3832972049713135\t▁ m w a n a ▁ y e m w e ▁ a l i ▁ n d i ▁ c h i k u d u m p h i r a ▁ m u m l e n g a l e n g a ▁ n d i ▁ m a n j a ▁ a t a t u ▁ a k u y a n g ▁ a n a\n",
            "D-364\t-0.3832972049713135\tmwana yemwe ali ndi chikudumphira mumlengalenga ndi manja atatu akuyang ana\n",
            "P-364\t-0.1245 -0.0822 -0.6381 -0.1607 -0.1541 -0.1077 -0.1844 -3.6501 -0.0716 -0.0690 -0.0389 -0.2404 -0.1174 -0.3008 -0.9599 -0.3459 -0.0879 -0.3301 -0.1649 -0.1202 -0.1247 -0.6951 -0.0569 -0.0399 -0.5600 -0.8596 -1.1393 -0.9754 -0.4565 -0.1405 -0.0657 -0.1104 -0.0797 -0.1012 -0.1107 -0.3101 -0.3192 -1.7200 -0.8858 -0.9507 -0.1016 -0.1501 -0.0780 -0.1007 -0.2461 -0.0660 -0.3692 -0.4211 -0.1591 -0.1212 -0.2984 -0.1126 -0.1104 -0.1403 -0.3384 -0.4961 -0.0251 -0.2007 -0.1306 -0.2274 -0.1019 -0.1082 -0.9983 -0.7229 -0.4212 -0.5234 -1.6597 -0.0824 -1.9310 -0.1823 -0.1487 -0.1282 -0.2333 -0.1492 -0.0495 -0.1434 -0.3867\n",
            "T-115\tskateboarder watsitsi lalitali amawuluka pamwamba pa masitepe a simenti ndi bannister yachitsulo\n",
            "H-115\t-0.29604730010032654\t▁ g a l i m o t o ▁ w a ▁ t s i t s i ▁ l a l i t a l i ▁ a m a w u l u k a ▁ p a m w a m b a ▁ p a ▁ m a s i t e p e ▁ a ▁ s i m e n t i ▁ p a n j i n g a ▁ y a c h i t s u l o\n",
            "D-115\t-0.29604730010032654\tgalimoto wa tsitsi lalitali amawuluka pamwamba pa masitepe a simenti panjinga yachitsulo\n",
            "P-115\t-0.1059 -1.0544 -1.1799 -0.1646 -0.9942 -0.1386 -0.2460 -0.0445 -0.0703 -0.1011 -0.3869 -0.2226 -0.2545 -1.5608 -0.1335 -0.0665 -0.0375 -0.0504 -0.0853 -0.0869 -0.2965 -0.1076 -0.0341 -0.0601 -0.0462 -0.0724 -0.0406 -0.0778 -0.1213 -0.2384 -1.7018 -0.1084 -1.7042 -0.0835 -0.1525 -0.0626 -0.1203 -0.1028 -0.1325 -0.0482 -0.1245 -0.2068 -0.7472 -0.0835 -0.0378 -0.0457 -0.1742 -0.1093 -0.0024 -0.0980 -0.0786 -0.3315 -0.0475 -0.2323 -0.0337 -0.0463 -0.1559 -0.0280 -0.4282 -0.0943 -0.1683 -0.5010 -0.4965 -0.3628 -2.7617 -0.1105 -0.0884 -0.1659 -0.0677 -0.2127 -0.9025 -0.1254 -0.8876 -1.9390 -0.1029 -0.0992 -0.0915 -0.0902 -0.2349 -0.0140 -0.0903 -0.4318 -0.0552 -0.0407 -0.2357 -0.1358 -0.0191 -0.0363 -0.0312 -0.7432\n",
            "T-66\twotsukira zenera akugwira kapu yoyamwa kuti azithandizira kukwapula pawindo lagalasi\n",
            "H-66\t-0.3961644470691681\t▁ w o s e w e r a ▁ z i y e r a ▁ a k u m w e t u l i r a ▁ a k u y a n g ▁ a n a ▁ k u t i ▁ a z i t a t u ▁ a k u k w e r a ▁ p a f u p i ▁ n d i ▁ n y u m b a ▁ y a c h i k a s u\n",
            "D-66\t-0.3961644470691681\twosewera ziyera akumwetulira akuyang ana kuti azitatu akukwera pafupi ndi nyumba yachikasu\n",
            "P-66\t-0.1138 -0.1336 -0.0889 -0.5307 -0.3885 -0.1825 -0.1163 -0.1515 -0.2881 -0.1012 -2.6354 -0.1179 -2.0374 -0.1339 -0.4490 -0.1127 -0.1258 -0.2934 -0.0421 -0.0939 -1.3461 -0.7688 -0.1933 -0.0743 -0.3132 -0.0591 -0.0829 -0.0398 -0.1048 -0.1130 -1.4375 -0.0978 -0.1277 -0.0640 -0.4030 -0.3344 -0.0614 -0.0755 -0.0964 -0.0981 -0.7625 -0.1013 -0.5683 -0.0874 -0.3139 -1.2871 -0.0858 -0.1245 -1.0833 -0.0561 -1.5229 -0.6812 -0.8235 -0.3925 -0.0875 -1.3098 -0.1169 -0.1562 -0.0833 -0.1315 -0.7732 -0.0510 -0.1182 -0.1140 -0.4067 -0.1536 -2.1717 -0.0589 -0.2698 -0.0924 -0.1061 -0.0888 -0.0394 -0.9053 -0.0761 -0.8868 -0.6535 -0.2381 -0.4010 -0.1702 -0.4879 -0.4181 -0.1830 -0.2604 -2.4521 -0.2606 -0.1454 -0.2884 -0.1123 -0.1043 -0.1396 -0.0174\n",
            "T-85\tkamtsikana kakuimba chitoliro chofiyira chojambulira pamene mtsikana wina akuimba gitala lapinki\n",
            "H-85\t-0.18417245149612427\t▁ k a m t s i k a n a ▁ k a k u i m b a ▁ c h i d o l e ▁ c h o f i i r a ▁ c h o j a m b u l i r a ▁ p a m e n e ▁ m t s i k a n a ▁ w i n a ▁ a k u y i m b a ▁ g i t a l a ▁ l a p i n k i\n",
            "D-85\t-0.18417245149612427\tkamtsikana kakuimba chidole chofiira chojambulira pamene mtsikana wina akuyimba gitala lapinki\n",
            "P-85\t-0.1199 -0.0484 -0.1439 -0.0401 -0.0484 -0.0463 -0.0479 -0.0199 -0.1379 -0.0685 -0.1359 -0.1174 -0.0500 -0.3215 -0.0980 -0.1364 -1.8869 -0.0839 -0.0276 -0.1193 -0.0922 -0.1106 -0.0854 -0.0684 -0.2656 -0.1860 -0.0220 -1.1511 -0.1439 -0.0116 -0.0591 -0.0336 -0.1223 -0.0709 -0.4111 -0.0443 -0.2008 -0.1380 -0.0390 -0.0405 -0.2154 -1.1044 -0.0908 -0.0677 -0.0824 -0.0233 -0.0832 -0.2037 -0.1741 -0.0958 -0.1280 -0.2534 -0.1790 -0.1598 -0.1019 -0.0657 -0.0724 -0.1097 -0.9237 -0.4031 -0.0399 -0.0442 -0.0109 -0.1040 -0.0553 -0.0894 -0.1236 -0.1134 -0.0616 -0.1133 -0.1066 -0.1075 -0.5351 -0.2149 -0.0735 -0.9278 -0.4063 -0.1073 -0.0738 -0.1597 -0.1005 -0.4577 -0.0642 -0.0231 -0.0926 -0.0287 -0.1071 -0.2978 -0.3285 -0.1687 -0.5862 -0.1645 -0.0410 -0.0832 -0.0529 -0.0836\n",
            "T-334\tmwamuna wovala malaya ofiirira akuyang ana mwamuna wovala malaya akuda akukoka nkhope yoseketsa\n",
            "H-334\t-0.22945797443389893\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ a k u y a n g ▁ a n a ▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u k w e r a ▁ k u ▁ o s e w e r a\n",
            "D-334\t-0.22945797443389893\tmwamuna wovala malaya ofiira akuyang ana mwamuna wovala malaya akuda akukwera ku osewera\n",
            "P-334\t-0.1213 -0.0417 -0.1732 -0.1305 -0.2304 -0.0911 -0.0840 -0.1235 -0.1054 -0.0875 -0.0730 -0.0491 -0.1389 -0.0843 -0.1446 -0.0949 -0.0258 -0.1184 -0.0623 -0.1300 -0.0751 -0.1255 -0.0922 -0.0228 -0.0824 -0.0674 -0.1212 -0.0891 -0.4212 -0.1049 -0.1644 -0.0822 -0.1095 -0.0666 -0.6220 -0.0469 -0.0862 -0.0681 -0.1101 -0.0431 -0.1213 -0.1013 -0.4244 -0.1564 -0.1206 -0.8091 -0.1258 -0.0648 -0.1679 -0.1108 -0.0600 -0.1859 -0.0405 -0.1312 -0.1026 -0.1265 -0.1054 -0.0508 -0.1110 -0.0843 -0.1389 -0.0291 -0.1220 -0.0861 -0.7159 -0.3139 -0.0974 -0.1130 -0.1005 -0.1046 -0.1471 -0.1170 -0.1368 -0.2510 -2.4750 -0.5531 -0.1799 -0.1212 -0.1306 -0.2095 -0.7887 -0.9362 -1.3046 -0.8201 -0.2643 -0.5089 -0.1731 -0.2300 -0.7868 -0.7842\n",
            "T-382\tmwana watsitsi komanso wamaso abuluu wanyamula ndege yamatabwa m manja mwake\n",
            "H-382\t-0.3214113414287567\t▁ m w a n a ▁ w a t s i t s i ▁ l a ▁ m a d z i ▁ o v a l a ▁ m a s o ▁ w a m n g ▁ o n o ▁ w a n y a m u l a ▁ j e k e t e ▁ y a m a t a b w a ▁ m ▁ m a n j a\n",
            "D-382\t-0.3214113414287567\tmwana watsitsi la madzi ovala maso wamng ono wanyamula jekete yamatabwa m manja\n",
            "P-382\t-0.1086 -0.1065 -0.0361 -0.1401 -0.0376 -0.1001 -0.1271 -0.0651 -0.2469 -0.1442 -0.0756 -0.0506 -0.0336 -0.0395 -0.0487 -0.0990 -0.4277 -0.1227 -0.6783 -0.1073 -0.1758 -0.1368 -0.0204 -0.1788 -0.1159 -1.9413 -1.4520 -0.1094 -0.2033 -0.1426 -0.1440 -0.1085 -0.1695 -0.2934 -0.1532 -0.1325 -1.6230 -0.1231 -1.5193 -0.6172 -1.6978 -0.1358 -0.0696 -0.0524 -0.0528 -0.1435 -1.9286 -0.2295 -1.5059 -0.0531 -0.0885 -0.0910 -0.0794 -0.0836 -0.1327 -0.1073 -1.6226 -0.0463 -0.1721 -0.0705 -0.0214 -0.0804 -0.1128 -0.2558 -0.1370 -1.2078 -0.1764 -0.6130 -0.2332 -0.0749 -0.0112 -0.0694 -0.3370 -0.6731 -0.0821 -0.4957 -0.3531 -0.0149 -0.0119 -0.0980 -0.4572\n",
            "T-423\tamuna awiri ndi akazi awiri ali kukhitchini ndi vinyo ndi zokhwasula khwasula\n",
            "H-423\t-0.39401185512542725\t▁ a m u n a ▁ a w i r i ▁ a t a k h a l a ▁ n d i ▁ a l i ▁ k u t i ▁ c h i t i n i ▁ n d i ▁ n y a n j a ▁ n d i ▁ z o k w a ▁ k u l a s u l a\n",
            "D-423\t-0.39401185512542725\tamuna awiri atakhala ndi ali kuti chitini ndi nyanja ndi zokwa kulasula\n",
            "P-423\t-0.1111 -0.2245 -0.1009 -0.0836 -0.0837 -0.1253 -0.1038 -0.1610 -0.0805 -0.1439 -0.0583 -0.1047 -0.1150 -0.1745 -0.3908 -0.1083 -1.4977 -0.1165 -0.1440 -0.0845 -0.1168 -0.1061 -3.6160 -0.0775 -0.1052 -0.1572 -0.7073 -2.4374 -0.1021 -0.2533 -0.0623 -0.0474 -0.7825 -0.8141 -0.0883 -0.1414 -0.0983 -0.0646 -0.6146 -1.2080 -0.3894 -0.1803 -0.1948 -0.1243 -0.0542 -0.0827 -0.1137 -0.6089 -1.0993 -0.4264 -0.1789 -0.1655 -0.4284 -0.2819 -0.3782 -0.0239 -0.0810 -0.3017 -0.0591 -0.4285 -0.1884 -0.8461 -0.5358 -2.0275 -1.0821 -0.8969 -0.1097 -0.1771 -0.3766 -0.1323 -0.4634 -0.5754 -0.1376\n",
            "T-249\tgulu la amuna likuyenda mumsewu wokhala ndi riboni yachikasu kutsogolo kwa nyumba yoyera ndi yofiira\n",
            "H-249\t-0.22531822323799133\t▁ g u l u ▁ l a ▁ a m u n a ▁ l i k u y e n d a ▁ m u m s e w u ▁ w a k h a l a ▁ n d i p o ▁ n y a n j a ▁ y a c h i t s u l o ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y o f i i r a\n",
            "D-249\t-0.22531822323799133\tgulu la amuna likuyenda mumsewu wakhala ndipo nyanja yachitsulo kutsogolo kwa nyumba yofiira\n",
            "P-249\t-0.1071 -0.0524 -0.0851 -0.1445 -0.1218 -0.0913 -0.1304 -0.2340 -0.0846 -0.1447 -0.1873 -0.0169 -0.0554 -0.1121 -0.0969 -0.1887 -0.1110 -0.0996 -0.0924 -0.2623 -0.1243 -0.0469 -0.0300 -0.1213 -0.1278 -0.0196 -0.4255 -0.0738 -0.1233 -0.0602 -0.0307 -0.0436 -0.0735 -0.0098 -0.2416 -0.6848 -0.2733 -0.1297 -0.0772 -0.1265 -0.1008 -0.1786 -0.0578 -0.0907 -2.8413 -0.0943 -0.0981 -1.9444 -0.1975 -0.1970 -0.5201 -0.0502 -0.1110 -0.1317 -1.1858 -0.2835 -0.0340 -0.1025 -0.0528 -0.3809 -0.3340 -0.0568 -0.1811 -0.0231 -0.0905 -0.2131 -0.3579 -0.0854 -0.0532 -0.0642 -0.0212 -0.0678 -0.1372 -0.0742 -0.0824 -0.0065 -0.0227 -0.1212 -0.2902 -1.2577 -0.0202 -0.0227 -0.0426 -0.0251 -0.1141 -0.1445 -0.2830 -0.5165 -1.3820 -0.0494 -0.1364 -0.0255 -0.1547 -0.8078\n",
            "T-12\tbambo wina wovala magalasi wakhala kuseri kwa tebulo lodzaza ndi zinthu zokumbukira zankhondo\n",
            "H-12\t-0.3543744683265686\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ m a g a l a s i ▁ a k u s e w e r a ▁ t e b u l o ▁ l o t s a z a ▁ n d i ▁ z o g u l i t s a ▁ k u m b u y o ▁ k w a k e\n",
            "D-12\t-0.3543744683265686\tbambo wina wovala magalasi akusewera tebulo lotsaza ndi zogulitsa kumbuyo kwake\n",
            "P-12\t-0.0984 -1.0453 -0.0918 -0.0590 -0.0848 -0.0994 -0.1223 -0.1358 -0.0548 -0.0730 -0.0944 -0.1146 -0.0848 -0.1420 -0.3733 -0.1129 -0.0889 -0.1192 -0.1027 -0.2280 -0.1067 -0.4671 -0.6328 -0.0686 -0.1126 -0.0310 -0.0915 -0.0606 -1.2532 -0.1160 -0.1511 -0.1024 -0.0529 -0.2532 -0.0400 -0.0852 -0.7511 -0.1239 -3.0661 -0.5688 -0.3065 -0.0909 -0.2026 -0.1079 -0.1204 -1.6866 -0.1027 -1.7785 -0.1649 -0.2091 -1.2897 -0.1135 -0.0873 -0.5017 -0.1142 -0.0964 -0.1892 -0.2310 -0.2710 -1.1825 -0.2359 -0.9196 -0.0724 -0.3533 -0.4095 -0.6163 -0.1048 -1.7490 -0.3217 -0.2427 -0.1147 -0.2979 -0.0450 -0.2024 -0.1991 -0.4107 -0.4249 -0.1164 -1.1390 -0.1900 -0.2321\n",
            "T-107\tgulu lalikulu la amuna ovala zoyera likuwoneka kuti likugwira ntchito pa grill yamtundu wina\n",
            "H-107\t-0.21233992278575897\t▁ g u l u ▁ l a l i k u l u ▁ a m u n a ▁ o v a l a ▁ z o y e r a ▁ n d i k u w o n e k a ▁ k u t i ▁ a g w i r a ▁ n t c h i t o ▁ p a m p h e p e t e ▁ m w a ▁ n y u m b a\n",
            "D-107\t-0.21233992278575897\tgulu lalikulu amuna ovala zoyera ndikuwoneka kuti agwira ntchito pamphepete mwa nyumba\n",
            "P-107\t-0.1110 -0.0851 -0.1581 -0.0878 -0.0964 -0.1050 -0.0231 -0.0782 -0.1959 -0.0770 -0.0094 -0.0759 -0.0314 -0.0658 -0.1167 -1.3663 -0.8206 -0.1911 -0.0443 -0.1063 -0.1246 -0.2717 -0.1762 -0.1584 -0.0752 -0.1130 -0.1252 -0.0168 -0.0724 -0.0680 -0.0799 -0.0784 -0.1099 -0.1157 -0.6359 -0.2617 -0.0827 -0.5397 -0.0673 -0.5280 -0.0910 -0.1401 -0.0472 -0.0938 -0.0650 -0.0781 -0.5457 -0.0789 -0.6371 -0.2002 -0.1326 -2.2532 -0.3875 -0.1132 -0.1604 -0.1460 -0.2998 -0.1218 -0.1719 -0.0774 -0.0134 -0.0663 -0.0610 -0.0221 -0.0238 -0.1032 -0.0605 -0.1217 -0.7747 -0.6948 -0.2506 -0.0684 -0.0867 -0.0873 -0.1704 -0.1044 -0.0660 -0.0859 -0.6474 -0.1240 -0.2126 -0.6315 -0.0544 -0.3561 -0.1197 -0.0310 -0.0860 -0.1749\n",
            "T-175\tmunthu wovala chipewa chakuda jekete mathalauza ndi nsapato atakhala pamphepete mwa konkire kumbuyo kwa njerwa\n",
            "H-175\t-0.30603721737861633\t▁ m u n t h u ▁ w o v a l a ▁ c h i p e w a ▁ c h a k u d a ▁ n d i ▁ j a k e t e ▁ m a d z i ▁ a t a k h a l a ▁ p a n j a ▁ p a m p h e p e t e ▁ m w a ▁ k o m a n j i r a ▁ k u m b u y o ▁ k w a k e\n",
            "D-175\t-0.30603721737861633\tmunthu wovala chipewa chakuda ndi jakete madzi atakhala panja pamphepete mwa komanjira kumbuyo kwake\n",
            "P-175\t-0.1053 -0.0979 -0.0670 -0.0552 -0.0210 -0.0638 -0.0746 -0.1299 -0.0425 -0.0696 -0.0519 -0.1106 -0.0989 -0.1168 -0.1011 -0.2321 -0.0637 -0.0687 -0.2982 -0.0780 -0.0572 -0.1007 -0.1121 -0.0248 -0.0495 -0.0643 -0.1319 -0.0802 -0.1784 -0.8106 -0.1087 -1.8121 -0.2052 -0.1437 -0.0864 -1.4262 -0.9966 -1.2557 -0.2103 -0.0084 -0.5822 -0.0776 -1.1112 -0.4893 -0.4479 -0.0213 -0.0690 -0.1009 -0.8256 -0.2645 -0.0945 -0.5328 -0.0576 -0.1137 -0.0541 -0.1020 -0.0949 -0.0334 -0.1029 -1.3101 -1.3240 -0.1551 -0.2183 -0.2627 -0.1214 -1.1919 -0.3256 -0.8794 -0.0986 -0.0102 -0.0361 -0.0228 -0.4294 -0.0627 -0.6410 -0.0150 -0.1291 -0.0869 -1.9566 -0.5421 -0.8526 -0.4282 -0.6052 -1.0241 -0.2112 -0.0367 -0.0498 -0.2137 -0.0848 -0.3987 -0.5938 -0.0676 -0.0725 -0.0498 -0.0351 -0.2468 -0.0077 -0.0278 -0.1046 -0.9813 -0.1326 -0.1874\n",
            "T-331\tbambo amachita chinyengo pagalimoto yake yaying ono mwendo umodzi ukuwuluka kumwamba\n",
            "H-331\t-0.31209442019462585\t▁ b a m b o ▁ a m a c h i t a ▁ c h i n y e n g o ▁ p a ▁ g a l i m o t o ▁ y a i n g ▁ o n o ▁ y a i n g ▁ o n o ▁ y o z i m b i r a ▁ k u t s o g o l o ▁ k w a ▁ m w a m b a\n",
            "D-331\t-0.31209442019462585\tbambo amachita chinyengo pa galimoto yaing ono yaing ono yozimbira kutsogolo kwa mwamba\n",
            "P-331\t-0.1071 -0.0588 -0.2396 -0.0557 -0.0425 -0.0936 -0.1062 -0.6701 -1.0014 -0.1190 -1.0261 -0.0881 -0.1971 -0.0120 -0.2170 -0.1021 -0.6508 -0.0623 -0.0602 -0.4114 -0.0516 -0.1093 -0.0392 -0.0694 -0.0316 -0.1308 -0.0649 -0.1130 -1.6567 -0.3492 -0.1319 -0.0599 -0.0443 -0.0477 -0.0593 -0.1010 -0.0564 -0.1275 -0.0187 -0.1495 -1.9889 -0.7692 -0.7030 -0.1141 -0.1192 -0.0525 -0.0522 -0.1715 -1.3136 -0.3107 -0.5725 -0.7269 -0.4059 -0.0769 -0.1347 -0.1251 -0.0776 -0.1969 -0.8195 -0.0506 -0.1415 -0.1647 -0.2413 -1.5405 -0.2187 -0.3449 -0.2389 -0.1244 -0.2504 -0.3393 -2.4148 -0.9634 -0.5454 -0.0119 -0.2391 -0.1585 -0.1543 -0.1573 -0.0311 -0.2144 -0.1023 -0.2060 -0.3237 -0.4028 -0.1063 -0.3572 -0.0538 -0.1003 -0.1144\n",
            "T-122\twoyimba gitala ali pa siteji akukweza mkono wake n kukweza manja kwa oonerera\n",
            "H-122\t-0.3708295524120331\t▁ w o y i m b a ▁ n d i ▁ t h a l a u z a ▁ l a ▁ s i t e j i ▁ a k u k w e z a ▁ m w a m u n a ▁ k u k w e z a ▁ m a n j a ▁ k w a ▁ o n e r e r a\n",
            "D-122\t-0.3708295524120331\twoyimba ndi thalauza la siteji akukweza mwamuna kukweza manja kwa onerera\n",
            "P-122\t-0.0985 -0.1261 -0.1033 -0.5112 -0.5215 -0.1811 -0.0208 -0.1858 -0.0965 -0.2253 -0.1317 -0.0906 -0.0977 -0.5461 -1.2319 -0.1043 -0.1897 -0.1113 -0.7948 -0.5238 -0.0918 -0.0942 -0.4329 -0.9226 -0.8585 -0.9680 -0.2995 -0.4333 -0.7249 -0.3098 -0.0432 -0.1136 -0.1782 -0.0734 -0.1901 -0.2069 -1.4544 -0.0509 -0.0404 -0.1040 -0.1251 -0.1475 -0.3648 -0.1459 -0.7469 -1.5975 -0.0594 -0.1725 -0.1355 -0.6624 -0.4366 -0.4236 -0.5037 -0.1151 -0.0606 -0.1047 -0.1117 -0.7393 -0.2086 -0.0124 -0.0536 -0.1052 -0.0975 -1.5754 -0.1537 -0.1382 -0.1187 -1.1142 -1.1239 -1.0290 -0.0519 -1.1971 -0.0736 -0.1067 -0.5170\n",
            "T-184\tmtsikana wina amene wavala bulawuzi wonyezimira akusonyeza kamtsikana zomera zomwe zakhala pa shelufu\n",
            "H-184\t-0.2982896864414215\t▁ m t s i k a n a ▁ w i n a ▁ w a ▁ b l o n d ▁ w a v a l a ▁ b u l a u z i ▁ w o n y e z i m i r a ▁ a k u s e w e r a ▁ p a n s i ▁ p a ▁ m t s i k a n a ▁ z o m w e ▁ z a c h i k a s u\n",
            "D-184\t-0.2982896864414215\tmtsikana wina wa blond wavala bulauzi wonyezimira akusewera pansi pa mtsikana zomwe zachikasu\n",
            "P-184\t-0.1257 -0.1315 -0.0561 -0.0497 -0.0417 -0.0326 -0.1182 -0.0703 -0.1281 -0.1071 -0.0696 -0.0750 -0.0928 -0.1248 -0.1090 -0.0990 -0.4472 -1.1349 -1.8216 -1.3845 -0.2107 -0.0866 -0.1080 -0.2120 -0.1819 -0.1671 -0.8597 -0.1199 -0.0784 -0.1313 -0.1324 -1.3042 -0.1031 -0.1739 -0.1627 -0.4084 -0.7331 -0.0731 -0.1245 -0.2077 -0.1357 -0.4182 -0.3511 -0.1108 -0.0930 -0.0280 -0.0774 -0.0549 -0.1001 -0.2348 -0.0915 -0.5903 -0.0434 -0.1170 -0.1109 -2.2879 -0.1969 -0.0812 -0.0938 -0.2139 -0.0925 -0.1526 -0.1684 -0.5210 -0.1210 -0.0553 -0.1078 -0.4633 -0.1713 -0.2874 -0.9598 -1.1110 -0.1695 -0.0308 -0.0126 -0.1314 -0.0641 -0.1261 -0.1536 -0.7456 -0.0270 -0.1489 -0.0785 -0.1917 -0.0916 -0.2633 -1.5317 -1.0884 -0.1148 -0.1656 -0.1442 -0.1697 -0.1023 -0.1671 -1.1784\n",
            "T-83\tmwana wamng ono akuthamanga m chithaphwi chachikulu m mphepete mwa nyanja mozunguliridwa ndi mitengo\n",
            "H-83\t-0.26142072677612305\t▁ m w a n a ▁ w a m n g ▁ o n o ▁ a k u t h a m a n g a ▁ p i n k i ▁ c h a c h i k u l u ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ n d i ▁ p a n j i r a\n",
            "D-83\t-0.26142072677612305\tmwana wamng ono akuthamanga pinki chachikulu m mphepete mwa nyanja ndi panjira\n",
            "P-83\t-0.1082 -0.1373 -0.1842 -0.1442 -0.0733 -0.0983 -0.1246 -0.1390 -0.1410 -0.5904 -0.0897 -0.0820 -0.0856 -0.0789 -0.0600 -0.0574 -0.1393 -0.4345 -0.2015 -0.0852 -0.0766 -0.0238 -0.1328 -0.0573 -0.0911 -0.0422 -0.0179 -0.1579 -0.0713 -1.9659 -1.8002 -0.2842 -0.4942 -0.1255 -0.1313 -0.1094 -0.0638 -0.1771 -0.6004 -0.0728 -0.0567 -0.2184 -0.0557 -0.0188 -0.1356 -0.1459 -1.8408 -0.0987 -0.5676 -0.0631 -0.1031 -0.0212 -0.0370 -0.0273 -0.0064 -0.0222 -0.0779 -0.0497 -0.0230 -0.1681 -0.1014 -0.0532 -0.0112 -0.1116 -0.5066 -0.0313 -0.0929 -0.1058 -0.4654 -0.1417 -0.0888 -0.2908 -2.0639 -0.3166 -0.4955 -0.6243 -0.2925 -0.4835 -0.0589 -1.2904\n",
            "T-195\tmunthu wovala zovala zofiira ndi zakuda akukwera m mbali mwa phiri lozizira kwambiri\n",
            "H-195\t-0.18829388916492462\t▁ m u n t h u ▁ w o v a l a ▁ z o v a l a ▁ z o f i i r a ▁ n d i ▁ z a k u d a ▁ a k u k w e r a ▁ m ▁ m b a l i ▁ m w a ▁ p h i r i ▁ l o s i y a ▁ k w a m b i r i\n",
            "D-195\t-0.18829388916492462\tmunthu wovala zovala zofiira ndi zakuda akukwera m mbali mwa phiri losiya kwambiri\n",
            "P-195\t-0.1194 -0.0730 -0.0968 -0.0593 -0.0289 -0.0724 -0.0934 -0.1281 -0.0486 -0.1162 -0.0559 -0.1306 -0.0822 -0.1282 -0.1145 -0.0275 -0.1203 -0.0525 -0.0923 -0.0710 -0.1209 -0.1083 -0.0062 -0.1958 -0.1452 -0.0448 -0.0731 -0.0554 -0.1710 -0.0948 -0.0729 -0.0761 -0.0798 -0.1075 -0.1729 -0.1426 -0.4399 -0.1242 -0.2074 -0.1476 -0.0984 -0.1519 -0.0239 -0.1457 -0.3696 -0.0443 -0.0420 -0.0590 -0.1043 -0.1112 -0.7754 -0.7065 -0.1555 -0.7103 -0.0950 -0.0572 -0.1044 -0.1160 -0.1106 -0.1005 -0.1321 -0.1057 -0.8947 -1.3489 -0.0629 -0.0759 -0.0658 -0.1281 -0.3705 -0.0443 -0.6636 -0.0688 -0.6839 -0.1103 -0.3123 -0.1267 -1.2431 -0.1215 -0.0860 -0.0662 -0.0890 -0.0168 -0.2213 -0.3993\n",
            "T-265\tgalu wakuda ndi galu wonyezimira amalimbana mu udzu wouma pafupi ndi madzi ambiri\n",
            "H-265\t-0.2846747636795044\t▁ g a l u ▁ w a k u d a ▁ n d i ▁ g a l u ▁ w o n y e z i m i r a ▁ a m a y i m b a ▁ m u z u n g u l i d w a ▁ p a f u p i ▁ n d i ▁ m a d z i ▁ a m b i r i\n",
            "D-265\t-0.2846747636795044\tgalu wakuda ndi galu wonyezimira amayimba muzungulidwa pafupi ndi madzi ambiri\n",
            "P-265\t-0.1130 -0.0121 -0.1068 -0.0379 -0.0837 -0.0972 -0.1106 -0.1256 -0.0889 -0.1103 -0.0365 -0.1655 -0.1199 -0.1145 -0.1017 -0.1024 -0.0699 -0.4138 -0.0873 -0.0615 -0.0517 -0.1127 -0.0172 -1.7583 -1.7329 -0.0593 -0.0765 -0.0194 -0.0303 -0.2134 -0.0288 -0.0834 -0.1795 -0.1159 -0.1100 -0.6712 -0.1247 -2.1530 -0.4859 -0.1578 -0.6401 -0.1529 -0.3204 -0.5392 -0.4895 -1.1950 -0.0676 -1.0401 -0.0756 -0.0698 -0.2966 -0.7448 -1.8581 -0.1852 -0.1400 -0.1138 -0.3297 -0.5967 -0.3691 -0.0527 -0.0834 -0.0469 -0.1037 -0.0300 -0.0697 -0.1165 -0.0858 -0.2297 -0.0849 -0.2710 -0.0483 -0.0600 -0.3885 -0.4148 -0.5562 -0.2142 -0.1074 -0.0401 -0.0568 -0.1484\n",
            "T-154\twachichepere akuyang ana paphewa lake pamene akuthamanga kumbuyo kuli mitengo ndi kasupe wamadzi\n",
            "H-154\t-0.3825601041316986\t▁ w o c h i t i t a ▁ y e k u ▁ a k u y a n g ▁ a n a ▁ p a p e w a ▁ a t a k h a l a ▁ p a m e n e ▁ m a n j a ▁ k u m b u y o ▁ k u m b u y o ▁ n d i ▁ g a l a s i ▁ l a ▁ m a d z i\n",
            "D-154\t-0.3825601041316986\twochitita yeku akuyang ana papewa atakhala pamene manja kumbuyo kumbuyo ndi galasi la madzi\n",
            "P-154\t-0.1023 -0.1460 -0.2598 -0.5172 -0.0921 -1.2068 -0.0212 -0.6904 -0.4995 -2.1279 -0.1536 -1.2746 -0.4585 -0.3040 -1.2016 -0.5421 -0.7848 -0.4689 -0.0916 -0.0313 -0.1653 -0.0465 -0.1032 -0.0955 -0.0979 -0.0449 -0.1261 -0.0923 -0.0314 -0.1386 -1.7879 -0.8009 -0.4787 -0.1291 -0.1216 -0.3580 -0.2493 -1.0091 -1.1833 -0.8460 -0.3779 -0.0618 -0.0985 -0.0962 -0.1192 -0.1075 -0.1513 -0.3584 -0.0312 -0.0663 -0.0702 -1.0918 -0.3843 -0.7664 -1.1181 -0.1088 -0.0806 -0.7135 -0.1078 -0.1987 -0.0200 -0.1133 -0.0277 -0.0449 -0.0916 -0.2649 -0.7051 -0.9570 -0.0590 -0.1361 -0.0502 -0.0607 -0.1008 -0.7822 -0.0503 -0.1224 -0.1130 -1.6546 -0.1744 -0.1839 -0.9675 -0.0260 -0.2173 -0.3307 -0.1795 -0.2493 -1.0410 -0.5157 -0.0552 -0.9361 -0.1334 -0.1378 -0.0885\n",
            "T-199\tmwamuna wovala zovala za chipale chofewa ndi chisoti akuyendetsa galimoto ya chipale chofewa m chipale chofewa\n",
            "H-199\t-0.20774854719638824\t▁ m w a n a ▁ w o v a l a ▁ z o v a l a ▁ z a c h i p a l e ▁ c h o f e w a ▁ n d i ▁ c h i s o t i ▁ c h a k u d y e t s a ▁ g a l i m o t o ▁ y a c h i p a l e ▁ c h o f e w a ▁ m ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-199\t-0.20774854719638824\tmwana wovala zovala zachipale chofewa ndi chisoti chakudyetsa galimoto yachipale chofewa m chipale chofewa\n",
            "P-199\t-0.1135 -0.0435 -0.1692 -0.1451 -0.3450 -0.1003 -0.1261 -0.0699 -0.0569 -0.1133 -0.1237 -0.0919 -0.1174 -0.1092 -0.0807 -0.0592 -0.0322 -0.1004 -0.0915 -0.1155 -0.1049 -0.0252 -1.6914 -0.4904 -0.0755 -0.0537 -0.5872 -0.4358 -0.1026 -0.0430 -0.0703 -0.0880 -0.0803 -0.0369 -0.0465 -0.2255 -0.0363 -0.1031 -0.1650 -0.1691 -0.1467 -0.1143 -0.1091 -0.4010 -0.1051 -0.0962 -1.0527 -0.2304 -0.0092 -0.0489 -0.1047 -0.4394 -0.0773 -0.2273 -0.1547 -0.1101 -0.2415 -0.4567 -0.3663 -0.1445 -0.0381 -0.0879 -0.0869 -2.0681 -0.5172 -0.0642 -0.0497 -0.1202 -0.0163 -0.0083 -0.0588 -0.0975 -0.0027 -0.1679 -0.2642 -0.0502 -0.0404 -2.0498 -0.0974 -0.1015 -0.0478 -0.0546 -0.0877 -0.0705 -0.0337 -0.0118 -0.0372 -0.0300 -0.0890 -0.1997 -2.1711 -0.7031 -0.2363 -0.0888 -0.1171 -0.0068 -0.1519 -0.1025 -0.0524 -0.0928 -0.0097 -0.0993 -0.0384 -0.0601 -0.0396 -0.0585 -0.1053 -0.1824\n",
            " 62% 8/13 [00:18<00:09,  1.85s/it, wps=1318]T-340\tchonyamulira chopanda kanthu komanso chonyamulira chomwe chili ndi anthu awiri chikusuntha\n",
            "H-340\t-0.31851840019226074\t▁ c h i n y a m a t a ▁ c h o v a l a ▁ c h o v a l a ▁ n d i ▁ k o m a n s o ▁ c h o y i r a ▁ c h o m w e ▁ c h i l i ▁ n d i ▁ c h i k w a n g w a n i\n",
            "D-340\t-0.31851840019226074\tchinyamata chovala chovala ndi komanso choyira chomwe chili ndi chikwangwani\n",
            "P-340\t-0.1156 -0.2301 -0.0731 -0.2625 -1.0547 -0.0762 -0.0957 -0.0719 -0.0880 -0.0965 -0.0848 -0.1417 -0.0901 -0.0992 -0.0428 -1.0855 -0.1128 -0.0989 -0.1200 -0.1161 -0.4719 -0.0715 -0.1257 -2.3608 -0.1008 -0.1488 -0.1288 -0.1269 -0.3294 -0.0945 -0.1276 -0.4813 -1.1820 -0.1997 -0.2991 -0.0814 -0.1423 -0.0203 -0.2115 -0.0801 -0.4859 -0.0549 -1.9522 -0.7155 -1.4194 -0.7653 -0.2113 -0.1315 -0.0368 -0.0568 -0.1959 -0.1166 -0.4817 -0.2835 -0.1084 -0.2285 -0.0754 -0.0656 -0.2390 -0.0761 -0.1246 -0.0241 -0.0422 -0.0840 -0.1122 -0.8015 -0.0939 -0.1862 -0.2721 -0.6957 -0.2064 -0.7697 -0.1181 -0.0359 -0.5300 -0.6964 -0.0597 -1.3506\n",
            "T-238\tmwamuna wovala suti yakuda atakhala ndi mkazi watsitsi lakuda atavala jekete labuluu padoko\n",
            "H-238\t-0.19822393357753754\t▁ m w a m u n a ▁ w o v a l a ▁ s u t i ▁ y a k u d a ▁ a t a k h a l a ▁ n d i ▁ m k a z i ▁ w a t s i t s i ▁ y a k u d a ▁ a t a v a l a ▁ j e k e t e ▁ y a ▁ b u l u u\n",
            "D-238\t-0.19822393357753754\tmwamuna wovala suti yakuda atakhala ndi mkazi watsitsi yakuda atavala jekete ya buluu\n",
            "P-238\t-0.1190 -0.0557 -0.0215 -0.1226 -0.1878 -0.0857 -0.0819 -0.1093 -0.1293 -0.0531 -0.0979 -0.5260 -0.1492 -0.1057 -0.1152 -0.1085 -1.0815 -0.0372 -0.0642 -0.2200 -0.0908 -0.0985 -0.0955 -0.1073 -0.0730 -0.0596 -0.1105 -0.1369 -0.2126 -1.1162 -0.0879 -0.7093 -0.1084 -0.0907 -0.0490 -0.0987 -0.1175 -0.3093 -0.0769 -0.0899 -0.1041 -0.0249 -0.1347 -0.1198 -0.0612 -0.0510 -0.0994 -0.0291 -0.1483 -1.1137 -0.0358 -0.0471 -0.0240 -0.0365 -0.0524 -0.0637 -1.1544 -0.1026 -0.0908 -0.1049 -0.0385 -0.1186 -0.1233 -0.1701 -0.1358 -0.0846 -0.0479 -0.1188 -0.1279 -0.1087 -0.0841 -0.3216 -0.2523 -0.2331 -0.0834 -0.0138 -0.0985 -0.0994 -0.7034 -0.0997 -1.1033 -0.5919 -0.4469 -0.0849 -0.0664 -0.3282 -0.6520\n",
            "T-146\tbanja likugwirana chanza ndipo mayi wina waimirira pambali pawo akujambula mumsewu wafumbi\n",
            "H-146\t-0.33965739607810974\t▁ m n y a m a t a ▁ a k u k w e r a ▁ c h i n a c h a k e ▁ n d i p o ▁ m a y i ▁ w i n a ▁ w a i m i r i r a ▁ p a m a l o ▁ o k u t i r a ▁ m u m s e w u ▁ w a ▁ m t s i n j e ▁ u d z u\n",
            "D-146\t-0.33965739607810974\tmnyamata akukwera chinachake ndipo mayi wina waimirira pamalo okutira mumsewu wa mtsinje udzu\n",
            "P-146\t-0.0991 -2.4263 -0.3771 -0.3092 -0.1245 -0.1727 -0.0957 -0.0701 -0.0941 -0.1131 -0.4631 -0.0327 -0.0906 -1.2847 -0.3586 -0.1861 -0.0461 -0.1018 -0.1030 -1.0647 -0.0440 -0.9673 -0.1305 -0.2818 -0.5210 -0.0659 -0.0800 -0.3691 -0.1198 -0.1135 -0.4589 -0.0792 -0.0949 -0.1389 -0.0477 -0.1815 -0.0842 -0.4869 -0.2535 -0.0614 -0.0871 -0.0323 -0.1227 -0.0620 -0.1582 -0.1564 -0.1414 -0.1267 -0.2180 -0.0483 -0.3851 -0.0671 -0.0644 -0.0187 -0.0900 -0.0886 -0.0790 -0.1287 -0.5573 -1.6707 -0.2371 -0.1578 -0.0655 -0.1279 -1.9834 -0.3605 -0.6452 -1.0736 -0.2818 -0.0956 -0.3213 -0.0744 -0.8063 -0.1225 -0.0792 -0.1905 -0.0619 -0.0181 -0.0922 -0.4317 -0.7085 -1.1678 -0.4085 -1.7458 -0.2584 -0.1209 -0.5188 -0.1335 -0.0756 -0.3715 -2.3402 -0.1399 -0.0230 -0.0784 -0.4542\n",
            "T-278\tmunthu wovala skis amakhalanso ndi paragliding yokhala ndi parachuti yofiira\n",
            "H-278\t-0.34971606731414795\t▁ m u n t h u ▁ w o v a l a ▁ t ▁ s h i r t ▁ a m a k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a ▁ a l i ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-278\t-0.34971606731414795\tmunthu wovala t shirt amakhala ndi chipale chofewa ali ndi chipale chofewa\n",
            "P-278\t-0.1051 -0.1000 -0.0618 -0.0647 -0.0277 -0.0470 -0.0819 -0.1346 -0.0857 -0.0688 -0.1040 -0.1046 -0.0864 -0.1073 -0.1040 -3.4250 -0.2232 -0.1082 -0.0787 -0.1664 -0.0342 -0.0212 -0.1642 -0.7100 -0.4465 -0.1478 -0.3756 -0.0749 -0.1076 -0.4349 -0.0973 -0.1135 -0.2465 -0.0888 -0.1111 -0.2370 -2.4672 -0.1193 -0.4196 -0.1700 -2.4962 -0.1157 -0.1416 -0.0466 -0.4850 -0.1258 -0.1308 -0.1524 -0.2912 -0.0485 -0.1010 -0.1925 -1.7094 -1.5487 -0.2068 -0.1098 -0.8382 -0.2250 -0.0880 -0.1231 -2.9087 -0.1347 -0.1510 -0.1678 -0.6170 -0.1886 -0.1207 -0.2025 -0.1524 -0.1184 -0.0261 -0.0053 -0.5696 -0.0503 -0.0758 -0.0405\n",
            "T-3\twokwera njingayo akugwira panjinga yake ali mumlengalenga ndi phiri kumbuyo kwake\n",
            "H-3\t-0.24413157999515533\t▁ w o k w e r a ▁ n j i n g a y o ▁ a k u g w i r a ▁ p a n j i n g a ▁ y a k e ▁ a t a n y a m u l a ▁ n d i ▁ m p i r a ▁ k u m b u y o ▁ k w a k e\n",
            "D-3\t-0.24413157999515533\twokwera njingayo akugwira panjinga yake atanyamula ndi mpira kumbuyo kwake\n",
            "P-3\t-0.1221 -0.1261 -0.0654 -0.0419 -0.0206 -0.0821 -0.0720 -0.0907 -0.1124 -1.7890 -0.0989 -0.0384 -0.0532 -0.4489 -0.1055 -1.9015 -0.0491 -0.1024 -0.1297 -0.0402 -0.1015 -0.0918 -0.0729 -0.1533 -0.0764 -0.1117 -0.1334 -0.4989 -0.1579 -0.2829 -0.1618 -0.0559 -0.1600 -0.0558 -0.1187 -0.1624 -0.0387 -0.1739 -0.3513 -0.0511 -0.0979 -0.4153 -0.7421 -0.1137 -0.8514 -0.0547 -0.3180 -0.1194 -0.0849 -0.1319 -0.1373 -0.1050 -0.9783 -0.1628 -0.1004 -0.1060 -0.5688 -1.0693 -0.0731 -0.0342 -0.2227 -0.2021 -1.4520 -0.0857 -0.5027 -0.1526 -0.0579 -0.0195 -0.0352 -0.3467 -0.0302 -0.1036 -0.0901 -0.3408 -0.0810 -0.0662\n",
            "T-14\tgalu wakuda akuthamanga kumbuyo kwa mbalame zitatu pamphepete mwa nyanja ndi mafunde kumbuyo\n",
            "H-14\t-0.27500665187835693\t▁ g a l u ▁ w a k u d a ▁ a k u t h a m a n g a ▁ k u m b u y o ▁ m ▁ m a d z i ▁ a t a t u ▁ p a m e n e ▁ m n y a n j a ▁ n d i ▁ m a f u n d e ▁ k u m b u y o\n",
            "D-14\t-0.27500665187835693\tgalu wakuda akuthamanga kumbuyo m madzi atatu pamene mnyanja ndi mafunde kumbuyo\n",
            "P-14\t-0.1155 -0.1314 -0.1178 -0.1114 -0.0737 -0.0959 -0.5474 -0.1304 -0.0196 -0.0921 -0.2438 -0.0963 -0.1160 -1.1382 -0.3229 -0.1215 -0.3820 -0.0859 -0.0824 -0.0482 -0.1529 -0.0595 -0.0486 -0.1212 -0.1042 -0.9518 -0.2037 -0.1102 -0.0481 -0.6836 -0.0132 -0.0698 -0.0931 -0.5291 -0.5267 -0.5907 -2.5674 -0.2206 -0.2371 -0.0596 -0.1358 -1.0201 -0.1380 -0.2817 -0.4813 -0.0936 -0.1161 -0.0307 -0.1041 -0.2152 -0.7569 -0.1050 -0.0611 -0.1004 -0.1008 -0.9161 -0.8221 -0.1149 -0.3018 -0.0338 -0.0891 -0.1489 -0.0441 -0.0631 -0.0836 -0.1360 -0.0440 -0.0481 -1.4164 -0.0403 -0.2206 -0.0323 -0.0106 -0.3875 -1.2450 -0.0303 -0.0511 -0.0146 -0.0334 -0.0490 -0.0613 -0.9081\n",
            "T-174\tkamtsikana kaimilira kumpanda uku akusuzumira mkati mwa kavaloyo\n",
            "H-174\t-0.37490230798721313\t▁ k a m t s i k a n a ▁ k a i m i r i r a ▁ k u t h a m a n g a ▁ k u t s o g o l e r a ▁ c h i n a c h a k e ▁ p a b w a l o\n",
            "D-174\t-0.37490230798721313\tkamtsikana kaimirira kuthamanga kutsogolera chinachake pabwalo\n",
            "P-174\t-0.1254 -0.8674 -0.1189 -0.0511 -0.0198 -0.0738 -0.0507 -0.0255 -0.1508 -0.1089 -0.1148 -0.1530 -0.2099 -0.1511 -0.7965 -0.1272 -0.0816 -0.1650 -0.0398 -0.0446 -0.1210 -0.1283 -0.2796 -0.3487 -2.3041 -0.5249 -0.1399 -0.9728 -0.1928 -0.0336 -0.1047 -0.9073 -0.0887 -1.3429 -0.1129 -0.5316 -0.0419 -1.3676 -0.1028 -0.3601 -0.1246 -1.3470 -0.0868 -0.4109 -0.2392 -1.1902 -0.0690 -0.0526 -0.4231 -0.2490 -0.5635 -0.0526 -0.0745 -0.1313 -0.7848 -0.3725 -0.9617 -0.1269 -2.1246 -0.1118 -0.1657 -0.0542 -0.0838 -0.7114\n",
            "T-234\tbambo wina wovala malaya amizeremizere yabuluu akudikirira chakudya chimene waitanitsa\n",
            "H-234\t-0.25201383233070374\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a ▁ b u l u u ▁ a k u d u m p h i r a ▁ n d i ▁ c h i d a ▁ c h a k u d y a ▁ c h i m e n e ▁ c h a t a n y i z a\n",
            "D-234\t-0.25201383233070374\tbambo wina wovala malaya amizeremizere ya buluu akudumphira ndi chida chakudya chimene chatanyiza\n",
            "P-234\t-0.1168 -0.0175 -0.1060 -0.0596 -0.0792 -0.0886 -0.1098 -0.0611 -0.0563 -0.0710 -0.1269 -0.1030 -0.0588 -0.0857 -0.0444 -0.1230 -0.1034 -0.1251 -0.0960 -0.0919 -0.1198 -0.0617 -0.1269 -0.0697 -0.1238 -0.0859 -0.1587 -0.2389 -0.0400 -0.0512 -0.0570 -0.0322 -0.0490 -0.0769 -0.0127 -0.0359 -0.0715 -0.0382 -0.0446 -0.1515 -0.0682 -0.0844 -0.5072 -0.0858 -0.1203 -0.0364 -0.0305 -0.0147 -0.0695 -0.1993 -0.1552 -0.1129 -0.6466 -0.0431 -0.2034 -0.0714 -0.0145 -0.2099 -1.0418 -0.1386 -0.1142 -1.0158 -0.4049 -0.1423 -0.1682 -0.1782 -0.0532 -0.0999 -1.0848 -0.5405 -0.1271 -0.1671 -0.0598 -0.1331 -0.3346 -0.0774 -0.0848 -0.9772 -0.0962 -0.1368 -0.0559 -0.0496 -0.6186 -1.0428 -0.2185 -0.0822 -0.2263 -0.0680 -2.3234 -0.0852 -0.3574 -2.2823 -0.1800 -0.6635 -0.8817 -0.9026 -0.8994 -0.2013 -0.5910\n",
            "T-116\tkhamu la anthu ovala nyengo yofunda likuima pamzere kutsogolo kwa nyumba kudikirira chinachake\n",
            "H-116\t-0.27976998686790466\t▁ a m u n a ▁ a t a t u ▁ o v a l a ▁ y u n i f o l o m u ▁ n d i k u y e n d a ▁ p a m z e r a ▁ k u t s o g o l o ▁ k w a ▁ n t c h i t o ▁ y a ▁ c h i n a c h a k e\n",
            "D-116\t-0.27976998686790466\tamuna atatu ovala yunifolomu ndikuyenda pamzera kutsogolo kwa ntchito ya chinachake\n",
            "P-116\t-0.1144 -0.4162 -0.1966 -0.0585 -0.0602 -0.0966 -0.1167 -0.1452 -1.7959 -0.0830 -0.1877 -0.0458 -0.0715 -0.0263 -0.1755 -0.1151 -0.0905 -0.1053 -0.1139 -1.6482 -0.0598 -0.0184 -0.0982 -0.0510 -0.0866 -0.1980 -0.1325 -0.0397 -0.1077 -0.1135 -0.3963 -0.0887 -0.6340 -2.1975 -0.1707 -0.0832 -0.6927 -0.3205 -0.0930 -0.1264 -0.1429 -0.1189 -0.1450 -1.4765 -0.0642 -0.1311 -0.0725 -1.8291 -0.1136 -0.3302 -0.2358 -0.3087 -0.0404 -0.0291 -0.0065 -0.0714 -0.0480 -0.0505 -0.0926 -0.0369 -0.0113 -0.1320 -0.0947 -0.1715 -1.2309 -0.5792 -0.0498 -0.0806 -0.0724 -0.0638 -0.1426 -1.8936 -0.2361 -0.6887 -0.3546 -0.0750 -0.0780 -0.2081 -0.2806 -0.1338 -0.0671 -0.1274 -0.0608 -0.0581 -0.1743\n",
            "T-220\tgulu la anthu lili pansi ndi manja ndi mawondo kupanga chinachake pansi\n",
            "H-220\t-0.4196147322654724\t▁ g a l u ▁ a t a t u ▁ a l i ▁ p a ▁ c h i p a l e ▁ c h o f i i r a ▁ n d i ▁ m a u t u ▁ a k u t h a m a n g a ▁ c h i n a c h a k e\n",
            "D-220\t-0.4196147322654724\tgalu atatu ali pa chipale chofiira ndi mautu akuthamanga chinachake\n",
            "P-220\t-0.1232 -0.3426 -0.1373 -0.0862 -0.1312 -0.1060 -0.6136 -1.8253 -0.1176 -0.7252 -0.0363 -0.0996 -0.6997 -0.4221 -0.2349 -0.1307 -0.1590 -0.1421 -1.0170 -0.5060 -0.0869 -0.1238 -0.2325 -0.3071 -1.6740 -0.8595 -0.0763 -0.1241 -0.0763 -0.7273 -1.0497 -1.2186 -0.6137 -0.1139 -0.1577 -0.1156 -0.0834 -0.0731 -0.1012 -0.2106 -0.0790 -0.1102 -2.3724 -0.6800 -0.4291 -0.0688 -0.8070 -1.5656 -0.0853 -1.4484 -0.1040 -0.2908 -0.7538 -0.1214 -0.0449 -0.1694 -0.1120 -0.0823 -1.5234 -0.0712 -0.1328 -0.5547 -0.1880 -0.6219 -0.0646 -0.0808 -0.3274 -0.0299 -0.3535\n",
            "T-33\tma brunettes awiri m modzi ali ndi ma tattoo kukumbatirana ndi kumwetulira pa kamera m nyumba\n",
            "H-33\t-0.34686508774757385\t▁ m w a m u n a ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ j e a n s ▁ a t a t u ▁ a k u k a m b i r a n a ▁ n d i ▁ k u m e t u l i r a ▁ p a m e n e ▁ a k u y a n g ▁ a n a\n",
            "D-33\t-0.34686508774757385\tmwamuna wina yemwe wavala jeans atatu akukambirana ndi kumetulira pamene akuyang ana\n",
            "P-33\t-0.1100 -0.1994 -0.7502 -0.0879 -0.0435 -0.0654 -0.0939 -0.1822 -0.1219 -0.5773 -0.5075 -0.2085 -0.1410 -0.1148 -3.5787 -0.0504 -0.0367 -0.1158 -0.0869 -0.1009 -0.4829 -0.1236 -1.2199 -0.1283 -0.1338 -0.0960 -0.1298 -0.3361 -0.5323 -0.5744 -0.0275 -0.3931 -0.0887 -1.1218 -0.1662 -0.1308 -0.2576 -0.2395 -0.1308 -1.9987 -0.0831 -0.1227 -0.5499 -1.2200 -0.2853 -0.0645 -0.0439 -0.1925 -0.1061 -0.0225 -0.1217 -0.1441 -0.3268 -0.6169 -0.0874 -1.1892 -0.3341 -0.3657 -1.6303 -0.0798 -0.6745 -0.2588 -0.1640 -0.0395 -0.0644 -0.1006 -0.1809 -0.3128 -0.1567 -0.7657 -0.0869 -0.0591 -0.0456 -0.1893 -0.3903 -0.7973 -0.1258 -0.1322 -0.0884 -0.0585 -0.4267 -0.2203 -0.0955 -0.1426 -1.1122 -0.0705\n",
            "T-325\tapolisi anayi kapena apolisi akujambula chithunzi pomwe awiri a iwo akukumbatirana\n",
            "H-325\t-0.43543267250061035\t▁ a p o l i s i ▁ a n a y i ▁ a t a y i m i r a ▁ a k u g w i r a ▁ n t c h i t o ▁ y a k u d a ▁ n d i p o ▁ m z i n d a ▁ w o m w e ▁ a l i ▁ n d i ▁ m a i k o l o f o n i ▁ a k u g w i r a ▁ n t c h i t o\n",
            "D-325\t-0.43543267250061035\tapolisi anayi atayimira akugwira ntchito yakuda ndipo mzinda womwe ali ndi maikolofoni akugwira ntchito\n",
            "P-325\t-0.1032 -0.2669 -3.7923 -0.0744 -0.3665 -0.0642 -0.0974 -0.0378 -0.1282 -0.1359 -0.2308 -0.0809 -0.1961 -0.0517 -0.0961 -0.1261 -0.0826 -0.1112 -1.0091 -0.2507 -0.2562 -2.1123 -0.5379 -0.9631 -0.1040 -0.3465 -0.3438 -0.1782 -1.5869 -0.7016 -0.0785 -0.2083 -0.2508 -0.1047 -1.7203 -0.1181 -0.2997 -0.1777 -0.0718 -0.0549 -0.1648 -0.1043 -1.4414 -0.1329 -1.2032 -0.1950 -0.1737 -0.2326 -0.1171 -0.7724 -0.2893 -0.1017 -1.6931 -0.0919 -0.0994 -0.2510 -0.9478 -0.1057 -0.4043 -0.1565 -0.4630 -0.5833 -0.1870 -0.3055 -0.3892 -0.1569 -0.2965 -0.1232 -0.4204 -0.3085 -0.1148 -0.1545 -1.1658 -0.1321 -0.1308 -0.1374 -1.9221 -0.8546 -2.1567 -0.1149 -0.5998 -0.4454 -0.0693 -0.8710 -0.1280 -0.2497 -0.0946 -0.3471 -0.5691 -0.2949 -0.1100 -1.9941 -0.2264 -0.3264 -0.0341 -0.1454 -0.6416 -0.4800 -0.9042 -0.1207 -0.1110 -0.0686 -0.0818 -0.2467 -0.2480\n",
            "T-54\tmayi wina wovala thalauza lofiira komanso malaya abuluu wotuwa akukwera panjinga yake kudutsa mlatho\n",
            "H-54\t-0.25236210227012634\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ t h a l a u z a ▁ l o f i i r a ▁ k o m a n s o ▁ m a l a y a ▁ a b u l u u ▁ n d i p o ▁ w a k u d a ▁ a k u k w e r a ▁ p a n j i n g a ▁ y a m a t a b w a\n",
            "D-54\t-0.25236210227012634\tmayi wina wovala thalauza lofiira komanso malaya abuluu ndipo wakuda akukwera panjinga yamatabwa\n",
            "P-54\t-0.1076 -0.0737 -0.0815 -0.0414 -0.0997 -0.0838 -0.0320 -0.0602 -0.0520 -0.1191 -0.1055 -0.0616 -0.0766 -0.0478 -0.1251 -0.0869 -0.1061 -0.1012 -1.7855 -0.3246 -0.1218 -0.7445 -0.1024 -0.0245 -0.0444 -0.1656 -0.1709 -0.2351 -0.0193 -0.0554 -0.0542 -0.0921 -0.0520 -0.1722 -0.1015 -0.2317 -0.4233 -0.0293 -0.0685 -0.0343 -0.0520 -0.0403 -0.0834 -0.1677 -0.1702 -0.0748 -0.1164 -0.0698 -0.1214 -0.0806 -0.0973 -0.4333 -0.0549 -0.0355 -0.1691 -0.0134 -0.0895 -1.4611 -0.1448 -0.1118 -1.5766 -0.0611 -0.1065 -0.2455 -0.3508 -1.1308 -0.2321 -0.4270 -0.0999 -0.1343 -0.5711 -0.1312 -0.0955 -1.8314 -0.0320 -0.0565 -0.0691 -0.1222 -0.0846 -1.7401 -0.1722 -0.1721 -0.0152 -0.1344 -0.0282 -0.0489 -0.0969 -0.1256 -0.0255 -0.0752 -1.2329 -0.4483 -0.4720 -1.0415 -0.4470 -0.0174 -0.0951 -0.8829\n",
            "T-188\tmayi wina wovala malaya akuda akuima kutsogolo kwa nthochi pamalo oikapo zipatso\n",
            "H-188\t-0.2736978828907013\t▁ m a y i ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u y i m a ▁ k u t s o g o l o ▁ k w a ▁ m a l a y a ▁ o i k a ▁ n d i ▁ p a t s o g o l o\n",
            "D-188\t-0.2736978828907013\tmayi wina wovala malaya akuda akuyima kutsogolo kwa malaya oika ndi patsogolo\n",
            "P-188\t-0.1262 -0.0804 -0.0980 -0.0342 -0.0927 -0.0964 -0.0306 -0.1030 -0.0519 -0.1190 -0.1192 -0.0467 -0.1001 -0.0536 -0.1413 -0.0854 -0.1175 -0.1102 -0.0540 -0.1068 -0.0688 -0.1364 -0.0541 -0.1161 -0.1190 -0.1276 -0.0684 -0.1098 -0.4201 -0.1515 -0.1145 -0.1881 -0.0771 -0.1423 -0.8366 -0.1273 -0.0550 -0.1518 -0.0946 -1.2248 -0.0446 -0.0062 -0.0455 -0.0715 -0.0159 -0.0818 -0.0509 -0.0903 -0.0945 -0.8726 -0.0331 -0.1183 -0.0812 -0.2427 -0.1553 -2.4840 -0.8360 -0.1871 -0.1164 -0.0941 -0.0579 -1.1169 -1.5571 -0.1268 -0.2459 -1.7329 -0.1495 -0.1213 -2.0025 -0.5141 -0.3963 -0.4655 -0.0517 -0.3481 -0.1377 -0.2076 -0.0641 -0.1882 -0.2649\n",
            "T-239\twosewera wa skateboard akukwera pa skateboard panja pazitsulo kutsogolo kwa nyumba ya konkire\n",
            "H-239\t-0.2270769476890564\t▁ w o s e w e r a ▁ w a ▁ s k a t e b o a r d ▁ a k u k w e r a ▁ p a n j a ▁ p a n j a ▁ p a ▁ t s o g o l o ▁ k u t s o g o l o ▁ k w a ▁ m p i r a\n",
            "D-239\t-0.2270769476890564\twosewera wa skateboard akukwera panja panja pa tsogolo kutsogolo kwa mpira\n",
            "P-239\t-0.1121 -0.4777 -0.0768 -0.1105 -0.0367 -0.0244 -0.0698 -0.0524 -0.1059 -0.1134 -0.2740 -0.1783 -0.5451 -0.7276 -0.7348 -0.1233 -0.0221 -0.1342 -0.0455 -0.0236 -0.0892 -0.0212 -0.0608 -0.2757 -0.1095 -0.0387 -0.1142 -0.1958 -0.2171 -0.1097 -0.1632 -0.1185 -0.1221 -0.1710 -0.1706 -0.2167 -0.0737 -0.1040 -0.2515 -0.0644 -0.1131 -0.3020 -0.0758 -0.2527 -0.2669 -0.4536 -0.1489 -0.5231 -1.9919 -0.0231 -0.8505 -0.2021 -0.0897 -0.0205 -0.0868 -0.0963 -0.0378 -0.7146 -0.6300 -0.0199 -0.0435 -0.0500 -0.0486 -0.1044 -0.0499 -0.0966 -0.0180 -0.0134 -0.1433 -0.2754 -1.7166 -0.0632 -0.0672 -0.0130 -0.5507 -0.4290\n",
            "T-53\twothamanga akudumpha mumlengalenga pafupi ndi mtengo wautali pamene mwamuna akumujambula pavidiyo\n",
            "H-53\t-0.2450241893529892\t▁ w o t h a m a n g a ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ p a f u p i ▁ n d i ▁ m t e n g o ▁ w a u t a l i ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ k u t s o g o l o ▁ k w a k e\n",
            "D-53\t-0.2450241893529892\twothamanga akudumpha mumlengalenga pafupi ndi mtengo wautali pamene mwamuna wina kutsogolo kwake\n",
            "P-53\t-0.1046 -0.1921 -0.1054 -0.1111 -0.0145 -0.0818 -0.0249 -0.0872 -0.0849 -0.0290 -0.0871 -0.1104 -0.5589 -0.0231 -0.1094 -0.1698 -0.0740 -0.0202 -0.0689 -0.0194 -0.1746 -0.1821 -0.1172 -1.6263 -0.1560 -0.1009 -0.0516 -0.0751 -0.0678 -0.0793 -0.0380 -0.0376 -0.0350 -0.0537 -0.0885 -0.1437 -0.1340 -0.1448 -0.2371 -0.0890 -0.0126 -0.0507 -0.0943 -0.0291 -0.0687 -0.1051 -0.1056 -0.6358 -0.7353 -0.9406 -0.1249 -0.0478 -0.0226 -0.0872 -0.0401 -2.9445 -0.3725 -0.1028 -0.2196 -0.1201 -0.0617 -0.1186 -0.4189 -0.1495 -0.1530 -0.2678 -0.0495 -0.0478 -0.0840 -0.4265 -0.6978 -0.1186 -0.0329 -0.0820 -0.0667 -0.1219 -0.1131 -0.3477 -1.4212 -0.0920 -0.1045 -0.1128 -2.1697 -0.0254 -0.7374 -0.5344 -0.0303 -0.0270 -0.1526 -0.0443 -0.5188 -0.2010 -0.1749 -0.0608 -0.1306 -1.3783 -0.0483 -0.1212\n",
            "T-320\tanyamata awiri akugwira magalasi pomwe amatha kuona chidindo chikusambira\n",
            "H-320\t-0.2719166576862335\t▁ a n y a m a t a ▁ a w i r i ▁ a k u g w i r a ▁ m a g a l a s i ▁ a ▁ m a k w e r a ▁ p a n j i n g a ▁ n d i ▁ c h i k u s a m b i r a\n",
            "D-320\t-0.2719166576862335\tanyamata awiri akugwira magalasi a makwera panjinga ndi chikusambira\n",
            "P-320\t-0.1094 -0.1001 -0.0268 -0.1847 -0.1013 -0.0430 -0.0989 -0.0390 -0.1082 -0.1238 -0.0723 -0.0363 -0.1137 -0.0584 -0.1178 -0.1023 -0.0986 -0.1635 -0.1059 -0.0826 -0.2454 -0.2489 -0.1082 -0.1268 -0.1662 -0.7407 -0.1284 -1.8488 -0.2330 -0.2255 -0.3132 -0.0252 -0.0402 -0.0758 -0.1850 -0.7306 -0.3244 -0.2886 -2.1162 -0.5423 -0.3996 -0.1728 -0.2223 -0.1278 -0.8933 -0.1557 -1.3880 -0.9576 -0.0844 -0.0539 -0.0327 -0.1014 -0.1815 -0.6951 -0.0210 -0.0967 -0.1656 -0.1970 -0.1170 -0.0497 -0.1604 -1.0346 -0.2960 -0.1135 -0.2141 -0.2230 -0.0479 -0.0564 -0.1011 -0.0741\n",
            "T-208\tagalu akuda ndi akuda pa matalala kusonyeza mano ndi kuuwa wina ndi mzake\n",
            "H-208\t-0.3370042145252228\t▁ a g a l u ▁ a k u d a ▁ n d i ▁ k a k u d a ▁ a t a v a l a ▁ m a l a y a ▁ a k u s e w e r a ▁ m ▁ m a d z i ▁ n d i ▁ w a u k u l u ▁ n d i ▁ z i n a\n",
            "D-208\t-0.3370042145252228\tagalu akuda ndi kakuda atavala malaya akusewera m madzi ndi waukulu ndi zina\n",
            "P-208\t-0.1144 -0.0860 -0.6495 -0.1234 -0.1061 -0.0955 -0.1000 -0.1274 -0.3261 -0.1313 -0.3562 -0.1683 -0.0928 -0.0637 -0.0919 -0.0906 -0.1323 -0.6146 -0.2551 -1.5289 -0.0868 -0.0672 -0.2129 -0.1002 -0.6993 -0.6502 -0.0963 -0.2138 -0.1258 -0.0872 -0.1124 -0.0999 -1.1931 -0.1441 -1.0273 -0.1224 -0.1448 -0.1149 -0.0892 -0.3116 -0.1810 -0.1198 -0.6330 -1.0998 -0.5864 -0.0782 -0.4715 -0.1336 -0.0962 -0.7275 -0.9770 -0.0579 -0.1355 -0.5070 -1.3277 -0.0470 -0.1219 -0.2341 -0.0738 -0.0688 -0.4128 -0.8403 -0.4925 -0.3866 -0.9099 -0.0602 -0.3568 -0.3036 -0.1573 -0.4120 -0.0528 -0.1339 -0.0796 -0.2473 -2.0467 -0.1912 -0.2814 -0.2908\n",
            "T-20\tmayi wina atanyamula galu wakuda ndi woyera m mphepete mwa msewu kutsogolo kwa magalimoto oimika\n",
            "H-20\t-0.2925328016281128\t▁ m a y i ▁ w i n a ▁ a t a n y a m u l a ▁ k u t s o g o l o ▁ k w a ▁ m p i r a ▁ m ▁ m p h e p e t e ▁ m w a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ i n a\n",
            "D-20\t-0.2925328016281128\tmayi wina atanyamula kutsogolo kwa mpira m mphepete mwa kutsogolo kwa nyumba ina\n",
            "P-20\t-0.1094 -0.0532 -0.1065 -0.0272 -0.0779 -0.0806 -0.1279 -0.1384 -0.0856 -0.1164 -0.1119 -0.3024 -0.0741 -0.1061 -0.3502 -0.0125 -0.0693 -0.0353 -0.1290 -0.0634 -0.1101 -0.1026 -1.5021 -1.8955 -1.1986 -1.3711 -0.1036 -0.0360 -0.0922 -0.0794 -0.2016 -0.1345 -1.2565 -0.0440 -0.1681 -0.1147 -0.9888 -0.0568 -0.8824 -0.0760 -0.0966 -0.1369 -0.2854 -0.3500 -0.4528 -0.0743 -0.0666 -0.0743 -0.0384 -0.0777 -0.0089 -0.1676 -0.0748 -0.1866 -0.0443 -0.1219 -0.0844 -1.1232 -0.6516 -0.1002 -0.0293 -0.0536 -0.0259 -0.0627 -0.0653 -0.0583 -0.0924 -0.0371 -0.0483 -0.1221 -0.1517 -2.5945 -0.2721 -0.0488 -0.0396 -0.2769 -0.1359 -0.5276 -1.8945 -0.3365 -0.1283 -0.1777\n",
            "T-61\tmunthu woyenda pa snowboard atavala zofiira akutsika phiri lokutidwa ndi chipale chofewa\n",
            "H-61\t-0.2832041084766388\t▁ m u n t h u ▁ w o y e n d a ▁ p a ▁ s n o w b o a r d ▁ a t a v a l a ▁ z o f i i r a ▁ a k u s e k a ▁ k u t i ▁ w o k h a l a ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-61\t-0.2832041084766388\tmunthu woyenda pa snowboard atavala zofiira akuseka kuti wokhala ndi chipale chofewa\n",
            "P-61\t-0.1210 -0.0856 -0.0412 -0.0623 -0.0312 -0.0516 -0.1013 -0.1537 -0.0394 -1.5899 -0.0890 -0.0969 -0.4586 -0.0397 -0.0885 -0.1433 -0.1724 -0.1287 -1.1669 -0.1864 -1.2466 -0.0996 -0.4634 -0.1507 -0.0505 -0.0973 -0.0844 -0.0786 -0.3330 -0.2350 -0.0181 -0.1014 -0.0574 -0.1045 -0.2116 -0.0946 -0.1221 -0.4730 -0.0740 -0.1489 -0.0985 -0.1210 -0.0526 -0.1587 -0.1086 -0.2371 -0.0287 -0.1319 -0.3237 -0.9564 -0.6116 -0.2211 -0.1116 -1.0526 -0.2607 -0.3946 -0.0551 -0.0958 -1.4666 -0.1748 -1.3463 -0.6368 -0.1207 -0.9397 -0.1654 -0.1109 -0.4354 -0.2553 -0.1244 -0.1223 -0.2409 -0.0595 -0.3232 -2.2354 -0.1685 -0.2957 -0.0270 -0.1301 -0.1800 -0.0798 -0.0700 -0.2210 -0.1213 -0.0932 -0.0758 -0.0228\n",
            "T-358\tanthu ena ayima m chipinda mozungulira desiki yozungulira yolandirira alendo\n",
            "H-358\t-0.2939929664134979\t▁ a n t h u ▁ a n a y i ▁ a l i ▁ m ▁ c h i p i n d a ▁ m o z u n g u l i r a ▁ t e s i t i ▁ y o z u n g u l i r a ▁ n d i ▁ a n t h u ▁ e n a ▁ a l i ▁ n d i ▁ m p i r a\n",
            "D-358\t-0.2939929664134979\tanthu anayi ali m chipinda mozungulira tesiti yozungulira ndi anthu ena ali ndi mpira\n",
            "P-358\t-0.1140 -0.0963 -0.1671 -0.0327 -0.0684 -0.0873 -0.1044 -0.9593 -1.2910 -0.4247 -0.0177 -0.0845 -0.1083 -0.2208 -0.6700 -0.0978 -0.0881 -0.0454 -0.1030 -1.9863 -0.0361 -0.0515 -1.8455 -0.0614 -0.0775 -0.0487 -0.0899 -0.1154 -0.1098 -0.1044 -0.1810 -0.1053 -0.0243 -0.0093 -0.0452 -0.0531 -0.0594 -0.0343 -0.1127 -0.1101 -0.6225 -0.1877 -0.3507 -0.1034 -0.0736 -0.7096 -0.1395 -0.1114 -1.8612 -0.2935 -0.0423 -0.0542 -0.0160 -0.0261 -0.0973 -0.0804 -0.0388 -0.1160 -0.1303 -0.7371 -0.2386 -0.0931 -0.1290 -0.6906 -0.4967 -0.0795 -0.1351 -0.1135 -0.1584 -1.0224 -0.0664 -0.1641 -0.5984 -0.4937 -0.1614 -0.3098 -0.1915 -0.2761 -0.1138 -0.1144 -0.1232 -0.3822 -0.5177 -2.7543 -0.0685 -0.0720 -0.1792\n",
            "T-356\tmayi wina wachiafirika waku america wovala malalanje akumenya mpira wa tenisi ndi racquet\n",
            "H-356\t-0.336293488740921\t▁ m a y i ▁ w i n a ▁ w a c h i k a s u ▁ n d i ▁ k a m e r i ▁ w a w o ▁ w o v a l a ▁ m a l a y a ▁ a k u n j a ▁ n d i ▁ m p i r a ▁ w a ▁ c h i z i n d i k i r a\n",
            "D-356\t-0.336293488740921\tmayi wina wachikasu ndi kameri wawo wovala malaya akunja ndi mpira wa chizindikira\n",
            "P-356\t-0.1013 -0.0955 -0.0795 -0.0754 -0.1169 -0.0906 -0.0304 -0.0749 -0.0694 -0.1256 -0.1073 -0.1491 -0.1070 -0.2233 -0.0417 -0.1443 -1.1895 -0.1401 -2.5709 -0.5627 -0.0968 -0.3988 -0.1194 -0.1151 -0.1342 -0.3427 -0.3125 -0.3775 -0.0964 -0.0383 -0.1330 -0.4682 -1.3895 -0.6424 -0.9447 -0.1853 -0.1121 -0.3219 -0.1064 -0.0477 -0.1456 -0.0749 -0.1162 -0.1179 -0.0800 -0.1001 -0.4978 -0.1324 -0.3176 -0.1152 -0.0983 -0.2629 -0.3664 -0.1066 -1.4622 -0.5166 -0.1185 -0.1560 -0.3079 -0.0863 -0.0791 -0.1395 -0.3239 -2.6746 -0.1275 -0.0661 -0.1239 -0.1811 -0.0352 -0.2182 -0.2716 -0.8339 -0.1747 -0.1317 -2.7780 -0.2952 -0.1205 -0.0857 -0.0835 -0.3114 -0.0689 -0.0375 -0.9364 -0.4920\n",
            "T-427\tmwamuna wina wovala zakuda akuwomba m manja munthu wothamanga yemwe wavala jeresi yofiira komanso nambala two eighty one\n",
            "H-427\t-0.28358349204063416\t▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ z a k u d a ▁ a k u w o m b a ▁ m ▁ m a n j a ▁ m u t u ▁ w a k h a l a ▁ p a m e n e ▁ m n y a m a t a ▁ w o v a l a ▁ j e k e t e ▁ y o f i i r a ▁ k o m a n s o ▁ m a d z i\n",
            "D-427\t-0.28358349204063416\tmwamuna wina wovala zakuda akuwomba m manja mutu wakhala pamene mnyamata wovala jekete yofiira komanso madzi\n",
            "P-427\t-0.1139 -0.1244 -0.0472 -0.1016 -0.0663 -0.0386 -0.1028 -0.1087 -0.1224 -0.1667 -0.0880 -0.0880 -0.1061 -0.1107 -0.0490 -0.0806 -0.0566 -0.1033 -0.0985 -0.1002 -0.1052 -0.0523 -0.0832 -0.0665 -0.0821 -0.1628 -0.1864 -0.1125 -2.1411 -0.0723 -0.1377 -0.2566 -0.1422 -1.1792 -0.5930 -0.1674 -0.1492 -0.3832 -0.5548 -0.1709 -0.3528 -0.0334 -0.0286 -0.0894 -0.1178 -0.2284 -1.5288 -0.9242 -0.0877 -0.0682 -0.0295 -0.6870 -0.2665 -0.4523 -0.1003 -0.3475 -0.1116 -0.1271 -1.0611 -0.0989 -0.2637 -1.7819 -0.1290 -0.0661 -0.0962 -0.4020 -0.5773 -0.0848 -0.1533 -0.0337 -0.1017 -0.0804 -0.0759 -0.0979 -0.3453 -0.2791 -0.3308 -0.1406 -0.0829 -0.0987 -0.0892 -0.1101 -0.1224 -0.6609 -0.0783 -0.1201 -0.0927 -0.0633 -1.1055 -0.2189 -0.2218 -0.0399 -0.1187 -0.0346 -0.1130 -0.1290 -0.5951 -1.4481 -0.0661 -0.1233 -0.0519 -0.0445 -0.0268 -0.1548 -1.6383 -0.8514 -1.2513 -0.1628 -0.2068 -0.6201\n",
            "T-72\tmayi wovala mpango wa silika wofiira ndi wachikasu akusewera cello\n",
            "H-72\t-0.2558148503303528\t▁ m a y i ▁ w o v a l a ▁ m a g a l a s i ▁ o f i i r a ▁ n d i ▁ w o f i i r a ▁ n d i ▁ w a c h i k a s u ▁ a k u s e w e r a ▁ s i t o l o\n",
            "D-72\t-0.2558148503303528\tmayi wovala magalasi ofiira ndi wofiira ndi wachikasu akusewera sitolo\n",
            "P-72\t-0.1137 -0.1335 -0.0721 -0.0192 -0.0658 -0.1245 -0.0610 -0.1586 -0.0841 -0.1285 -0.0804 -0.1139 -0.0922 -0.0905 -0.6661 -0.5058 -0.3017 -0.0873 -0.1553 -0.0766 -0.0377 -0.0758 -2.9437 -0.5634 -0.0397 -0.2066 -0.0565 -1.1519 -0.1173 -0.2992 -0.0860 -0.1092 -0.4227 -0.9641 -0.0290 -0.1435 -0.0754 -0.2321 -0.0674 -0.3915 -0.1228 -0.3030 -0.0649 -0.0886 -0.2836 -0.5167 -0.1580 -0.3238 -0.0833 -0.0589 -0.0129 -0.0872 -0.0115 -0.2010 -0.1161 -0.6242 -0.0250 -0.1125 -0.1003 -0.0388 -0.0911 -0.0399 -0.0527 -0.1009 -0.5389 -0.6681 -0.3388 -1.1129 -0.7184 -0.1373 -0.0321 -0.1111\n",
            "T-194\tmunthu ameneyu wavala malaya abuluu akusenga thabwa la boti limene akulimanga\n",
            "H-194\t-0.26523900032043457\t▁ m u n t h u ▁ a m e n e ▁ w a v a l a ▁ m a l a y a ▁ a b u l u u ▁ a k u s e w e r a ▁ p a b w a l o ▁ l o t c h i n g i r a ▁ k u m a o n e r a\n",
            "D-194\t-0.26523900032043457\tmunthu amene wavala malaya abuluu akusewera pabwalo lotchingira kumaonera\n",
            "P-194\t-0.1207 -0.1346 -0.0658 -0.0652 -0.0369 -0.0707 -0.0732 -0.1422 -0.6273 -0.2352 -0.3098 -0.1932 -0.5000 -0.1257 -0.0883 -0.7404 -0.1251 -0.1368 -0.0852 -0.1253 -0.1158 -0.1552 -0.0966 -0.0457 -0.1218 -0.0918 -0.1075 -0.0951 -0.1195 -0.3638 -0.0620 -0.0368 -0.1576 -0.0143 -0.1056 -0.0792 -0.0455 -0.0723 -0.1519 -0.0839 -0.4806 -0.1005 -0.1588 -0.1168 -0.1305 -1.3324 -0.1657 -0.8644 -0.5740 -0.0771 -0.1106 -0.0386 -0.1276 -0.0455 -0.9303 -1.0651 -0.1497 -0.0435 -0.0455 -0.1743 -0.6073 -0.3807 -0.2891 -0.3848 -0.2157 -0.2134 -0.1717 -0.3948 -0.2492 -2.0700 -0.2174 -0.4157 -0.7739 -0.5318 -0.1224\n",
            "T-377\twosewera mpira wa tennis akumenya mpira ndi racquet yake pomwe ena amawonera masewerawo\n",
            "H-377\t-0.39593741297721863\t▁ m o s e w e r a ▁ m p i r a ▁ w a ▁ c h i p i n d a ▁ c h a k u m e n y a ▁ n d i ▁ m t s i k a n a ▁ k u m e n y a ▁ n d i p o ▁ m w a m u n a ▁ w o s i y a n a s i y a n a\n",
            "D-377\t-0.39593741297721863\tmosewera mpira wa chipinda chakumenya ndi mtsikana kumenya ndipo mwamuna wosiyanasiyana\n",
            "P-377\t-0.1132 -0.0543 -3.2302 -0.1761 -0.0766 -0.0282 -0.0560 -0.0666 -0.1146 -0.1144 -0.2790 -1.3202 -0.1013 -0.0205 -0.0832 -0.1549 -0.1093 -0.1694 -0.2926 -1.3483 -0.2516 -0.1540 -1.8588 -0.1278 -0.6509 -0.3191 -0.1767 -0.1254 -1.4047 -0.1312 -0.1394 -0.2274 -0.1048 -0.2270 -1.6475 -0.1550 -0.1280 -0.1230 -0.4747 -0.5702 -0.2949 -0.1217 -0.1452 -1.9330 -0.4174 -0.1075 -0.1301 -0.1540 -0.2389 -0.0818 -0.1073 -0.1541 -1.5799 -0.3991 -0.1211 -0.6272 -0.3507 -0.4693 -0.2945 -0.1512 -1.7847 -0.6488 -0.1491 -0.5057 -0.0455 -0.1216 -0.5340 -0.5034 -0.2297 -0.1334 -0.2136 -0.0381 -0.1968 -0.1485 -0.5959 -0.2021 -0.3786 -2.0093 -0.1495 -0.1912 -0.3963 -0.0587 -0.1775 -0.1047 -0.0960 -0.2118 -0.2397 -0.0846 -0.3043\n",
            "T-253\tanthu angapo atayima ndi kukhala m kalasi kapena m chipinda chochitira misonkhano\n",
            "H-253\t-0.2979477643966675\t▁ a n t h u ▁ a n g a p o ▁ a t a y i m a ▁ n d i ▁ k u k h a l a ▁ m ▁ k a l a s i ▁ k a p e n a ▁ c h i t h u n z i ▁ c h o c h i t i r a ▁ m u m s e w u\n",
            "D-253\t-0.2979477643966675\tanthu angapo atayima ndi kukhala m kalasi kapena chithunzi chochitira mumsewu\n",
            "P-253\t-0.1071 -0.1416 -0.0412 -0.0324 -0.0786 -0.0771 -0.0920 -0.1905 -0.5085 -0.0588 -0.1109 -0.0324 -0.0703 -0.0810 -0.1166 -0.1320 -0.0821 -0.2596 -0.1262 -0.0335 -0.2858 -0.0832 -0.3711 -0.1518 -0.1296 -0.7080 -0.2282 -0.4082 -0.0309 -0.3575 -0.1530 -0.0914 -0.1273 -0.1026 -0.1557 -0.6183 -0.3132 -0.3321 -2.8049 -0.1235 -0.0332 -0.0575 -0.1178 -0.7094 -0.5497 -1.0505 -0.0720 -0.0158 -0.1220 -0.1086 -1.6687 -0.1653 -0.0960 -1.6680 -0.3429 -0.0651 -0.0352 -0.3397 -0.0761 -0.2894 -0.4628 -0.0785 -0.5133 -0.2982 -0.0640 -0.0927 -0.1204 -0.2000 -0.0521 -0.0960 -0.1670 -0.1551 -1.9590 -0.1458 -0.0770 -0.4320 -0.0666 -0.0890 -0.9368\n",
            "T-342\tmayi wina wokalamba akuyeretsa mazenera pasitolo pafupi ndi msewu\n",
            "H-342\t-0.4060443639755249\t▁ m a y i ▁ w i n a ▁ w o k h a l a ▁ n d i ▁ a k u y e s a ▁ m a z e n e r a ▁ p a ▁ s i t o l o ▁ p a f u p i\n",
            "D-342\t-0.4060443639755249\tmayi wina wokhala ndi akuyesa mazenera pa sitolo pafupi\n",
            "P-342\t-0.1147 -0.0974 -0.0917 -0.0318 -0.0732 -0.1094 -0.1035 -0.0770 -0.0555 -0.1102 -0.1020 -0.4715 -0.2259 -0.0414 -0.4807 -0.1110 -0.0377 -0.1128 -0.1049 -2.2746 -0.4492 -0.1351 -0.1371 -1.4294 -0.3682 -0.0991 -0.2235 -0.1094 -0.3717 -0.4986 -0.0826 -0.0950 -0.0962 -0.5055 -0.4791 -1.2617 -0.8113 -0.0397 -0.3601 -0.1424 -0.8055 -0.1548 -0.5855 -1.4366 -0.1364 -0.0204 -0.4212 -0.2953 -0.7089 -0.3413 -1.3244 -0.2137 -0.2470 -0.0269 -0.2646 -0.0737 -3.5666\n",
            "T-19\twoyenda pa skateboard wovala t shirt yakuda ndi mathalauza akuda ali kutsogolo kwa nyumba ya njerwa zofiira\n",
            "H-19\t-0.24000756442546844\t▁ w o y e n d a ▁ p a ▁ s k a t e b o a r d ▁ c h a k u d y a ▁ n d i ▁ m a t h a l a u z a ▁ o t h a w i r a ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ y a ▁ z o f i i r a\n",
            "D-19\t-0.24000756442546844\twoyenda pa skateboard chakudya ndi mathalauza othawira ali kutsogolo kwa nyumba ya zofiira\n",
            "P-19\t-0.1049 -0.0437 -0.0525 -0.1218 -0.3822 -0.0763 -0.0239 -0.1115 -0.1103 -0.0233 -0.1479 -0.0666 -0.0546 -0.0588 -0.0518 -0.0515 -0.0993 -0.0156 -0.0278 -0.0860 -0.0235 -0.0343 -0.2172 -3.0566 -0.1092 -1.1297 -0.3192 -0.1211 -0.1949 -0.1156 -0.1347 -0.1224 -0.3037 -0.1113 -0.1082 -0.1111 -0.0556 -0.1183 -0.3488 -0.0828 -0.0623 -0.1509 -0.1081 -0.0269 -0.0469 -0.0584 -0.1337 -0.1656 -1.6092 -0.4806 -0.1466 -1.5158 -0.1522 -0.6348 -0.0906 -0.1735 -0.2102 -0.3097 -0.1430 -0.1871 -0.0276 -0.1340 -0.1548 -0.0100 -0.0417 -0.0400 -0.0626 -0.0812 -0.0892 -0.0984 -0.0271 -0.0143 -0.1030 -0.0931 -0.4699 -0.5600 -0.3887 -0.0881 -0.0441 -0.1046 -0.1198 -0.1621 -1.2154 -0.6665 -0.9867 -0.7600 -0.1212 -0.1281 -0.1103 -0.0288 -0.1263 -0.0887\n",
            "T-299\tkamnyamata kakang ono kovala malaya amizeremizere yakuda ndi yofiira akuyenda pansi paphiri laudzu\n",
            "H-299\t-0.19336293637752533\t▁ k a m n y a m a t a ▁ k a k a n g ▁ o n o ▁ k o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ y a k u d y a ▁ n d i ▁ j e k e t e ▁ y o f i i r a ▁ p a n s i ▁ y a ▁ u d z u\n",
            "D-299\t-0.19336293637752533\tkamnyamata kakang ono kovala malaya amizeremizere yakudya ndi jekete yofiira pansi ya udzu\n",
            "P-299\t-0.1046 -0.2493 -0.3475 -0.0669 -0.0359 -0.0496 -0.1158 -0.0937 -0.1294 -0.0474 -0.1319 -0.1015 -0.0107 -0.1021 -0.0751 -0.1027 -0.0739 -0.0620 -0.0786 -0.0891 -0.0425 -0.0981 -0.1056 -0.0092 -0.1191 -0.3085 -0.0955 -0.0731 -0.1190 -0.0928 -0.0422 -0.1005 -0.1357 -0.1083 -0.0279 -0.1145 -0.0694 -0.1612 -0.3102 -0.1023 -0.1330 -0.0528 -0.0566 -0.0410 -0.0893 -0.0979 -0.0427 -0.0723 -0.0435 -0.0330 -0.0952 -0.3880 -0.1536 -0.1620 -0.1120 -0.1513 -1.8043 -0.4771 -0.1183 -0.0830 -0.0708 -0.0994 -0.1944 -2.4870 -0.1726 -0.2727 -0.0825 -0.1001 -0.1387 -0.0709 -0.0539 -0.0937 -0.4801 -0.1205 -0.1903 -0.0448 -0.1333 -0.1074 -0.1395 -0.1028 -0.1949 -0.1130 -0.0661 -0.0952 -0.2715 -0.0919 -0.9392 -0.7946 -0.5157 -0.0180 -0.0860 -0.9378\n",
            "T-335\tkamtsikana kakang ono kovala pinki kakugwera m madzi pamene mtsikana wina atavala mawotchi ofiira\n",
            "H-335\t-0.24457082152366638\t▁ k a m t s i k a n a ▁ k a k a n g ▁ o n o ▁ k o v a l a ▁ p i n k i ▁ a k u k w e r a ▁ m ▁ m a d z i ▁ p a m e n e ▁ m t s i k a n a ▁ w i n a ▁ a t a v a l a ▁ m a l a y a ▁ o f i i r a\n",
            "D-335\t-0.24457082152366638\tkamtsikana kakang ono kovala pinki akukwera m madzi pamene mtsikana wina atavala malaya ofiira\n",
            "P-335\t-0.1060 -2.9669 -0.2063 -0.0275 -0.0224 -0.0580 -0.0455 -0.0394 -0.1522 -0.0879 -0.1333 -0.1073 -0.3190 -0.1244 -0.1904 -0.0999 -0.0810 -0.0187 -0.0836 -0.0476 -0.0628 -0.0488 -0.1094 -0.6348 -0.0436 -0.0478 -0.0955 -0.1101 -0.1263 -0.1050 -1.1281 -0.0839 -0.0396 -0.0968 -0.0703 -0.1089 -1.0725 -0.0212 -0.1284 -2.1671 -1.1160 -0.0596 -0.1609 -0.1054 -0.1992 -0.2205 -0.5699 -0.0817 -0.0978 -0.1603 -0.0404 -0.0785 -0.1446 -0.0587 -0.1244 -0.0698 -0.4259 -0.0458 -0.2996 -0.1013 -0.1870 -0.1369 -0.0258 -0.0337 -0.0452 -0.1414 -0.0290 -0.1086 -0.1317 -0.3506 -0.0313 -0.0788 -0.1158 -0.1231 -0.4382 -0.0275 -0.1421 -0.0226 -0.0958 -0.0749 -0.1216 -0.1166 -0.6889 -0.1573 -2.3244 -0.3637 -0.2964 -0.1140 -0.1310 -0.0371 -0.6994 -0.0610 -0.1381 -0.0313 -0.1165 -0.3631\n",
            "T-109\tgalu woyera wokhala ndi makutu abulauni amathamanga panjira ya miyala ndi mpira m kamwa\n",
            "H-109\t-0.26730769872665405\t▁ g a l u ▁ w o y e r a ▁ w o k h a l a ▁ n d i ▁ m a k u t u ▁ a b u l a u n i ▁ a t a m a n g a ▁ p a n j i r a ▁ y a m i y a l a ▁ n d i ▁ m p i r a ▁ m ▁ k a m w a\n",
            "D-109\t-0.26730769872665405\tgalu woyera wokhala ndi makutu abulauni atamanga panjira yamiyala ndi mpira m kamwa\n",
            "P-109\t-0.1145 -0.0368 -0.1017 -0.0508 -0.0831 -0.1357 -0.4064 -0.0525 -0.0193 -0.1273 -0.0758 -0.0966 -0.1214 -0.1246 -0.3166 -0.0588 -0.1918 -0.1118 -0.0817 -0.1201 -0.1162 -0.0280 -0.1184 -0.0893 -0.1140 -0.0720 -0.2796 -1.5577 -0.1619 -0.0514 -0.0731 -0.1401 -0.0954 -3.0845 -0.0696 -0.1334 -0.3474 -0.0691 -0.0481 -0.0929 -0.1129 -0.0974 -0.2846 -0.1410 -0.4732 -0.3402 -0.3047 -1.3016 -0.1436 -0.1141 -0.5778 -0.1360 -0.6248 -0.0345 -0.0690 -0.1456 -0.0899 -0.1049 -0.0191 -0.3223 -2.4018 -0.3836 -0.2795 -0.1169 -0.0232 -0.1187 -0.1052 -0.8700 -0.0989 -0.0931 -0.1083 -0.0547 -0.2913 -0.1258 -0.1222 -0.0953 -0.3052 -0.4201 -0.3641 -1.2353 -0.1037 -0.0492 -0.0311 -0.0826 -0.2350\n",
            "T-338\tmunthu wopanda pokhala akugona pansi pa bulangete lobiriwira m mbali mwa khoma la simenti\n",
            "H-338\t-0.35219693183898926\t▁ m u n t h u ▁ w o k h a l a ▁ p a k a t i ▁ w o k h a l a ▁ p a n s i ▁ p a ▁ b o l o d i ▁ l a ▁ n j e r w a ▁ n d i ▁ m b a l i ▁ m w a ▁ k u m a s i\n",
            "D-338\t-0.35219693183898926\tmunthu wokhala pakati wokhala pansi pa bolodi la njerwa ndi mbali mwa kumasi\n",
            "P-338\t-0.1151 -0.0738 -0.3429 -0.0452 -0.0523 -0.0694 -0.1208 -0.1319 -0.0806 -0.1939 -0.3907 -0.6866 -0.1061 -0.1654 -0.1287 -0.1298 -1.5676 -0.6562 -0.3095 -0.4015 -1.2622 -0.2906 -0.1116 -0.5559 -0.2293 -0.0979 -1.1910 -0.1316 -0.0847 -0.1041 -0.1061 -0.8951 -0.1071 -0.2557 -0.6317 -0.0682 -0.1371 -0.0846 -0.3278 -0.5135 -0.4137 -0.5241 -0.7029 -0.9871 -0.0692 -0.1188 -0.1217 -0.3574 -0.3520 -0.9694 -1.0438 -0.3216 -0.4968 -0.8163 -0.0689 -0.2789 -0.1669 -0.9434 -0.0760 -0.0857 -0.2785 -0.5251 -0.0480 -0.0964 -0.0567 -0.0825 -0.0944 -0.5505 -0.0364 -0.1118 -0.2521 -0.3263 -0.5331 -0.0423 -0.0887 -0.1968 -0.2525 -2.0318\n",
            "T-173\tmwamuna wovala malaya abulauni akugwira dzanja la mwana watsitsi lalitali kutsogolo kwa chithunzi\n",
            "H-173\t-0.22710619866847992\t▁ m w a m u n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a k u j a m b u l a ▁ z a ▁ m w a n a ▁ w a t s i t s i ▁ l a l i t a l i ▁ k u t s o g o l o ▁ k w a ▁ c h i n t h u\n",
            "D-173\t-0.22710619866847992\tmwamuna wovala malaya abulauni akujambula za mwana watsitsi lalitali kutsogolo kwa chinthu\n",
            "P-173\t-0.1199 -0.0784 -0.0554 -0.1081 -0.0932 -0.0789 -0.0661 -0.1053 -0.1232 -0.0802 -0.0584 -0.1062 -0.1314 -0.0949 -0.1199 -0.1026 -0.0334 -0.1073 -0.0544 -0.1171 -0.0502 -0.1159 -0.0863 -0.1447 -0.1154 -0.0634 -0.0805 -0.3304 -0.0452 -0.0257 -0.0708 -0.0937 -0.1124 -0.0301 -0.0963 -2.5993 -0.0941 -0.1454 -0.0669 -0.1886 -0.0822 -0.1227 -0.1227 -1.7877 -0.2800 -0.6517 -0.8478 -0.4846 -0.1216 -0.0937 -0.1232 -0.1231 -0.1497 -0.1294 -1.5988 -0.0619 -0.0825 -0.0173 -0.2269 -0.1127 -0.0772 -0.7539 -0.1499 -0.0768 -0.0603 -0.0310 -0.0839 -0.0347 -0.0580 -0.1508 -0.4371 -0.0604 -0.0369 -0.1249 -0.0652 -0.0161 -0.0889 -0.0902 -0.0572 -0.1464 -0.0211 -0.0562 -0.1252 -0.1219 -0.3654 -0.0727 -0.0503 -2.4448 -0.6476 -0.0914 -0.0216 -0.6659\n",
            "T-222\tanyamata anayi amasewera m gulu lawo akuimba ndi kusewera gitala ndi bass\n",
            "H-222\t-0.32366445660591125\t▁ a n y a m a t a ▁ a n a y i ▁ a l i ▁ a m a c h e n g a ▁ m ▁ b u l u u ▁ a w i r i ▁ a k u i m b a ▁ n d i ▁ k u s e w e r a ▁ g i t a l a ▁ n d i ▁ t s i t s i\n",
            "D-222\t-0.32366445660591125\tanyamata anayi ali amachenga m buluu awiri akuimba ndi kusewera gitala ndi tsitsi\n",
            "P-222\t-0.1086 -0.1059 -0.1303 -0.0444 -0.1116 -0.0473 -0.1010 -0.0205 -0.1022 -0.1291 -0.1314 -0.6485 -0.6420 -0.0668 -0.1191 -0.1071 -0.1166 -2.2530 -0.1147 -0.1020 -1.6700 -0.1072 -0.0992 -0.4513 -0.0591 -0.8166 -0.6371 -0.0851 -0.1447 -0.1012 -0.0979 -0.6265 -1.8818 -0.3364 -0.5854 -0.4834 -0.1026 -0.0901 -0.2163 -0.3549 -0.2526 -0.1035 -0.1790 -0.0934 -0.1103 -0.0631 -0.1938 -0.3545 -0.0675 -0.0334 -0.1129 -0.0724 -0.2127 -0.1944 -0.0982 -0.2876 -1.4894 -0.1155 -0.5232 -0.0613 -0.0892 -0.0753 -0.0606 -0.1034 -0.0826 -0.7607 -0.1288 -0.0193 -0.0797 -0.0318 -0.1048 -0.1498 -1.2512 -0.0563 -0.3013 -0.0884 -2.5456 -0.7908 -0.2386 -0.4039 -0.4372 -0.1586 -0.1385\n",
            "T-336\tovodafone amathandizira timu ya mpira wa emirates nthawi yayitali ku barcelona\n",
            "H-336\t-0.3540251851081848\t▁ w o g w i r a ▁ n t c h i t o ▁ a m a t h a m a n g i z i r a ▁ t i m u ▁ y a ▁ m p i r a ▁ w a i m i t s i r a ▁ m ▁ n y a n j a ▁ n d i ▁ g a l u ▁ w a m a s e w e r a\n",
            "D-336\t-0.3540251851081848\twogwira ntchito amathamangizira timu ya mpira waimitsira m nyanja ndi galu wamasewera\n",
            "P-336\t-0.1091 -0.3967 -0.1199 -0.4047 -0.3930 -0.4996 -0.0900 -0.1008 -0.0926 -0.8121 -0.3338 -0.7005 -0.1190 -0.3900 -0.0984 -0.0962 -0.0947 -0.1561 -0.0609 -0.0857 -0.3612 -0.6073 -0.0985 -0.7391 -0.1634 -0.0358 -0.1064 -0.0564 -0.3075 -0.6359 -0.0338 -0.1016 -0.1291 -1.6548 -0.6232 -0.2078 -0.0184 -0.0737 -0.1045 -0.1832 -0.2212 -0.2089 -0.0738 -0.1106 -0.0371 -0.1136 -0.1401 -0.0276 -0.1497 -1.9439 -0.0303 -1.9023 -0.1454 -0.1734 -0.0978 -1.6369 -0.4566 -0.1120 -0.3600 -0.4381 -0.7326 -0.1241 -0.1260 -0.5629 -0.1127 -0.1250 -0.1370 -1.9728 -0.1998 -0.0730 -0.4887 -0.9028 -0.8074 -0.0648 -0.6612 -0.2719 -0.1742 -0.2571 -0.2883 -0.2127 -0.4203 -0.6673 -0.0320 -1.1551 -0.0543 -0.1156 -0.2856\n",
            "T-205\tokwatirana ovala zovala zowala akuyenda manja ndi manja m mphepete mwa msewu\n",
            "H-205\t-0.24641117453575134\t▁ w o k w e r a ▁ m p i r a ▁ w o v a l a ▁ z o v a l a ▁ z o v a l a ▁ z o y e r a ▁ a k u y e n d a ▁ m ▁ m a n j a ▁ n d i ▁ m a n j a ▁ m w a m s e w u\n",
            "D-205\t-0.24641117453575134\twokwera mpira wovala zovala zovala zoyera akuyenda m manja ndi manja mwamsewu\n",
            "P-205\t-0.1164 -0.1584 -0.0617 -0.1092 -0.0352 -0.2364 -0.1160 -0.0861 -0.1070 -2.5879 -0.6268 -0.5748 -0.0808 -0.0969 -0.1214 -0.0522 -0.1653 -0.0244 -0.1150 -0.0853 -0.1238 -0.1081 -0.0369 -0.0755 -0.1020 -0.0934 -0.0777 -0.1244 -0.1219 -0.0109 -0.1267 -1.5723 -0.0910 -0.0882 -0.1244 -0.1096 -0.6773 -0.1773 -0.5026 -0.0608 -0.0858 -0.1018 -0.1124 -0.0927 -0.0982 -0.1517 -0.2440 -0.1950 -0.0953 -0.0622 -0.1003 -0.0943 -0.1938 -0.1625 -0.1856 -0.1147 -0.0653 -0.0094 -0.1065 -0.1085 -0.2798 -0.0773 -0.1046 -0.1927 -0.1074 -0.7735 -1.0837 -0.0196 -0.0965 -0.1297 -0.4042 -0.6964 -0.1134 -1.0148 -0.9690 -0.3997 -0.4194 -0.1919 -0.0511\n",
            "T-388\twothamanga amadula miyendo yake pamene akuwuluka mumlengalenga pamwamba pa phiri la ski\n",
            "H-388\t-0.2697588801383972\t▁ w o t h a m a n g a ▁ a m a d u m p h a ▁ m ▁ m i y e n d o ▁ y a k e ▁ p a m e n e ▁ a k u l u a k a ▁ m u m l e n g a l e n g a ▁ p a m w a m b a ▁ p a ▁ p h i r i\n",
            "D-388\t-0.2697588801383972\twothamanga amadumpha m miyendo yake pamene akuluaka mumlengalenga pamwamba pa phiri\n",
            "P-388\t-0.1034 -0.6433 -0.0551 -0.0178 -0.0482 -0.0798 -0.0258 -0.1106 -0.0734 -0.0144 -0.0900 -0.0988 -0.1334 -1.1238 -0.1190 -0.2180 -0.1400 -0.4812 -0.6047 -0.0355 -0.2900 -0.1854 -0.3571 -0.8545 -1.3578 -0.4185 -1.0311 -0.2225 -0.0216 -0.0446 -0.1328 -0.0813 -0.1126 -0.1328 -0.7496 -0.0410 -0.0917 -0.2185 -0.1050 -0.1000 -0.3248 -0.0455 -0.0805 -0.0854 -0.5041 -0.3813 -0.0947 -1.3853 -0.0285 -0.9187 -0.1028 -0.4855 -0.0924 -0.0748 -1.9431 -0.1482 -0.7330 -0.0340 -0.0730 -0.2061 -0.1004 -0.0572 -0.0261 -0.0295 -0.1691 -0.1090 -0.0959 -0.1098 -0.1648 -0.4435 -0.2363 -0.1016 -0.0291 -0.0538 -0.1152 -0.1145 -0.0248 -0.1533 -0.3128 -0.9217 -0.6672 -0.0403 -0.0378 -0.0895 -0.2200\n",
            "T-36\tbambo wa jekete la imvi ndi magalasi ofiira ali ndi makamera ndipo waima kutsogolo kwa galimoto\n",
            "H-36\t-0.3065398633480072\t▁ b a m b o ▁ w a c h i c h e p e r e ▁ a l i ▁ n d i ▁ m a g a l a s i ▁ o f i i r a ▁ a l i ▁ n d i ▁ m a k h a l a ▁ n d i p o ▁ a i m a ▁ k u t s o g o l o ▁ k w a k e\n",
            "D-36\t-0.3065398633480072\tbambo wachichepere ali ndi magalasi ofiira ali ndi makhala ndipo aima kutsogolo kwake\n",
            "P-36\t-0.1008 -0.0858 -0.1284 -0.0780 -0.0222 -0.0555 -0.1211 -0.0881 -0.2298 -1.2527 -0.0825 -0.1024 -1.7612 -0.0798 -1.5119 -0.2200 -0.5568 -0.1436 -0.6915 -0.1376 -0.4698 -0.4252 -0.1054 -0.0964 -0.2381 -0.0653 -0.0949 -0.1257 -0.0820 -0.0661 -0.9738 -0.2974 -0.0977 -0.2462 -0.0333 -0.0588 -0.0882 -0.4357 -0.0090 -0.0501 -0.1439 -0.0316 -0.2806 -0.0959 -0.3637 -0.1734 -0.0738 -0.0714 -0.0428 -0.0608 -0.0831 -0.0895 -0.1191 -0.3303 -0.2503 -2.3364 -0.1061 -0.7357 -0.6179 -0.1181 -1.8100 -0.1104 -0.0855 -1.0438 -0.0392 -0.0841 -0.9793 -1.2676 -0.1514 -0.0504 -0.0914 -0.1743 -0.0504 -0.1231 -0.0129 -0.0344 -0.0341 -0.0586 -0.0510 -0.0907 -0.1638 -0.0330 -0.0752 -0.1209 -2.0363 -0.0460 -0.2178\n",
            "T-376\tbambo wina atanyamula chitenje akuyang ana chapatali ndi dzanja lake pakamwa\n",
            "H-376\t-0.2854698598384857\t▁ b a m b o ▁ w i n a ▁ a t a n y a m u l a ▁ c h i t e n g e ▁ a k u j a m b u l a ▁ c h a n a ▁ a t a l i ▁ n d i ▁ d z a n j a ▁ l a k e ▁ p a m w a m b a\n",
            "D-376\t-0.2854698598384857\tbambo wina atanyamula chitenge akujambula chana atali ndi dzanja lake pamwamba\n",
            "P-376\t-0.1097 -0.0331 -0.1108 -0.0432 -0.0769 -0.1435 -0.0995 -0.0424 -0.0975 -0.0816 -0.1274 -0.0930 -0.0811 -0.0770 -0.1082 -0.1179 -0.0177 -0.0739 -0.0290 -0.0713 -0.0514 -0.1018 -0.0971 -0.1616 -0.0554 -0.0655 -0.9121 -0.2512 -0.2892 -1.2581 -0.5810 -0.1833 -1.2261 -0.0965 -0.0842 -2.3792 -0.0871 -0.0562 -0.0749 -0.3979 -0.0624 -0.1289 -0.1134 -0.0626 -0.0980 -0.1447 -1.7335 -1.3063 -0.2887 -1.3886 -0.1975 -0.1132 -1.2114 -0.0750 -0.1401 -0.1817 -0.0592 -0.1426 -0.0904 -1.3501 -0.0915 -0.1088 -0.0222 -0.0038 -0.1184 -0.0958 -0.0187 -0.1427 -0.2063 -0.0173 -0.3997 -0.7124 -0.1120 -0.5615 -0.1876 -0.0823 -0.2642 -0.2439 -0.1284 -0.3869\n",
            "T-369\twosewera mpira wa tenesi yemwe wavala chovala chobiriwira kumutu ali wokonzeka kumenya mpira\n",
            "H-369\t-0.27211135625839233\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ y e m w e ▁ w a v a l a ▁ c h o v a l a ▁ c h o b i r i w i r a ▁ k u t u ▁ a l i ▁ p a l i ▁ z e n e r a ▁ k u m b u y o\n",
            "D-369\t-0.27211135625839233\twosewera mpira wa tenisi yemwe wavala chovala chobiriwira kutu ali pali zenera kumbuyo\n",
            "P-369\t-0.1093 -0.0523 -0.0459 -0.2184 -0.0855 -0.0308 -0.0722 -0.0392 -0.1159 -0.1065 -0.0287 -0.0137 -0.0668 -0.0437 -0.0938 -0.1196 -0.0344 -0.1560 -0.1438 -0.0864 -0.4727 -0.1798 -0.3134 -0.9569 -0.6505 -0.0946 -1.1376 -0.0799 -0.0323 -0.0798 -0.5522 -0.1180 -0.4826 -0.1718 -0.0225 -0.1395 -0.1460 -0.1383 -0.1112 -0.0275 -0.0849 -0.2399 -0.0712 -0.0640 -0.0813 -0.1289 -0.0958 -0.0192 -0.0745 -0.8169 -0.2481 -0.0406 -0.0548 -0.0834 -0.0324 -0.0479 -0.0433 -0.1397 -0.1251 -0.8148 -0.1336 -0.1928 -0.5253 -0.1733 -0.9502 -0.0139 -0.0468 -0.1086 -0.2375 -0.1401 -0.8317 -0.0749 -0.1210 -1.6693 -0.7638 -0.1123 -1.6233 -0.9099 -0.2422 -0.6486 -0.4509 -0.3042 -0.0905 -1.7322 -0.2643 -0.0492 -0.0482 -0.6104\n",
            "T-393\tgalu wa dalmation aluma kanthambi kakang ono pamtengo ali ndi miyendo yakumbuyo\n",
            "H-393\t-0.37884441018104553\t▁ g a l u ▁ w a b u l a u n i ▁ n d i ▁ w a n k h a l a ▁ n d i ▁ k a m w a ▁ m u n t h u ▁ p a m t e n g o ▁ a l i ▁ n d i ▁ n y u m b a ▁ k u m b u y o\n",
            "D-393\t-0.37884441018104553\tgalu wabulauni ndi wankhala ndi kamwa munthu pamtengo ali ndi nyumba kumbuyo\n",
            "P-393\t-0.1061 -0.0260 -0.1030 -0.0662 -0.1402 -0.0965 -0.0981 -0.6705 -1.8771 -0.0765 -0.0648 -0.0828 -0.0558 -0.0312 -0.0912 -0.1356 -0.2311 -0.0864 -0.0824 -0.1132 -1.2155 -0.5410 -0.7964 -1.3126 -0.1447 -0.1102 -0.3791 -0.3655 -0.1437 -1.1695 -0.1482 -0.0861 -0.1472 -0.4492 -0.1837 -0.3949 -2.2555 -0.2550 -0.2614 -1.3512 -1.0324 -0.3088 -0.5583 -0.0780 -0.4114 -0.0996 -1.2187 -0.0874 -0.2217 -1.0554 -0.0205 -0.0579 -0.0179 -0.0354 -0.0868 -2.5528 -0.0666 -0.0509 -0.0931 -0.0213 -0.0443 -0.1039 -0.0716 -0.8715 -2.1518 -0.0802 -0.3238 -0.1045 -0.1001 -0.3495 -0.2236 -0.0825 -0.1850 -0.0266 -0.0424 -0.0333 -0.0523 -0.6824\n",
            "T-158\tmayi wina amene wavala chovala akudumphira kavalo wabulauni pamwamba pa chinthu chooneka ngati ndege\n",
            "H-158\t-0.2676578760147095\t▁ m a y i ▁ w i n a ▁ a m e n e ▁ w o v a l a ▁ c h o v a l a ▁ k u d u m p h i r a ▁ p a b w a l o ▁ l a ▁ m w a m b a ▁ p a ▁ c h i p a l e ▁ c h o y e n d a ▁ n d i ▁ c h o y e r a\n",
            "D-158\t-0.2676578760147095\tmayi wina amene wovala chovala kudumphira pabwalo la mwamba pa chipale choyenda ndi choyera\n",
            "P-158\t-0.1034 -0.0805 -0.0769 -0.0441 -0.0972 -0.0870 -0.0720 -0.0802 -0.1025 -0.1086 -0.1139 -1.8768 -0.6136 -0.0720 -0.1034 -0.0920 -0.1030 -0.0571 -0.3177 -0.0204 -0.1164 -0.0852 -0.1207 -0.0982 -0.0480 -0.0812 -0.1414 -0.1914 -0.0908 -0.0573 -0.1339 -0.1069 -2.4545 -0.4287 -0.3383 -0.1272 -0.1649 -0.0181 -0.1261 -0.1520 -0.0393 -0.1142 -0.1006 -0.6842 -0.1041 -0.4282 -0.0272 -0.0827 -0.0824 -0.0373 -0.0957 -0.0972 -0.1743 -0.3201 -0.4104 -0.7499 -0.1272 -0.0640 -1.1638 -0.1198 -0.0948 -0.1700 -0.1015 -0.2446 -0.8567 -0.1056 -0.0687 -1.1374 -0.0948 -0.6486 -0.0503 -0.0622 -0.3332 -0.0967 -0.0279 -0.6349 -0.0667 -1.4168 -0.0312 -0.1770 -0.1735 -0.0901 -0.1765 -0.0719 -0.1261 -1.4856 -0.1053 -0.4680 -0.3200 -0.1330 -0.4452 -0.1449 -0.4061\n",
            "T-404\tbasi yaima mumsewu pomwe bambo wina akuyendetsa njinga ndipo wachiwiri akuyenda mumsewu\n",
            "H-404\t-0.308927059173584\t▁ b a s i ▁ l a ▁ i m a ▁ m u m s e w u ▁ p o m w e ▁ b a m b o ▁ w i n a ▁ a k u y e n d e t s a ▁ n j i n g a ▁ n d i p o ▁ a c h i k u l i r e ▁ a k u y e n d a ▁ m u m s e w u\n",
            "D-404\t-0.308927059173584\tbasi la ima mumsewu pomwe bambo wina akuyendetsa njinga ndipo achikulire akuyenda mumsewu\n",
            "P-404\t-0.0944 -1.9146 -0.1207 -1.0705 -0.1719 -0.0894 -0.7320 -0.2746 -0.9238 -1.1859 -0.0777 -0.1195 -0.2983 -0.1194 -0.4860 -0.3898 -0.0660 -0.1460 -0.0693 -0.0635 -0.0883 -0.6105 -0.8130 -0.0879 -0.1680 -0.0899 -0.0867 -1.2879 -0.2280 -0.1584 -0.0686 -0.0824 -0.1060 -0.0734 -0.0932 -0.0829 -0.1160 -0.1137 -0.6626 -0.1682 -0.0849 -0.4375 -0.1392 -0.1949 -0.0615 -2.1574 -0.0208 -0.0553 -0.2382 -0.0787 -0.2141 -0.2874 -0.0752 -0.0316 -0.0504 -0.1033 -0.1235 -1.1079 -0.1019 -0.0938 -0.9649 -0.0650 -0.1116 -0.3835 -0.6638 -0.1987 -0.0693 -0.3100 -2.1214 -0.3709 -0.0526 -0.1188 -0.2426 -0.1109 -0.7399 -0.2467 -0.1413 -0.2062 -0.0792 -0.0788 -0.0350 -0.1707 -0.1905 -0.1216 -0.3825 -0.1147 -0.2039 -0.1575 -0.0477 -0.0557 -0.0998\n",
            "T-142\tmunthu akukwera madzi pa bolodi limodzi atagwira pa chothandizira ndi dzanja limodzi\n",
            "H-142\t-0.29206612706184387\t▁ m u n t h u ▁ a k u k w e r a ▁ m a d z i ▁ p a b w a l o ▁ n d i ▁ m m o d z i ▁ a t a g w i r a ▁ c h i n t h u ▁ c h o t a n d i z i r a ▁ n d i ▁ z i m o d z i\n",
            "D-142\t-0.29206612706184387\tmunthu akukwera madzi pabwalo ndi mmodzi atagwira chinthu chotandizira ndi zimodzi\n",
            "P-142\t-0.1052 -0.1104 -0.1324 -0.0440 -0.0148 -0.0355 -0.0857 -0.1268 -0.6787 -0.0166 -0.1493 -0.0467 -0.3388 -0.2899 -0.0582 -0.0997 -0.1024 -0.9206 -0.6077 -0.5687 -0.0620 -0.0342 -0.1170 -0.6061 -0.1552 -0.8555 -0.3934 -0.0574 -0.1779 -0.0554 -0.1432 -0.2645 -0.0708 -0.0938 -0.0929 -0.1030 -1.2546 -0.2594 -0.0986 -0.0579 -0.0432 -0.0737 -0.1102 -1.0991 -0.1061 -0.3335 -0.2153 -0.1920 -0.0456 -0.1877 -0.0972 -1.0211 -0.0693 -0.1005 -1.6523 -0.0410 -0.2076 -0.1442 -0.1336 -0.8910 -0.0572 -0.9264 -0.2805 -1.4216 -0.2454 -0.2015 -0.0810 -0.2100 -0.0942 -0.2397 -0.2534 -0.1515 -0.0579 -0.0768 -0.0952 -0.0849 -0.6512 -0.9277 -1.6226 -0.0592 -0.1243 -0.0428 -0.0553 -0.3242\n",
            "T-343\tamuna awiri aima pamwamba pa thanthwe moyang anizana ndi gombe lamchenga\n",
            "H-343\t-0.23862050473690033\t▁ a m u n a ▁ a w i r i ▁ a i m a ▁ p a m w a m b a ▁ p a ▁ m o y a n g ▁ a n i z a n a ▁ n d i ▁ n g o l o ▁ a m a c h e n g a\n",
            "D-343\t-0.23862050473690033\tamuna awiri aima pamwamba pa moyang anizana ndi ngolo amachenga\n",
            "P-343\t-0.1120 -0.1023 -0.3369 -0.0743 -0.0969 -0.0997 -0.0996 -0.0921 -0.0448 -0.1118 -0.0816 -0.1033 -0.0944 -0.1047 -0.5248 -0.0374 -0.0963 -0.0894 -0.0798 -0.1408 -0.0941 -0.1507 -0.0934 -0.0670 -0.0470 -0.1256 -0.0934 -0.6497 -0.1582 -0.2937 -0.7670 -1.7186 -0.2093 -0.1173 -0.2191 -0.4101 -0.0950 -0.0774 -0.0587 -0.5586 -0.0055 -0.1018 -0.0282 -0.1281 -0.1502 -0.0360 -0.0736 -0.1871 -0.1384 -1.2973 -0.5198 -0.0317 -0.7569 -0.0905 -0.2495 -0.5314 -0.4060 -0.1067 -0.3568 -0.0683 -1.4697 -0.1156 -0.0082 -0.0630 -0.0630\n",
            "T-378\tmnyamata wina wothamanga wavala thukuta la teaal ndi malaya amtundu wa nike ndipo ali ndi racket ya tenisi\n",
            "H-378\t-0.3196903169155121\t▁ m n y a m a t a ▁ w i n a ▁ w o t h a m a n g a ▁ w a v a l a ▁ t h u k u t a ▁ l a ▁ j e a n ▁ n d i ▁ m a l a y a ▁ a m t u n d u ▁ w a i m a ▁ n d i p o ▁ a n t h u ▁ a k e ▁ n d i ▁ c h i n a c h a k e\n",
            "D-378\t-0.3196903169155121\tmnyamata wina wothamanga wavala thukuta la jean ndi malaya amtundu waima ndipo anthu ake ndi chinachake\n",
            "P-378\t-0.1055 -0.1192 -0.0834 -0.0345 -0.1096 -0.0794 -0.0953 -0.0403 -0.1195 -0.1017 -0.1229 -0.0679 -0.0833 -0.1156 -0.1111 -0.1336 -1.6737 -0.1787 -0.1885 -0.0774 -0.0226 -0.0776 -0.0537 -0.0314 -0.1099 -0.0791 -0.1730 -0.1781 -0.3869 -0.1185 -0.0847 -0.1184 -0.1052 -1.1901 -0.4188 -0.1110 -0.0304 -0.0831 -0.0304 -0.0742 -0.1305 -0.0599 -0.1255 -0.9420 -1.9260 -0.1208 -0.8206 -0.0325 -0.3611 -0.8656 -0.2444 -0.1590 -0.1349 -0.0205 -0.1479 -0.2681 -0.1378 -0.0486 -0.1383 -0.0654 -0.0862 -0.6186 -1.2373 -0.1122 -0.9307 -0.1029 -0.1389 -0.0995 -0.0700 -0.1324 -0.2710 -0.0762 -0.1477 -0.0655 -1.0772 -0.0930 -0.1066 -2.0179 -0.0871 -0.0882 -0.5857 -0.6832 -0.4188 -0.1857 -0.1381 -0.0963 -0.6544 -1.0845 -0.9619 -0.1200 -0.9705 -0.0541 -0.0830 -0.0757 -1.6170 -0.1075 -0.2222 -1.5645 -1.6939 -0.2636 -0.1028 -0.1042 -0.0480 -0.0419 -0.2634\n",
            "T-412\tgulu la anthu akuluakulu aimirira m bafa akuyang ana pansi mwana wamng ono akusamba\n",
            "H-412\t-0.29776066541671753\t▁ g u l u ▁ l a ▁ a n t h u ▁ l a k u y a n k h u l a ▁ n d i ▁ l a p a k a ▁ a k u y a n g ▁ a n a ▁ p a n j i n g a ▁ w a m n g ▁ o n o ▁ k u s a n g a l a l a\n",
            "D-412\t-0.29776066541671753\tgulu la anthu lakuyankhula ndi lapaka akuyang ana panjinga wamng ono kusangalala\n",
            "P-412\t-0.1151 -0.0613 -0.0693 -0.1342 -0.0739 -0.1007 -0.0806 -0.0937 -0.1247 -0.1801 -0.0288 -0.0186 -0.1551 -0.1578 -0.0897 -1.4528 -0.1545 -0.1967 -0.1577 -0.5039 -0.1071 -0.0473 -0.7694 -0.0391 -0.0966 -0.0833 -0.1349 -0.1407 -0.4257 -0.1771 -0.1069 -0.1505 -1.6359 -0.3459 -1.1185 -0.1934 -0.6438 -0.1951 -0.3865 -0.2186 -0.1414 -0.0729 -0.0264 -0.1263 -0.0478 -0.0729 -0.0773 -0.0924 -0.0716 -0.1406 -0.0831 -1.6916 -0.1488 -0.7807 -0.8652 -0.3729 -0.1695 -0.0623 -0.1097 -0.1345 -1.3164 -0.2411 -0.2643 -0.2290 -0.3853 -0.0548 -0.0461 -0.0609 -0.0769 -0.1991 -0.5650 -0.0900 -1.3931 -0.0738 -1.1267 -0.6268 -0.3972 -0.1310 -0.1165 -0.3765 -0.2270 -0.1653\n",
            " 69% 9/13 [00:20<00:07,  1.79s/it, wps=1409]T-400\tbambo wandevu wavala chovala chamutu chosokedwa chokhala ndi zithunzi za spiderman\n",
            "H-400\t-0.3025076389312744\t▁ b a m b o ▁ w a ▁ n d e v u ▁ w a v a l a ▁ c h o v a l a ▁ c h a ▁ m u n t h u ▁ c h o f i i r i r a ▁ c h o k h a l a ▁ n d i ▁ z i n t h u ▁ z a ▁ p a n s i\n",
            "D-400\t-0.3025076389312744\tbambo wa ndevu wavala chovala cha munthu chofiirira chokhala ndi zinthu za pansi\n",
            "P-400\t-0.0959 -0.1518 -0.1271 -0.0651 -0.0393 -0.0948 -0.1040 -0.0814 -0.0952 -0.6618 -2.5182 -0.0527 -0.3016 -0.6867 -0.0406 -0.0836 -0.0570 -0.2774 -0.1646 -0.1293 -0.1111 -0.1238 -0.1127 -0.0154 -0.0641 -0.2053 -0.0270 -0.1001 -0.0945 -0.1364 -0.1044 -0.0136 -0.0625 -0.1201 -0.6833 -0.5282 -0.9161 -0.7942 -0.0408 -0.1080 -0.1280 -0.1108 -0.5369 -0.0721 -0.1755 -0.0743 -0.6306 -0.5914 -0.0729 -1.0645 -0.2335 -0.1310 -0.1109 -2.0052 -0.0838 -0.0648 -0.0258 -0.0309 -0.1330 -0.1918 -0.1497 -0.0809 -0.0247 -0.1388 -0.1038 -0.0901 -0.2198 -0.0492 -0.2368 -0.0452 -0.0584 -0.0458 -0.1530 -0.0608 -0.1433 -0.4860 -2.2599 -0.1995 -0.3504 -0.7547 -0.1779 -2.3194\n",
            "T-23\twosewera mpira wa basketball akulendewera pamphepete pomwe mpira uli mudengu\n",
            "H-23\t-0.3272615373134613\t▁ w o s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ w o b i r i w i r a ▁ n d i ▁ t s i t s i ▁ l a p i n k i ▁ a k u m e n y a ▁ p i n k i\n",
            "D-23\t-0.3272615373134613\twosewera mpira wa basketball wobiriwira ndi tsitsi lapinki akumenya pinki\n",
            "P-23\t-0.1127 -0.0506 -0.1009 -0.0985 -0.0521 -0.0395 -0.0939 -0.0383 -0.1065 -0.1220 -0.0301 -0.0480 -0.0896 -0.0603 -0.0977 -0.1292 -0.1752 -0.1521 -0.3215 -0.1282 -0.2135 -0.0491 -0.1745 -0.1028 -0.0133 -0.0703 -0.0533 -0.0336 -1.4140 -0.1158 -1.0565 -0.5089 -2.6057 -0.0620 -0.0337 -0.0793 -0.0322 -0.0922 -0.0915 -0.1540 -0.1366 -0.5707 -0.2879 -0.0810 -0.1355 -1.6739 -1.2554 -0.1537 -0.1210 -0.1601 -0.2712 -0.0683 -0.1223 -0.1133 -0.8871 -0.2587 -1.8344 -0.2521 -0.0801 -0.1198 -0.5346 -0.2269 -0.1514 -0.1936 -1.1250 -0.0924 -0.1962 -0.5596 -0.1754 -2.2632 -0.2834 -0.4615 -0.0494 -0.1183 -0.5275\n",
            "T-419\tgulu la anthu ovala masuti laima mozungulira bambo wina wovala malaya apinki amene amaphunzitsa\n",
            "H-419\t-0.2554247975349426\t▁ g u l u ▁ l a ▁ a n t h u ▁ o v a l a ▁ m a s u t i ▁ a m a y e n d a ▁ m o z u n g u l i r a ▁ p a m b u y o ▁ w i n a ▁ a t a v a l a ▁ m a l a y a ▁ o y e n d a ▁ m ▁ m a d z i\n",
            "D-419\t-0.2554247975349426\tgulu la anthu ovala masuti amayenda mozungulira pambuyo wina atavala malaya oyenda m madzi\n",
            "P-419\t-0.1013 -0.0980 -0.0584 -0.1166 -0.0746 -0.1011 -0.0414 -0.0972 -0.0994 -0.1066 -0.0349 -0.0634 -0.1075 -0.1053 -0.0944 -0.0760 -0.0237 -0.1149 -0.0876 -0.1284 -0.1118 -0.0753 -0.2061 -0.4430 -0.1772 -0.0591 -0.0558 -0.0891 -0.0814 -0.6066 -0.2145 -0.7048 -0.7163 -0.1815 -0.2430 -0.0936 -0.1420 -0.0762 -0.7007 -0.0649 -0.0509 -0.0215 -0.0285 -0.0271 -0.0395 -0.0674 -0.0390 -0.1150 -0.1220 -0.3840 -0.1324 -0.1008 -1.6079 -1.4985 -0.1923 -0.1660 -0.0731 -1.1221 -0.0578 -0.0814 -0.1035 -0.1151 -0.9912 -0.7771 -0.1038 -0.0490 -0.1196 -0.1052 -0.1204 -0.1020 -0.1028 -0.1970 -0.1946 -0.1168 -0.0508 -0.1022 -0.0661 -0.8279 -0.3627 -0.2683 -0.8693 -0.0977 -0.6632 -0.1366 -0.7947 -0.1616 -0.3590 -0.3715 -1.5495 -0.0845 -0.0796 -0.7548\n",
            "T-367\tmunthu watsitsi lofiira ndi malaya akuda waima panja akulankhula ndi manja ndi manja\n",
            "H-367\t-0.1879153549671173\t▁ m u n t h u ▁ w a t s i t s i ▁ l o f i i r a ▁ n d i ▁ m a l a y a ▁ a k u d a ▁ w a i m a ▁ p a n j a ▁ a k u y a n g ▁ a n a ▁ n d i ▁ m a n j a\n",
            "D-367\t-0.1879153549671173\tmunthu watsitsi lofiira ndi malaya akuda waima panja akuyang ana ndi manja\n",
            "P-367\t-0.1091 -0.0974 -0.0703 -0.0542 -0.0281 -0.0515 -0.0920 -0.1295 -0.1001 -0.6080 -0.7853 -0.0524 -0.0736 -0.0391 -0.0245 -0.0817 -0.1058 -0.2372 -0.0491 -0.0657 -0.0597 -0.1012 -0.0534 -1.1505 -0.1140 -0.1248 -0.0703 -0.1581 -0.1018 -0.1148 -0.0956 -0.1367 -0.1238 -0.0530 -0.1012 -0.0962 -1.3236 -0.1414 -0.1029 -0.0339 -0.0901 -0.0977 -0.2231 -0.1954 -0.7782 -0.0268 -0.0811 -0.0826 -0.1639 -0.1067 -0.0829 -0.0128 -0.0802 -0.1847 -0.1117 -0.0733 -0.1496 -0.5358 -0.2914 -0.0427 -0.6889 -0.0856 -0.0842 -0.0344 -0.5857 -0.1445 -0.1390 -0.5388 -0.1365 -0.1008 -0.1031 -0.1318 -0.0489 -0.0107 -0.1469 -0.7798\n",
            "T-172\tatsikana awiri achichepere ovala madiresi a denim akusewera pafupi ndi mpando wakumanja\n",
            "H-172\t-0.2479601949453354\t▁ a t s i k a n a ▁ a w i r i ▁ a c h i c h e p e r e ▁ o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ m a t e n g e ▁ a k u s e w e r a ▁ p a f u p i ▁ n d i ▁ m a l o ▁ a k u m a n j a\n",
            "D-172\t-0.2479601949453354\tatsikana awiri achichepere ovala malaya ofiira ndi matenge akusewera pafupi ndi malo akumanja\n",
            "P-172\t-0.1091 -0.1202 -0.0565 -0.0725 -0.0806 -0.0220 -0.1203 -0.0435 -0.1417 -0.0871 -0.1018 -0.0612 -0.1006 -0.0578 -0.0887 -0.0965 -0.1278 -0.4593 -0.0783 -0.0893 -0.7271 -0.1212 -0.0772 -0.0233 -0.1878 -0.1963 -0.2177 -0.1128 -0.4709 -0.8003 -0.1124 -0.0843 -0.1228 -0.0902 -0.0381 -0.1111 -0.9742 -0.1170 -0.1398 -0.1296 -0.0764 -0.1428 -1.7224 -0.1108 -0.1727 -0.0533 -0.2649 -0.0905 -1.7761 -0.0607 -0.0950 -0.0678 -0.3236 -0.2596 -0.6550 -0.0994 -0.7167 -0.3923 -0.3515 -0.1162 -0.2616 -0.0721 -0.1477 -0.0788 -0.0250 -0.0255 -0.0504 -0.0626 -0.1439 -0.0881 -0.0800 -0.1766 -1.8530 -0.0367 -0.0407 -0.0675 -0.0833 -0.0294 -0.0608 -0.0977 -0.0735 -0.2830 -0.3046 -1.2430 -0.1904 -0.1508 -0.1496 -0.9465 -0.5031 -0.6002 -0.5221 -0.0238 -0.2693 -0.1047 -0.1936\n",
            "T-102\tgalu woyera watsitsi lalitali ali m dera lomwe lili ndi masamba abulauni akugwa\n",
            "H-102\t-0.27629968523979187\t▁ g a l u ▁ w o y e r a ▁ w a t s i t s i ▁ l a l i t a l i ▁ l a l i t a l i ▁ l o m w e ▁ l i l i ▁ n d i ▁ m a s a m b a ▁ a k u l a n k h u l a\n",
            "D-102\t-0.27629968523979187\tgalu woyera watsitsi lalitali lalitali lomwe lili ndi masamba akulankhula\n",
            "P-102\t-0.1005 -0.0185 -0.1071 -0.0713 -0.1036 -0.1080 -0.2620 -0.3241 -0.0239 -0.1190 -0.0771 -0.0876 -0.1113 -0.2760 -0.2753 -1.3792 -0.0199 -0.0590 -0.0582 -0.0471 -0.0595 -0.0940 -0.3240 -0.1132 -0.0208 -0.0559 -0.0113 -0.0974 -0.0180 -0.0621 -0.1029 -0.5752 -0.0879 -1.2832 -0.0832 -2.2711 -1.1170 -0.1129 -0.1192 -0.1224 -0.6610 -0.0781 -0.1491 -0.3493 -0.1053 -0.0777 -0.3381 -0.0835 -0.0838 -0.1097 -0.1186 -0.9666 -0.1338 -0.0908 -0.1045 -0.1460 -0.1103 -0.2429 -0.1352 -0.0649 -0.0232 -0.1068 -0.0984 -0.1079 -2.1395 -0.1074 -1.6550 -0.4830 -0.0802 -0.1853 -0.0397 -0.0382 -0.0381 -0.1809 -0.9297\n",
            "T-237\tgalu wakuda akuyandikira kamera ndi miyendo yake yakumbuyo ndi makutu ake kutsogolo\n",
            "H-237\t-0.26247236132621765\t▁ g a l u ▁ w a k u d a ▁ a k u y e n d a ▁ k a m e r a ▁ n d i ▁ m i y a l a ▁ y a k e ▁ y a k u m b u y o ▁ n d i ▁ m a k u t u ▁ a k e ▁ k u t s o g o l o\n",
            "D-237\t-0.26247236132621765\tgalu wakuda akuyenda kamera ndi miyala yake yakumbuyo ndi makutu ake kutsogolo\n",
            "P-237\t-0.1071 -0.0191 -0.0950 -0.0517 -0.1406 -0.0988 -0.0540 -0.1969 -0.0738 -0.1012 -0.1021 -0.1473 -0.1069 -1.5226 -0.0474 -0.1409 -0.1548 -0.7285 -0.0862 -0.0478 -1.0473 -0.1079 -1.4469 -0.3427 -0.1430 -0.1653 -0.0444 -0.1022 -0.1163 -0.4049 -0.0928 -0.1156 -0.0829 -0.2662 -0.2539 -0.5484 -0.2906 -0.1598 -0.0873 -0.0990 -0.3073 -0.1263 -0.5391 -0.1568 -0.0797 -0.0216 -0.1213 -0.5784 -0.1828 -0.3786 -0.3849 -0.1545 -0.0755 -0.0619 -0.1043 -0.1557 -0.0737 -0.0936 -0.1601 -0.1524 -0.1015 -1.5292 -1.1382 -0.1370 -0.0330 -0.2074 -0.1049 -1.7968 -0.1937 -0.2340 -0.2490 -0.0436 -0.2843 -0.1586 -0.0356 -0.0070 -0.0881 -0.0589 -0.1000 -0.6486\n",
            "T-226\tanthu angapo atakhala pamipando yopindika pafupi ndi mapangidwe a geological\n",
            "H-226\t-0.309354692697525\t▁ a n t h u ▁ a n g a p o ▁ a t a k h a l a ▁ p a m i t u n d u ▁ y o p i n d i k a ▁ p a f u p i ▁ n d i ▁ m a t h a n d i z i ▁ a l i ▁ n d i ▁ l o t c h i\n",
            "D-226\t-0.309354692697525\tanthu angapo atakhala pamitundu yopindika pafupi ndi mathandizi ali ndi lotchi\n",
            "P-226\t-0.1132 -0.0959 -0.2922 -0.0266 -0.0365 -0.0855 -0.1072 -0.0958 -0.7897 -0.1564 -0.0976 -0.0200 -0.0540 -0.1037 -0.0888 -0.0580 -0.1269 -0.3709 -0.0314 -0.1131 -0.0430 -0.0997 -0.1117 -0.0468 -0.1131 -0.5691 -0.4547 -0.4297 -0.4357 -0.0630 -0.0168 -0.1398 -0.2950 -0.1862 -0.0283 -0.0349 -0.7217 -0.0766 -0.2124 -0.2726 -0.1075 -0.1554 -0.1776 -0.4685 -0.1188 -1.2071 -0.0450 -0.0154 -0.0561 -0.0996 -0.0677 -0.0901 -0.0763 -0.0869 -0.2762 -0.1240 -0.5945 -0.5006 -0.0941 -2.3305 -0.4860 -0.0814 -0.7267 -1.4248 -0.1314 -0.2234 -0.4383 -0.1528 -0.1314 -0.5249 -0.0441 -0.0661 -0.1345 -2.5853 -0.0871 -1.0154 -1.7978 -0.2217 -0.1152 -0.4543\n",
            "T-240\tmwana wovala chijasi chofiyira ndi chipewa chanyamula chipale chofewa chachikulu\n",
            "H-240\t-0.3313964307308197\t▁ m w a n a ▁ w o v a l a ▁ c h i j a s i ▁ c h o y e r a ▁ n d i ▁ c h i p e w a ▁ c h a ▁ c h i p a n g a ▁ c h a ▁ m u n a ▁ c h o f e w a ▁ c h a c h i k u l u\n",
            "D-240\t-0.3313964307308197\tmwana wovala chijasi choyera ndi chipewa cha chipanga cha muna chofewa chachikulu\n",
            "P-240\t-0.1077 -0.0762 -0.4469 -0.1474 -0.0994 -0.1011 -0.1325 -0.0919 -0.0606 -0.4726 -0.1347 -0.1152 -0.1225 -0.1198 -0.0729 -0.0507 -0.0890 -1.2333 -0.1300 -1.3932 -0.1473 -0.0974 -0.0491 -0.0514 -0.1149 -1.1176 -0.4850 -0.9309 -0.1144 -0.1802 -1.5049 -0.1342 -0.0861 -0.0870 -0.8157 -0.0819 -0.0739 -0.9118 -0.4964 -0.2304 -0.1264 -0.1152 -0.0337 -0.0665 -0.5329 -0.6684 -1.3390 -0.1508 -0.0773 -0.4880 -0.3061 -0.8929 -1.0745 -0.4006 -0.1410 -0.0380 -0.0561 -0.3751 -0.9372 -0.2646 -0.4179 -0.3552 -0.3706 -0.2389 -0.9649 -0.0615 -0.5641 -0.5213 -0.6852 -0.1413 -0.1275 -0.2545 -0.0364 -0.0493 -0.4144 -0.5049 -0.0491 -0.0302 -0.0308 -0.0877 -0.0108 -0.0458 -0.5512\n",
            "T-252\tmunthu akuyika pa zenera kunja kwa nyumba yozunguliridwa ndi malalanje ochenjeza\n",
            "H-252\t-0.26228126883506775\t▁ m u n t h u ▁ a k u y e n d a ▁ p a z e n e r a ▁ k u n j a ▁ k w a ▁ n y u m b a ▁ y o z u n g u l i r i d w a ▁ n d i ▁ m a l o ▁ o c h e z a\n",
            "D-252\t-0.26228126883506775\tmunthu akuyenda pazenera kunja kwa nyumba yozunguliridwa ndi malo ocheza\n",
            "P-252\t-0.1081 -0.0736 -0.0307 -0.0831 -0.0366 -0.0370 -0.0779 -0.1341 -0.0963 -0.0866 -0.1066 -0.9235 -0.8601 -0.3455 -0.2009 -0.1084 -0.1191 -0.3126 -0.1563 -0.6206 -1.0288 -0.1023 -1.8239 -0.1466 -0.1256 -0.1353 -0.0250 -0.1062 -0.5772 -0.0477 -0.0743 -0.1152 -0.0281 -0.1019 -0.1036 -0.1090 -1.0177 -0.0348 -0.0232 -0.0654 -0.0415 -0.1153 -0.1305 -1.9185 -0.0949 -0.0205 -0.0356 -0.0298 -0.0209 -0.0770 -0.0650 -0.0850 -0.1168 -0.2128 -0.0877 -0.0278 -0.1411 -0.1243 -0.7016 -0.2535 -0.1017 -0.1325 -0.0656 -0.1031 -0.8406 -1.0051 -0.1340 -0.0716 -0.4338 -0.1415 -0.2248 -0.3575 -0.4586 -0.7290\n",
            "T-119\tmwamuna wovala chijasi chofiira amasainira mapepala kwa mwamuna wina wovala malaya abuluu\n",
            "H-119\t-0.2563195824623108\t▁ m w a m u n a ▁ w o v a l a ▁ c h i j a s i ▁ c h o f i i r a ▁ a m a i m i r i r a ▁ p a ▁ p h i r a ▁ l a k e ▁ p a m w a m b a ▁ w i n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u\n",
            "D-119\t-0.2563195824623108\tmwamuna wovala chijasi chofiira amaimirira pa phira lake pamwamba wina wovala malaya abuluu\n",
            "P-119\t-0.1044 -0.5772 -0.1563 -0.0958 -0.0548 -0.0646 -0.0782 -0.1031 -0.1123 -0.1616 -0.0987 -0.2611 -0.1165 -0.1121 -0.1093 -0.1112 -0.2342 -0.0746 -0.0821 -1.1432 -0.1754 -0.1375 -0.1041 -0.0925 -0.1027 -0.0672 -0.0239 -0.0341 -0.0791 -0.7927 -0.0719 -0.2340 -0.1302 -0.0867 -0.2490 -0.0882 -1.3275 -0.1040 -0.1860 -0.2201 -0.1571 -0.0379 -0.1068 -0.0952 -0.0223 -0.1098 -1.4423 -0.9824 -0.6330 -1.0076 -0.0333 -0.8169 -0.1673 -0.1197 -0.1311 -0.7696 -1.0528 -0.0889 -0.8037 -0.1314 -0.0958 -0.7734 -0.0902 -0.0648 -0.0876 -0.0953 -0.1137 -1.6263 -0.1609 -0.0474 -0.1271 -0.1313 -1.2385 -0.3113 -0.0214 -0.1124 -0.1081 -0.1117 -0.1666 -0.1914 -0.0961 -0.0991 -0.1028 -0.0306 -0.0976 -0.3073 -0.1298 -0.0182 -0.1024 -0.1344 -0.0532 -0.0617 -0.0621\n",
            "T-37\tanthu atatu akuchita masewera olimbitsa thupi a ballet atavala zovala zapamwamba\n",
            "H-37\t-0.3071592152118683\t▁ a n t h u ▁ a t a t u ▁ a k u c h i t a ▁ m a s e w e r a ▁ o l i m b i t s a ▁ t h u p i ▁ y a ▁ b a s e b a l l ▁ a t a v a l a ▁ z o v a l a ▁ z a m a g a l a s a\n",
            "D-37\t-0.3071592152118683\tanthu atatu akuchita masewera olimbitsa thupi ya baseball atavala zovala zamagalasa\n",
            "P-37\t-0.0971 -0.1156 -0.0590 -0.0272 -0.0550 -0.0727 -0.1021 -0.2424 -0.0503 -0.0853 -0.0280 -0.0471 -0.0845 -0.2886 -0.0343 -0.1315 -2.1435 -0.0545 -0.0546 -0.0279 -0.1200 -0.0827 -0.0186 -0.2024 -0.0212 -0.1236 -0.0528 -0.1010 -0.0425 -0.0939 -0.1111 -0.1063 -1.8164 -0.1008 -0.1155 -0.0148 -0.1101 -0.0472 -0.0258 -0.1157 -0.0717 -0.1585 -0.2333 -0.0576 -0.0300 -0.1042 -0.1101 -0.1648 -0.1220 -0.6989 -1.1445 -0.1849 -1.8769 -0.4474 -0.1637 -0.0711 -0.0246 -0.0858 -0.2207 -0.2956 -0.4306 -0.1483 -1.6532 -0.8289 -0.0649 -0.1195 -0.1028 -0.1301 -0.0773 -2.1028 -0.0781 -0.0843 -0.1266 -0.1156 -0.0131 -0.4565 -1.5413 -0.8852 -1.1104 -0.1561 -0.0905 -0.1289 -0.0346 -0.4973 -1.6414\n",
            "T-200\tmnyamata wovala kabudula wofiira akudumphira mumtsinje pamene ana ena akusambira\n",
            "H-200\t-0.23905900120735168\t▁ m n y a m a t a ▁ w o v a l a ▁ k a b u d u l a ▁ w o f i i r a ▁ a k u d u m p h i r a ▁ m u m s e w u ▁ p a m e n e ▁ a n y a n j a ▁ a k u s a m b i r a\n",
            "D-200\t-0.23905900120735168\tmnyamata wovala kabudula wofiira akudumphira mumsewu pamene anyanja akusambira\n",
            "P-200\t-0.1218 -0.0433 -0.1158 -0.0367 -0.1105 -0.0580 -0.1018 -0.0261 -0.1005 -0.1230 -0.0761 -0.0767 -0.0409 -0.1105 -0.0935 -0.1115 -0.1206 -1.1996 -0.4120 -0.0733 -0.1197 -0.0364 -0.1133 -0.0647 -0.1369 -0.1525 -0.0910 -0.1867 -0.9590 -0.0424 -0.0759 -0.0452 -0.1774 -0.1223 -0.7917 -0.0310 -0.1537 -0.1254 -0.0483 -0.1471 -0.0422 -0.0477 -0.1263 -0.0161 -0.1215 -0.1284 -0.0747 -1.4712 -0.3172 -0.8597 -0.5805 -0.4731 -0.0297 -0.1661 -0.2550 -0.1280 -0.3579 -0.0857 -0.0655 -0.0840 -0.1283 -0.6413 -0.4059 -0.6543 -0.1394 -0.8989 -0.8408 -0.1462 -0.2940 -1.5893 -0.0609 -0.2617 -0.0325 -0.3929 -0.0911 -0.0377 -0.0380 -0.0562 -0.0791 -0.1327\n",
            "T-327\tmtsikana wovala malaya amaluwa ndi jinzi waima pagombe lamiyala akuyang ana kumadzi\n",
            "H-327\t-0.2582932114601135\t▁ m t s i k a n a ▁ w o v a l a ▁ m a l a y a ▁ a m i l u w a ▁ n d i ▁ j i n z i ▁ w a i m a ▁ p a m o d z i ▁ p a m e n e ▁ a k u y a n g ▁ a n a ▁ k u y a n g ▁ a n a\n",
            "D-327\t-0.2582932114601135\tmtsikana wovala malaya amiluwa ndi jinzi waima pamodzi pamene akuyang ana kuyang ana\n",
            "P-327\t-0.1175 -0.7440 -0.0176 -0.1751 -0.0399 -0.0458 -0.0984 -0.0445 -0.1212 -0.1036 -0.0857 -0.0907 -0.2678 -0.1179 -0.1085 -0.1295 -0.1022 -0.0659 -0.1185 -0.0722 -0.1395 -0.0384 -0.1134 -0.0951 -0.1651 -0.6074 -0.7845 -1.3649 -0.3743 -1.2600 -0.1438 -0.1168 -0.0396 -0.0598 -0.0982 -0.1128 -0.2372 -0.5282 -0.0330 -0.1059 -0.0613 -0.0774 -0.6131 -0.1524 -0.1636 -0.0710 -0.0953 -0.0745 -0.0086 -0.0985 -1.3058 -0.6176 -1.0378 -0.2479 -0.0793 -0.0982 -1.5967 -0.1146 -0.1339 -0.4195 -0.0777 -0.0371 -0.0849 -0.2481 -0.8297 -0.0948 -0.0136 -0.1423 -0.0350 -0.3629 -0.0812 -0.0791 -0.0707 -0.1650 -0.1531 -0.1103 -0.0872 -1.3484 -0.1015 -0.0646 -0.1552 -0.1032 -0.0865 -0.0721 -0.1105 -1.3473\n",
            "T-168\tmtsikana wina akudumpha m manja mwa munthu wina yemwe ali m dziwe lomwe lili pafupi ndi nyanja\n",
            "H-168\t-0.2498769462108612\t▁ m t s i k a n a ▁ w i n a ▁ a k u d u m p h a ▁ m ▁ n y a n j a ▁ m ▁ m a n j a ▁ m u m t u n d a ▁ y e m w e ▁ a l i ▁ m ▁ d z i w e ▁ l o m w e ▁ l i l i ▁ p a f u p i ▁ n d i ▁ n y a n j a\n",
            "D-168\t-0.2498769462108612\tmtsikana wina akudumpha m nyanja m manja mumtunda yemwe ali m dziwe lomwe lili pafupi ndi nyanja\n",
            "P-168\t-0.1174 -0.0317 -0.1067 -0.0283 -0.0409 -0.0339 -0.1167 -0.0651 -0.1086 -0.1010 -0.5248 -0.0903 -0.0868 -0.1338 -0.0953 -0.2528 -0.0391 -0.1463 -0.0505 -0.0694 -0.0423 -0.0176 -0.0437 -0.0819 -0.1336 -0.2265 -0.1070 -2.1123 -0.4121 -0.4337 -0.2104 -0.0501 -0.1237 -0.1398 -0.2963 -0.8705 -0.0418 -0.3068 -0.2791 -0.6642 -0.1368 -0.1222 -0.8601 -0.6971 -0.9317 -1.8601 -0.2716 -0.2931 -0.0553 -0.1285 -0.1103 -1.3451 -0.5682 -0.0812 -0.0161 -0.1069 -0.0911 -0.1760 -0.0237 -0.0908 -0.1028 -1.1693 -0.1507 -1.5429 -0.1216 -0.0527 -0.0307 -0.0340 -0.0805 -0.3559 -0.0489 -0.0617 -0.0184 -0.0700 -0.0849 -0.1887 -0.0776 -0.0818 -0.0768 -0.1276 -0.4991 -0.1175 -0.1641 -0.0414 -0.0322 -0.0596 -0.1595 -0.0194 -0.1681 -0.0849 -0.1062 -1.0078 -0.2119 -0.1425 -0.1926 -0.0249 -0.1043 -0.0757\n",
            "T-290\tazimayi angapo amitundu ya pastel amaima pamzere wina atanyamula mwana pamapewa ake\n",
            "H-290\t-0.32781556248664856\t▁ m t s i k a n a ▁ y e m w e ▁ a l i ▁ p a m t u n d u ▁ y a ▁ s k a t e b o a r d ▁ a t a y i m a ▁ p a m z e r e ▁ w i n a ▁ a t a n y a m u l a ▁ m a n j a ▁ m w a k e\n",
            "D-290\t-0.32781556248664856\tmtsikana yemwe ali pamtundu ya skateboard atayima pamzere wina atanyamula manja mwake\n",
            "P-290\t-0.1127 -0.0742 -1.1249 -0.0335 -0.2549 -0.0541 -0.0967 -0.0790 -0.1054 -0.1238 -1.1113 -0.0892 -1.4476 -0.1880 -0.1530 -0.0792 -0.1457 -1.8897 -0.4413 -0.1146 -1.9500 -0.3270 -0.5714 -0.6636 -0.2974 -0.0389 -0.0320 -0.5611 -0.1043 -0.2021 -0.1839 -0.4406 -0.2594 -0.4874 -0.0514 -0.0507 -0.0264 -0.1394 -0.1417 -0.0915 -0.0444 -0.0598 -0.1143 -0.6683 -1.9475 -0.0948 -0.6520 -0.5105 -0.0685 -0.2528 -0.0945 -0.3957 -0.1178 -0.4000 -0.1852 -0.0896 -0.1255 -0.0429 -0.0848 -0.4562 -0.0920 -0.0761 -0.1203 -0.1185 -0.4451 -0.5186 -0.0855 -0.2577 -0.0177 -0.1344 -0.0270 -0.1158 -0.0654 -0.1218 -0.0850 -0.6848 -0.7806 -1.3520 -0.2756 -0.0832 -0.1186 -0.8883 -0.0805 -0.1196 -0.0640 -0.0427 -1.0051\n",
            "T-58\twoyenda panjinga atavala chisoti chakuda ndi jekete yabuluu amalumphira pa mulu wa m munda\n",
            "H-58\t-0.2397610992193222\t▁ w o y e n d a ▁ p a n j i n g a ▁ a t a v a l a ▁ c h i s o t i ▁ c h a k u d a ▁ n d i ▁ j e k e t e ▁ y a k u d a ▁ p a m a l o ▁ o f i i r a ▁ a k u y a n g ▁ a n a\n",
            "D-58\t-0.2397610992193222\twoyenda panjinga atavala chisoti chakuda ndi jekete yakuda pamalo ofiira akuyang ana\n",
            "P-58\t-0.1011 -0.1623 -0.1254 -0.0503 -0.3026 -0.0620 -0.0098 -0.0822 -0.1160 -0.0642 -0.1180 -0.1695 -0.3920 -0.0742 -0.0376 -0.0517 -0.0885 -0.1290 -0.8945 -0.0187 -0.1040 -0.0282 -0.1085 -0.1041 -0.1072 -0.1069 -0.0559 -0.0836 -0.0792 -0.2866 -0.0595 -0.0168 -0.0593 -0.0867 -0.0098 -0.0642 -0.1246 -0.3727 -0.0930 -0.0564 -0.9977 -0.1147 -0.2290 -0.1242 -0.1042 -0.1400 -0.5386 -0.6975 -0.2056 -0.0639 -0.0375 -0.0731 -0.1029 -0.3096 -0.1374 -1.2607 -0.2087 -0.2079 -0.3439 -0.1065 -1.1343 -0.0867 -0.0646 -0.2177 -0.2581 -0.0798 -0.0704 -0.6859 -1.4883 -0.0686 -0.1644 -0.0463 -0.1638 -0.1247 -0.2025 -1.3139 -0.1528 -0.9711 -0.2092 -0.0850 -0.1061 -0.0646 -0.1137 -0.0951 -0.1233 -1.4681\n",
            "T-191\tgalu wokhala ndi malaya abulauni ndi oyera amathamanga m munda wa udzu wobiriwira kwambiri\n",
            "H-191\t-0.2646503746509552\t▁ g a l u ▁ w o k h a l a ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ w o y e r a ▁ a t a m a n g a ▁ m u n d a ▁ w a u d z u ▁ w a i m i r i r a ▁ k u m b u y o ▁ k w a m b i r i\n",
            "D-191\t-0.2646503746509552\tgalu wokhala ndi malaya oyera ndi woyera atamanga munda waudzu waimirira kumbuyo kwambiri\n",
            "P-191\t-0.0990 -0.0610 -0.1129 -0.0518 -0.0770 -0.0911 -0.0935 -0.0779 -0.1672 -0.0556 -0.1111 -0.0738 -0.1202 -0.0981 -0.0274 -0.0586 -0.1061 -0.0735 -0.0585 -0.1051 -0.1671 -0.1132 -0.0248 -0.0934 -0.0842 -1.1899 -1.4822 -0.1157 -0.0788 -0.1004 -0.1149 -0.0323 -0.0724 -0.0929 -0.1577 -0.3069 -0.0343 -0.0276 -0.1306 -0.1692 -0.1225 -0.1128 -0.1047 -0.4810 -0.1561 -1.4489 -0.2285 -0.1211 -0.2131 -0.1048 -0.0921 -0.1057 -0.7980 -0.9727 -0.1873 -0.2223 -0.0799 -0.0252 -0.1027 -1.8595 -0.3941 -0.1658 -0.0430 -0.0836 -0.0488 -0.9709 -0.0736 -0.0909 -2.3516 -0.1915 -0.0502 -0.0694 -0.0902 -0.2152 -2.3198 -0.1482 -0.3268 -0.0201 -1.0075 -0.0616 -0.1014 -0.1882 -0.2197 -0.0177 -0.1072 -0.5205 -0.0215 -0.0610 -0.0145 -0.1027 -0.1588\n",
            "T-51\tgalu wakuda ndi wakhungu akusewera ndi chidole ndikugudubuzika paudzu\n",
            "H-51\t-0.2846487760543823\t▁ g a l u ▁ w a k u d a ▁ n d i ▁ w a b u l a u n i ▁ a k u s e w e r a ▁ n d i ▁ c h i d o l e ▁ c h o k u t i d w a ▁ p a u d z u\n",
            "D-51\t-0.2846487760543823\tgalu wakuda ndi wabulauni akusewera ndi chidole chokutidwa paudzu\n",
            "P-51\t-0.1065 -0.1607 -0.1116 -0.0973 -0.0975 -0.1065 -0.1359 -0.1363 -0.1269 -0.1151 -0.1352 -0.1017 -0.1023 -0.0235 -0.0577 -0.1153 -0.1163 -0.0106 -0.1014 -2.5279 -0.0942 -0.1024 -0.6737 -0.0438 -0.0781 -0.1342 -0.1144 -0.0622 -0.0234 -0.1284 -0.8106 -0.0277 -0.0331 -0.0824 -0.0522 -0.1335 -0.0882 -0.1008 -0.1581 -0.1366 -0.2910 -0.4578 -0.1173 -0.0858 -1.7422 -0.0631 -0.0133 -0.0385 -0.0970 -1.1276 -0.2125 -0.2243 -0.8272 -0.2718 -0.4357 -1.5659 -0.3591 -0.0482 -0.0800 -0.1260 -0.9164 -0.1105 -1.6274 -0.1185 -0.0559 -0.1758 -0.3189\n",
            "T-421\tmkazi wanyamula mwana pamene mwamuna akumuyang ana ngati mwamuna wina atanyamula mwana akuyang ana\n",
            "H-421\t-0.29347723722457886\t▁ m t s i k a n a ▁ w a m n g ▁ o n o ▁ a m a k h a l a ▁ p a m e n e ▁ m w a m u n a ▁ w i n a ▁ a t a n y a m u l a ▁ c h i n a c h a k e ▁ m n y a m a t a ▁ w i n a ▁ a k u y a n g ▁ a n a\n",
            "D-421\t-0.29347723722457886\tmtsikana wamng ono amakhala pamene mwamuna wina atanyamula chinachake mnyamata wina akuyang ana\n",
            "P-421\t-0.1051 -0.0738 -1.3604 -0.2772 -0.1166 -0.1054 -0.0881 -0.0796 -0.1043 -0.1122 -0.2798 -0.6494 -0.5055 -0.0433 -0.4369 -0.0879 -0.1280 -0.1411 -0.0648 -0.1329 -0.4759 -0.6351 -0.1076 -2.7970 -0.5583 -0.1032 -0.0810 -0.0970 -0.1283 -0.7011 -0.0897 -0.0764 -0.7943 -0.1772 -0.1182 -0.0743 -0.8613 -0.4476 -0.2683 -0.1935 -0.1004 -0.0757 -0.1411 -0.0963 -1.8087 -0.0691 -0.0845 -0.1473 -0.1091 -0.2566 -0.1768 -0.2567 -0.7055 -1.2673 -0.0892 -0.0818 -0.2150 -0.1036 -0.1199 -0.1148 -1.1440 -0.1244 -0.0780 -0.1141 -1.0551 -0.7383 -0.1198 -0.1600 -0.3016 -0.0486 -0.1127 -0.3910 -0.4595 -0.0522 -0.1672 -0.0955 -0.1301 -0.0264 -0.0902 -0.1065 -1.5707 -0.0737 -0.0995 -0.1139 -0.2006 -0.1756 -0.0969 -0.0595 -0.0254 -0.1038 -0.0538 -0.0591 -0.1307 -0.0769 -0.0534 -0.1242 -0.2375\n",
            "T-426\tkayaker atanyamula nkhafi akukweza manja ake onse m mwamba pamene mafunde akuwomba mozungulira\n",
            "H-426\t-0.33563554286956787\t▁ k a g a l u ▁ k a k a n g ▁ o n o ▁ k a ▁ m p i r a ▁ a k u k w e r a ▁ n j i n g a ▁ y a m o t o ▁ p a m e n e ▁ m a t h a m a n g a ▁ a k u m w e t u l i r a ▁ m o z u n g u l i r a\n",
            "D-426\t-0.33563554286956787\tkagalu kakang ono ka mpira akukwera njinga yamoto pamene mathamanga akumwetulira mozungulira\n",
            "P-426\t-0.1071 -0.2447 -0.2699 -2.4130 -0.1150 -0.0596 -0.5075 -0.0888 -0.5437 -0.1328 -0.8395 -0.2121 -0.2192 -1.4756 -0.0946 -0.0894 -0.1238 -0.0472 -0.1020 -0.3493 -0.2317 -0.3083 -0.6899 -0.2659 -0.0716 -0.2379 -0.1101 -0.1339 -0.4345 -0.0674 -0.0936 -0.7925 -0.0398 -0.0521 -0.0622 -0.0999 -0.1503 -0.7364 -0.2573 -0.3640 -0.2757 -0.0522 -0.0800 -0.1149 -1.4853 -0.2424 -0.4699 -0.6995 -0.2363 -0.7843 -0.1234 -0.3926 -0.1701 -0.2182 -0.0292 -0.0313 -0.0339 -0.0731 -0.1740 -1.1745 -0.2220 -0.7550 -0.0790 -0.2752 -0.1186 -0.1065 -0.2063 -0.1705 -0.0951 -0.9633 -0.2822 -0.0882 -1.3746 -0.7271 -1.9994 -0.2386 -0.0723 -0.0918 -0.0580 -0.0476 -0.0729 -0.4444 -0.5409 -1.7236 -0.1660 -0.0255 -0.0136 -0.0318 -0.0269 -0.0330 -0.0484 -0.0598 -0.1324 -0.1641\n",
            "T-64\tgalu wabulauni akuyang ana hatchi yakuda yomwe ikulowetsa mutu wake kumpanda\n",
            "H-64\t-0.361127108335495\t▁ g a l u ▁ w a b u l a u n i ▁ a k u y a n g ▁ a n a ▁ c h i n a c h a k u d y a ▁ l o m w e ▁ l i k u y e n d a ▁ m ▁ m o d z i ▁ m ▁ m p h a t c h i\n",
            "D-64\t-0.361127108335495\tgalu wabulauni akuyang ana chinachakudya lomwe likuyenda m modzi m mphatchi\n",
            "P-64\t-0.1032 -0.1725 -0.1004 -0.0641 -0.0505 -0.0989 -0.0298 -0.1236 -0.2913 -0.0592 -0.0549 -0.0931 -0.0609 -0.0535 -0.0648 -0.0948 -0.2182 -0.0376 -0.1143 -0.0380 -0.2563 -0.0365 -0.0506 -0.0831 -0.0873 -0.0594 -0.1217 -0.0989 -2.9545 -0.0767 -0.0512 -0.1237 -0.5760 -0.1528 -0.0453 -0.0587 -0.0485 -0.4009 -1.4075 -0.6354 -0.1578 -0.1292 -2.3748 -1.3984 -0.0662 -0.1190 -0.0875 -0.0834 -0.2044 -0.1396 -0.0668 -0.0443 -1.5592 -0.2359 -1.2428 -0.0706 -0.2699 -0.1586 -0.2658 -1.2542 -0.0735 -1.4515 -0.4629 -0.1151 -0.1531 -0.1549 -1.0171 -0.8138 -0.6938 -0.2689 -0.2182 -0.7665 -0.5754 -1.2276 -0.1694 -0.2534 -0.2148\n",
            "T-372\tmnyamata wovala malaya a new york mets atakhala pa chidole chamoto cha harly davison pa bwalo la tennis\n",
            "H-372\t-0.2699437141418457\t▁ m n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ a m i z e r e m i z e r e ▁ a t a k h a l a ▁ p a ▁ c h i d o l e ▁ c h a ▁ m u n t h u ▁ a l i ▁ n d i ▁ c h i d a ▁ z o v a l a ▁ z o f i i r a\n",
            "D-372\t-0.2699437141418457\tmnyamata wovala malaya amizeremizere atakhala pa chidole cha munthu ali ndi chida zovala zofiira\n",
            "P-372\t-0.1059 -0.1155 -0.0271 -0.0312 -0.1142 -0.0559 -0.0958 -0.0203 -0.1106 -0.0969 -0.1104 -0.0667 -0.0584 -0.1247 -0.1068 -0.1232 -0.0983 -0.0398 -0.0966 -0.0696 -0.1231 -0.0504 -0.1329 -0.0969 -0.1704 -0.5658 -0.1412 -1.1723 -0.6442 -0.0940 -0.3756 -0.2699 -0.0138 -0.1619 -0.4313 -0.0870 -0.1460 -0.0793 -0.3083 -0.0867 -0.1314 -0.1391 -0.1223 -0.1267 -0.1270 -0.1185 -0.1133 -0.3756 -0.1148 -0.5038 -0.0609 -0.0768 -0.0884 -0.1945 -0.0472 -0.1291 -0.0676 -0.1473 -0.0064 -0.0652 -0.3326 -0.4867 -0.0876 -2.3761 -0.7707 -0.0336 -0.0573 -0.0982 -0.0856 -1.2049 -1.8512 -0.0928 -0.1179 -0.6486 -0.0715 -0.1053 -0.0832 -0.5907 -0.1028 -0.5559 -0.2232 -0.2251 -0.1193 -0.9153 -0.1204 -0.7575 -0.1085 -0.0858 -0.1191 -0.1139 -0.6190 -0.5699 -2.3016 -0.1622 -0.0820 -0.0468 -0.2253 -0.3316\n",
            "T-262\tmnyamata wokwera njinga yamapiri akutera atadumpha atakwera m nkhalango\n",
            "H-262\t-0.2882567346096039\t▁ m n y a m a t a ▁ w o k w e r a ▁ n j i n g a ▁ y a m a p i r i ▁ a k u t h a m a n g i t s a ▁ t h a n t h w e ▁ l a k e ▁ l a ▁ m k a z i\n",
            "D-262\t-0.2882567346096039\tmnyamata wokwera njinga yamapiri akuthamangitsa thanthwe lake la mkazi\n",
            "P-262\t-0.1087 -0.1390 -0.0267 -0.0437 -0.1297 -0.0669 -0.1001 -0.0324 -0.1141 -0.1053 -0.2744 -0.1195 -0.0684 -0.0437 -0.0606 -0.0838 -0.0930 -0.0960 -0.0378 -0.0143 -0.0426 -0.0245 -0.0372 -0.1040 -0.1733 -0.0041 -0.1834 -0.1551 -0.4344 -0.6796 -0.1054 -0.0452 -0.0693 -0.0964 -0.0790 -0.0901 -0.1386 -0.0826 -0.4381 -0.8315 -0.7626 -0.1245 -0.1414 -0.3565 -0.5566 -0.8301 -0.2045 -0.0847 -0.0718 -2.5943 -0.0848 -0.4636 -0.5497 -0.9643 -0.2353 -0.2799 -0.0628 -0.1448 -0.3035 -0.2444 -0.0755 -0.5789 -0.1813 -0.0934 -0.1773 -1.5228 -1.0295 -0.9445 -0.0783 -1.0164 -0.0688 -0.3555\n",
            "T-26\tbambo wovala malaya akuda ndi magalasi akukweza manja atakhala patebulo la poker\n",
            "H-26\t-0.2453153133392334\t▁ b a m b o ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ n d i ▁ m a t h a l a u z a ▁ a k u d a ▁ m a n j a ▁ a t a k h a l a ▁ p a t e b u l o\n",
            "D-26\t-0.2453153133392334\tbambo wovala malaya akuda ndi mathalauza akuda manja atakhala patebulo\n",
            "P-26\t-0.1105 -1.1667 -0.1324 -0.0465 -0.0508 -0.0867 -0.1178 -0.2097 -0.1656 -0.3878 -0.1264 -0.0827 -0.1232 -0.1187 -0.0418 -0.1222 -0.0702 -0.1312 -0.0397 -0.1318 -0.0984 -0.1599 -0.1002 -0.1407 -0.2099 -0.1786 -0.1181 -0.2060 -0.1765 -0.1054 -0.1041 -0.0452 -0.1269 -0.6075 -0.1897 -0.0882 -0.1879 -0.0922 -0.1478 -0.0994 -0.0488 -0.1070 -0.1401 -0.1238 -0.1459 -2.2717 -0.3314 -0.1145 -0.3458 -0.7670 -0.2973 -0.0130 -0.1026 -0.1111 -0.0922 -0.0568 -0.0988 -0.4898 -0.8317 -0.2126 -0.0323 -0.1339 -0.1282 -0.0532 -0.0944 -1.4348 -0.0780 -0.1013 -0.1510 -0.0722 -0.0345 -2.0021\n",
            "T-44\tgalu wotuwa komanso woyera akuwoneka wamantha pamene akukwaza m madzi\n",
            "H-44\t-0.32188230752944946\t▁ g a l u ▁ w a k u d a ▁ w a b u l a u n i ▁ w o y e r a ▁ a k u w o n e k a ▁ m a n j a ▁ a k u y a n g ▁ a n a ▁ k u w o n e t s a ▁ m a d z i\n",
            "D-44\t-0.32188230752944946\tgalu wakuda wabulauni woyera akuwoneka manja akuyang ana kuwonetsa madzi\n",
            "P-44\t-0.1032 -0.0603 -0.1151 -0.0593 -0.0680 -0.1143 -0.0244 -0.2299 -0.4557 -0.1533 -0.3071 -0.1195 -0.1215 -1.5579 -0.3613 -1.1573 -0.1811 -0.0491 -0.1480 -0.0378 -0.0618 -0.0942 -0.1399 -1.9244 -0.0864 -0.0555 -0.0884 -0.0823 -0.1022 -0.1311 -0.2516 -0.0538 -0.1359 -0.0544 -0.7961 -0.2719 -0.1746 -0.0153 -0.0993 -0.0876 -0.1601 -1.2531 -0.5912 -1.4532 -0.1183 -0.1534 -0.2879 -1.2333 -0.4348 -0.2332 -0.1235 -0.0580 -0.2819 -0.1013 -0.1177 -0.0674 -0.5997 -0.1119 -0.8675 -0.0744 -1.6782 -1.6458 -0.3659 -0.1614 -0.1660 -0.0443 -0.1209 -0.1769 -0.1758 -0.4314 -0.2059 -0.0415 -0.0930 -0.0596\n",
            "T-224\tmayi akumwetulira wovala malaya abulauni atsamira mwamuna wovala juzi\n",
            "H-224\t-0.3064243793487549\t▁ a m u n a ▁ a k u t e n g a ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a k u t h a m a n g i r a ▁ m w a m u n a ▁ w o v a l a ▁ j e a n s\n",
            "D-224\t-0.3064243793487549\tamuna akutenga wovala malaya abulauni akuthamangira mwamuna wovala jeans\n",
            "P-224\t-0.1085 -0.1571 -0.1064 -0.7187 -0.1186 -0.1272 -0.1613 -0.3917 -0.3099 -0.1608 -0.8600 -1.0495 -1.1095 -0.7411 -0.0797 -0.0781 -2.0332 -0.1702 -0.0367 -0.1168 -0.0686 -0.1113 -0.1116 -0.1926 -0.0938 -0.0657 -0.1298 -0.0403 -0.1302 -0.0784 -0.1972 -0.8968 -0.0745 -0.0789 -0.1215 -0.0449 -0.0168 -0.0577 -0.1014 -0.0774 -1.7921 -0.0997 -0.0786 -0.1026 -0.1026 -0.0816 -0.1004 -0.0663 -0.0729 -0.3137 -0.1401 -0.1028 -0.1408 -0.1584 -1.0161 -0.0998 -1.4191 -0.2410 -0.0531 -0.1515 -0.1356 -0.7087 -0.1358 -0.0550 -0.0990 -0.0731 -0.1147 -0.1857 -0.4953 -1.1989 -0.8423 -0.1124 -0.0205 -0.8409\n",
            "T-354\twothamanga mumsewu akutsetsereka motsetsereka kwambiri ndipo kumbuyo kwake kuli phiri\n",
            "H-354\t-0.36687737703323364\t▁ w o t h a m a n g a ▁ m u m s e w u ▁ w a k u t s e t s e r e k a ▁ m ▁ m o d z i ▁ a k u s e k a ▁ n d i ▁ g a l u ▁ w o k h a l a ▁ n d i ▁ b u l u u\n",
            "D-354\t-0.36687737703323364\twothamanga mumsewu wakutsetsereka m modzi akuseka ndi galu wokhala ndi buluu\n",
            "P-354\t-0.0951 -0.1410 -0.0388 -0.0572 -0.1109 -0.0827 -0.0441 -0.0857 -0.0810 -0.0510 -0.0843 -0.1022 -0.2077 -0.9907 -1.0422 -0.1158 -0.2257 -0.0857 -0.1056 -0.1059 -0.5759 -0.1870 -0.3904 -0.1334 -3.1612 -0.0499 -0.2774 -0.3031 -0.0523 -0.0482 -0.0693 -0.0509 -0.0132 -0.1379 -0.1104 -0.0797 -1.1210 -0.0653 -0.3913 -0.2205 -0.0702 -0.8083 -0.1182 -1.3186 -0.1440 -0.2279 -1.0584 -0.0263 -0.5798 -0.1050 -0.0522 -0.5033 -0.0891 -0.1006 -0.5761 -1.9946 -0.4461 -0.3420 -0.6657 -0.1256 -0.5896 -1.1209 -0.1543 -0.5396 -0.1257 -0.1538 -0.1878 -0.1028 -0.2429 -0.0457 -0.1110 -0.1458 -2.0669 -0.0933 -0.3127 -0.5337 -0.0679 -1.3782\n",
            "T-375\tgulu la anthu litakhala pansi pa mtengo wamaluwa wa pinki ndi woyera womwe uli ndi udzu\n",
            "H-375\t-0.28051191568374634\t▁ g u l u ▁ l a ▁ a n t h u ▁ l i t a k h a l a ▁ p a n s i ▁ p a ▁ m t e n g o ▁ w a ▁ m a l u w a ▁ p i n k i ▁ n d i ▁ m p i r a ▁ w o m w e ▁ u l i ▁ n d i ▁ u d z u\n",
            "D-375\t-0.28051191568374634\tgulu la anthu litakhala pansi pa mtengo wa maluwa pinki ndi mpira womwe uli ndi udzu\n",
            "P-375\t-0.1047 -0.0933 -0.0696 -0.1447 -0.0999 -0.0934 -0.0614 -0.1148 -0.1183 -0.1039 -0.2289 -0.0432 -0.1024 -0.1002 -0.0854 -0.1612 -0.1019 -1.1982 -0.0904 -0.4884 -0.0425 -0.1172 -0.0736 -0.1189 -0.0946 -0.2454 -0.1258 -1.2942 -0.2801 -0.0482 -0.0942 -0.0673 -0.1278 -0.9981 -0.0517 -0.2455 -0.4197 -0.1658 -0.0258 -0.0325 -0.0883 -0.0077 -0.1687 -0.5695 -0.1176 -0.0959 -1.2699 -1.8679 -0.0498 -0.1028 -0.1127 -0.9576 -0.7839 -0.1496 -0.1487 -0.0938 -0.1177 -0.1223 -0.0306 -0.0845 -0.1426 -1.5851 -0.8938 -0.1560 -0.0596 -0.0787 -0.1236 -0.3214 -0.4419 -0.5579 -0.2495 -0.0836 -0.0902 -0.4624 -0.0437 -0.0623 -0.1216 -0.2226 -0.0410 -0.0932 -0.1248 -2.3586 -0.2479 -0.0591 -0.0402 -0.2504\n",
            "T-198\tgulu la anthu lasonkhana m mphepete mwa sitolo pafupi ndi msewu womwe uli ndi zinyalala\n",
            "H-198\t-0.24649816751480103\t▁ g u l u ▁ l a ▁ a n t h u ▁ o s a n g a l a l a ▁ m p h e p e t e ▁ m w a ▁ p a f u p i ▁ n d i ▁ m t s i n j e ▁ w o m w e ▁ u l i ▁ n d i ▁ z i n y a l a l a\n",
            "D-198\t-0.24649816751480103\tgulu la anthu osangalala mphepete mwa pafupi ndi mtsinje womwe uli ndi zinyalala\n",
            "P-198\t-0.0997 -4.3606 -0.2446 -0.0728 -0.0574 -0.0996 -0.1707 -0.0807 -0.0922 -0.1388 -0.1376 -0.0273 -0.0981 -0.1398 -0.0949 -0.0614 -0.0509 -0.4604 -0.0942 -0.2618 -0.0905 -0.2353 -0.1429 -0.3222 -0.2954 -0.1369 -0.4813 -0.3954 -0.5887 -0.0703 -0.1144 -0.1274 -0.0108 -0.0777 -0.0831 -0.1006 -0.1518 -0.1461 -0.1209 -0.6913 -0.3372 -1.4806 -0.0590 -0.0459 -0.0647 -0.0982 -0.0542 -0.1074 -0.1090 -0.0943 -0.6267 -0.8542 -0.0354 -0.1300 -0.1682 -0.1543 -0.0264 -0.1039 -0.3924 -0.0583 -0.0978 -0.0638 -0.1094 -0.0961 -0.4993 -1.1251 -0.0700 -0.1110 -0.1023 -0.0838 -0.1118 -0.1155 -0.1155 -0.1325 -0.3087 -0.2286 -0.0821 -0.0136 -0.1177 -0.0648 -0.1080 -0.2288\n",
            "T-132\tgalu waubweya wa beige akusewera m madzi amtsinje wakuda\n",
            "H-132\t-0.23308154940605164\t▁ g a l u ▁ w a b u l a u n i ▁ w a ▁ k u ▁ a s i a ▁ a k u s e w e r a ▁ m ▁ m a d z i ▁ n d i ▁ u d z u ▁ w a k u d a\n",
            "D-132\t-0.23308154940605164\tgalu wabulauni wa ku asia akusewera m madzi ndi udzu wakuda\n",
            "P-132\t-0.1005 -0.0508 -0.0949 -0.0796 -0.2528 -0.1112 -0.0440 -0.1737 -0.3809 -0.1323 -0.0644 -0.1765 -0.0252 -0.0532 -0.1304 -0.1233 -0.1360 -0.2512 -1.1697 -0.4773 -0.3533 -0.0527 -0.1212 -1.0819 -0.1136 -0.2526 -0.1059 -0.2339 -0.0543 -0.0934 -0.8187 -0.0209 -0.0508 -0.0633 -0.0589 -0.1008 -0.1127 -0.1584 -0.2575 -0.0437 -0.0457 -0.0716 -0.0280 -0.0503 -0.1392 -0.3534 -0.1226 -0.0882 -0.1442 -2.7553 -0.5093 -0.0485 -0.1412 -0.7952 -0.0443 -0.1474 -0.0561 -0.0990 -0.0964 -0.1183 -0.1875\n",
            "T-414\tgalu wabulauni akugona pamunda waudzu pamene mphepo ikuwomba ubweya wake\n",
            "H-414\t-0.3851710855960846\t▁ g a l u ▁ w a k u d a ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ w a u d z u ▁ n d i p o ▁ m t e n g o ▁ w i n a ▁ k u m b a l i ▁ m ▁ m u n d a ▁ w a k e\n",
            "D-414\t-0.3851710855960846\tgalu wakuda wabulauni akuthamanga waudzu ndipo mtengo wina kumbali m munda wake\n",
            "P-414\t-0.1120 -0.0132 -0.1102 -0.0462 -0.0872 -0.0981 -0.1158 -0.6380 -0.7348 -0.1069 -1.0482 -0.2241 -0.0924 -0.7181 -0.4770 -1.6975 -0.1247 -0.0649 -0.0880 -0.0445 -0.1382 -0.1183 -0.0960 -0.2412 -0.3665 -0.1496 -1.5991 -0.2232 -0.1066 -0.1618 -0.0871 -0.0465 -0.0950 -0.1280 -0.1014 -2.3081 -0.1052 -0.5250 -0.2172 -0.9283 -0.1168 -0.1069 -0.3818 -0.1467 -0.0647 -1.3695 -0.0500 -0.1181 -0.1794 -2.5998 -0.3646 -0.1008 -0.3587 -0.0723 -0.1013 -0.6567 -0.8100 -0.2024 -0.1960 -0.1830 -0.1471 -0.0428 -0.5522 -0.0419 -0.4841 -0.9105 -0.4033 -0.1426 -0.4094 -1.1890 -0.8002 -0.8945 -0.2974 -0.2458 -0.1357 -0.7422 -0.0791 -0.1243 -0.7015 -0.1644 -0.1270\n",
            "T-349\tmnyamata wakwera njonjo ya blue ndi yellow merry go round ndi dzanja la mwamuna wamkulu kutsogolo\n",
            "H-349\t-0.31845346093177795\t▁ m n y a m a t a ▁ w o k w e r a ▁ n j o n j i ▁ y a ▁ b u l u u ▁ n d i ▁ y o y e r a ▁ n d i ▁ j a n j i ▁ a t a n y a m u l a ▁ m w a m u n a ▁ k u t s o g o l o\n",
            "D-349\t-0.31845346093177795\tmnyamata wokwera njonji ya buluu ndi yoyera ndi janji atanyamula mwamuna kutsogolo\n",
            "P-349\t-0.1145 -0.0948 -0.0419 -0.0944 -0.1369 -0.0631 -0.1031 -0.0563 -0.1116 -0.1122 -0.4016 -0.1016 -0.0185 -0.8287 -0.0485 -0.1191 -0.0788 -0.0984 -0.0710 -0.0149 -0.1304 -0.4202 -1.2277 -1.8663 -0.1068 -0.0595 -0.1379 -0.2072 -0.3332 -0.7309 -0.0368 -0.0984 -0.0549 -0.0822 -0.2589 -0.1243 -0.0885 -0.1341 -0.1886 -0.6957 -0.2945 -0.0475 -0.0694 -0.0931 -0.0961 -1.3265 -0.2951 -0.0894 -0.2570 -2.0069 -1.3323 -0.2666 -1.3073 -0.0942 -0.0914 -1.2727 -0.5621 -0.0953 -0.3859 -0.8887 -0.1032 -0.0659 -0.0724 -0.0577 -0.1220 -0.0769 -0.4328 -0.6285 -0.1273 -0.4235 -0.3259 -0.1814 -0.1235 -0.1659 -1.5554 -0.0415 -0.0791 -0.0538 -0.0390 -0.0201 -0.0501 -0.0481 -0.0769 -1.3149\n",
            "T-34\tgalu wa bulauni ndi woyera waima pa trampoline lilime lake likulendewera panja\n",
            "H-34\t-0.33411625027656555\t▁ k a m w a n a ▁ k a k a n g ▁ o n o ▁ n d i ▁ w o y e r a ▁ a t a k h a l a ▁ p a f u p i ▁ n d i ▁ n y u m b a ▁ y a k e ▁ n d i ▁ m p i r a ▁ p a n s i\n",
            "D-34\t-0.33411625027656555\tkamwana kakang ono ndi woyera atakhala pafupi ndi nyumba yake ndi mpira pansi\n",
            "P-34\t-0.1049 -1.3106 -0.6616 -0.3822 -0.3136 -0.1067 -0.4020 -0.1120 -0.1145 -0.1669 -0.1749 -0.7974 -0.6286 -0.1040 -0.4950 -0.1586 -0.1059 -0.1975 -0.2721 -0.1490 -0.4891 -0.0361 -0.1151 -0.1583 -0.1702 -0.1682 -0.0347 -0.1226 -0.1391 -0.0839 -0.1410 -0.8709 -0.0519 -0.1081 -0.7419 -0.1359 -0.1474 -0.0657 -0.1104 -0.1226 -0.1235 -0.1722 -0.9886 -0.0874 -0.1820 -0.0467 -0.0641 -0.0307 -0.1418 -0.0833 -0.0982 -1.2630 -0.1745 -1.2976 -0.2208 -0.6706 -0.9495 -0.1026 -0.8274 -0.8726 -0.3004 -0.0800 -0.1150 -0.6421 -0.0862 -0.0952 -0.4501 -1.3680 -0.8049 -0.4039 -0.1088 -0.0826 -0.4157 -0.4480 -0.0992 -0.2353 -1.2057 -0.0538 -0.2320\n",
            "T-163\tzipaipi zikuseweredwa mukuyenda parade kapena chochitika mumsewu\n",
            "H-163\t-0.48064836859703064\t▁ z i p a l i ▁ z i k u s e w e r a ▁ m u t u ▁ w a ▁ k a y e n d a ▁ p a n j a ▁ p a ▁ c h i t h u n z i ▁ c h o k h a l a ▁ n d i ▁ m s e w u\n",
            "D-163\t-0.48064836859703064\tzipali zikusewera mutu wa kayenda panja pa chithunzi chokhala ndi msewu\n",
            "P-163\t-0.1038 -1.5273 -0.0955 -1.1310 -0.1670 -0.4170 -0.0547 -0.1585 -0.6943 -0.3384 -0.0368 -0.1207 -0.5959 -0.3959 -0.2052 -0.1860 -0.0974 -1.1904 -0.1231 -1.4452 -0.6615 -1.6569 -0.2775 -0.0865 -0.3222 -0.3062 -0.7046 -1.8957 -0.9767 -0.4984 -1.4375 -0.1098 -0.0174 -0.1105 -0.1706 -0.0509 -0.1336 -2.2912 -0.6686 -0.2195 -0.1550 -0.4407 -0.3598 -0.6023 -0.7738 -0.1710 -0.4702 -0.7951 -0.4356 -0.0857 -0.0851 -0.2392 -0.0526 -0.2848 -0.1296 -0.1134 -0.4158 -1.0141 -0.0786 -0.1307 -1.9348 -0.2164 -0.1220 -0.9475 -0.3753 -0.1377 -0.0887 -0.8689 -1.3985 -0.1583 -0.1519 -0.0493 -0.1251\n",
            "T-268\tgalu wotuwa amakhala pa kapinga atavala jekete lamanja lalitali la buluu wonyezimira\n",
            "H-268\t-0.3375997543334961\t▁ g a l u ▁ w a k u d a ▁ a m a k h a l a ▁ p a k a t i ▁ n d i ▁ g a l a s i ▁ a t a v a l a ▁ m a n j a ▁ a l i ▁ p a n j a ▁ y a b u l u u ▁ n d i ▁ z i n y a l a\n",
            "D-268\t-0.3375997543334961\tgalu wakuda amakhala pakati ndi galasi atavala manja ali panja yabuluu ndi zinyala\n",
            "P-268\t-0.1006 -0.0148 -0.0938 -0.0732 -0.1317 -0.0887 -0.0312 -0.0833 -0.9740 -0.1344 -0.7680 -0.1726 -0.0983 -0.2636 -0.7480 -0.1362 -0.0534 -0.0617 -0.1054 -0.1111 -0.1133 -0.0967 -0.0243 -0.1017 -2.1386 -0.0994 -0.0388 -0.0571 -0.0938 -1.5083 -0.2311 -0.2121 -0.1042 -2.1116 -0.1490 -0.1356 -0.2040 -1.8154 -0.3259 -0.0719 -0.7877 -0.0772 -0.0793 -0.8203 -0.1633 -0.2016 -0.1246 -0.0819 -0.5679 -0.1444 -0.4219 -0.0102 -0.1806 -0.0887 -0.1133 -0.5234 -0.0723 -0.1071 -0.4368 -0.1423 -1.6345 -0.2062 -0.3287 -0.1518 -1.1418 -0.1359 -1.4838 -0.0653 -0.0492 -0.0940 -0.0252 -0.1964 -0.2834 -0.0724 -0.1016 -0.0688 -0.7072 -0.1490 -0.3094 -0.9460 -0.1146 -0.2246 -0.1919 -0.6553\n",
            "T-406\tmwamuna ali pampando akugwira mbiya yaikulu pagudumu loumba mbiya\n",
            "H-406\t-0.31760531663894653\t▁ m w a m u n a ▁ a l i ▁ p a m p a n d o ▁ w a g w i r a ▁ m ▁ n y a n j a ▁ y a i k u l u ▁ n d i ▁ m u n t h u ▁ w o b i r i w i r a\n",
            "D-406\t-0.31760531663894653\tmwamuna ali pampando wagwira m nyanja yaikulu ndi munthu wobiriwira\n",
            "P-406\t-0.1085 -0.0698 -0.0286 -0.1124 -0.0613 -0.0531 -0.0546 -0.1207 -0.1289 -1.1260 -0.0668 -0.0984 -0.1097 -0.0106 -0.1178 -0.4761 -0.8351 -0.3557 -0.0744 -0.0104 -0.0535 -0.0850 -0.9986 -0.2390 -1.6570 -0.1030 -0.0680 -0.0827 -0.1832 -0.1192 -0.5101 -0.5583 -0.9088 -0.1398 -0.2098 -0.4268 -0.9299 -0.2239 -0.1391 -0.1293 -0.1294 -0.4688 -0.3897 -0.0820 -0.1034 -0.0356 -0.1335 -0.9398 -0.0985 -0.5546 -0.2031 -3.0134 -0.3035 -0.0938 -0.9621 -0.0745 -0.1105 -0.1089 -0.1971 -0.5211 -0.7195 -0.0915 -0.0548 -0.0728 -0.1950 -0.0602 -0.0544 -0.1020 -0.2569\n",
            "T-5\tgalu woyera ndi wakuda watsala pang ono kugwira chinthu ataima m chipale chofewa\n",
            "H-5\t-0.33836740255355835\t▁ g a l u ▁ w o y e r a ▁ n d i ▁ w a k u d a ▁ w a t s a l a ▁ p a m w a m b a ▁ p a ▁ c h i t h u n z i ▁ p a m i y a l a ▁ y a c h i k a s u\n",
            "D-5\t-0.33836740255355835\tgalu woyera ndi wakuda watsala pamwamba pa chithunzi pamiyala yachikasu\n",
            "P-5\t-0.1070 -0.0203 -0.1010 -0.0620 -0.0649 -0.1334 -0.2496 -0.1653 -0.0201 -0.0853 -0.0387 -0.0893 -0.1145 -0.0202 -0.0611 -0.1070 -0.1010 -0.0296 -0.0924 -0.1304 -0.1186 -0.1316 -0.7979 -0.1060 -0.0524 -0.1349 -1.0905 -0.0196 -0.1007 -1.4707 -0.1481 -0.0927 -0.4949 -0.1343 -0.2224 -2.3965 -0.1428 -0.0300 -0.1562 -0.4594 -0.0796 -0.7988 -0.1513 -0.1218 -1.7551 -0.2224 -0.0978 -1.3491 -0.0935 -0.0953 -0.0597 -0.0878 -0.0720 -0.1197 -1.9812 -0.1142 -0.7364 -1.0970 -0.8809 -0.1022 -0.0280 -0.5608 -0.2294 -0.5679 -0.6166 -1.6870 -0.0598 -0.1533 -0.0971 -0.0959 -0.2574 -0.0612 -0.1774\n",
            "T-145\tgalu waima m chipale chofewa chakuya atazunguliridwa ndi mitengo\n",
            "H-145\t-0.26219800114631653\t▁ g a l u ▁ w a i m a ▁ m ▁ c h i p e w a ▁ c h o f e w a ▁ c h o f i i r a ▁ a t a z u n g u l i r i d w a ▁ n d i ▁ m t e n g o\n",
            "D-145\t-0.26219800114631653\tgalu waima m chipewa chofewa chofiira atazunguliridwa ndi mtengo\n",
            "P-145\t-0.1024 -0.0200 -0.1071 -0.0826 -0.0736 -0.0960 -0.0824 -0.4169 -0.5937 -0.0270 -0.0779 -0.1049 -0.1298 -0.1866 -0.0627 -0.0800 -0.1129 -0.0251 -1.1163 -0.1255 -0.0830 -0.1102 -0.0109 -0.0711 -0.0182 -0.0392 -0.2691 -0.0608 -0.1037 -0.1131 -0.3809 -0.0598 -1.4091 -0.6550 -1.1550 -0.7204 -0.1519 -0.1333 -0.1250 -0.1019 -0.8353 -0.1072 -0.8735 -0.3175 -0.1110 -0.0106 -0.0442 -0.0835 -0.0484 -0.1254 -0.0522 -0.0192 -0.0235 -0.1174 -0.0888 -0.0607 -0.0561 -0.1573 -0.1137 -0.5333 -1.3258 -0.3840 -0.0363 -0.9341 -0.1301 -1.3211\n",
            "T-56\tmunthu wovala malaya ofiira ndi ofiira akuyenda pa chipale chofewa pamwamba pa chipale chofewa\n",
            "H-56\t-0.15393474698066711\t▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o f i i r a ▁ n d i ▁ w o f i i r a ▁ a k u y a n g ▁ a n a ▁ c h i p a l e ▁ c h o f e w a ▁ p a m w a m b a ▁ p a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-56\t-0.15393474698066711\tmunthu wovala malaya ofiira ndi wofiira akuyang ana chipale chofewa pamwamba pa chipale chofewa\n",
            "P-56\t-0.1171 -0.1316 -0.1059 -0.0450 -0.0255 -0.0543 -0.1204 -0.1268 -0.0378 -0.1898 -0.2727 -0.1120 -0.0839 -0.1319 -0.1097 -0.0448 -0.1140 -0.0618 -0.1199 -0.0281 -0.1351 -0.1030 -0.0217 -0.0644 -0.0587 -0.0797 -0.0590 -0.1269 -0.1173 -0.0251 -0.0412 -0.0681 -0.1218 -1.2924 -0.0453 -0.6448 -0.0695 -0.2089 -0.1037 -0.2046 -0.1145 -0.0789 -0.5891 -0.0968 -0.0202 -1.9290 -0.0337 -0.2310 -0.0874 -0.0876 -0.1860 -0.1390 -0.0766 -0.2108 -0.0818 -0.0647 -1.8537 -0.1015 -0.0647 -0.0301 -0.0663 -0.0107 -0.0615 -0.0584 -0.0507 -0.0311 -0.0150 -0.0873 -0.1171 -0.1911 -0.1178 -0.1624 -0.1325 -0.1019 -0.0350 -0.0739 -0.1098 -0.0931 -0.0097 -0.1118 -0.1025 -0.0330 -0.1133 -0.1024 -0.3209 -0.1035 -0.0498 -0.1950 -0.1214 -0.0076 -0.0755 -0.0446 -0.0127 -0.1893 -0.0257 -0.0679 -0.0287\n",
            "T-231\tgalu wamkulu wabulauni amayamba kunjenjemera ataima m madzi\n",
            "H-231\t-0.2903214395046234\t▁ g a l u ▁ w a m k u l u ▁ w a b u l a u n i ▁ a m a t h a m a n g a ▁ k u c h o k e r a ▁ a t a i m a ▁ m ▁ m b a l i\n",
            "D-231\t-0.2903214395046234\tgalu wamkulu wabulauni amathamanga kuchokera ataima m mbali\n",
            "P-231\t-0.1224 -0.1148 -0.1396 -0.0625 -0.1060 -0.1163 -0.0274 -0.0798 -0.2517 -0.0440 -0.0473 -0.2520 -0.0437 -0.1116 -0.0641 -0.0942 -0.0622 -0.0654 -0.0663 -0.0955 -0.0213 -0.0744 -0.0707 -0.0994 -0.0687 -0.2330 -0.1106 -2.1079 -0.1653 -0.1298 -0.1088 -0.1147 -0.1312 -0.3541 -0.3225 -0.1034 -2.0129 -0.0754 -0.8573 -0.0790 -1.2107 -0.1772 -0.0809 -0.0144 -0.0613 -0.1089 -0.7765 -0.0608 -0.0880 -1.9945 -0.0273 -0.0884 -0.1121 -0.1297 -0.1018 -0.0950 -1.2973 -0.0689 -0.0397 -0.1299 -1.8395\n",
            "T-306\tatsikana awiri ovala malaya akhala moyang anizana ndi zakumwa m manja\n",
            "H-306\t-0.25670576095581055\t▁ a t s i k a n a ▁ a w i r i ▁ a k u k w e r a ▁ m a l a y a ▁ a ▁ m o y a n g ▁ a n i z a n a ▁ n d i ▁ z o k o n g o l a\n",
            "D-306\t-0.25670576095581055\tatsikana awiri akukwera malaya a moyang anizana ndi zokongola\n",
            "P-306\t-0.1064 -0.2621 -0.2327 -0.1222 -0.1488 -0.0399 -0.1241 -0.0345 -0.1116 -0.1300 -0.0559 -0.0211 -0.0846 -0.0517 -0.0899 -0.1111 -0.2630 -0.1026 -0.2331 -0.5737 -1.4509 -0.6014 -0.0982 -0.0939 -0.1781 -0.2582 -0.1988 -0.2118 -0.1350 -0.0875 -0.1242 -0.0761 -0.1636 -1.5567 -0.7860 -1.0249 -0.0900 -0.1052 -0.0393 -0.1584 -0.0807 -0.0840 -0.0365 -0.2245 -0.4734 -0.1671 -0.0114 -0.1077 -0.1284 -0.0277 -0.0449 -0.0839 -0.1226 -0.1472 -0.1135 -0.3659 -0.4313 -0.1735 -0.4334 -0.0521 -0.1445 -0.9777 -1.4034\n",
            "T-75\tazimayi awiri mmodzi atakhala pampando wina ataima akuwoneka kuti avulala\n",
            "H-75\t-0.2621948719024658\t▁ a z i m a y i ▁ a w i r i ▁ m ▁ m o d z i ▁ a t a k h a l a ▁ p a m p a n d o ▁ w i n a ▁ a t a i m a ▁ p a m e n e ▁ w a n y a m u l a ▁ z i w o\n",
            "D-75\t-0.2621948719024658\tazimayi awiri m modzi atakhala pampando wina ataima pamene wanyamula ziwo\n",
            "P-75\t-0.0952 -0.2113 -0.8827 -0.0703 -0.0483 -0.1137 -0.0318 -0.0987 -0.0869 -0.1039 -0.0187 -0.1180 -0.0380 -0.1082 -0.0973 -0.3567 -0.6635 -0.0345 -0.0852 -0.0479 -0.0430 -0.1027 -0.0995 -0.1244 -0.0121 -0.1069 -0.1079 -0.0384 -0.1239 -0.0594 -0.1129 -0.0919 -0.0455 -0.1209 -0.1900 -0.0693 -0.2796 -0.0187 -0.0069 -0.0316 -0.0897 -0.0793 -0.0693 -0.1091 -0.1191 -0.1218 -0.0772 -0.0517 -0.1033 -0.6975 -0.0577 -0.0931 -0.0905 -1.2225 -0.2187 -1.1817 -1.1732 -0.0778 -0.0502 -0.1079 -1.1945 -0.1762 -2.0305 -0.6002 -0.1263 -0.2091 -0.2686 -0.1818 -0.1237 -0.1512 -1.0918 -0.0884 -0.2352 -0.7054 -1.5941\n",
            "T-190\tkamnyamata ka jekete yochindikala kayimilira ndi dzanja lake pamwamba pamutu\n",
            "H-190\t-0.3076082468032837\t▁ k a m n y a m a t a ▁ k a k a n j a ▁ c h i t h u n z i ▁ n d i ▁ k a y i m i r i r a ▁ n d i ▁ z a n j a ▁ l a k e ▁ p a m w a m b a ▁ p a ▁ m u n t h u\n",
            "D-190\t-0.3076082468032837\tkamnyamata kakanja chithunzi ndi kayimirira ndi zanja lake pamwamba pa munthu\n",
            "P-190\t-0.1010 -2.6350 -0.4860 -0.0528 -0.0470 -0.0142 -0.0913 -0.0645 -0.0997 -0.0406 -0.1290 -0.0960 -0.1231 -0.1090 -1.6377 -0.2598 -0.2750 -0.2155 -1.0038 -0.1081 -1.5500 -0.0652 -0.1597 -1.3967 -0.1454 -0.1275 -0.0425 -0.1600 -0.0703 -0.1307 -1.3041 -0.1144 -0.1280 -0.2848 -0.0709 -0.1337 -0.8917 -0.1313 -1.0344 -0.1649 -0.6572 -0.0435 -0.1466 -0.1193 -0.0970 -0.8777 -0.1050 -0.1101 -0.1185 -0.0376 -0.1857 -0.0708 -0.0214 -0.0940 -0.0986 -1.6720 -0.1995 -0.5367 -0.0157 -0.1206 -0.0623 -0.1419 -0.1267 -0.1465 -0.0847 -0.0263 -0.0962 -0.1219 -0.2517 -0.0265 -0.0938 -0.2293 -0.2597 -0.2604 -0.3750 -0.2093 -0.0429 -0.0613 -0.6616\n",
            "T-266\tgulu la basketball la atsikana asanu ndi atatu likugwirana manja\n",
            "H-266\t-0.35673025250434875\t▁ g u l u ▁ l a ▁ b a s k e t b a l ▁ a t a t s i k a n a ▁ m u ▁ d z u ▁ n d i ▁ a t a t u ▁ l i k u g w i r a ▁ m a n j a\n",
            "D-266\t-0.35673025250434875\tgulu la basketbal atatsikana mu dzu ndi atatu likugwira manja\n",
            "P-266\t-0.1089 -0.2918 -0.0770 -0.1722 -0.0686 -0.1020 -0.1192 -0.0931 -0.1626 -1.2044 -0.1244 -0.1563 -1.5260 -0.0961 -0.0127 -0.3058 -0.2296 -0.0451 -1.3322 -0.2771 -0.6009 -0.5661 -0.9684 -0.0248 -0.6122 -0.0469 -0.1409 -0.1550 -0.1185 -0.2320 -0.3740 -0.1768 -0.3970 -1.3311 -1.2313 -0.0256 -0.2527 -0.6643 -0.2066 -0.0853 -0.1545 -0.5616 -0.2494 -0.2646 -0.1816 -0.0388 -0.1313 -1.9511 -0.0543 -0.0142 -0.0774 -0.5554 -0.4719 -0.2516 -0.0586 -0.1166 -1.4807 -0.5362 -0.1482 -0.2169 -0.0130 -0.1304 -0.1001\n",
            "T-361\tgalu wabulauni wovala kolala walalanje akudumpha kuti agwire mpira wamitundu yowala\n",
            "H-361\t-0.2647766172885895\t▁ g a l u ▁ w a b u l a u n i ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ a k u d u m p h a ▁ k u t s o g o l o ▁ k w a ▁ m p i r a ▁ w a m t u n d u ▁ w o y e r a\n",
            "D-361\t-0.2647766172885895\tgalu wabulauni wovala malaya oyera ndi akudumpha kutsogolo kwa mpira wamtundu woyera\n",
            "P-361\t-0.1033 -0.0050 -0.0990 -0.0751 -0.2131 -0.0913 -0.0737 -2.3006 -0.4341 -0.0961 -0.0720 -0.1040 -0.0591 -0.0773 -0.0681 -0.0955 -0.6963 -0.0874 -0.0942 -0.0990 -0.0889 -0.1252 -0.1091 -0.4504 -0.1154 -0.0508 -0.1067 -0.0377 -0.1056 -0.0877 -0.3032 -0.5950 -1.0260 -0.0776 -0.1184 -0.0997 -0.9463 -0.5276 -0.0984 -0.1099 -0.1847 -0.0806 -0.2071 -0.0299 -0.0997 -0.1575 -0.0317 -0.0439 -0.0872 -0.1303 -0.5423 -0.0776 -0.8235 -0.6536 -0.9543 -0.0549 -0.1374 -0.1963 -0.5132 -0.1047 -0.1252 -0.0846 -0.1862 -0.1552 -0.0962 -0.0374 -0.2066 -0.0634 -0.1044 -0.1337 -0.1476 -0.0996 -0.8947 -0.8751 -0.0862 -0.0650 -0.0452 -0.1702 -0.1560 -0.0104 -1.4332 -1.6765 -0.1867 -0.0825 -0.1211 -0.2937\n",
            "T-8\tophunzira achichepere atatu atakhala pamatebulo m laibulale akugwira ntchito ya kunyumba\n",
            "H-8\t-0.3473358154296875\t▁ w o c h i t i r a ▁ c h i c h e p e r a ▁ a t a t u ▁ a t a k h a l a ▁ p a m a t e b u l o\n",
            "D-8\t-0.3473358154296875\twochitira chichepera atatu atakhala pamatebulo\n",
            "P-8\t-0.1174 -0.4039 -0.0837 -3.5545 -0.0771 -0.0577 -0.1418 -0.1411 -0.2421 -0.0827 -0.1219 -0.2997 -0.0431 -0.0730 -1.3931 -0.0826 -0.3503 -0.3515 -0.1979 -0.1371 -0.8057 -0.1559 -0.1351 -0.0333 -0.1766 -0.1041 -0.0898 -0.1451 -0.6187 -0.0715 -0.1413 -0.9473 -0.2067 -0.1161 -0.0556 -0.1035 -0.1148 -0.1145 -0.2535 -0.4106 -0.1102 -0.6094 -0.7391 -0.1127 -0.0692 -0.0808 -0.0584 -2.1400\n",
            "T-167\tmnyamata pa skateboard ali pa khoma pafupi ndi madzi ndi pafupi ndi udzu\n",
            "H-167\t-0.2721731662750244\t▁ m n y a m a t a ▁ a t a t u ▁ p a ▁ s k a t e b o a r d ▁ a l i ▁ p a k h o m a ▁ p a f u p i ▁ n d i ▁ m a d z i ▁ p a f u p i ▁ n d i ▁ c h i t s u l o\n",
            "D-167\t-0.2721731662750244\tmnyamata atatu pa skateboard ali pakhoma pafupi ndi madzi pafupi ndi chitsulo\n",
            "P-167\t-0.1079 -0.4792 -0.1133 -0.0697 -0.0941 -0.0498 -0.0827 -0.0347 -0.1092 -0.1138 -1.4006 -0.1706 -0.1724 -0.0998 -0.6097 -0.0937 -1.8876 -0.1096 -0.3136 -0.1243 -0.2772 -0.1053 -0.0083 -0.0814 -0.1715 -0.0593 -0.0746 -0.0457 -0.1044 -0.2078 -0.1694 -0.8871 -0.0749 -0.1282 -0.0557 -0.1213 -2.5991 -0.4527 -0.0304 -0.1439 -0.1039 -0.1468 -0.5465 -0.0882 -1.0297 -0.0511 -0.0250 -0.0741 -0.0933 -0.0269 -0.0939 -0.1069 -0.0665 -0.4777 -0.2973 -0.1908 -0.0479 -0.0555 -0.0959 -0.7529 -0.1278 -0.4046 -0.0736 -0.0241 -0.0792 -0.1257 -0.0390 -0.0820 -0.1058 -0.0915 -2.3449 -0.2397 -0.1356 -0.3605 -0.0852 -0.3871 -0.1525 -0.1325 -0.1051\n",
            " 77% 10/13 [00:21<00:05,  1.73s/it, wps=1480]T-219\tgalu wakuda akudumpha mu mulu wa chipale chofewa chokhuthala\n",
            "H-219\t-0.3499041199684143\t▁ g a l u ▁ w a k u d a ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ p a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-219\t-0.3499041199684143\tgalu wakuda akudumpha mumlengalenga pa chipale chofewa\n",
            "P-219\t-0.1165 -0.0762 -0.1329 -0.0607 -0.2889 -0.1115 -0.2545 -0.1050 -0.3918 -0.2698 -0.0361 -0.1144 -0.1056 -0.1887 -0.2643 -0.1457 -0.2762 -0.0844 -0.0845 -0.0307 -0.0130 -0.3804 -0.1709 -0.5421 -0.3166 -1.0023 -0.4868 -0.6667 -0.2189 -0.0888 -2.2495 -0.3648 -0.1124 -0.1525 -0.4027 -0.7759 -0.2691 -1.6191 -0.1530 -1.1167 -0.0546 -0.0762 -0.0841 -1.9742 -0.1130 -0.0931 -0.0370 -0.0715 -0.0146 -0.0940 -0.0403 -1.0225 -0.5431 -0.0900 -0.3205 -0.7249\n",
            "T-69\tamuna amene ali m ngalawa akukonza zitsulo ndipo akuyang ana m mwamba\n",
            "H-69\t-0.3051118850708008\t▁ a m u n a ▁ a w i r i ▁ a t a v a l a ▁ m a l a y a ▁ a k u d z a ▁ c h i k w a n g w a n i ▁ n d i k u y a n g ▁ a n a ▁ m ▁ m w a m b a\n",
            "D-69\t-0.3051118850708008\tamuna awiri atavala malaya akudza chikwangwani ndikuyang ana m mwamba\n",
            "P-69\t-0.0982 -0.1210 -0.1103 -0.1174 -0.0768 -0.0871 -0.1164 -0.2000 -1.0115 -0.1614 -0.0820 -0.1128 -0.0916 -0.2547 -0.9778 -0.0910 -0.9238 -0.1152 -0.0791 -0.1032 -0.1013 -0.6596 -0.1242 -0.4851 -0.1530 -0.0989 -0.1237 -0.0970 -0.8638 -0.2085 -0.1372 -1.1783 -0.9138 -0.1222 -0.1597 -2.2407 -0.2170 -0.1465 -0.3419 -0.4798 -0.0904 -0.4086 -0.1330 -0.0386 -0.1622 -0.1636 -0.0477 -0.1852 -0.3003 -0.0309 -0.1135 -3.1421 -0.2142 -0.0129 -0.1029 -0.0466 -0.1359 -0.0660 -0.1023 -0.0754 -0.1295 -0.2028 -0.4566 -0.3389 -0.4130 -0.1351 -0.0997 -0.0958 -0.1241 -0.1360 -0.1756\n",
            "T-272\tgalu wakuda pabwalo la udzu akugwira mpira wabuluu ndi wofiira mkamwa mwake\n",
            "H-272\t-0.2710181772708893\t▁ g a l u ▁ w a k u d a ▁ w a b u l a u n i ▁ w a b u l a u n i ▁ a k u g w i r a ▁ n t c h i t o ▁ m ▁ m p h e p e t e ▁ m w a ▁ m k a m w a ▁ m w a k e\n",
            "D-272\t-0.2710181772708893\tgalu wakuda wabulauni wabulauni akugwira ntchito m mphepete mwa mkamwa mwake\n",
            "P-272\t-0.1052 -0.0782 -0.0825 -0.0778 -0.6175 -0.0965 -0.0188 -0.0982 -0.0546 -0.1054 -0.0308 -0.0848 -0.1066 -0.5049 -0.2636 -1.1246 -0.2646 -0.0890 -0.1058 -0.0218 -0.0561 -0.0799 -0.0862 -0.4078 -0.2547 -1.9469 -0.1826 -0.0775 -0.1599 -0.0236 -0.0804 -0.1076 -0.1236 -0.2966 -0.0457 -0.1307 -0.5124 -0.0334 -0.0950 -0.0527 -0.1342 -0.1774 -1.2807 -0.0718 -0.6907 -0.1504 -0.1543 -0.3959 -0.0899 -0.0691 -1.1147 -1.4137 -0.2860 -0.3955 -0.5565 -0.5728 -0.2944 -0.1623 -0.3405 -0.0465 -0.0691 -0.7806 -0.0139 -0.1150 -0.1191 -0.4882 -0.9694 -0.0731 -0.0924 -0.0367 -0.0965 -0.8128 -0.0840 -0.0584 -0.1045 -0.0189 -0.0739 -0.0511\n",
            "T-381\tmnyamata wamng ono wovala malaya abuluu ndi chisoti chofiira atakwera njinga m mphepete mwa msewu\n",
            "H-381\t-0.17581187188625336\t▁ m n y a m a t a ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ c h i s o t i ▁ c h o f i i r a ▁ c h o f i i r a ▁ a k u y a n g ▁ a n a ▁ m p h e p e t e ▁ m w a ▁ m s e w u\n",
            "D-381\t-0.17581187188625336\tmnyamata wamng ono wovala malaya abuluu ndi chisoti chofiira chofiira akuyang ana mphepete mwa msewu\n",
            "P-381\t-0.1142 -0.0587 -0.1625 -0.0787 -0.1259 -0.0711 -0.1046 -0.0288 -0.1145 -0.1036 -0.1370 -0.0956 -0.0938 -0.0268 -0.0907 -0.0787 -0.1138 -0.0575 -0.0763 -0.1040 -0.0525 -0.3237 -0.1524 -0.1050 -0.0877 -0.1136 -0.1015 -0.1574 -0.0991 -0.0397 -0.1167 -0.0621 -0.1227 -0.0853 -0.2193 -0.9170 -0.1489 -0.0465 -0.2186 -0.0302 -0.0844 -0.1830 -0.1117 -0.1360 -0.0970 -1.0780 -0.0759 -0.0459 -0.6784 -0.0639 -0.1831 -0.0430 -0.1398 -0.0242 -0.0685 -0.0706 -0.4607 -0.0781 -0.2972 -0.0676 -0.1942 -0.1097 -1.3922 -0.0502 -0.1676 -0.2841 -0.1039 -0.3685 -0.0946 -0.2145 -0.0897 -0.2595 -0.4837 -0.0756 -0.0468 -0.1602 -0.0477 -0.4185 -0.0741 -0.0823 -0.0499 -0.9332 -0.0885 -0.1800 -0.9709 -0.3944 -0.1331 -0.0257 -0.0590 -0.0117 -0.0507 -0.1035 -0.0135 -0.0186 -0.1099 -0.1062 -0.0677 -0.5874 -0.0873 -0.0468 -0.0435 -0.1095\n",
            "T-263\tmwamuna wa blond wovala malaya oyera waima kutsogolo kwa maikolofoni ndi gitala\n",
            "H-263\t-0.20362108945846558\t▁ m w a m u n a ▁ w a m n g ▁ o n o ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ w a i m a ▁ k u t s o g o l o ▁ k w a ▁ m a i k o l o f o n i ▁ n d i ▁ g i t a l a\n",
            "D-263\t-0.20362108945846558\tmwamuna wamng ono wovala malaya oyera waima kutsogolo kwa maikolofoni ndi gitala\n",
            "P-263\t-0.1081 -0.0526 -0.0584 -0.1355 -0.2007 -0.0659 -0.1099 -0.1149 -0.1057 -0.2189 -0.2008 -2.2549 -0.8479 -0.1631 -0.1330 -0.0953 -0.0525 -0.1524 -0.0990 -0.0589 -0.1022 -0.0465 -0.1217 -0.0952 -0.1226 -0.0921 -0.0668 -0.1347 -0.0611 -0.1261 -0.0591 -0.1272 -0.0878 -0.0248 -0.0482 -0.1404 -0.0495 -0.1117 -0.1020 -1.1649 -0.6945 -0.1689 -0.0160 -0.1061 -0.0798 -0.1715 -0.2055 -0.0172 -0.0449 -0.0459 -0.0131 -0.0703 -0.0593 -0.0778 -0.0971 -0.0266 -0.0124 -0.1135 -0.1289 -0.1850 -0.1928 -0.5423 -1.0525 -0.1140 -0.1339 -0.0186 -0.0152 -0.0581 -0.0230 -0.1250 -0.2492 -0.0382 -0.0542 -0.1019 -0.0901 -1.5036 -0.4770 -0.3740 -0.0695 -0.0500 -0.0987 -0.8681\n",
            "T-136\tmnyamata amachita zamatsenga pa skateboard yake pamalo omwe ali ndi zolemba zambiri\n",
            "H-136\t-0.22664912045001984\t▁ m n y a m a t a ▁ a m a c h i t a ▁ z a m a s e w e r a ▁ p a ▁ s k a t e b o a r d ▁ p a m a l o ▁ o m w e ▁ a l i ▁ n d i ▁ z o y e n d a ▁ z a m b i r i\n",
            "D-136\t-0.22664912045001984\tmnyamata amachita zamasewera pa skateboard pamalo omwe ali ndi zoyenda zambiri\n",
            "P-136\t-0.1001 -0.0839 -0.1182 -0.0431 -0.1075 -0.0750 -0.0978 -0.0676 -0.1103 -0.1275 -1.5117 -1.5735 -0.1023 -0.3339 -0.1101 -0.1718 -0.0232 -0.0943 -0.1161 -0.0452 -0.0948 -0.3173 -0.1137 -1.7018 -0.0775 -1.3743 -0.1591 -0.2782 -0.1145 -0.1388 -0.1165 -0.1282 -0.3665 -0.5449 -0.1847 -0.0558 -0.0212 -0.0131 -0.2530 -0.0363 -0.0968 -0.0169 -0.0181 -0.1638 -0.5445 -0.1452 -0.1822 -0.3490 -0.0292 -0.0217 -0.0794 -0.0275 -0.4034 -0.0744 -0.0942 -0.0781 -0.0460 -0.0175 -0.1100 -0.1034 -0.1598 -0.1296 -0.0771 -0.1140 -0.0659 -0.2095 -0.7204 -0.3208 -0.6286 -0.0512 -0.1291 -0.5212 -0.1145 -0.1656 -0.6673 -0.1068 -0.0382 -0.0534 -0.0760 -0.0778\n",
            "T-288\tgalu wabulauni ndi wakuda akugona pa chipale chofewa atavala vest ya lalanje\n",
            "H-288\t-0.3127998113632202\t▁ g u l u ▁ l a ▁ a m u n t h u ▁ a k u j a m b u l a ▁ c h i p a l e ▁ c h o f e w a ▁ a t a v a l a ▁ t ▁ s h i r t ▁ y o y e r a\n",
            "D-288\t-0.3127998113632202\tgulu la amunthu akujambula chipale chofewa atavala t shirt yoyera\n",
            "P-288\t-0.1044 -1.8861 -0.2128 -0.0827 -0.0687 -0.0945 -0.0326 -0.0827 -0.1339 -0.4399 -0.1268 -0.3650 -0.1443 -1.1586 -0.2576 -0.5041 -0.1104 -0.7308 -0.0172 -0.1039 -0.3445 -0.0986 -0.2698 -0.1965 -0.0726 -0.2053 -0.1071 -0.0966 -0.5046 -0.0706 -0.0540 -0.3962 -0.1076 -0.1251 -0.0383 -0.0598 -0.0149 -0.0707 -0.0299 -0.0117 -0.0522 -0.0229 -0.0892 -0.1637 -0.4831 -0.0514 -0.1051 -0.3104 -0.1093 -0.1493 -0.1030 -0.1048 -1.4064 -1.8455 -0.2943 -0.3140 -0.2760 -0.0308 -0.0565 -0.1034 -0.0504 -0.9463 -0.7590 -0.2459 -0.4246 -0.1787 -2.7500\n",
            "T-298\tmayi wovala malaya apinki akuseweretsa galu wotuwa ndi woyera pagombe\n",
            "H-298\t-0.24824431538581848\t▁ m a y i ▁ w o v a l a ▁ m a l a y a ▁ a p i n k i ▁ a k u s e w e r e t s a ▁ g a l u ▁ w a k u d a ▁ n d i ▁ w o y e r a\n",
            "D-298\t-0.24824431538581848\tmayi wovala malaya apinki akuseweretsa galu wakuda ndi woyera\n",
            "P-298\t-0.1039 -0.0957 -0.1142 -0.0219 -0.0809 -0.0851 -0.0864 -0.2339 -0.2284 -0.1144 -0.0905 -0.1201 -0.0908 -0.0244 -0.1303 -0.0849 -0.1178 -0.0381 -0.1158 -0.0822 -0.5607 -1.2860 -0.1623 -0.0221 -0.1111 -0.0733 -0.1704 -0.2588 -0.0206 -0.0942 -0.0542 -0.0319 -0.1577 -0.0735 -0.1347 -1.7385 -0.1066 -0.0180 -0.1232 -0.1051 -1.6859 -0.1475 -0.1100 -0.1159 -0.0924 -0.0396 -0.6214 -1.0818 -0.1814 -0.0898 -0.2672 -0.1224 -0.0218 -0.0590 -0.1050 -0.1045 -0.0804 -0.1621 -0.0181 -0.1198 -0.1136 -0.1107 -2.8267\n",
            "T-416\tmunthu wovala zakuda ndi zoyera wanyamula chikwangwani chake cha tenisi kudikirira mpira\n",
            "H-416\t-0.2878306210041046\t▁ m u n t h u ▁ w o v a l a ▁ z a k u d a ▁ n d i ▁ z o y e r a ▁ w a n y a m u l a ▁ c h i n g w a n i ▁ c h a ▁ m ▁ n j a n j i ▁ c h a k e ▁ k u m b u y o ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-416\t-0.2878306210041046\tmunthu wovala zakuda ndi zoyera wanyamula chingwani cha m njanji chake kumbuyo ndi chipale chofewa\n",
            "P-416\t-0.1023 -0.0601 -0.0589 -0.0828 -0.0392 -0.0772 -0.0971 -0.1075 -0.1804 -1.9386 -0.1614 -0.1106 -0.0920 -0.1253 -0.0955 -0.1589 -0.0672 -0.2055 -0.0813 -0.3134 -0.2344 -0.0846 -0.0348 -0.3523 -0.1344 -0.0927 -0.0722 -0.0520 -0.0391 -0.1725 -0.1028 -0.1092 -0.0963 -0.1136 -0.1128 -0.1042 -0.0298 -0.0935 -0.0307 -0.0328 -0.0429 -0.1264 -0.0878 -0.0170 -0.0824 -0.0718 -0.4612 -0.8365 -0.0570 -1.2667 -0.2819 -0.1992 -0.0978 -0.3008 -0.1316 -0.0997 -0.1083 -1.2608 -1.6427 -1.2527 -0.8842 -0.1580 -0.2916 -0.2042 -0.1704 -0.0956 -0.7830 -0.0979 -0.3410 -0.6921 -0.0413 -0.0888 -1.1869 -0.0257 -1.0575 -0.7924 -0.5308 -0.1659 -0.2295 -0.1170 -0.5897 -0.0747 -0.1176 -0.1803 -1.7983 -0.1037 -0.0573 -0.9517 -0.3024 -0.2038 -0.1673 -0.2592 -0.3084 -0.1142 -0.3177 -0.1485 -0.2296 -0.0499 -0.1144 -0.0655\n",
            "T-73\twosewera mpira wachikazi ali pamzere kuti atenge swing ndi racquet yake\n",
            "H-73\t-0.39382636547088623\t▁ w o s e w e r a ▁ m p i r a ▁ w a c h i k a s u ▁ a t a v a l a ▁ m i z e r e ▁ y a k u d a ▁ n d i ▁ t s i t s i ▁ l a k e ▁ n d i ▁ a n t h u\n",
            "D-73\t-0.39382636547088623\twosewera mpira wachikasu atavala mizere yakuda ndi tsitsi lake ndi anthu\n",
            "P-73\t-0.1048 -0.3349 -0.0860 -0.0919 -0.0363 -0.0334 -0.0797 -0.0549 -0.0852 -0.1032 -0.0475 -0.0973 -0.0716 -0.0251 -0.0854 -0.1203 -0.0515 -0.1531 -1.5644 -0.1021 -0.0501 -1.3900 -0.0861 -0.9041 -0.4794 -0.1282 -0.1147 -0.4007 -0.1256 -1.6911 -0.6207 -0.0931 -0.3254 -0.0886 -0.2966 -1.8686 -0.1637 -0.1192 -0.0157 -0.0510 -0.4540 -0.1735 -0.1621 -0.9727 -0.2520 -0.5501 -1.1266 -0.1147 -0.8395 -0.0604 -0.1142 -0.0871 -2.6024 -0.2009 -0.0809 -0.1152 -0.0892 -0.0542 -0.0478 -0.1457 -0.1728 -1.1956 -0.0338 -0.1593 -2.1657 -0.0750 -0.0811 -0.1059 -1.4934 -0.3977 -0.0060 -0.4834 -1.5317 -0.6574\n",
            "T-392\tana ovala zovala zamitundumitundu akusewera pasiteji pafupi ndi nyumba yoyera\n",
            "H-392\t-0.23400184512138367\t▁ a n a ▁ o v a l a ▁ z o v a l a ▁ z a m i t u n d u ▁ n d i ▁ m u n t h u ▁ a k u s e w e r a ▁ p a ▁ s i t e j i ▁ p a f u p i ▁ n d i ▁ n y u m b a ▁ y o y e r a\n",
            "D-392\t-0.23400184512138367\tana ovala zovala zamitundu ndi munthu akusewera pa siteji pafupi ndi nyumba yoyera\n",
            "P-392\t-0.1045 -0.1360 -0.0783 -0.1548 -0.0824 -0.2183 -0.1707 -0.0890 -0.0912 -0.1275 -0.1130 -0.0654 -0.0401 -0.0481 -0.1036 -0.0828 -0.1346 -0.0987 -0.0128 -0.1827 -0.7925 -0.3163 -0.0058 -0.0423 -0.0868 -0.0623 -0.0416 -1.0263 -1.2969 -0.1715 -0.2738 -0.1697 -0.2059 -0.4504 -1.1831 -0.0375 -0.0499 -0.0642 -0.1083 -0.1249 -0.0799 -0.1005 -0.2288 -0.0334 -0.0587 -0.0519 -0.0913 -0.1345 -0.1091 -0.1526 -0.1330 -0.1518 -0.2610 -0.4811 -0.0990 -0.0817 -0.1576 -0.0374 -0.1045 -0.9310 -0.1083 -1.4385 -0.0682 -0.0347 -0.0574 -0.0900 -0.0630 -0.0747 -0.1043 -0.2424 -2.7252 -0.3148 -0.0876 -0.0422 -0.2545 -0.1010 -0.4089 -0.3939 -0.4465 -0.1349 -0.1155 -0.0486 -0.1253 -0.0525\n",
            "T-177\tanthu awiriwa anayang ana zithunzi zapadera zomwe zinali pakhoma\n",
            "H-177\t-0.3521650731563568\t▁ a n t h u ▁ a w i r i ▁ a t a y i m a ▁ k u t h a m a n g a ▁ z i t h u n z i ▁ z a k e ▁ z o m w e ▁ z i n a ▁ a w o\n",
            "D-177\t-0.3521650731563568\tanthu awiri atayima kuthamanga zithunzi zake zomwe zina awo\n",
            "P-177\t-0.0995 -0.1159 -0.0788 -0.0135 -0.0538 -0.1141 -0.0933 -0.1087 -0.4542 -0.0891 -0.0451 -0.0850 -0.1018 -0.1139 -1.3058 -0.1110 -1.1011 -0.3948 -0.3277 -0.4077 -0.0847 -2.4236 -0.1790 -0.3938 -0.2932 -0.0967 -0.5473 -0.1391 -0.0936 -0.2507 -0.1965 -0.1086 -0.0826 -0.0555 -0.9729 -0.1233 -0.0941 -0.0730 -0.0022 -0.0587 -0.2095 -0.1042 -0.2757 -1.5037 -0.0297 -0.1182 -0.5725 -0.0440 -0.1730 -0.1471 -0.1319 -0.0811 -0.0889 -0.0367 -0.4018 -0.3058 -1.1078 -1.2131 -1.3947 -0.1292 -1.9294\n",
            "T-368\tmunthu wovala malaya achikasu amakhala m mphepete mwa thanthwe akuyang ana pansi\n",
            "H-368\t-0.18647152185440063\t▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ a c h i k a s u ▁ a m a k h a l a ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a ▁ a k u y a n g ▁ a n a ▁ p a n s i\n",
            "D-368\t-0.18647152185440063\tmunthu wovala malaya achikasu amakhala m mphepete mwa nyanja akuyang ana pansi\n",
            "P-368\t-0.1068 -0.1874 -0.3427 -0.0651 -0.0252 -0.1914 -0.0933 -0.1057 -0.4829 -0.0520 -0.5212 -0.1158 -0.0739 -0.1194 -0.0966 -0.0311 -0.0892 -0.0902 -0.1313 -0.0338 -0.1212 -0.0829 -0.1924 -0.0177 -0.0449 -0.0766 -0.4162 -0.1408 -0.0375 -0.2359 -0.0778 -0.4214 -0.2040 -0.1054 -0.0487 -0.0366 -0.1003 -0.1123 -0.1318 -0.0894 -0.1969 -0.5352 -1.0965 -0.0132 -0.0653 -0.0850 -0.0298 -0.0540 -0.0036 -0.0346 -0.0863 -0.0302 -0.0130 -0.1407 -0.0953 -0.6512 -0.6026 -0.0999 -1.0036 -0.8535 -0.1113 -0.1943 -0.2362 -0.0427 -0.1290 -0.0138 -0.1253 -0.0428 -0.0946 -0.1108 -0.0772 -0.0704 -0.1572 -0.6986 -1.0798 -0.1294 -0.1175 -0.0643 -0.0536 -0.0299\n",
            "T-97\tbambo wina wokwera njinga yalalanje akudumphira mumlengalenga ndi mzere wa mzinda kumbuyo kwake\n",
            "H-97\t-0.1660538613796234\t▁ b a m b o ▁ w i n a ▁ w o k w e r a ▁ n j i n g a ▁ y a l a l a n j e ▁ a k u d u m p h i r a ▁ m u m l e n g a l e n g a ▁ n d i ▁ m t s i n j e ▁ w a m z i n d a ▁ k u m b u y o ▁ k w a k e\n",
            "D-97\t-0.1660538613796234\tbambo wina wokwera njinga yalalanje akudumphira mumlengalenga ndi mtsinje wamzinda kumbuyo kwake\n",
            "P-97\t-0.1020 -0.0667 -0.1105 -0.0353 -0.0866 -0.0730 -0.1068 -0.0725 -0.0544 -0.0741 -0.1228 -0.1093 -0.0692 -0.2233 -0.0617 -0.1901 -0.0943 -0.1461 -0.0905 -0.1001 -0.0352 -0.0285 -0.0486 -0.0242 -0.1043 -0.1031 -0.1395 -0.0286 -0.0995 -1.6575 -0.0882 -0.4507 -0.1020 -0.0600 -0.0233 -0.0583 -0.1098 -0.5007 -0.0513 -0.1310 -0.0884 -0.0803 -0.0290 -0.0307 -0.1650 -0.0544 -0.0225 -0.1059 -0.1254 -0.0909 -1.3325 -0.6202 -0.2059 -0.0621 -0.0615 -0.0862 -0.0964 -0.0476 -0.0403 -0.0329 -0.0767 -0.0957 -0.1857 -1.1336 -0.1520 -0.0853 -0.0884 -0.2314 -0.1031 -0.1071 -0.1375 -0.2045 -0.4049 -0.0408 -0.0883 -0.0243 -0.1287 -0.3506 -1.3621 -0.3679 -0.2353 -0.0259 -0.2362 -0.2415 -0.0327 -0.0487 -0.0610 -0.0204 -0.0598 -0.0157 -0.0586 -0.2765 -0.0067 -0.0174 -0.1225 -0.0614 -0.1157 -0.0575\n",
            "T-417\tanthu angapo akuyang ana bambo wina yemwe anavala sweti yofiira akusewera gofu\n",
            "H-417\t-0.2673989236354828\t▁ a n t h u ▁ a n g a p o ▁ a k u y a n g ▁ a n a ▁ p a ▁ m a y i ▁ w i n a ▁ y e m w e ▁ w a v a l a ▁ s u t i ▁ y o f i i r a ▁ a k u s e w e r a ▁ g u l u\n",
            "D-417\t-0.2673989236354828\tanthu angapo akuyang ana pa mayi wina yemwe wavala suti yofiira akusewera gulu\n",
            "P-417\t-0.1043 -0.1454 -0.0907 -0.0868 -0.0783 -0.0917 -0.0905 -0.2487 -0.2059 -0.1166 -0.1013 -0.0227 -0.0553 -0.0850 -0.1142 -0.1447 -0.1260 -0.0530 -0.1168 -0.0572 -0.0809 -0.0711 -0.0943 -0.0289 -0.1256 -0.1034 -0.5077 -0.1255 -0.8481 -0.4545 -0.9674 -1.5630 -0.1867 -0.0964 -0.0958 -0.0417 -0.0442 -0.1052 -0.1131 -1.3775 -0.0177 -0.1174 -0.0922 -0.0954 -0.1220 -1.1072 -0.1068 -1.1452 -0.1229 -0.0935 -0.1150 -0.1230 -0.0931 -0.7423 -0.0479 -0.1709 -0.1106 -0.0910 -0.0256 -0.0982 -0.1259 -0.1735 -0.0293 -0.1707 -0.1188 -0.1429 -0.0494 -0.1513 -0.0822 -0.0539 -0.0230 -0.0556 -0.0523 -0.1208 -0.1991 -2.3687 -0.7538 -0.1584 -0.1722 -2.5862\n",
            "T-394\tmayi wina atavala diresi ya plaid ataima m mphepete mwa msewu pafupi ndi galu woyera\n",
            "H-394\t-0.24502037465572357\t▁ m a y i ▁ w i n a ▁ a t a v a l a ▁ j e r e s i ▁ y a k e ▁ a t a y i m a ▁ m ▁ m p h e p e t e ▁ m w a ▁ m s e w u ▁ p a f u p i ▁ n d i ▁ g a l u ▁ w i n a\n",
            "D-394\t-0.24502037465572357\tmayi wina atavala jeresi yake atayima m mphepete mwa msewu pafupi ndi galu wina\n",
            "P-394\t-0.0998 -0.1110 -0.0853 -0.0494 -0.1057 -0.0890 -0.1321 -0.0619 -0.0773 -0.1304 -0.0945 -0.1729 -0.0386 -0.1231 -0.0738 -0.1064 -0.0776 -0.0987 -0.1001 -0.1803 -0.9867 -0.4689 -1.1416 -0.0378 -0.2439 -0.0714 -0.6021 -0.1187 -2.4980 -0.1708 -0.0850 -0.2745 -0.4948 -0.0858 -0.6688 -0.1049 -0.0510 -0.1112 -0.0773 -0.3603 -0.8939 -0.6074 -0.0068 -0.1057 -0.0879 -0.0437 -0.0558 -0.0066 -0.0309 -0.0643 -0.0227 -0.0356 -0.1537 -0.1010 -0.0234 -0.0572 -0.1044 -0.0485 -0.0370 -0.1047 -0.1729 -0.1612 -0.0220 -0.0673 -0.0415 -0.0864 -0.0813 -0.0249 -0.1014 -0.1059 -0.0839 -2.8225 -0.1116 -0.0485 -0.1456 -0.1764 -0.7646 -0.8372 -0.1753 -0.1152 -0.4482\n",
            "T-171\tanyamata anayi akusewera mpira kutsogolo kwa zitseko zazikulu zokongola\n",
            "H-171\t-0.2441510558128357\t▁ a n y a m a t a ▁ a n a y i ▁ a k u s e w e r a ▁ m p i r a ▁ k u t s o g o l o ▁ k w a ▁ z i t s e k o ▁ z a z i k u l u ▁ z o k o n g o l a\n",
            "D-171\t-0.2441510558128357\tanyamata anayi akusewera mpira kutsogolo kwa zitseko zazikulu zokongola\n",
            "P-171\t-0.1015 -2.1392 -0.1450 -0.0469 -0.1139 -0.0613 -0.1006 -0.0311 -0.1125 -0.1336 -0.1130 -1.7812 -0.2155 -0.0811 -0.1188 -0.1010 -0.1088 -0.0495 -0.1133 -0.2944 -0.0425 -0.0268 -0.0924 -0.0845 -0.1233 -0.0848 -1.0486 -0.5292 -0.1025 -0.0746 -0.1064 -0.1019 -0.8247 -0.3370 -0.4592 -0.1691 -0.0273 -0.0161 -0.0773 -0.0712 -0.0652 -0.1657 -0.0416 -0.0694 -0.1558 -0.0796 -0.1896 -0.5605 -2.0536 -0.0559 -0.0711 -1.3291 -0.0384 -0.0616 -0.0103 -0.1939 -0.3336 -0.0400 -0.0280 -0.1497 -0.0396 -0.1117 -0.2096 -0.1280 -0.3755 -0.2726 -0.1377 -0.2047 -0.0558 -0.0362 -0.0269 -0.1224 -0.0479\n",
            "T-379\tbambo wina akumenya mpira wa tenesi pa mpikisano wa akatswiri\n",
            "H-379\t-0.3363211750984192\t▁ b a m b o ▁ w i n a ▁ a k u m e n y a ▁ m p i r a ▁ w a ▁ t e n i s i ▁ p a k a t i ▁ p a ▁ b w a l o ▁ l a c h i k a s u\n",
            "D-379\t-0.3363211750984192\tbambo wina akumenya mpira wa tenisi pakati pa bwalo lachikasu\n",
            "P-379\t-0.1156 -0.0411 -0.1197 -0.0439 -0.0531 -0.0727 -0.1175 -0.0503 -0.0628 -0.0938 -0.1254 -0.1099 -0.7995 -0.0807 -0.1022 -0.1635 -0.1415 -0.0787 -0.0940 -0.1061 -0.7079 -0.8202 -0.5125 -0.2052 -0.0522 -0.2025 -0.1407 -0.0475 -0.1323 -0.2090 -0.1890 -1.8350 -0.2397 -0.2213 -0.1133 -0.3459 -0.0834 -0.0529 -0.1575 -1.8931 -0.3174 -0.0930 -0.0357 -0.1050 -1.4558 -0.1076 -0.0696 -1.8491 -1.3516 -0.0691 -1.1160 -0.0382 -0.1712 -0.1145 -0.1573 -1.4713 -0.1541 -0.0819 -0.6965 -0.1456 -0.1025 -0.6503 -0.1022\n",
            "T-332\tmayi wina wa ku asia wakhala pansi pakati pa zinyalala zamatabwa atanyamula ndodo\n",
            "H-332\t-0.2661200761795044\t▁ m a y i ▁ w i n a ▁ w a k u ▁ a s i a ▁ w a k h a l a ▁ p a n s i ▁ p a ▁ z i n y a l a l a ▁ z a m a t a b w a ▁ a t a n y a m u l a ▁ n d o d o\n",
            "D-332\t-0.2661200761795044\tmayi wina waku asia wakhala pansi pa zinyalala zamatabwa atanyamula ndodo\n",
            "P-332\t-0.1097 -2.3656 -0.1627 -0.0242 -0.0711 -0.0805 -0.1371 -0.0735 -0.0720 -0.1240 -0.1056 -0.5776 -0.5334 -0.9080 -0.2239 -0.1363 -0.1496 -0.7908 -0.0982 -0.1298 -0.0837 -0.7266 -0.4381 -0.1725 -0.1079 -0.1288 -0.3600 -0.1192 -0.1257 -0.0534 -0.1195 -0.3299 -1.4608 -0.0660 -0.0876 -0.2546 -0.1521 -0.2233 -0.8750 -0.2373 -0.2161 -0.6489 -0.0845 -0.0450 -0.1366 -0.2281 -0.1281 -0.1051 -0.2024 -0.1374 -0.6876 -0.1642 -0.0273 -0.3464 -0.1357 -0.0136 -0.1014 -0.1165 -0.2416 -0.0232 -0.0897 -0.1417 -0.0060 -0.0694 -0.0265 -0.0498 -0.0548 -0.1103 -0.1437 -0.7022 -0.0508 -0.0974 -0.0033 -0.0373 -1.5910\n",
            "T-9\tgalu akupalasa chipika chomwe chagwa pafupi ndi mtsinje pamalo omwe pali udzu\n",
            "H-9\t-0.3574335277080536\t▁ g a l u ▁ a k u k w e r a ▁ c h i p i k a ▁ c h o m w e ▁ c h a k u d a ▁ p a f u p i ▁ n d i ▁ z i n j i ▁ p a m a l o ▁ o m w e ▁ g a l i m o t s i\n",
            "D-9\t-0.3574335277080536\tgalu akukwera chipika chomwe chakuda pafupi ndi zinji pamalo omwe galimotsi\n",
            "P-9\t-0.0960 -0.0318 -0.0939 -0.0595 -0.0696 -0.0922 -0.2105 -0.0217 -0.1257 -0.3871 -1.4280 -0.1497 -0.0437 -0.1323 -0.0967 -1.6747 -0.1349 -0.0490 -2.0731 -0.2303 -0.5029 -0.2008 -0.2112 -0.5299 -0.0598 -0.4739 -0.0920 -0.2428 -0.1163 -0.1262 -0.0689 -0.0483 -0.7525 -0.6781 -0.0902 -1.5665 -1.3344 -0.1164 -0.5604 -0.1324 -0.2145 -0.0470 -0.0189 -0.0819 -0.1086 -0.0234 -0.1237 -0.1308 -0.0870 -0.7856 -0.0801 -0.8757 -1.7755 -0.4037 -1.3591 -0.0839 -0.1385 -0.3528 -0.1317 -0.0555 -0.0451 -0.0692 -0.0783 -0.5268 -0.1284 -0.0691 -0.1054 -2.7065 -0.1511 -0.0699 -0.1218 -0.4397 -0.3592 -0.0707 -0.3221 -0.2320 -0.0448\n",
            "T-277\tmnyamata akukwera njinga pamwamba pa msewu wa mtawuni pafupi ndi njanji\n",
            "H-277\t-0.29214170575141907\t▁ m n y a m a t a ▁ a k u k w e r a ▁ n j i n g a ▁ y a m o t o ▁ p a m w a m b a ▁ p a ▁ m t s i k a n a ▁ p a f u p i ▁ n d i ▁ c h i n t h u\n",
            "D-277\t-0.29214170575141907\tmnyamata akukwera njinga yamoto pamwamba pa mtsikana pafupi ndi chinthu\n",
            "P-277\t-0.1085 -0.2266 -0.0633 -0.0502 -0.1118 -0.0329 -0.0973 -0.0200 -0.1089 -0.1145 -0.4976 -0.1267 -0.1172 -0.1619 -0.0179 -0.1029 -0.0789 -0.0861 -0.1067 -0.0877 -0.0306 -0.0560 -0.0261 -0.0586 -0.1059 -0.1365 -0.5767 -0.0947 -1.9392 -0.3977 -0.0413 -0.0760 -0.1295 -0.4803 -0.1188 -0.3648 -1.5632 -0.2531 -0.0376 -0.3346 -0.1167 -0.0929 -0.0334 -0.1425 -0.0815 -0.7885 -0.7524 -1.9470 -1.3800 -0.2655 -0.1308 -0.3246 -0.2112 -0.2797 -1.7690 -0.1127 -0.9684 -0.0321 -0.0493 -0.0986 -0.2602 -0.0342 -0.0966 -0.1183 -0.1059 -0.4940 -0.1040 -0.0856 -0.4786 -0.3555 -0.3483 -0.0961 -0.0336\n",
            "T-45\tgalu wabulauni wokhala ndi kolala wakuda anyambita pakamwa pake\n",
            "H-45\t-0.2960520386695862\t▁ g a l u ▁ w a b u l a u n i ▁ w o k h a l a ▁ n d i ▁ k o l a l a ▁ w a k u j a m b u l i d w a ▁ n d i ▁ k a m w a ▁ k a m w a k e\n",
            "D-45\t-0.2960520386695862\tgalu wabulauni wokhala ndi kolala wakujambulidwa ndi kamwa kamwake\n",
            "P-45\t-0.1025 -0.0085 -0.1082 -0.0610 -0.0554 -0.0972 -0.0681 -0.7318 -0.5970 -0.0691 -0.0616 -0.1278 -0.0507 -0.0381 -0.0884 -0.0836 -0.1239 -0.5319 -0.0724 -0.0284 -0.1028 -0.0533 -0.0931 -0.0931 -0.0233 -0.0933 -0.1069 -0.2452 -0.8062 -0.8080 -0.4629 -0.1400 -0.2915 -0.1038 -0.1144 -0.4883 -0.1873 -0.1400 -0.2631 -2.7071 -0.0905 -0.1374 -0.0543 -0.1611 -0.0714 -1.0282 -0.2174 -0.4070 -0.0889 -0.1206 -1.4240 -0.1447 -0.1497 -0.1359 -0.8701 -0.2071 -0.3805 -0.0916 -0.0887 -0.2146 -0.3361 -0.2823 -1.9732 -0.1479 -0.0800 -0.5112 -0.1452 -0.1431\n",
            "T-125\tmwamuna akuyendetsa moped ndi chisamaliro chakumbali ndi jeepney kumbuyo\n",
            "H-125\t-0.3521025776863098\t▁ m w a m u n a ▁ a k u y e n d e t s a ▁ m ▁ c h i p i n d i k a ▁ c h a m a l i r o ▁ k u m b a l i ▁ n d i ▁ c h i n t h u ▁ c h a k u m b u y o\n",
            "D-125\t-0.3521025776863098\tmwamuna akuyendetsa m chipindika chamaliro kumbali ndi chinthu chakumbuyo\n",
            "P-125\t-0.1036 -0.1629 -0.0454 -0.1060 -0.0614 -0.0548 -0.0860 -0.1046 -0.1210 -0.2082 -0.0956 -0.1123 -0.7594 -0.0400 -1.2619 -0.0296 -0.2179 -0.0182 -0.0328 -0.1003 -0.0890 -1.2907 -0.7314 -0.3916 -0.0778 -0.1281 -0.7678 -0.1098 -0.5221 -0.4628 -0.6683 -0.3629 -1.0963 -0.1561 -1.1179 -0.0631 -0.2134 -1.1470 -0.0756 -0.0521 -0.9499 -0.7456 -0.1000 -0.0784 -0.3340 -0.0948 -0.3614 -0.0752 -0.4136 -0.1186 -0.0448 -0.1001 -1.2298 -0.3477 -0.2056 -0.1079 -0.4622 -0.0940 -0.0835 -1.1607 -0.6309 -0.1781 -0.0504 -0.1669 -1.1272 -0.0959 -2.4970 -0.6285 -0.1995 -0.0760 -0.0925 -0.0697 -0.0531 -0.0583 -0.1303\n",
            "T-160\tazimayi awiri ali ndi ngolo m nyumba yomwe ili pafupi ndi tebulo ndi mipando\n",
            "H-160\t-0.3649055063724518\t▁ a t s i k a n a ▁ a w i r i ▁ a l i ▁ n d i ▁ g u l u ▁ l o m w e ▁ l i l i ▁ p a f u p i ▁ n d i ▁ k a f u p i ▁ n d i ▁ t e b u l o ▁ n d i ▁ n k h a l a n d o\n",
            "D-160\t-0.3649055063724518\tatsikana awiri ali ndi gulu lomwe lili pafupi ndi kafupi ndi tebulo ndi nkhalando\n",
            "P-160\t-0.1028 -2.4461 -0.2249 -0.0400 -0.1114 -0.0964 -0.0933 -0.0892 -0.1191 -0.1277 -0.1142 -0.0200 -0.1015 -0.0613 -0.0921 -0.0953 -0.2465 -0.3168 -0.1080 -0.1051 -0.0873 -0.0529 -0.0877 -0.1031 -2.1560 -1.3407 -0.0980 -0.2662 -0.0845 -0.1115 -0.3688 -0.2008 -0.0975 -0.0790 -0.0795 -0.3016 -0.1042 -1.0509 -0.2522 -0.1127 -1.8205 -0.1149 -0.5503 -0.1901 -0.2122 -0.0383 -0.0760 -0.5947 -0.1136 -0.0936 -0.1773 -0.4392 -0.6765 -1.6655 -0.1955 -0.9453 -0.0961 -0.0882 -0.1795 -0.0503 -0.0884 -0.1346 -1.8963 -0.2307 -0.3311 -0.1387 -0.0550 -0.0413 -0.1057 -0.8741 -0.0772 -0.0767 -0.1604 -2.1824 -1.4475 -0.1493 -0.3171 -0.3516 -0.5032 -0.0553 -0.5542 -0.2595 -0.1923\n",
            "T-192\tmwana akudumpha pa trampoline kutsogolo kwa khoma la njerwa ndi pansi pa mbendera zamitundu\n",
            "H-192\t-0.39766818284988403\t▁ m a y i ▁ a k u d u m p h a ▁ c h i n t h u ▁ c h o z u n g u l i r a ▁ k w a ▁ k a n j i r a ▁ n d i ▁ m k a z i ▁ p a m b e n d e r a ▁ z a m i t u n d u\n",
            "D-192\t-0.39766818284988403\tmayi akudumpha chinthu chozungulira kwa kanjira ndi mkazi pambendera zamitundu\n",
            "P-192\t-0.1022 -0.0545 -0.7310 -0.1414 -0.1470 -0.0856 -0.2822 -0.0257 -0.1174 -0.7083 -0.0693 -0.0990 -0.0613 -0.0392 -0.0737 -0.1259 -0.8983 -0.0574 -1.6871 -0.8974 -0.4529 -0.0125 -0.0937 -0.1385 -0.6198 -0.1257 -0.3098 -2.4043 -0.4774 -0.0708 -0.0169 -0.1075 -0.2008 -0.2409 -0.2767 -0.1438 -0.1341 -0.2547 -2.0512 -0.1416 -0.2043 -1.7515 -0.5417 -0.3660 -0.0718 -0.1116 -0.1062 -0.1040 -0.1359 -1.0797 -0.1107 -0.1068 -0.4636 -1.0694 -0.5024 -0.1272 -0.6269 -0.0874 -0.1015 -0.9053 -0.1299 -0.0822 -2.4711 -0.2346 -0.2999 -0.2513 -0.1123 -0.0713 -0.1015 -0.1569 -0.0378 -0.2373 -2.0625 -0.1046 -0.0068 -0.1037 -0.1244 -0.1001 -0.0465 -1.8276\n",
            "T-271\tgalu wakuda mkati mwa nyumba akuyang ana chinthu chapamwamba\n",
            "H-271\t-0.26051977276802063\t▁ g a l u ▁ w a k u d a ▁ n d i ▁ k a t i ▁ m w a n a ▁ a k u y a n g ▁ a n a ▁ c h i n t h u ▁ c h a ▁ p a m w a m b a\n",
            "D-271\t-0.26051977276802063\tgalu wakuda ndi kati mwana akuyang ana chinthu cha pamwamba\n",
            "P-271\t-0.1156 -0.0405 -0.1184 -0.0364 -0.0830 -0.0921 -0.0849 -0.1268 -0.0409 -0.1289 -0.1587 -0.2945 -0.1120 -0.6562 -0.2490 -0.1124 -0.0782 -0.3720 -0.1824 -3.2013 -0.0990 -0.1486 -0.0611 -0.2970 -0.1275 -1.1554 -0.0832 -0.0945 -0.1520 -0.1016 -0.0668 -2.5989 -0.0745 -0.0467 -0.0615 -0.0863 -0.0793 -0.0408 -0.1211 -0.1167 -0.0502 -0.0691 -0.1313 -0.1107 -0.0659 -0.1351 -0.1610 -0.2624 -0.4221 -0.1000 -0.1081 -0.5018 -0.7328 -0.1584 -0.1068 -0.2333 -0.0745 -0.0808 -0.0304 -0.1263 -0.3343\n",
            "T-310\tbambo wina wachikulire akugulitsa chakudya pasitolo kwa mnyamata wina\n",
            "H-310\t-0.23972225189208984\t▁ b a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ a k u g w i r i t s a ▁ c h a k u d y a ▁ c h a c h i t o l o ▁ p a m n y a m a t a ▁ w i n a\n",
            "D-310\t-0.23972225189208984\tbambo wina wachikulire akugwiritsa chakudya chachitolo pamnyamata wina\n",
            "P-310\t-0.1157 -0.1375 -0.1168 -0.0880 -0.0489 -0.0648 -0.1152 -0.0714 -0.0749 -0.0922 -0.1433 -0.1042 -0.0238 -0.4123 -0.1929 -0.0619 -0.0473 -0.0253 -0.0403 -0.0486 -0.0615 -0.0316 -0.0240 -0.1009 -0.0936 -0.1414 -0.0855 -0.1168 -1.1197 -0.0707 -0.0987 -0.2538 -0.0528 -0.2218 -0.1324 -0.0922 -1.0293 -0.1352 -0.2232 -0.2460 -0.0786 -0.1532 -0.5334 -0.1056 -0.1522 -1.3345 -0.1374 -0.3701 -1.3644 -0.1543 -0.0458 -0.7222 -0.1936 -0.9216 -0.5070 -0.1557 -0.2459 -0.1773 -0.1314 -1.4788 -0.0945 -0.1284 -0.0479 -0.1320 -0.0331 -0.1008 -0.3697 -0.0671 -0.0585 -0.0833 -0.1043 -0.7208\n",
            "T-322\tawiri amipanda amachitira limodzi wina amalumpha pamene wina agwada\n",
            "H-322\t-0.4037606418132782\t▁ a m u n a ▁ a w i r i ▁ p a n j a ▁ m a t s i k a n a ▁ y e m w e ▁ w i n a ▁ a m a t h a m a n g a ▁ p a m e n e ▁ w i n a ▁ a t a g o n a\n",
            "D-322\t-0.4037606418132782\tamuna awiri panja matsikana yemwe wina amathamanga pamene wina atagona\n",
            "P-322\t-0.1123 -0.1409 -0.4602 -0.7244 -0.5218 -0.2506 -0.1171 -0.2799 -0.2918 -0.0925 -0.0585 -0.1065 -0.1170 -1.4564 -0.1428 -0.4229 -0.5101 -0.4442 -0.1567 -0.4729 -0.5765 -0.8638 -1.0012 -0.0723 -0.7250 -0.6289 -0.8427 -0.0685 -0.3479 -2.0856 -0.0670 -0.0903 -0.0637 -0.1087 -0.1154 -0.3466 -0.2374 -0.1146 -0.1502 -0.1120 -0.8836 -0.3370 -0.1205 -3.5198 -0.2362 -0.1006 -0.1377 -0.1847 -0.0823 -0.0655 -0.3070 -0.0887 -0.0080 -0.1409 -0.1732 -0.1690 -0.1016 -0.0571 -0.1048 -2.0579 -0.0380 -0.1307 -0.1168 -0.2981 -0.0703 -0.1634 -0.1010 -2.5453 -0.8122 -0.1738 -0.0986 -0.1487\n",
            "T-232\tgalu wamkulu wakuda ndi woyera amathamanga m madzi a m nyanja\n",
            "H-232\t-0.21003185212612152\t▁ g a l u ▁ w a m k u l u ▁ w a k u d a ▁ n d i ▁ w o y e r a ▁ a m a t h a m a n g a ▁ m ▁ m a d z i ▁ a l i ▁ n d i ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-232\t-0.21003185212612152\tgalu wamkulu wakuda ndi woyera amathamanga m madzi ali ndi chipale chofewa\n",
            "P-232\t-0.1151 -0.2120 -0.1408 -0.0852 -0.2164 -0.1343 -0.3207 -0.1231 -0.3869 -0.0543 -0.0572 -0.2957 -0.0747 -0.1347 -0.0474 -0.1074 -0.0872 -0.1011 -0.0446 -0.0828 -0.1177 -0.0490 -0.0802 -0.0969 -0.1011 -0.0321 -0.0495 -0.1737 -0.1977 -0.0995 -0.1021 -0.1546 -0.0496 -0.3394 -0.0846 -0.0102 -0.2351 -0.0805 -0.0495 -0.0852 -0.0663 -0.1081 -0.1159 -0.0884 -0.0545 -0.0604 -0.0509 -0.1710 -0.3566 -0.4482 -0.0974 -0.1265 -1.3871 -0.1464 -0.1283 -0.1119 -2.2018 -0.3025 -0.0950 -0.1218 -1.9194 -0.1560 -0.3320 -0.3918 -0.2035 -0.1376 -0.2536 -0.1123 -0.2178 -0.1007 -0.0346 -0.5446 -0.1094 -0.0337 -0.0772 -0.0894\n",
            "T-337\tmnyamata wina amene ali ndi ma dreadlocks akuda atakhala pansi pamene wina akukonza\n",
            "H-337\t-0.2599600851535797\t▁ m n y a m a t a ▁ w i n a ▁ a m e n e ▁ a l i ▁ n d i ▁ m a ▁ j e k e t e ▁ a k u d a ▁ a t a k h a l a ▁ p a n s i ▁ p a ▁ m e n e ▁ w i n a ▁ a k u w o n z a\n",
            "D-337\t-0.2599600851535797\tmnyamata wina amene ali ndi ma jekete akuda atakhala pansi pa mene wina akuwonza\n",
            "P-337\t-0.1076 -0.1085 -0.0388 -0.0600 -0.1204 -0.0736 -0.0994 -0.0279 -0.1284 -0.1022 -0.0772 -0.1102 -0.0860 -0.1153 -0.1080 -2.1195 -0.0419 -0.0403 -0.1033 -0.0764 -0.1169 -0.1235 -0.0542 -0.0943 -0.0885 -0.0335 -0.0645 -0.1281 -0.0856 -0.0215 -0.1092 -1.6968 -0.4941 -0.0331 -1.7293 -0.0852 -0.0455 -0.1167 -0.1223 -0.2364 -0.1358 -0.0933 -0.5208 -0.5244 -0.1278 -0.1229 -0.5652 -0.0955 -0.2562 -0.0412 -0.1110 -0.0877 -0.0992 -0.0936 -0.0235 -0.1214 -1.6066 -0.0900 -0.0994 -0.1163 -0.0184 -0.1402 -0.5239 -0.0719 -0.4138 -0.0674 -0.0778 -0.1244 -1.1602 -0.1645 -0.0929 -0.1154 -0.1595 -0.1301 -0.0339 -0.1073 -1.5225 -0.5224 -0.2855 -1.1143 -0.0871 -0.2276\n",
            "T-21\tmnyamata akupanga masewera otsetsereka pansi pa masitepe achitsulo\n",
            "H-21\t-0.2477758526802063\t▁ m n y a m a t a ▁ a k u p a m a s e w e r a ▁ o t s e t s e r e k a ▁ p a n s i ▁ p a ▁ m a s i t e p e ▁ a ▁ c h i t s u l o\n",
            "D-21\t-0.2477758526802063\tmnyamata akupamasewera otsetsereka pansi pa masitepe a chitsulo\n",
            "P-21\t-0.1136 -0.1229 -0.0290 -0.0544 -0.1159 -0.1036 -0.0932 -0.0292 -0.1107 -0.1157 -1.2858 -0.5074 -0.0691 -0.1911 -0.3899 -1.3202 -0.2566 -1.3384 -0.0796 -0.0710 -0.3429 -0.0636 -0.2680 -0.1317 -0.8356 -0.2576 -0.0140 -0.0801 -0.0142 -0.0140 -0.0323 -0.0726 -0.0861 -0.0163 -0.1597 -0.1308 -0.0563 -0.1470 -0.2936 -0.4167 -0.0801 -0.1273 -0.0266 -0.2014 -0.5458 -0.0805 -0.3145 -0.8852 -0.0902 -0.0623 -0.0945 -0.0937 -0.0740 -0.1590 -0.6945 -1.2132 -0.2048 -0.2142 -0.0557 -0.5220 -0.0243 -0.2407 -0.0305 -0.0207 -0.2200\n",
            "T-204\tamuna anayi akudumphira mumlengalenga pamene wachisanu waima pansi kunja kwa nyumba\n",
            "H-204\t-0.24371574819087982\t▁ a m u n a ▁ a n a y i ▁ a k u d u m p h i r a ▁ m u m l e n g a l e n g a ▁ p a m e n e ▁ w a c h i t s a ▁ n y u m a ▁ y e m w e ▁ a l i ▁ k u n j a ▁ k w a ▁ n y u m b a\n",
            "D-204\t-0.24371574819087982\tamuna anayi akudumphira mumlengalenga pamene wachitsa nyuma yemwe ali kunja kwa nyumba\n",
            "P-204\t-0.0973 -0.1319 -0.1109 -0.0694 -0.0544 -0.1099 -0.1146 -0.1908 -0.9577 -0.2683 -0.0317 -0.1074 -0.0857 -0.1367 -0.1147 -0.1553 -0.0536 -0.0648 -0.0475 -0.0486 -0.0209 -0.1439 -0.0172 -0.0915 -0.1090 -0.0379 -0.8306 -0.5445 -0.1183 -0.0803 -0.0747 -0.0466 -0.0844 -0.0586 -0.0695 -0.0385 -0.0553 -0.0882 -0.1262 -0.1501 -0.1450 -0.4713 -0.0841 -0.0254 -0.0732 -0.0871 -0.8336 -0.5076 -0.6068 -0.0809 -0.0499 -0.3824 -0.0344 -0.2646 -0.2294 -1.1983 -0.5768 -0.9564 -0.1682 -0.8122 -0.0974 -0.3053 -0.2219 -0.0879 -0.2673 -0.2307 -0.1013 -1.1637 -1.2450 -0.1264 -0.0785 -0.7116 -0.0913 -1.0531 -0.0469 -0.1188 -0.1422 -0.1244 -0.1435 -0.0851 -0.0864 -0.5731 -0.0204 -0.0403 -0.0705 -0.0280 -0.0774 -0.7837\n",
            "T-386\tgalu wofiirira waubweya akuthamanga m dera laudzu\n",
            "H-386\t-0.23102538287639618\t▁ g a l u ▁ w o f i i r i r a ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ m ▁ m p h e p e t e ▁ m w a ▁ u d z u\n",
            "D-386\t-0.23102538287639618\tgalu wofiirira wabulauni akuthamanga m mphepete mwa udzu\n",
            "P-386\t-0.1122 -0.0472 -0.1418 -0.1230 -0.2379 -0.1243 -0.0868 -0.0512 -0.0201 -0.0627 -0.1331 -0.0403 -0.3346 -0.0744 -0.0952 -0.1333 -0.0314 -0.3224 -1.1319 -0.1813 -0.1512 -0.2904 -0.0597 -0.0711 -0.1415 -0.1267 -0.0737 -0.7070 -0.0924 -0.0694 -0.0875 -0.0919 -0.0261 -0.1081 -0.0607 -0.1006 -0.3451 -0.1013 -0.8411 -0.7214 -0.8607 -0.1480 -0.1308 -0.2005 -0.1954 -0.3065 -0.0600 -0.0871 -0.1298 -0.3177 -0.0555 -0.1079 -0.4843 -2.0579 -0.2391 -0.1697 -0.0519 -0.0446\n",
            "T-424\tatsikana awiri akusewera ndi mipira yapulasitiki m dzenje la mpira\n",
            "H-424\t-0.2651229798793793\t▁ a t s i k a n a ▁ a w i r i ▁ a k u s e w e r a ▁ n d i ▁ m p i r a ▁ a k u l a s i t i k i z a ▁ n j i r a\n",
            "D-424\t-0.2651229798793793\tatsikana awiri akusewera ndi mpira akulasitikiza njira\n",
            "P-424\t-0.1119 -0.0970 -0.0352 -0.0883 -0.0716 -0.0286 -0.1277 -0.0445 -0.1077 -0.1190 -0.1163 -0.2406 -0.0837 -0.0570 -0.0997 -0.1228 -0.2029 -0.0470 -0.1296 -0.0290 -0.0293 -0.0420 -0.1077 -0.0626 -0.1188 -0.0856 -0.2241 -0.1652 -0.1291 -0.0965 -0.2643 -0.0146 -0.1444 -0.0543 -0.1215 -0.1341 -1.3626 -0.2422 -0.1161 -0.8981 -0.4531 -0.5669 -0.0364 -0.0985 -0.1294 -0.0876 -0.0785 -0.4036 -1.4293 -0.5770 -1.4343 -0.8939 -0.6707 -0.1706 -0.1036 -1.3405\n",
            "T-274\twoyenda panyanja atavala suti yakuda wakwera mafunde oyera m nyanja\n",
            "H-274\t-0.28528478741645813\t▁ m n y a m a t a ▁ p a n y a n j a ▁ a t a v a l a ▁ s u t i ▁ y a k u d a ▁ a k u y a n g ▁ a n a ▁ m a f u n d e ▁ o y e r a\n",
            "D-274\t-0.28528478741645813\tmnyamata panyanja atavala suti yakuda akuyang ana mafunde oyera\n",
            "P-274\t-0.1011 -1.7592 -1.3865 -0.1739 -0.1072 -0.0732 -0.1548 -0.0739 -0.1053 -0.1003 -1.2637 -0.1180 -0.6812 -1.2151 -0.0993 -0.2855 -0.0347 -0.1258 -0.1219 -0.0838 -0.0163 -0.1120 -0.1362 -0.1304 -0.0891 -0.1110 -0.1005 -1.3769 -0.0794 -0.0217 -0.0384 -0.0708 -0.0574 -0.1520 -0.1334 -0.1041 -0.0120 -0.1098 -0.1234 -0.4452 -0.0749 -0.1191 -0.3317 -0.2210 -0.3459 -0.0734 -0.0627 -0.1104 -0.1715 -0.1139 -0.0855 -1.5029 -0.2683 -0.1849 -0.1260 -0.0954 -0.0232 -0.0109 -0.0888 -0.0591 -0.0696 -0.1285 -0.0436 -0.1206 -2.6272\n",
            "T-294\tamuna angapo ovala zovala zobiriwira ndi zakuda kutsogolo kwa chipilala\n",
            "H-294\t-0.20533688366413116\t▁ a m u n a ▁ a n g a p o ▁ o v a l a ▁ z o v a l a ▁ z o b i r i w i r a ▁ n d i ▁ z a k u d a ▁ k u t s o g o l o ▁ k w a ▁ c h i p i r a\n",
            "D-294\t-0.20533688366413116\tamuna angapo ovala zovala zobiriwira ndi zakuda kutsogolo kwa chipira\n",
            "P-294\t-0.1110 -0.1090 -0.1268 -0.1096 -0.0352 -0.1200 -0.1091 -0.1441 -0.2422 -0.6116 -0.1208 -0.0199 -0.0512 -0.0807 -0.0462 -0.0287 -0.1406 -0.0733 -0.1326 -0.1204 -0.0503 -0.0660 -0.0455 -0.1070 -0.0786 -0.1156 -0.1047 -0.0126 -0.1477 -0.3799 -0.0567 -0.0495 -0.0745 -0.0317 -0.0688 -0.0581 -0.1101 -0.1284 -0.0501 -0.1644 -0.0793 -0.1275 -0.8698 -0.1776 -0.6933 -0.1417 -0.2929 -0.5558 -0.1182 -2.0422 -0.4441 -0.5733 -0.3909 -0.0356 -0.0248 -0.1169 -0.0402 -0.1049 -0.1345 -0.0169 -0.0226 -0.1883 -0.1197 -0.1579 -0.0652 -0.0800 -0.2699 -0.1644 -1.6798 -0.1397 -0.2779\n",
            "T-113\tmwamuna wovala suti akugwira mutu wake pamene wina akulankhula pa maikolofoni\n",
            "H-113\t-0.2334664911031723\t▁ m w a m u n a ▁ w o v a l a ▁ s u t i ▁ y a k u d a ▁ m u n t h u ▁ w a k e ▁ p a m e n e ▁ m n y a m a t a ▁ a k u l a n k h u l a ▁ p a ▁ m a i k o l o f o n i\n",
            "D-113\t-0.2334664911031723\tmwamuna wovala suti yakuda munthu wake pamene mnyamata akulankhula pa maikolofoni\n",
            "P-113\t-0.1114 -0.1519 -0.0961 -0.1245 -0.1138 -0.0704 -0.0893 -0.1269 -0.1136 -0.0904 -0.0778 -0.0467 -0.1159 -0.1209 -0.1243 -0.1274 -0.3274 -0.0308 -0.0694 -0.1155 -0.1174 -0.2146 -0.0855 -0.1335 -0.1068 -0.1008 -0.0907 -0.1447 -2.6166 -0.0451 -1.4883 -0.1199 -0.1022 -0.1132 -0.1037 -0.0175 -0.1658 -1.5524 -0.1036 -0.1055 -0.1753 -0.1008 -0.1355 -0.0796 -0.0530 -0.0729 -0.1179 -0.3092 -0.4489 -0.1059 -0.1339 -0.1024 -0.1454 -0.0699 -0.0980 -0.1048 -0.7700 -0.0849 -0.1387 -0.2539 -0.2462 -0.0843 -0.0487 -0.0297 -0.0428 -0.0459 -0.1011 -0.1341 -0.4562 -0.0983 -0.9630 -1.1303 -0.0774 -1.8226 -0.1561 -0.0435 -0.1539 -0.0227 -0.2575 -0.0126 -0.0320 -0.0815 -0.0645\n",
            "T-93\tbambo wina akuyenda kutsogolo kwa galimoto yaikulu yabuluu yomwe inayima pakati pa nyumba\n",
            "H-93\t-0.23811686038970947\t▁ b a m b o ▁ w i n a ▁ a k u y e n d a ▁ k u t s o g o l o ▁ k w a ▁ g a l i m o t o ▁ y a ▁ m u n t h u ▁ w i n a ▁ y e m w e ▁ w a k h a l a ▁ p a n g ▁ o n o\n",
            "D-93\t-0.23811686038970947\tbambo wina akuyenda kutsogolo kwa galimoto ya munthu wina yemwe wakhala pang ono\n",
            "P-93\t-0.1036 -0.0461 -0.1075 -0.0412 -0.0655 -0.0492 -0.1142 -0.0885 -0.0579 -0.0699 -0.1348 -0.0995 -0.0914 -1.3007 -0.1055 -0.8020 -0.0594 -0.0878 -0.0438 -0.1241 -0.1097 -0.0497 -0.1196 -0.0880 -0.0252 -0.0347 -0.0176 -0.1308 -0.0527 -0.0550 -0.1090 -0.0357 -0.0885 -0.1103 -0.0979 -0.6943 -0.0902 -0.0905 -0.0524 -0.0410 -0.0314 -0.0324 -0.0306 -0.1608 -0.0113 -0.1293 -0.9262 -0.3822 -0.3640 -0.9234 -0.8840 -0.0984 -0.0885 -0.1046 -2.6893 -0.1285 -0.0932 -0.1313 -0.1978 -1.0638 -0.1024 -0.0390 -0.0265 -0.0876 -0.1164 -1.0916 -0.1215 -0.3318 -0.1622 -0.1292 -0.1341 -0.1179 -0.2121 -0.0324 -0.1083 -0.9571 -0.7910 -0.1511 -0.0346 -0.2766 -0.0678 -0.2785\n",
            "T-359\tmayi wina wa ku america waku africa akutsamira uku atanyamula racket ya tennis\n",
            "H-359\t-0.36367759108543396\t▁ m a y i ▁ w i n a ▁ w a ▁ k u ▁ a m e r i c a ▁ w a ▁ k u ▁ a s i a ▁ a k u s a m i r a ▁ t a n y a m u l a ▁ t e n i s i ▁ y a k e\n",
            "D-359\t-0.36367759108543396\tmayi wina wa ku america wa ku asia akusamira tanyamula tenisi yake\n",
            "P-359\t-0.1004 -0.0636 -0.1484 -0.0361 -0.0753 -0.0867 -0.0379 -0.0711 -0.0475 -0.1167 -0.1007 -0.0479 -1.0283 -2.1193 -0.0266 -0.6448 -0.0332 -0.0857 -0.2278 -0.0268 -0.1675 -0.1211 -0.0607 -0.1148 -0.1035 -0.1178 -0.1628 -2.0415 -0.4113 -0.2242 -0.0391 -0.1367 -1.0772 -0.0554 -0.3795 -0.0686 -0.9551 -0.1209 -0.0996 -0.3803 -0.2497 -0.7323 -0.3572 -0.2004 -0.1372 -0.0926 -1.9004 -0.4134 -0.0981 -0.0485 -0.0643 -0.0330 -0.0643 -0.0571 -0.1303 -0.0851 -1.0529 -0.6938 -1.3033 -0.8947 -0.3005 -0.2735 -0.5631 -0.3038 -0.1090 -1.1357 -0.0492 -1.4245\n",
            "T-425\tmunthu wovala zakuda ndi zoyera zosambira akugwera mumchenga m mphepete mwa nyanja\n",
            "H-425\t-0.17247925698757172\t▁ m u n t h u ▁ w o v a l a ▁ z a k u d a ▁ n d i ▁ z o y e r a ▁ z o s a m b i r a ▁ a k u g w i r a ▁ n t c h i t o ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a\n",
            "D-425\t-0.17247925698757172\tmunthu wovala zakuda ndi zoyera zosambira akugwira ntchito m mphepete mwa nyanja\n",
            "P-425\t-0.0934 -0.1399 -0.7262 -0.0384 -0.0663 -0.0511 -0.0882 -0.1007 -0.1233 -0.0677 -0.0670 -0.1046 -0.0745 -0.1142 -0.1011 -0.1224 -0.2844 -0.1406 -0.0850 -0.1553 -0.7511 -0.0813 -0.0403 -0.2127 -0.1250 -0.0787 -0.1732 -0.0417 -0.8531 -0.1311 -0.1933 -0.1224 -0.0968 -0.1109 -0.2335 -0.0621 -0.0930 -0.0689 -0.0187 -0.0536 -0.0542 -0.1116 -0.0751 -0.2181 -0.0266 -0.1531 -0.1007 -0.0256 -0.4027 -0.0381 -0.1250 -0.0989 -0.5993 -0.3137 -0.0170 -0.0856 -0.3283 -0.1828 -0.5437 -0.0715 -0.2811 -0.6731 -0.5489 -0.0126 -0.0953 -0.1897 -0.0249 -0.0665 -0.0217 -1.1726 -0.0964 -0.0823 -0.0153 -0.1299 -0.1476 -0.2378 -0.1367 -0.0920 -0.0454 -0.0383 -0.0930 -0.0854\n",
            "T-144\tmunthu wovala chipewa amakhala pachinthu chachikasu pamene akuwedza pamwala\n",
            "H-144\t-0.24723590910434723\t▁ m u n t h u ▁ w o v a l a ▁ c h i p e w a ▁ c h o k h a l a ▁ p a ▁ c h i n t h u ▁ c h a c h i k a s u ▁ p a m e n e ▁ a k u y e n d a ▁ p a n s i\n",
            "D-144\t-0.24723590910434723\tmunthu wovala chipewa chokhala pa chinthu chachikasu pamene akuyenda pansi\n",
            "P-144\t-0.1117 -0.2994 -0.0852 -0.0799 -0.0243 -0.0556 -0.0929 -0.1422 -0.0219 -0.3085 -0.0348 -0.1203 -0.0994 -0.1304 -0.1062 -0.0864 -0.0722 -0.0587 -0.0349 -0.0744 -0.0491 -0.0941 -0.0924 -1.3719 -0.0849 -0.8993 -1.3894 -0.1263 -0.0765 -0.1184 -0.1262 -0.1172 -0.4251 -0.1155 -1.6023 -0.0171 -0.0599 -0.0696 -0.2838 -0.0436 -0.2098 -0.0630 -0.1143 -0.0103 -0.0597 -0.1696 -0.1557 -0.0907 -0.0446 -0.0282 -0.1408 -0.0718 -0.0579 -0.0681 -0.4905 -0.1412 -0.1129 -0.0125 -0.0285 -0.0542 -0.0708 -0.3200 -0.0430 -0.1063 -0.8343 -0.2178 -0.7778 -0.1554 -0.1217 -0.1203 -0.2989 -0.1612 -1.6863 -0.4558 -0.6481 -1.4462\n",
            "T-180\tmnyamata wagwira ukonde wokhala ndi njoka pafupi ndi nthaka\n",
            "H-180\t-0.3091454803943634\t▁ m n y a m a t a ▁ w a g o n a ▁ w o k o n d e ▁ w o k h a l a ▁ n d i ▁ n j i n g a ▁ p a f u p i ▁ n d i ▁ t a k h a l a\n",
            "D-180\t-0.3091454803943634\tmnyamata wagona wokonde wokhala ndi njinga pafupi ndi takhala\n",
            "P-180\t-0.1318 -0.0669 -0.1502 -0.0771 -0.1090 -0.0967 -0.1046 -0.0193 -0.1107 -0.1243 -0.0379 -0.1184 -2.1714 -1.7247 -0.5836 -0.0965 -0.0881 -0.8467 -1.2743 -0.0788 -0.3540 -0.0106 -0.0316 -0.2341 -0.8722 -0.5324 -0.2804 -0.0252 -0.0286 -0.1230 -0.0879 -0.1196 -0.0952 -0.0239 -0.1021 -0.1222 -0.1005 -0.4832 -0.0682 -0.3857 -0.0854 -0.1899 -0.1152 -0.1401 -0.8489 -0.1204 -0.4365 -0.0388 -0.1836 -0.0789 -0.2821 -0.0520 -0.1079 -0.1063 -0.1548 -1.8324 -0.5225 -0.5223 -0.6016 -0.1923 -0.0775 -0.1542 -0.5408\n",
            "T-89\tmayi watsitsi lalifupi akuyang ana maluwa omwe amamera m munda\n",
            "H-89\t-0.27999937534332275\t▁ m a y i ▁ w a t s i t s i ▁ l a l i f u p i ▁ a k u y a n g ▁ a n a ▁ m w a m u n a ▁ w o m w e ▁ a m a y e n d a ▁ m ▁ m u n d a\n",
            "D-89\t-0.27999937534332275\tmayi watsitsi lalifupi akuyang ana mwamuna womwe amayenda m munda\n",
            "P-89\t-0.0958 -0.0557 -0.0891 -0.0948 -0.0642 -0.0996 -0.0350 -0.1416 -0.1197 -0.0438 -0.0435 -0.0250 -0.0358 -0.0431 -0.0829 -0.0901 -0.0990 -0.0393 -0.0583 -1.1005 -0.0631 -0.0958 -0.1153 -0.0772 -0.7578 -0.0553 -0.0738 -0.0304 -0.1224 -0.1184 -0.0450 -0.0658 -0.0872 -0.0670 -0.1201 -0.1124 -0.2554 -1.9950 -0.1115 -0.0981 -0.2032 -0.0676 -0.1023 -0.1261 -0.7859 -1.2516 -0.2877 -0.1949 -0.1083 -0.0957 -0.1187 -0.5883 -0.0818 -2.1296 -0.1500 -1.5612 -0.1068 -0.1720 -0.2709 -0.0542 -1.7808 -0.4669 -0.5561 -0.1231 -0.0393 -0.0757 -0.3374\n",
            "T-285\tbambo wina amene ali ndi chakumwa cham chitini waima pansi pa mathithi\n",
            "H-285\t-0.35633230209350586\t▁ w i n a ▁ a l i ▁ n d i ▁ c h a k u m w a ▁ c h a ▁ m ▁ c h i t h u n z i ▁ c h i k w a n g w a n i ▁ p a m a d z i\n",
            "D-285\t-0.35633230209350586\twina ali ndi chakumwa cha m chithunzi chikwangwani pamadzi\n",
            "P-285\t-0.1110 -0.2653 -0.8849 -0.0783 -0.1324 -0.1609 -0.0971 -0.0233 -0.1769 -0.0907 -0.4917 -0.0815 -0.1139 -0.0820 -0.1341 -0.0566 -1.4338 -0.2367 -0.0914 -1.6115 -0.1588 -0.0775 -0.0907 -0.2224 -0.0589 -0.2113 -0.5937 -0.0779 -0.7618 -0.6288 -0.0629 -0.1138 -0.5735 -1.0516 -0.2587 -0.0520 -0.5454 -0.1066 -0.1347 -2.6083 -0.1178 -1.0417 -0.2326 -0.0062 -0.1525 -0.8945 -0.5499 -0.0739 -0.1859 -0.0531 -0.1006 -0.2383 -0.1598 -0.2928 -0.2264 -0.1309 -1.1526 -0.4910 -0.0801 -0.4557\n",
            "T-179\tmnyamata akuchita chinyengo chapakhoma ndi njinga yake pakhoma lolembedwapo\n",
            "H-179\t-0.25258055329322815\t▁ m n y a m a t a ▁ a k u c h i t a ▁ c h i n y e n g o ▁ p a k h o m a ▁ n d i ▁ n j i n g a ▁ y a k e ▁ p a k h o m a ▁ l o l e m b e d w a\n",
            "D-179\t-0.25258055329322815\tmnyamata akuchita chinyengo pakhoma ndi njinga yake pakhoma lolembedwa\n",
            "P-179\t-0.0974 -0.2350 -0.0303 -0.0268 -0.1202 -0.1008 -0.1240 -0.0979 -0.1175 -0.1121 -0.3178 -0.0389 -0.0758 -0.3218 -0.0587 -0.0717 -0.0214 -0.1454 -0.0915 -0.0518 -0.0558 -0.0486 -0.4416 -0.0320 -0.0347 -0.0580 -0.1268 -0.0444 -0.0940 -0.9504 -0.1309 -0.7803 -0.9567 -0.1079 -0.4803 -0.0836 -0.2000 -0.3458 -0.4105 -0.1280 -0.0852 -1.6364 -0.0313 -0.0583 -0.0519 -0.1617 -0.0967 -0.0986 -0.0507 -0.0919 -0.1693 -0.0198 -0.0814 -0.2736 -0.1186 -0.8739 -0.7308 -0.0525 -0.0521 -0.1762 -0.2219 -0.0498 -2.1153 -0.3899 -0.1127 -0.7623 -0.0605 -0.0420 -0.0849 -0.4188 -0.0975 -1.1521\n",
            "T-131\tmwana yemwe ali ndi malaya oyera ndi chisoti atakwera njinga m nkhalango\n",
            "H-131\t-0.23137497901916504\t▁ m w a n a ▁ y e m w e ▁ a l i ▁ n d i ▁ m a l a y a ▁ o y e r a ▁ n d i ▁ c h i s o t i ▁ y a k u d a ▁ n d i ▁ n j a n j i ▁ y a ▁ k a n g ▁ o n o\n",
            "D-131\t-0.23137497901916504\tmwana yemwe ali ndi malaya oyera ndi chisoti yakuda ndi njanji ya kang ono\n",
            "P-131\t-0.1029 -0.0958 -0.0778 -0.1324 -0.1695 -0.0916 -0.2051 -0.1118 -0.0242 -0.0216 -0.0488 -0.1032 -0.0856 -0.0992 -0.0107 -0.0692 -0.0885 -0.0414 -0.0723 -0.1097 -0.0792 -0.0393 -0.1011 -0.0695 -0.1211 -0.0519 -0.1364 -0.1066 -0.0485 -0.0545 -0.0945 -0.0406 -0.1032 -0.1167 -0.3252 -0.1319 -0.1242 -0.0902 -0.6465 -0.1236 -0.0980 -0.2026 -0.0587 -0.0305 -0.0497 -0.0910 -1.0341 -0.1212 -0.2229 -0.2259 -0.4930 -0.1116 -0.1041 -0.1538 -0.2404 -0.1045 -0.0825 -0.3362 -0.3051 -0.1821 -0.2157 -0.2163 -0.0850 -0.1308 -1.5151 -0.1018 -1.5485 -1.8776 -0.2259 -1.3169 -0.2229 -0.7652 -0.0885 -0.0761 -0.2335 -0.3509\n",
            "T-374\tgulu la akavalo ndi okwera akusewera polo pa udzu\n",
            "H-374\t-0.28291305899620056\t▁ g u l u ▁ l a ▁ a k h a l a ▁ n d i ▁ l o k w e r a ▁ a k u s e w e r a ▁ k u t s o g o l o ▁ k w a ▁ u d z u\n",
            "D-374\t-0.28291305899620056\tgulu la akhala ndi lokwera akusewera kutsogolo kwa udzu\n",
            "P-374\t-0.1102 -0.1352 -0.0392 -0.1182 -0.0845 -0.1068 -0.0656 -0.1029 -0.1770 -0.1600 -0.9075 -1.3779 -0.1122 -0.0923 -0.4811 -0.1123 -0.6154 -0.0437 -0.0800 -0.1057 -0.8550 -0.1266 -0.6913 -1.2664 -0.1172 -0.0729 -0.0971 -0.1131 -0.4676 -0.0793 -0.1037 -0.5778 -0.0422 -0.0590 -0.0911 -0.0461 -0.1432 -0.1171 -0.7421 -0.0899 -0.0915 -0.2594 -1.4563 -0.0140 -0.1264 -0.0507 -0.1770 -0.2075 -0.3525 -0.0506 -0.0924 -0.3143 -1.1591 -0.5426 -0.0342 -0.2337 -0.0378\n",
            "T-403\tana atatu ovala zosanja aimirira panja pa kanyumba kaudzu\n",
            "H-403\t-0.2674664855003357\t▁ a n a ▁ a t a t u ▁ o v a l a ▁ z o s a n j a ▁ a l i ▁ n d i ▁ a p a n j a ▁ p a n j a ▁ p a ▁ u d z u\n",
            "D-403\t-0.2674664855003357\tana atatu ovala zosanja ali ndi apanja panja pa udzu\n",
            "P-403\t-0.1125 -0.0855 -0.0502 -0.1520 -0.0963 -0.0832 -0.1149 -0.0728 -0.0219 -0.0441 -0.0778 -0.1038 -0.0296 -0.1195 -0.0783 -0.1169 -0.1224 -0.1759 -0.0725 -0.2504 -0.1435 -0.7185 -0.7179 -0.2815 -0.2486 -1.0853 -0.1200 -0.1662 -0.1140 -0.4243 -0.1015 -0.0988 -0.0854 -0.7508 -1.8180 -0.1654 -0.0731 -0.1294 -0.2764 -0.1458 -0.4128 -0.1079 -1.5387 -0.0438 -0.2695 -0.2135 -0.0186 -0.1070 -0.5442 -0.5061 -0.3999 -0.1218 -0.0356 -0.4793\n",
            "T-323\tmunthu wovala malaya oyera akuda ndi ofiira akuyenda motsetsereka\n",
            "H-323\t-0.20102791488170624\t▁ m u n t h u ▁ w o v a l a ▁ m a l a y a ▁ o y e r a ▁ a k u d y a ▁ n d i ▁ o f i i r a ▁ a k u y e n d a ▁ m u m s e w u\n",
            "D-323\t-0.20102791488170624\tmunthu wovala malaya oyera akudya ndi ofiira akuyenda mumsewu\n",
            "P-323\t-0.1136 -0.0689 -0.1059 -0.0383 -0.0385 -0.0712 -0.1238 -0.1224 -0.1009 -0.0585 -0.1197 -0.1062 -0.0685 -0.1243 -0.1005 -0.0221 -0.1065 -0.0429 -0.1196 -0.0523 -0.1189 -0.1007 -0.0241 -0.0363 -0.0851 -0.0527 -0.1069 -0.1215 -0.1600 -0.1839 -0.1037 -1.4068 -1.6760 -0.5712 -0.1130 -0.5905 -0.1520 -0.0623 -0.1466 -0.9402 -0.0562 -0.0772 -0.0798 -0.0397 -0.1707 -0.1006 -0.1826 -0.0474 -0.1237 -0.0909 -0.0248 -0.0838 -0.0348 -0.1216 -0.1150 -0.0180 -1.3287 -0.1887 -0.0513 -0.0804 -0.0692 -0.0853 -1.0376\n",
            "T-344\twosewera pa skateboarder akudumpha mumlengalenga kutsogolo kwa mtengo wa telegraph\n",
            "H-344\t-0.14457093179225922\t▁ w o s e w e r a ▁ p a ▁ s k a t e b o a r d ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a ▁ k u t s o g o l o ▁ k w a ▁ m t e n g o ▁ w a k e\n",
            "D-344\t-0.14457093179225922\twosewera pa skateboard akudumpha mumlengalenga kutsogolo kwa mtengo wake\n",
            "P-344\t-0.1090 -0.0568 -0.1022 -0.2661 -0.0517 -0.0298 -0.0664 -0.0529 -0.1239 -0.1065 -0.2584 -0.1380 -0.0948 -0.0458 -0.0720 -0.0716 -0.0305 -0.0355 -0.0340 -0.0212 -0.0760 -0.0308 -0.0134 -0.2695 -0.4412 -0.0242 -0.1186 -0.0637 -0.0671 -0.0210 -0.0477 -0.0419 -0.0960 -0.1628 -0.1546 -0.3439 -0.2013 -0.1994 -0.1177 -0.0676 -0.1535 -0.0843 -0.0441 -0.1006 -0.0428 -0.0808 -0.0639 -0.1428 -0.8453 -0.0626 -0.0507 -0.2194 -0.0405 -0.0217 -0.0746 -0.0607 -0.0781 -0.0946 -1.1241 -0.0525 -0.1338 -0.1688 -0.2419 -0.9885 -0.0533 -0.1424 -0.0122 -0.0352 -0.2861 -0.1453 -0.1709 -0.3333 -0.0988 -0.1245\n",
            "T-13\tgalu akugudubuzika chagada pa udzu ndi kukamwa\n",
            "H-13\t-0.4128936529159546\t▁ g a l u ▁ a k u t u l u t s i k a ▁ c h i t h u n z i ▁ p a u d z u ▁ n d i ▁ a n t h u\n",
            "D-13\t-0.4128936529159546\tgalu akutulutsika chithunzi paudzu ndi anthu\n",
            "P-13\t-0.1143 -0.1723 -0.1961 -0.0462 -0.0723 -0.0936 -0.3099 -0.0676 -0.1607 -1.1770 -0.3833 -0.2388 -0.8346 -0.1549 -0.3981 -0.1448 -1.0223 -0.1480 -0.1207 -0.5981 -0.0499 -0.0559 -0.2586 -0.3753 -0.4241 -0.2376 -0.0732 -0.0705 -0.1540 -2.2261 -0.4868 -1.2111 -0.5340 -0.1763 -0.0588 -0.5274 -0.8843 -0.1573 -0.0804 -0.6385 -1.2284 -1.4787 -0.8822 -0.0464 -0.0899 -0.1338\n",
            "T-279\tmayi akunyamula zipatso ndi ndiwo zamasamba kuti akagulitse patebulo\n",
            "H-279\t-0.48055723309516907\t▁ a n y a m a t a ▁ a m b u k u ▁ a s i a ▁ n d i ▁ n d i ▁ z a m a s a m b a ▁ a k u c h e z a ▁ k u g w i r i t s a ▁ t e b u l o\n",
            "D-279\t-0.48055723309516907\tanyamata ambuku asia ndi ndi zamasamba akucheza kugwiritsa tebulo\n",
            "P-279\t-0.0963 -2.0288 -1.1883 -0.2206 -0.1131 -0.0557 -0.1529 -0.0936 -0.0890 -0.1208 -0.9376 -0.5786 -0.8023 -0.6917 -1.6810 -0.0972 -0.6295 -1.1598 -0.1355 -0.4091 -0.6901 -0.1290 -0.0272 -0.0756 -0.0886 -0.0885 -1.7558 -0.4118 -0.3903 -0.1470 -1.6244 -0.2202 -0.0794 -0.1459 -0.1077 -0.0956 -0.3814 -0.0757 -0.1170 -0.0885 -1.2784 -0.0475 -0.1215 -1.5524 -0.0686 -0.2623 -0.6526 -0.1722 -0.1001 -0.0809 -0.0867 -3.1383 -0.4190 -0.4890 -0.2238 -1.0094 -0.0556 -0.1684 -1.0458 -0.2059 -1.5039 -0.1453 -0.4929 -0.4935 -0.0582 -0.0658 -0.2383\n",
            "T-150\tmunthu wovala chisoti chakuda akukwera njinga yofiira kudutsa m nkhalango\n",
            "H-150\t-0.2978302538394928\t▁ m u n t h u ▁ w o v a l a ▁ c h i s o t i ▁ c h a k u d y a ▁ n d i ▁ n j i n g a ▁ y o f i i r a ▁ k u t h a m a n g a\n",
            "D-150\t-0.2978302538394928\tmunthu wovala chisoti chakudya ndi njinga yofiira kuthamanga\n",
            "P-150\t-0.1143 -0.6990 -0.0595 -0.1174 -0.0387 -0.0666 -0.0819 -0.1396 -0.0258 -1.2748 -0.1391 -0.1133 -0.0737 -0.1201 -0.0986 -0.0713 -0.0611 -0.0665 -0.8811 -0.0310 -0.0352 -0.1087 -0.1133 -0.0215 -0.0493 -0.0792 -0.0964 -0.0663 -0.1661 -0.9519 -0.0969 -0.1095 -0.4686 -1.0146 -0.1178 -0.1282 -2.1211 -0.0944 -0.1965 -0.4350 -0.1528 -0.1146 -0.1366 -0.0195 -0.4222 -0.0065 -0.0651 -0.3302 -0.0283 -0.1077 -0.1196 -0.2257 -0.0475 -1.0154 -1.8625 -0.0914 -0.3041 -0.3748 -0.1584 -0.0391 -0.1667 -1.9330\n",
            "T-256\tkumbuyo kwa anthu atatu onse ovala malaya ofiira omwe amati kupewa pa iwo\n",
            "H-256\t-0.26551929116249084\t▁ g u l u ▁ l a ▁ a n t h u ▁ a t a t u ▁ o v a l a ▁ z o v a l a ▁ m a l a y a ▁ o f i i r a ▁ k o m a n y a m a t a ▁ k u t s o g o l o\n",
            "D-256\t-0.26551929116249084\tgulu la anthu atatu ovala zovala malaya ofiira komanyamata kutsogolo\n",
            "P-256\t-0.0989 -0.7728 -0.1029 -0.1252 -0.0686 -0.0901 -0.1130 -0.1023 -0.1107 -0.2839 -0.1070 -0.1032 -0.1008 -0.0703 -0.0950 -0.3792 -0.0212 -0.0904 -0.0239 -0.0903 -0.0825 -0.1030 -0.4271 -0.0923 -0.0802 -0.1182 -0.1095 -0.6149 -0.6643 -0.0547 -0.0844 -0.0761 -0.1208 -0.1092 -0.1901 -0.0993 -0.1095 -0.0972 -0.0249 -0.1301 -0.0999 -0.0554 -0.0209 -0.0592 -0.0577 -0.0569 -0.1472 -0.1130 -1.2364 -0.3284 -0.1932 -0.1184 -0.0788 -1.6662 -0.0835 -0.1203 -0.2901 -0.4194 -0.1741 -0.1417 -2.2015 -0.1795 -0.2148 -1.8246 -0.0849 -0.0657 -0.0597 -0.0638 -0.0864 -2.0065\n",
            "T-0\tmwamuna wovala jekete loyera akuyang ana kutali ndi zomwe wina aliyense akuyang ana\n",
            "H-0\t-0.3003261089324951\t▁ m w a m u n a ▁ w o v a l a ▁ c h i p e w a ▁ c h o y e r a ▁ a k u y a n g ▁ a n a ▁ n d i ▁ z o m w e ▁ z i n a y e n d a ▁ z a k u y a n g ▁ a n a\n",
            "D-0\t-0.3003261089324951\tmwamuna wovala chipewa choyera akuyang ana ndi zomwe zinayenda zakuyang ana\n",
            "P-0\t-0.1005 -0.1107 -0.0411 -0.1194 -0.0509 -0.0765 -0.0730 -0.1299 -0.1085 -0.1229 -0.0670 -0.1376 -0.1249 -0.1247 -0.1209 -0.0964 -1.4001 -0.0753 -0.2596 -1.5363 -0.0877 -0.1459 -0.1324 -0.1221 -0.3527 -0.1110 -0.1599 -0.0444 -0.0697 -0.0747 -0.1073 -0.1087 -0.2038 -0.0533 -0.1439 -0.0189 -0.3977 -0.0501 -0.1865 -0.0733 -0.0943 -0.0783 -0.1595 -0.0780 -1.5144 -0.8338 -0.0855 -0.1027 -0.1130 -0.6318 -0.7624 -1.7701 -0.4629 -0.0900 -0.3463 -0.4124 -0.8319 -0.2580 -1.9168 -0.6604 -0.0603 -0.4965 -0.0907 -0.1547 -1.6373 -0.4297 -0.2015 -0.1303 -0.1588 -0.1789 -0.0916 -0.1268 -0.2001 -0.0963 -0.0760 -0.1435 -0.1294\n",
            "T-260\tgalu woyera ndi wofiirira akuthamanga mumsewu wafumbi m paki\n",
            "H-260\t-0.15600495040416718\t▁ g a l u ▁ w o y e r a ▁ n d i ▁ w o f i i r i r a ▁ a k u t h a m a n g a ▁ m u m s e w u\n",
            "D-260\t-0.15600495040416718\tgalu woyera ndi wofiirira akuthamanga mumsewu\n",
            "P-260\t-0.1109 -0.0242 -0.0815 -0.0628 -0.0881 -0.1160 -0.2221 -0.4421 -0.0235 -0.0795 -0.2746 -0.0973 -0.1404 -0.0260 -0.0658 -0.0811 -0.0722 -0.1026 -0.1622 -0.0138 -0.0423 -0.1260 -0.0722 -0.5824 -0.1593 -0.1537 -0.1156 -0.1542 -0.2550 -0.1060 -0.0672 -0.0953 -0.1001 -0.0409 -0.1118 -0.1119 -0.0423 -0.1518 -0.0971 -0.2639 -0.5845 -0.2742 -0.1006 -0.0749 -0.0459 -0.0268 -1.0896\n",
            " 85% 11/13 [00:23<00:03,  1.67s/it, wps=1555]T-396\tmunthu wadazi wovala malaya abuluu akuwotcha ng anjo yamoto\n",
            "H-396\t-0.30988410115242004\t▁ m u n t h u ▁ w a d a z i ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ w a c h i k a s u ▁ n d i ▁ m u n t h u\n",
            "D-396\t-0.30988410115242004\tmunthu wadazi wovala malaya abuluu wachikasu ndi munthu\n",
            "P-396\t-0.1148 -0.0904 -0.0687 -0.1239 -0.0339 -0.0504 -0.0719 -0.1236 -0.0277 -0.5702 -3.2708 -0.1520 -0.2182 -0.0671 -0.1290 -0.0722 -0.0932 -0.0840 -0.1379 -0.0912 -0.1268 -0.1101 -0.0379 -0.1081 -0.0465 -0.1306 -0.0343 -0.1253 -0.0821 -0.0992 -0.4237 -0.1173 -0.0542 -0.3556 -0.0342 -0.0800 -0.3238 -0.1783 -2.0301 -0.0801 -0.2210 -0.2401 -0.1219 -0.7553 -0.0804 -0.1037 -0.4595 -0.2515 -0.0915 -0.0815 -2.4010 -0.1312 -0.3146 -0.0619 -0.0414 -0.0708 -2.0671\n",
            "T-300\tbambo wina wachikulire atavala chovala chabuluu wakhala pansi pafupi ndi zikwama zake\n",
            "H-300\t-0.1531468778848648\t▁ b a m b o ▁ w i n a ▁ w a c h i k u l i r e ▁ a t a v a l a ▁ c h o v a l a ▁ c h a ▁ b u l u u ▁ w a k h a l a ▁ p a n s i ▁ p a f u p i ▁ n d i ▁ z i d a ▁ z a k e\n",
            "D-300\t-0.1531468778848648\tbambo wina wachikulire atavala chovala cha buluu wakhala pansi pafupi ndi zida zake\n",
            "P-300\t-0.1045 -0.4239 -0.1806 -0.1993 -0.0607 -0.0938 -0.0969 -0.0307 -0.0796 -0.0869 -0.1040 -0.1409 -0.1671 -0.1239 -0.2350 -0.0532 -0.0775 -0.0377 -0.0594 -0.1481 -0.0697 -0.0695 -0.0888 -0.1004 -0.1162 -0.0220 -0.0859 -0.0380 -0.0967 -0.1134 -0.1008 -0.0977 -0.0551 -0.0414 -0.5871 -0.0249 -0.0817 -0.1059 -0.1059 -0.1041 -0.0174 -0.0472 -0.1369 -1.2967 -0.0931 -0.1210 -0.0719 -0.1062 -0.0166 -0.0738 -0.0905 -0.1505 -0.0593 -0.0309 -0.1138 -0.0931 -0.1235 -0.1041 -0.0892 -0.1099 -0.3488 -0.0544 -0.0805 -0.1103 -0.1379 -0.1832 -0.1568 -0.0425 -0.1036 -0.0899 -0.1362 -0.0223 -0.0665 -0.1227 -0.0877 -0.3764 -0.1129 -1.2259 -0.0840 -0.2104 -0.0315 -0.1485 -0.8063 -0.3725 -0.3511\n",
            "T-409\tgalu wakuda ndi woyera akusewera ndi mpira walalanje mu chipale chofewa\n",
            "H-409\t-0.16655461490154266\t▁ g a l u ▁ w a k u d a ▁ n d i ▁ w o y e r a ▁ a k u s e w e r a ▁ n d i ▁ m p i r a ▁ w a l a l a n j e ▁ m ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-409\t-0.16655461490154266\tgalu wakuda ndi woyera akusewera ndi mpira walalanje m chipale chofewa\n",
            "P-409\t-0.0991 -0.0138 -0.0977 -0.0633 -0.0952 -0.0893 -0.0184 -0.0996 -0.0780 -0.1011 -0.0224 -0.0926 -0.0862 -0.1242 -0.0787 -0.0872 -0.0737 -0.0088 -0.0919 -0.0225 -0.1140 -0.0584 -0.1120 -0.1013 -0.6123 -0.0228 -0.1050 -0.0931 -0.0431 -0.0349 -0.1058 -0.0531 -0.0938 -0.0846 -0.6080 -0.1845 -0.1318 -0.1114 -0.2070 -0.0257 -0.0889 -0.0525 -0.0884 -0.1511 -0.2075 -0.1595 -2.3567 -0.1133 -0.4850 -0.1025 -0.0687 -0.0856 -0.1180 -0.1337 -0.3600 -1.2119 -1.0281 -0.0717 -0.0715 -0.0146 -0.1057 -0.0349 -0.0375 -0.0525 -0.0358 -0.0778 -0.0349 -0.0088 -0.0833 -0.0483 -0.0791 -0.0777\n",
            "T-269\tgalu wamkulu wabulauni akudumphira munthu wovala suti yodziteteza\n",
            "H-269\t-0.19857409596443176\t▁ g a l u ▁ w a m k u l u ▁ w a b u l a u n i ▁ a k u d u m p h i r a ▁ m u n t h u ▁ w o v a l a ▁ s u t i ▁ y o d z i t e t e z a\n",
            "D-269\t-0.19857409596443176\tgalu wamkulu wabulauni akudumphira munthu wovala suti yodziteteza\n",
            "P-269\t-0.1151 -0.0079 -0.1023 -0.0517 -0.0741 -0.1022 -0.0377 -0.0787 -0.1754 -0.2414 -0.0665 -0.0780 -0.0468 -0.1017 -0.1567 -0.1009 -0.4523 -0.1051 -0.0967 -0.1058 -0.0777 -0.0665 -0.1233 -0.1086 -0.5174 -0.0541 -0.1587 -0.0942 -0.0760 -0.0548 -0.0366 -0.0492 -0.0633 -0.0173 -0.1031 -0.1160 -0.0865 -0.1620 -1.6376 -0.0072 -0.0356 -0.1131 -0.0991 -0.0290 -0.1419 -0.0330 -0.1196 -0.0951 -0.1162 -0.1183 -0.0903 -0.0840 -0.2505 -0.0674 -0.1805 -0.8355 -0.0604 -0.4290 -1.3130 -1.4373 -0.3406 -0.2532 -0.1576 -0.2285 -0.2109 -0.2253 -0.3325\n",
            "T-90\tchimbalangondo chachikazi ndi mwana wake akungolirana\n",
            "H-90\t-0.3241528868675232\t▁ c h i n y a m a t a ▁ c h a ▁ n g a p o ▁ c h a c h i k a z i ▁ n d i ▁ m w a m u n a ▁ w a k e ▁ a k u m b u y o\n",
            "D-90\t-0.3241528868675232\tchinyamata cha ngapo chachikazi ndi mwamuna wake akumbuyo\n",
            "P-90\t-0.1217 -0.6583 -0.0502 -0.1037 -0.7467 -0.2505 -0.1159 -0.2195 -0.4388 -0.3824 -0.1311 -0.1297 -1.0704 -0.1921 -0.1715 -0.9482 -0.8524 -1.0540 -0.1187 -1.8477 -0.0753 -0.0978 -0.0801 -0.1026 -0.4123 -0.6951 -0.1132 -0.0559 -0.0675 -0.1430 -0.3554 -0.0583 -0.1205 -0.1112 -0.0475 -0.0696 -0.1334 -0.0630 -0.0401 -0.1345 -0.1451 -0.8760 -0.0620 -0.1054 -0.0924 -1.3332 -0.3769 -0.1279 -0.0744 -0.2745 -0.1933 -0.2958 -0.0809 -0.9460 -0.1547 -0.2844 -0.0514 -0.1218 -0.9488\n",
            "T-128\tgulu la anthu lili kutsogolo kwa sitolo likuyenda pampitawu\n",
            "H-128\t-0.29321178793907166\t▁ g u l u ▁ l a ▁ a n t h u ▁ l i k u s o g o l o ▁ k w a ▁ s i t o l o ▁ l i k u y e n d a ▁ p a m t a b w a\n",
            "D-128\t-0.29321178793907166\tgulu la anthu likusogolo kwa sitolo likuyenda pamtabwa\n",
            "P-128\t-0.1123 -0.0516 -0.0509 -0.1506 -0.0864 -0.1023 -0.1368 -0.1004 -0.1179 -0.1302 -0.0303 -0.0611 -0.0755 -0.1203 -0.1008 -1.1616 -0.0719 -0.2451 -0.0918 -0.7269 -0.1343 -0.9920 -0.2135 -0.1000 -0.1681 -0.1375 -0.1587 -0.0484 -0.1567 -0.1281 -0.6481 -0.1558 -0.0586 -0.3996 -0.0466 -0.0790 -0.1520 -2.7457 -0.5156 -0.0390 -0.0601 -0.0511 -0.0455 -0.0428 -0.0425 -0.1477 -0.1406 -0.7508 -0.1637 -0.3600 -1.5511 -0.3961 -1.2920 -0.0321 -0.0747 -0.4670\n",
            "T-203\tagalu awiri apakati ndi galu wamng ono akusewera m madzi osaya\n",
            "H-203\t-0.28439223766326904\t▁ a g a l u ▁ a w i r i ▁ a b u l a u n i ▁ a t a t u ▁ w a m n g ▁ o n o ▁ a k u s e w e r a ▁ m a d z i ▁ o s a y a\n",
            "D-203\t-0.28439223766326904\tagalu awiri abulauni atatu wamng ono akusewera madzi osaya\n",
            "P-203\t-0.1115 -0.1226 -0.5178 -0.0959 -0.0773 -0.0938 -0.1069 -0.2113 -0.0876 -0.0555 -0.0770 -0.0879 -0.1182 -0.3745 -1.7481 -1.5144 -0.1165 -0.0844 -0.1514 -0.0478 -0.0492 -0.1095 -0.2589 -0.6856 -0.1527 -1.1879 -0.4606 -0.1019 -2.2095 -0.1379 -0.7072 -0.5163 -0.1519 -0.0942 -0.0753 -0.0454 -0.0485 -0.1424 -1.1464 -0.0345 -0.0908 -0.1057 -0.0239 -0.0475 -0.0660 -0.0579 -0.1948 -0.1463 -0.1127 -0.4021 -0.2015 -0.0113 -0.1489 -0.6368 -0.2569 -0.0655 -0.0901 -0.0600 -0.1347 -0.0940\n",
            "T-413\tbambo wina wakhala pabenchi kutsogolo kwa nyumba ina imene inasiyidwa\n",
            "H-413\t-0.2387428879737854\t▁ b a m b o ▁ w i n a ▁ w a k h a l a ▁ p a n j i n g a ▁ k u t s o g o l o ▁ k w a ▁ n y u m b a ▁ i m e n e ▁ i n a ▁ s i t o l o\n",
            "D-413\t-0.2387428879737854\tbambo wina wakhala panjinga kutsogolo kwa nyumba imene ina sitolo\n",
            "P-413\t-0.1187 -0.0230 -0.0981 -0.0405 -0.0442 -0.0598 -0.1122 -0.0641 -0.0600 -0.0909 -0.1131 -0.1168 -0.0496 -0.7300 -0.9146 -0.0915 -0.1087 -0.0795 -0.1107 -0.1122 -0.0620 -0.1067 -0.8806 -0.3340 -0.2418 -0.4126 -0.1202 -0.1185 -0.1493 -0.3567 -0.1081 -0.5842 -0.0406 -0.0458 -0.0261 -0.0626 -0.0416 -0.0679 -0.0914 -0.0176 -0.0088 -0.1456 -0.0912 -0.8093 -0.0143 -0.1070 -0.0366 -0.0194 -0.1168 -0.1473 -0.3699 -1.7588 -0.0424 -0.1042 -0.2726 -0.1082 -0.3899 -0.6370 -0.1092 -1.2282 -0.8173 -0.2759 -0.1387 -0.1587 -0.6654 -0.2070 -0.2094\n",
            "T-178\tmwamuna wavala chipewa chakuda ndi mpango wabulauni mumsewu wa mumzinda\n",
            "H-178\t-0.24678608775138855\t▁ m w a m u n a ▁ w o v a l a ▁ c h i p e w a ▁ c h a k u d y a ▁ n d i ▁ m p a n g o ▁ w a ▁ m t s i n j e ▁ w a ▁ m u m z i n d a\n",
            "D-178\t-0.24678608775138855\tmwamuna wovala chipewa chakudya ndi mpango wa mtsinje wa mumzinda\n",
            "P-178\t-0.1048 -0.0760 -0.0519 -0.1104 -0.0974 -0.0590 -0.0692 -0.1047 -0.1094 -0.2741 -1.4241 -0.2720 -0.1216 -0.0951 -0.1178 -0.1068 -0.0734 -0.0632 -0.0760 -0.3955 -0.1471 -0.0416 -0.1078 -0.1044 -0.0422 -0.0600 -0.0861 -0.1075 -0.0920 -0.1217 -1.3716 -0.1051 -0.1055 -0.2970 -0.2020 -0.0974 -0.1554 -1.4763 -0.2748 -0.3549 -0.0531 -0.3046 -0.1359 -0.0821 -0.7677 -0.2981 -1.0471 -0.2484 -1.3788 -0.0519 -0.2556 -0.2969 -0.2232 -0.0182 -0.1119 -0.0238 -0.6209 -0.4242 -0.0458 -0.3505 -0.0890 -0.1345 -0.1190 -0.0516 -0.0202 -0.1103 -0.1189\n",
            "T-201\tgalu wokhala ndi ubweya wagolide amakhala pachifuwa m madzi\n",
            "H-201\t-0.3703394830226898\t▁ g a l u ▁ w o k h a l a ▁ n d i ▁ w a b u l a u n i ▁ w o g o n a ▁ n d i ▁ a m a k h a l a ▁ p a c h i f u w a ▁ m ▁ m a d z i\n",
            "D-201\t-0.3703394830226898\tgalu wokhala ndi wabulauni wogona ndi amakhala pachifuwa m madzi\n",
            "P-201\t-0.1028 -0.0129 -0.1052 -0.0487 -0.0728 -0.0972 -0.1119 -0.9280 -0.0443 -0.0334 -0.1062 -0.1230 -0.1086 -0.1115 -0.0636 -0.1004 -0.0890 -0.1047 -2.8688 -0.6694 -2.1523 -0.1306 -0.0677 -0.1799 -0.0269 -0.0557 -0.1500 -0.1217 -0.6531 -0.4304 -1.9402 -0.4338 -0.9275 -0.4825 -0.1183 -0.3205 -0.0820 -0.0823 -0.2023 -0.3428 -2.2237 -0.2112 -0.4182 -0.1823 -0.0966 -0.1460 -0.1130 -0.1000 -0.3200 -0.1037 -1.6511 -0.0600 -0.0590 -2.0077 -0.0377 -0.0256 -0.0834 -0.3017 -0.3313 -0.2721 -0.0307 -0.0877 -0.2963 -0.2658 -0.0727 -0.1422\n",
            "T-183\tbambo wina amene waika pensulo m khutu akumeta thabwa\n",
            "H-183\t-0.3798438310623169\t▁ b a m b o ▁ w i n a ▁ y e m w e ▁ a l i ▁ k u t s o g o l o ▁ k w a ▁ t h u k u t a ▁ l o m w e ▁ l i t a v a l a\n",
            "D-183\t-0.3798438310623169\tbambo wina yemwe ali kutsogolo kwa thukuta lomwe litavala\n",
            "P-183\t-0.1113 -0.2330 -0.0886 -0.0582 -0.0490 -0.1050 -0.1126 -0.2590 -0.0810 -0.1092 -0.1305 -0.1360 -1.9451 -0.0501 -0.0654 -0.0663 -0.1486 -0.1124 -0.5433 -0.0742 -0.1288 -0.0943 -1.4889 -0.5201 -0.5284 -0.0536 -0.9650 -0.1297 -0.0936 -0.1157 -0.0668 -0.1123 -0.0614 -1.1375 -0.1181 -0.1655 -1.4555 -0.5264 -0.0873 -0.2168 -0.0590 -0.7779 -1.1067 -0.3346 -0.8503 -0.9234 -0.1350 -0.9684 -0.0759 -0.2539 -0.4635 -0.2902 -0.4299 -0.2234 -1.9422 -0.1598 -0.1030 -0.2792 -0.4898\n",
            "T-339\tmunthu waima pansanjika ya njerwa akujambula chinthu chapatali\n",
            "H-339\t-0.2958085536956787\t▁ m u n t h u ▁ w a i m a ▁ p a n s a n j i k a ▁ y a ▁ n j e r w a ▁ a k u j a m b u l a ▁ c h i t h u n z i ▁ c h a ▁ p a r a d e\n",
            "D-339\t-0.2958085536956787\tmunthu waima pansanjika ya njerwa akujambula chithunzi cha parade\n",
            "P-339\t-0.1025 -0.1478 -0.0764 -0.0739 -0.0234 -0.0707 -0.0833 -0.1115 -0.1116 -0.3419 -0.2160 -0.0268 -0.1770 -0.0644 -0.0215 -0.1229 -0.1924 -0.0397 -0.2829 -0.0341 -0.2293 -0.1780 -1.3193 -0.1325 -0.1420 -0.4675 -0.3436 -0.6017 -0.4105 -0.1113 -0.6784 -0.5643 -0.2273 -0.1105 -0.1118 -0.1931 -0.3791 -0.1357 -1.9790 -0.0750 -0.0520 -0.0631 -0.0504 -0.0429 -0.1232 -0.1265 -0.1723 -0.1161 -0.0415 -0.9394 -0.0548 -0.1425 -0.0429 -0.1059 -0.0677 -0.1811 -0.2011 -0.1761 -0.0924 -0.1564 -0.7090 -0.2506 -2.1715 -0.7966 -1.0212 -0.8233 -0.3881\n",
            "T-68\tatsikana awiri aang ono amavina pansi pamatabwa olimba m nyumba\n",
            "H-68\t-0.3069046139717102\t▁ a t s i k a n a ▁ a w i r i ▁ a n g ▁ o n o a n g ▁ o n o ▁ a k u k h a l a ▁ n d i ▁ p a m a t h a b w a ▁ o l i m b a ▁ m u m s e w u\n",
            "D-68\t-0.3069046139717102\tatsikana awiri ang onoang ono akukhala ndi pamathabwa olimba mumsewu\n",
            "P-68\t-0.1003 -0.1825 -0.0524 -0.0659 -0.2305 -0.0366 -0.0923 -0.0276 -0.1275 -0.1113 -0.0781 -0.0522 -0.1682 -0.0593 -0.1110 -0.1264 -0.2687 -1.4248 -0.4119 -0.0691 -0.0255 -0.1291 -0.1151 -0.4311 -0.0221 -0.0816 -0.1230 -0.0744 -0.0550 -0.1164 -0.2078 -0.1809 -1.9096 -0.3877 -0.9624 -0.2684 -0.1445 -0.4544 -0.1173 -0.0933 -1.5735 -0.1099 -0.1034 -0.3073 -1.2587 -0.2192 -0.1845 -0.3486 -0.0659 -0.8598 -0.1880 -1.2688 -0.0297 -0.0694 -0.1961 -0.1184 -0.8566 -0.1462 -0.0375 -0.0814 -0.1821 -0.4210 -0.2818 -1.0015 -0.3248 -0.9720 -0.3917 -0.0888 -0.0394 -0.0613\n",
            "T-399\tanthu awiri ovala malaya ndi masiketi atakhala ndikumwetulira\n",
            "H-399\t-0.3074184060096741\t▁ a n t h u ▁ a w i r i ▁ o v a l a ▁ m a l a y a ▁ n d i ▁ m a s i t i ▁ a t a k h a l a ▁ n d i ▁ k a k u m e t u l i r a\n",
            "D-399\t-0.3074184060096741\tanthu awiri ovala malaya ndi masiti atakhala ndi kakumetulira\n",
            "P-399\t-0.0994 -0.0975 -0.1159 -0.0415 -0.1023 -0.1164 -0.1093 -0.0897 -0.3283 -0.0901 -0.0441 -0.1145 -0.1154 -0.0390 -0.0430 -0.0882 -0.0890 -0.1074 -0.0987 -0.0939 -0.1250 -0.1547 -0.1120 -0.0405 -0.1031 -0.0952 -4.1951 -0.2375 -0.1141 -0.0885 -0.0186 -0.0934 -0.8895 -0.0590 -0.1778 -0.9689 -0.6028 -0.1458 -0.3595 -0.1025 -0.3328 -0.0933 -0.1203 -0.1382 -0.1024 -0.0886 -1.5550 -0.1114 -0.0989 -0.3942 -0.1205 -0.5535 -2.7078 -0.3460 -0.2466 -0.1194 -0.1367 -0.6142 -0.1104 -0.0738 -0.3396 -0.1033 -0.1532\n",
            "T-365\tmnyamatayo wavala malaya abuluu ndipo mtsikanayo wavala zakuda\n",
            "H-365\t-0.22889097034931183\t▁ m n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ a b u l u u ▁ n d i ▁ m t s i k a n a ▁ w o v a l a ▁ z a k u d a\n",
            "D-365\t-0.22889097034931183\tmnyamata wovala malaya abuluu ndi mtsikana wovala zakuda\n",
            "P-365\t-0.1192 -0.0670 -0.0737 -0.0363 -0.1281 -0.0607 -0.1033 -0.0498 -0.1197 -0.1893 -0.3190 -1.8114 -0.2402 -0.1054 -0.0952 -0.1048 -0.1146 -0.1542 -0.1134 -0.2399 -0.1281 -0.0725 -0.1220 -0.0871 -0.2218 -2.3884 -0.1026 -0.0512 -0.3436 -0.0425 -0.0938 -0.0737 -0.0716 -0.1074 -0.1245 -0.7279 -0.4911 -0.0403 -0.0452 -0.6197 -0.1134 -0.0391 -0.1104 -0.2034 -0.1156 -0.2073 -0.1452 -0.0973 -0.1132 -0.1060 -0.1359 -0.1318 -0.1677 -0.1228 -0.2035 -0.0115 -0.0925 -0.9591\n",
            "T-86\takazi awiri akumwetulira atayima moyandikana\n",
            "H-86\t-0.25790002942085266\t▁ a t s i k a n a ▁ a w i r i ▁ a k u m w e t u l i r a ▁ a t a i m a ▁ n d i ▁ m o y a n d i k a n a\n",
            "D-86\t-0.25790002942085266\tatsikana awiri akumwetulira ataima ndi moyandikana\n",
            "P-86\t-0.1089 -0.1285 -3.0456 -0.0969 -0.1241 -0.0626 -0.1491 -0.0931 -0.1135 -0.1346 -0.0930 -0.1817 -0.0865 -0.0503 -0.0909 -0.1160 -0.0796 -0.1722 -0.1410 -0.0172 -0.4581 -0.0395 -0.0134 -0.0282 -0.0237 -0.0520 -0.0457 -0.1352 -0.1156 -1.9373 -0.0830 -0.0947 -0.8766 -0.0415 -0.0958 -0.1076 -1.4450 -0.0574 -0.0816 -0.1812 -0.2151 -0.8994 -0.1511 -0.1871 -0.0695 -0.1893 -0.2802 -0.1178 -0.1139 -0.0829 -0.0860 -0.0202\n",
            "T-31\tkamnyamata kakugwedezeka m mphepete mwa mitengo ndi mtsinje\n",
            "H-31\t-0.3200426995754242\t▁ a m u n a ▁ a t a t u ▁ a k u k w e z e k a ▁ m ▁ m p h e p e t e ▁ m w a ▁ m s e w u ▁ n d i ▁ m t s i n j e\n",
            "D-31\t-0.3200426995754242\tamuna atatu akukwezeka m mphepete mwa msewu ndi mtsinje\n",
            "P-31\t-0.0948 -1.0626 -0.5440 -0.1474 -0.0310 -0.1452 -0.1083 -0.1447 -0.0795 -0.1065 -0.2607 -0.1694 -0.0758 -0.4813 -0.0493 -0.1459 -0.2992 -0.2107 -0.0594 -0.1071 -0.4123 -0.2812 -0.3336 -0.0803 -0.0992 -0.7088 -2.3508 -0.1760 -0.0329 -0.1296 -1.7421 -0.0697 -0.0051 -0.0820 -0.0954 -0.5904 -0.0301 -0.1829 -0.1098 -0.3509 -1.9477 -0.2020 -0.1988 -0.0273 -0.2592 -0.3338 -0.0900 -0.0668 -0.1080 -0.8440 -0.8441 -0.1475 -0.0461 -0.0807 -0.0505 -0.0385 -0.7717\n",
            "T-120\tgalu wabulauni ndi woyera amathamanga m madzi ndi mitengo ndi nthambi zozungulira\n",
            "H-120\t-0.29403966665267944\t▁ g a l u ▁ w a b u l a u n i ▁ n d i ▁ w o y e r a ▁ a t a v a l a ▁ m a g a l a s i ▁ n d i ▁ t h a n g o ▁ n d i ▁ z o z u n g u l i r a\n",
            "D-120\t-0.29403966665267944\tgalu wabulauni ndi woyera atavala magalasi ndi thango ndi zozungulira\n",
            "P-120\t-0.1033 -2.8561 -0.1552 -0.0566 -0.1033 -0.1150 -0.1421 -0.7610 -0.0887 -0.1079 -0.0861 -0.0986 -0.0494 -0.0562 -0.1470 -0.0877 -0.0688 -0.1052 -0.1444 -0.1332 -0.0430 -0.0434 -0.0366 -0.1036 -0.2769 -0.1362 -0.1406 -0.0947 -0.6791 -0.2086 -1.1777 -0.1261 -0.1586 -0.1198 -0.1084 -0.0994 -0.1865 -2.1788 -0.1446 -0.8120 -0.2102 -0.0720 -0.0542 -0.0963 -0.3101 -0.0789 -0.0995 -0.1425 -0.9563 -0.7050 -0.2967 -0.3032 -0.6855 -0.1355 -0.0885 -1.2145 -0.1067 -0.1057 -0.1213 -0.0152 -0.1189 -2.0176 -0.0616 -0.0753 -0.0101 -0.0289 -0.0482 -0.0540 -0.0381 -0.1637 -0.1219\n",
            "T-291\tbambo wina wovala chisoti chabuluu akudumpha kuchokera paphiri panjinga yadothi\n",
            "H-291\t-0.21109364926815033\t▁ b a m b o ▁ w i n a ▁ w o v a l a ▁ c h i s o t i ▁ c h a ▁ b u l u u ▁ a k u t h a m a n g a ▁ k u c h o k e r a ▁ p a n j i n g a ▁ y a d o t h i\n",
            "D-291\t-0.21109364926815033\tbambo wina wovala chisoti cha buluu akuthamanga kuchokera panjinga yadothi\n",
            "P-291\t-0.1154 -0.7043 -0.1150 -0.3020 -0.0468 -0.0554 -0.1261 -0.0398 -0.0734 -0.0822 -0.1384 -0.1032 -0.0396 -0.0701 -0.1103 -0.1135 -0.1096 -0.1015 -0.0921 -0.1064 -0.0805 -0.1010 -0.1504 -0.0635 -0.0130 -0.0671 -0.1005 -0.0429 -0.0775 -0.0786 -0.3711 -0.3429 -0.5922 -0.0636 -0.0750 -0.0297 -0.0926 -0.1007 -0.0184 -0.1314 -0.9764 -1.2356 -0.0757 -0.1571 -0.2939 -0.0431 -0.3068 -0.1826 -0.0695 -1.2845 -0.0694 -1.1434 -0.0502 -0.0786 -0.0838 -0.0758 -0.0363 -0.0825 -0.0859 -0.0495 -0.1362 -0.1197 -0.0155 -0.0577 -0.2234 -0.0494 -0.0937 -0.1655 -0.0018 -0.1265 -2.3872 -0.0395 -0.0295 -0.3658 -0.1045 -0.5087\n",
            "T-135\twadazi wa masharubu oyera wavala khutu la bluetooth\n",
            "H-135\t-0.4435555040836334\t▁ w o t h a m a n g a ▁ m ▁ m a c h i t o ▁ o y e r a ▁ w o v a l a ▁ t ▁ s h i r t ▁ y a k u d a\n",
            "D-135\t-0.4435555040836334\twothamanga m machito oyera wovala t shirt yakuda\n",
            "P-135\t-0.1007 -0.2274 -0.0639 -1.8180 -0.1241 -0.0840 -1.2076 -0.1005 -0.2992 -1.1477 -0.2610 -0.1172 -0.2491 -0.2969 -0.5641 -0.0376 -1.1514 -0.0657 -0.5209 -1.0693 -0.7909 -0.2457 -0.5474 -0.1194 -0.0768 -0.1062 -0.1064 -0.1418 -0.9676 -0.3188 -1.2618 -0.1185 -0.0950 -0.0993 -0.1226 -2.0116 -0.8173 -0.1163 -0.1743 -0.3759 -0.0214 -0.0218 -0.1544 -0.3430 -0.0800 -0.9122 -0.2972 -0.0978 -0.7294 -1.4004\n",
            "T-50\tmbalame yaikulu yotuwa ndi yoyera imayamba kuuluka\n",
            "H-50\t-0.3140770196914673\t▁ m b a l a m e ▁ y a i k u l u ▁ y o t h a m a n g i r a ▁ n d i ▁ y o y e r a ▁ i m a t h a m a n g a\n",
            "D-50\t-0.3140770196914673\tmbalame yaikulu yothamangira ndi yoyera imathamanga\n",
            "P-50\t-0.1142 -0.7891 -0.8757 -0.1277 -0.1226 -0.1046 -0.0550 -0.0440 -0.1044 -0.0384 -0.2879 -0.1455 -0.9459 -0.2078 -0.0699 -0.0898 -0.1173 -0.2925 -0.1209 -0.3599 -0.5858 -0.2580 -0.4542 -0.2791 -0.0213 -0.1486 -0.5470 -0.1805 -0.0981 -0.1692 -0.3107 -0.4273 -0.1190 -0.1182 -0.1758 -1.8776 -0.0094 -0.2689 -0.0730 -0.1092 -0.1371 -0.8321 -0.3580 -0.1440 -1.9512 -0.1860 -0.1241 -0.0312 -0.1097 -0.0497 -0.0452 -0.1292 -1.3050\n",
            "T-363\tparade of cheerleaders ovala yunifolomu yakuda pinki ndi yoyera\n",
            "H-363\t-0.3413659930229187\t▁ a n y a m a t a ▁ o f i i r a ▁ z o v a l a ▁ z o b i r i w i r a ▁ a k u j a m b u l a ▁ p i n k i ▁ n d i ▁ o y e r a\n",
            "D-363\t-0.3413659930229187\tanyamata ofiira zovala zobiriwira akujambula pinki ndi oyera\n",
            "P-363\t-0.1005 -1.0557 -0.6403 -1.7764 -0.1268 -0.1108 -0.1284 -0.0504 -0.0849 -0.1370 -0.4993 -1.6185 -0.0975 -0.1384 -0.0396 -0.1979 -0.0880 -0.4102 -0.0803 -0.4764 -0.1035 -0.0717 -0.1030 -0.1070 -0.0051 -0.3261 -1.2149 -0.1764 -0.0663 -0.0913 -0.0594 -0.0564 -0.0519 -0.1022 -0.1416 -0.4567 -0.0924 -0.1369 -1.6954 -0.0986 -0.2362 -0.2156 -0.1003 -0.1057 -1.6344 -0.1824 -0.9647 -0.5511 -0.2691 -0.2864 -0.1245 -0.4612 -0.1811 -0.0360 -0.0756 -0.1182 -2.2482 -0.0660 -0.0709 -0.0345 -0.1524 -0.0357\n",
            "T-217\tmunthu wovala malaya akuda akuliza gitala lamagetsi\n",
            "H-217\t-0.30643513798713684\t▁ m n y a m a t a ▁ w o v a l a ▁ m a l a y a ▁ a k u d a ▁ a k u d a ▁ a t a g w i r a ▁ n t c h i t a ▁ m a g a l a s i\n",
            "D-217\t-0.30643513798713684\tmnyamata wovala malaya akuda akuda atagwira ntchita magalasi\n",
            "P-217\t-0.1029 -0.2096 -0.9567 -0.2337 -0.1299 -0.0753 -0.1263 -0.0172 -0.1301 -0.1147 -0.0667 -0.0577 -0.2559 -0.1241 -0.0788 -0.1212 -0.1032 -0.0344 -0.1132 -0.0665 -0.1118 -0.0185 -0.1095 -0.1016 -0.2618 -0.4437 -0.0723 -0.0414 -0.1134 -0.1021 -0.0785 -0.4196 -0.0811 -2.4725 -0.2912 -0.1326 -0.2500 -0.6780 -0.1259 -1.3379 -0.4908 -0.0509 -0.0735 -0.5751 -0.1536 -0.9499 -0.1792 -0.3231 -0.1951 -0.1066 -0.0802 -0.4868 -0.1312 -0.8357 -0.2818 -1.0471 -0.7124 -0.1683 -0.3288 -0.1217 -0.1285 -1.2172\n",
            "T-384\tamuna angapo akusewera mpira wa basketball ku paki usiku\n",
            "H-384\t-0.222469761967659\t▁ a m u n a ▁ a n g a p o ▁ a k u s e w e r a ▁ m p i r a ▁ w a ▁ b a s k e t b a l l ▁ p a ▁ p h i r i\n",
            "D-384\t-0.222469761967659\tamuna angapo akusewera mpira wa basketball pa phiri\n",
            "P-384\t-0.1049 -0.3503 -0.1807 -0.0965 -0.0480 -0.1072 -0.0956 -0.2005 -0.0539 -0.4935 -0.1406 -0.0721 -0.0463 -0.0917 -0.1102 -0.0504 -0.1152 -0.0365 -0.0297 -0.0556 -0.1045 -0.0514 -0.1129 -0.0983 -0.1087 -0.3362 -0.0510 -0.0691 -0.1306 -0.1379 -0.0964 -0.2439 -0.1661 -1.2990 -0.2379 -0.0718 -0.2405 -0.1270 -0.0077 -0.1665 -0.0812 -0.0994 -0.3927 -0.4883 -0.7162 -0.3015 -0.5380 -1.8302 -0.1345 -0.0790 -0.1902 -0.3442 -0.2585\n",
            "T-7\tmtsikana wamkulu akuseka ndikumugwira mtsikanayo panja\n",
            "H-7\t-0.30051201581954956\t▁ m t s i k a n a ▁ w a m k u l u ▁ a k u s e k a ▁ n d i ▁ k u g w i r a ▁ m t s i k a n a ▁ w o k h a l a ▁ n d i ▁ n j a n j i\n",
            "D-7\t-0.30051201581954956\tmtsikana wamkulu akuseka ndi kugwira mtsikana wokhala ndi njanji\n",
            "P-7\t-0.1000 -0.6284 -0.0290 -0.0767 -0.0453 -0.0318 -0.1087 -0.0695 -0.1113 -0.1091 -0.3405 -0.4171 -0.1709 -0.0432 -0.1847 -0.0455 -0.0733 -0.1192 -0.2367 -0.0342 -0.0983 -0.0938 -0.0380 -1.2384 -0.0722 -0.0884 -0.0518 -0.0778 -0.1157 -0.2612 -0.3279 -0.5817 -1.2136 -0.6992 -0.1180 -0.0394 -0.1165 -0.2089 -0.3723 -1.3463 -0.0296 -0.0658 -0.0627 -0.1059 -0.0891 -0.1172 -0.2142 -2.3959 -0.4295 -1.0885 -0.0586 -0.1346 -0.2922 -0.1374 -0.1637 -0.0833 -1.1433 -0.1793 -0.1464 -1.2780 -0.5601 -0.3652 -0.1219 -0.0775 -0.1908 -0.1687\n",
            "T-355\tgalu amabisala muudzu wautali m mphepete mwa nyanja\n",
            "H-355\t-0.3111148774623871\t▁ g a l u ▁ a m a b i s a n o ▁ n d i ▁ a m u z u ▁ w a u t a l i ▁ m ▁ m p h e p e t e ▁ m w a ▁ n y a n j a\n",
            "D-355\t-0.3111148774623871\tgalu amabisano ndi amuzu wautali m mphepete mwa nyanja\n",
            "P-355\t-0.1130 -0.0054 -0.1244 -0.0459 -0.2514 -0.1085 -0.1766 -0.0785 -0.0936 -2.1399 -1.0014 -1.0498 -0.2195 -1.2683 -1.0902 -0.1117 -0.7435 -0.0477 -0.1033 -0.1089 -0.4315 -0.4253 -0.1152 -1.8679 -0.1458 -0.1384 -0.3776 -0.2747 -0.4375 -0.4492 -0.2005 -0.0486 -0.1147 -0.1203 -0.4875 -0.1018 -1.3865 -0.0628 -0.0540 -0.0437 -0.0722 -0.0473 -0.0051 -0.0309 -0.0948 -0.0180 -0.0480 -0.1385 -0.1132 -0.0885 -0.2806 -0.0891 -0.0146 -0.0389 -0.1109 -0.0666\n",
            "T-352\tma raft awiri amtundu wa buluu akuwombana pamadzi oyera\n",
            "H-352\t-0.3497951328754425\t▁ m a y i ▁ a t a t u ▁ a l i ▁ m u m t u ▁ w a b u l u u ▁ n d i ▁ w o k h a l a ▁ p a m b a l i ▁ p a ▁ m a d z i ▁ o y e r a\n",
            "D-352\t-0.3497951328754425\tmayi atatu ali mumtu wabuluu ndi wokhala pambali pa madzi oyera\n",
            "P-352\t-0.1098 -0.0586 -0.2141 -0.0805 -0.1593 -0.0773 -0.2571 -0.2530 -0.1033 -0.8621 -0.1113 -0.0905 -0.2396 -1.3873 -0.1074 -0.1699 -0.4118 -0.8704 -0.5624 -0.7504 -0.2588 -0.3973 -0.1061 -0.1185 -1.5104 -0.1500 -0.0647 -0.6912 -0.0614 -0.1095 -1.4109 -0.0619 -0.0889 -0.2528 -0.7330 -0.2421 -0.4674 -1.2124 -0.1198 -0.1061 -0.1163 -0.1260 -1.0149 -0.1145 -0.3790 -1.4465 -0.0925 -0.3987 -0.0478 -0.1042 -0.1564 -0.1645 -0.6932 -0.1977 -0.1274 -0.4077 -0.0125 -0.0636 -0.3186 -0.2542 -1.1731 -0.0417 -0.0488 -0.1087 -0.0886\n",
            "T-420\tamuna awiri ndi mkazi akuombera limodzi\n",
            "H-420\t-0.3741424083709717\t▁ a m e n e ▁ a w i r i ▁ n d i ▁ m k a z i ▁ a k u m b i r a ▁ m o d z i\n",
            "D-420\t-0.3741424083709717\tamene awiri ndi mkazi akumbira modzi\n",
            "P-420\t-0.1166 -3.4881 -0.1172 -0.6888 -0.2636 -0.2842 -0.1061 -0.0881 -0.0410 -0.1230 -0.0442 -0.1346 -0.1349 -0.1341 -0.1052 -0.1013 -0.0989 -1.6321 -0.0521 -0.1546 -0.0099 -0.0475 -0.1025 -0.1547 -0.0663 -0.1003 -0.7253 -0.3781 -0.7548 -0.0333 -0.1273 -0.2474 -1.0293 -0.2644 -1.5775 -0.0400 -0.0630 -0.5869\n",
            "T-74\tamuna ndi akazi amasonkhana kuti apeze chakudya pamalo otsika\n",
            "H-74\t-0.35261863470077515\t▁ a m u n a ▁ n d i ▁ a k a z i ▁ a m a s o n k h a n a ▁ k u t i ▁ a k u j a m b u l i d w a ▁ k u j a m b u l a ▁ p a m a d z i\n",
            "D-74\t-0.35261863470077515\tamuna ndi akazi amasonkhana kuti akujambulidwa kujambula pamadzi\n",
            "P-74\t-0.0968 -0.1719 -0.0729 -0.0984 -0.0985 -0.1871 -0.1249 -0.1288 -0.0398 -0.1744 -0.0859 -0.1182 -1.4122 -0.8354 -0.0543 -0.1774 -0.0926 -0.0923 -2.2113 -0.0899 -0.1169 -0.2630 -0.5426 -0.0740 -0.0142 -0.0915 -0.0209 -0.1896 -0.1229 -0.4952 -0.1529 -0.2820 -2.1248 -0.0642 -0.1147 -0.3908 -0.1481 -1.1812 -0.1099 -0.4502 -0.1658 -0.8260 -0.1456 -1.0826 -0.9020 -0.2454 -0.1932 -0.1000 -0.1879 -0.0690 -0.8814 -0.0818 -0.2098 -0.0939 -0.0390 -0.0426 -0.1243 -0.2624 -1.3889 -0.2300 -1.0640 -0.2766 -0.8116 -0.1608 -0.0509 -0.3247\n",
            "T-380\tmunthu amene wanyamula chiwalo cha tenisi akumenya mpira wachikaso\n",
            "H-380\t-0.29474788904190063\t▁ m u n t h u ▁ a m e n e ▁ w a n y a m u l a ▁ c h i n y a m a t a ▁ c h a ▁ t e n i s ▁ a k u m e n y a ▁ m p i r a ▁ w a c h i k a s u\n",
            "D-380\t-0.29474788904190063\tmunthu amene wanyamula chinyamata cha tenis akumenya mpira wachikasu\n",
            "P-380\t-0.1130 -0.0745 -0.1107 -0.1034 -0.0875 -0.0970 -0.0937 -0.1327 -0.4618 -0.0936 -0.0199 -0.0677 -0.0942 -0.1214 -0.1671 -0.0750 -2.1236 -0.0065 -0.0791 -0.1334 -0.0364 -0.0478 -0.1108 -0.1012 -0.4811 -0.0644 -0.0542 -0.3632 -0.3180 -0.1361 -1.0294 -0.4169 -0.0681 -0.1270 -0.1468 -0.2832 -0.0858 -0.1680 -1.2523 -2.0045 -0.4048 -0.1609 -0.3126 -0.1704 -1.5453 -0.3284 -0.1406 -0.1249 -0.2883 -0.7234 -0.0774 -0.0474 -0.0916 -0.1265 -0.3721 -0.1454 -0.0743 -0.0513 -0.2745 -0.5559 -1.1202 -0.1180 -0.9787 -0.1425 -0.0605 -0.0974 -0.1476 -0.0307 -0.3179 -0.0519\n",
            "T-46\tgalu wakuda ndi wabulauni amasewera ndi ndodo yayitali\n",
            "H-46\t-0.2785623073577881\t▁ g a l u ▁ w a k u d a ▁ n d i ▁ w o v a l a ▁ m a g a l a s i ▁ a m a s e w e r a ▁ n d i ▁ n d o d o ▁ y a d z u\n",
            "D-46\t-0.2785623073577881\tgalu wakuda ndi wovala magalasi amasewera ndi ndodo yadzu\n",
            "P-46\t-0.1113 -0.0273 -0.0911 -0.0605 -0.0687 -0.1081 -0.0438 -0.1094 -0.1309 -0.1055 -0.2653 -0.2708 -0.1040 -0.0215 -0.0804 -0.0979 -0.1066 -0.0268 -0.7508 -0.6308 -0.0768 -0.1059 -0.1329 -0.1037 -0.4983 -0.2344 -1.4978 -1.1643 -0.1216 -0.1066 -0.0955 -0.0778 -0.0719 -0.1111 -0.2066 -0.0941 -1.6165 -0.0602 -0.0411 -0.0997 -0.0872 -0.0887 -0.1074 -0.0492 -0.0463 -0.1610 -0.0933 -0.4847 -0.1774 -0.1756 -0.0052 -0.0755 -0.3602 -0.0202 -0.2222 -3.2052 -1.1028 -0.1563 -0.0886\n",
            "T-362\tmwana wamng ono wanyamula mpira wa pinki wa ulusi\n",
            "H-362\t-0.2986597716808319\t▁ m n y a m a t a ▁ w a m n g ▁ o n o ▁ w a n y a m u l a ▁ m p i r a ▁ w a ▁ p h i r i ▁ n d i ▁ w a u d z u\n",
            "D-362\t-0.2986597716808319\tmnyamata wamng ono wanyamula mpira wa phiri ndi waudzu\n",
            "P-362\t-0.1143 -0.1072 -1.7745 -0.0497 -0.1418 -0.0819 -0.1197 -0.1085 -0.1316 -0.1177 -0.1146 -0.4685 -1.2558 -0.0203 -0.1153 -0.0781 -0.0885 -0.0362 -0.0514 -0.1514 -0.1308 -0.3472 -0.7730 -0.0091 -0.1097 -0.1361 -0.0249 -0.0337 -0.1031 -0.0795 -0.4613 -0.7871 -0.3183 -0.1116 -0.0977 -0.1237 -0.0510 -0.1714 -0.1942 -1.2717 -0.9616 -0.1276 -0.0576 -0.1886 -0.1522 -1.0849 -0.0916 -0.0980 -0.2964 -2.0021 -0.1581 -0.1702 -0.3060 -0.1169 -0.0822 -0.3690\n",
            "T-305\tgalu akuthamanga m madzi ambiri ndikupangitsa kuti agwetse\n",
            "H-305\t-0.32012417912483215\t▁ g a l u ▁ a k u t h a m a n g a ▁ m ▁ m a d z i ▁ n d i ▁ a m b i r i ▁ a k u t h a m a n g i t s a ▁ k u k w e z a\n",
            "D-305\t-0.32012417912483215\tgalu akuthamanga m madzi ndi ambiri akuthamangitsa kukweza\n",
            "P-305\t-0.0979 -0.2236 -0.1168 -0.0659 -0.2227 -0.0984 -0.8131 -0.0464 -0.0964 -0.1243 -0.0231 -0.0885 -0.0887 -0.0827 -0.0804 -0.0409 -0.1199 -0.0847 -0.1061 -0.1899 -0.2025 -0.2198 -0.9371 -0.4062 -0.1133 -0.1075 -0.6908 -0.0696 -0.1091 -0.1044 -0.2256 -0.7748 -1.0301 -0.1312 -0.0851 -0.0937 -0.1397 -1.5712 -0.1766 -0.1429 -1.1838 -0.9802 -0.1598 -0.3423 -0.3059 -0.0617 -0.3619 -0.0561 -0.0606 -0.0243 -0.1360 -0.1066 -0.6358 -0.0538 -2.3588 -0.3581 -0.0881 -1.2777 -0.1148 -0.3993\n",
            "T-206\tmunthu yemwe ali ndi suti ya buluu ndi yakuda akusefukira\n",
            "H-206\t-0.29113972187042236\t▁ m u n t h u ▁ y e m w e ▁ a l i ▁ n d i ▁ s u t i ▁ y a ▁ b u l u u ▁ n d i ▁ a k u j a m b u l a ▁ a s i l i v a\n",
            "D-206\t-0.29113972187042236\tmunthu yemwe ali ndi suti ya buluu ndi akujambula asiliva\n",
            "P-206\t-0.1218 -0.0569 -0.0439 -0.1284 -0.0377 -0.0291 -0.0804 -0.1631 -1.4294 -0.2066 -0.0284 -0.0353 -0.0820 -0.0832 -0.2172 -0.0974 -0.1212 -0.1121 -0.0219 -0.0780 -0.1015 -0.0901 -0.9775 -0.5811 -0.1100 -0.4329 -0.0958 -0.2124 -0.1046 -0.3350 -0.0518 -1.3754 -0.0620 -0.0914 -0.0333 -0.0664 -0.0613 -0.0822 -0.1019 -0.1081 -0.3282 -0.1707 -0.2731 -0.7110 -0.1002 -0.7980 -0.3067 -0.0493 -0.0575 -0.1804 -0.1391 -0.5488 -1.1413 -0.5958 -1.1565 -0.2924 -0.9806 -0.8490 -0.2501\n",
            "T-308\tkamwana akuyang ana nkhunda kutsidya lina la msewu\n",
            "H-308\t-0.38714054226875305\t▁ m w a m u n a ▁ w i n a ▁ w o v a l a ▁ k o n d a ▁ k o m a n s o ▁ c h i p i n d a ▁ m u m s e w u\n",
            "D-308\t-0.38714054226875305\tmwamuna wina wovala konda komanso chipinda mumsewu\n",
            "P-308\t-0.1080 -0.7403 -0.1023 -0.1322 -0.7504 -0.0736 -0.0877 -0.1243 -0.1140 -0.5085 -0.3697 -0.1126 -0.1360 -0.1114 -0.4206 -0.0967 -0.4461 -0.1334 -0.0981 -0.1119 -0.1137 -1.2625 -0.5916 -0.5252 -0.1937 -0.1135 -0.1341 -0.3468 -0.2895 -1.7375 -1.4938 -0.1625 -0.2426 -0.3682 -0.0817 -0.6284 -0.0845 -0.1959 -0.9444 -0.5720 -0.0889 -0.8546 -0.1302 -0.1349 -1.1990 -1.2061 -0.2535 -0.7968 -0.0373 -0.0222 -0.0493 -0.4985\n",
            "T-371\tmnyamata akumenya mpira wa tenisi ndi racket yakuda ndi yachikasu\n",
            "H-371\t-0.3202425241470337\t▁ m n y a m a t a ▁ a k u m e n y a ▁ m p h e p e t e ▁ w a ▁ t s i t s i ▁ l a k e ▁ a k u j a m b u l a ▁ c h i t h u n z i\n",
            "D-371\t-0.3202425241470337\tmnyamata akumenya mphepete wa tsitsi lake akujambula chithunzi\n",
            "P-371\t-0.1022 -0.0846 -0.0414 -0.0241 -0.1226 -0.1051 -0.1007 -0.0269 -0.1182 -0.1072 -0.1544 -0.0764 -0.0910 -0.9469 -0.4094 -0.1227 -0.0860 -0.1429 -0.1426 -0.6137 -0.0709 -1.0080 -0.2238 -0.4191 -0.0843 -0.0370 -0.0866 -0.0640 -1.0597 -0.1189 -0.0965 -0.0979 -1.9145 -0.0616 -0.0584 -0.9867 -0.1076 -0.0708 -0.1743 -0.1157 -1.0317 -0.2883 -0.0983 -0.6368 -0.4003 -0.0563 -0.9722 -0.1730 -0.7823 -0.1194 -0.4882 -0.1517 -0.7759 -0.2802 -0.5117 -0.1562 -0.0871 -1.0567 -0.6135 -0.3155 -0.3379 -0.1804 -0.0781 -0.4284\n",
            "T-63\tmwana wovala malaya a baseball amakwawa ndi chubu\n",
            "H-63\t-0.32970061898231506\t▁ m w a n a ▁ w o v a l a ▁ m a l a y a ▁ a b u l a u n i ▁ a m a k o k a ▁ n d i ▁ c h i d o l e\n",
            "D-63\t-0.32970061898231506\tmwana wovala malaya abulauni amakoka ndi chidole\n",
            "P-63\t-0.1126 -0.0907 -0.1316 -0.1180 -0.1717 -0.0934 -0.1370 -0.1110 -0.0599 -0.1129 -0.1292 -0.0863 -0.1257 -0.1023 -0.0303 -0.1371 -0.1201 -0.1403 -0.0379 -0.1130 -0.0918 -0.2320 -0.9679 -0.4651 -0.1913 -0.1285 -0.1291 -0.1746 -0.1308 -0.1389 -0.6211 -1.4645 -0.2347 -1.4261 -0.4408 -1.7389 -0.1787 -0.0892 -1.0110 -0.1396 -0.1074 -0.1731 -0.5070 -0.1995 -0.0569 -0.3932 -1.2529 -0.1196 -0.3643 -1.1555\n",
            "T-385\tgulu la anthu akuyang ana nyumba yokongola kwambiri\n",
            "H-385\t-0.1544787436723709\t▁ g u l u ▁ l a ▁ a n t h u ▁ a k u y a n g ▁ a n a ▁ n y u m b a ▁ y o k o n g o l a ▁ k w a m b i r i\n",
            "D-385\t-0.1544787436723709\tgulu la anthu akuyang ana nyumba yokongola kwambiri\n",
            "P-385\t-0.1062 -0.0198 -0.0556 -0.0873 -0.0704 -0.1032 -0.0399 -0.0893 -0.1201 -0.0883 -0.0328 -0.0090 -0.0393 -0.1572 -0.1047 -0.8492 -0.0512 -0.0994 -0.0057 -0.1681 -0.0248 -0.0307 -0.0907 -0.1058 -0.0344 -0.1291 -0.1218 -1.0431 -0.3246 -0.0982 -0.1539 -0.0167 -0.1127 -0.1023 -0.2399 -0.0631 -0.4285 -0.4174 -0.2608 -0.0368 -0.0602 -0.0412 -0.1020 -0.4783 -0.1980 -0.2986 -0.1183 -0.4883 -0.0240 -0.0600 -0.0572 -0.0806 -0.0486\n",
            "T-57\tmunthu wovala jekete lakuda akudumpha mumlengalenga panjinga\n",
            "H-57\t-0.2481011599302292\t▁ m u n t h u ▁ w o v a l a ▁ c h i p e w a ▁ c h a k u d a ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a\n",
            "D-57\t-0.2481011599302292\tmunthu wovala chipewa chakuda akudumpha mumlengalenga\n",
            "P-57\t-0.1131 -0.1137 -0.0598 -0.1881 -0.0403 -0.0505 -0.0903 -0.1437 -0.1255 -0.0410 -0.1365 -0.1339 -0.0596 -0.1253 -0.0955 -0.7448 -0.0640 -0.2253 -0.9687 -0.3358 -0.1474 -0.1093 -0.1210 -0.6284 -0.0825 -0.1076 -0.1052 -0.0864 -0.1693 -0.4681 -0.1018 -0.2226 -0.0178 -0.1412 -0.4998 -0.0329 -0.0310 -0.0329 -0.0510 -0.0864 -0.1326 -0.3748 -2.5242 -0.2159 -0.1004 -0.1335 -0.1667 -0.1047 -0.0831 -0.0111 -0.0690 -0.0314 -0.1788 -0.0744 -2.3467\n",
            "T-212\tazimayi awiri atakumbatirana akumwetulira mu kamera\n",
            "H-212\t-0.247702956199646\t▁ a t s i k a n a ▁ a w i r i ▁ a t a t u ▁ a k u m w e t u l i r a ▁ k u m w e t u l i r a ▁ m u ▁ k a m e r a\n",
            "D-212\t-0.247702956199646\tatsikana awiri atatu akumwetulira kumwetulira mu kamera\n",
            "P-212\t-0.1077 -0.0938 -0.2533 -0.1342 -0.0972 -0.2074 -0.0903 -0.1344 -0.1149 -0.1731 -0.1404 -0.0259 -0.1415 -0.0613 -0.0900 -0.0909 -0.0892 -0.4452 -0.1415 -0.3494 -0.1639 -0.1014 -0.5572 -0.4476 -0.0889 -0.5935 -1.8952 -0.9004 -0.0125 -0.3691 -0.0646 -0.1414 -0.0570 -0.1262 -0.1444 -0.6451 -0.2722 -0.4914 -0.4569 -0.0836 -0.0101 -0.0186 -0.0182 -0.0532 -0.0296 -0.1147 -0.1711 -0.2236 -0.9672 -0.9082 -0.5317 -0.0988 -0.0867 -0.0788 -0.0351 -0.0934 -0.0859\n",
            "T-314\tkamnyamata ka shati lakuda ndi jinzi ya buluu akuyenda m njira\n",
            "H-314\t-0.3171340823173523\t▁ k a m n y a m a t a ▁ k a k a n s a ▁ c h a k u d y a ▁ n d i ▁ j i n z i ▁ y a ▁ b u l u u ▁ a k u y e n d a ▁ m u m c h i r a\n",
            "D-314\t-0.3171340823173523\tkamnyamata kakansa chakudya ndi jinzi ya buluu akuyenda mumchira\n",
            "P-314\t-0.0991 -0.3974 -0.1977 -0.0868 -0.1053 -0.0288 -0.1291 -0.0442 -0.1155 -0.0425 -0.1475 -0.0956 -0.1025 -0.1114 -1.2871 -0.4368 -1.5367 -0.4199 -0.3146 -0.1139 -1.2097 -0.0705 -1.1239 -0.1741 -0.0675 -0.0335 -0.1289 -0.1248 -0.1034 -0.3191 -0.1483 -0.1132 -0.0805 -0.0986 -1.4277 -0.1134 -0.0551 -0.1007 -0.1104 -0.6770 -0.0967 -0.5248 -1.1796 -0.2163 -0.0381 -0.0410 -0.0373 -0.0818 -0.7787 -0.0445 -0.1019 -0.5578 -0.2579 -0.0339 -0.0434 -0.1499 -0.2559 -0.1487 -1.3942 -0.1556 -0.7372 -0.1294 -0.4005 -1.1860 -0.1168 -0.1302\n",
            "T-353\tgalu wa bulauni akudumpha panjira yotchinga m chipinda\n",
            "H-353\t-0.2161097377538681\t▁ g a l u ▁ w a b u l a u n i ▁ a k u d u m p h a ▁ p a n j i r a ▁ c h i n t h u ▁ m ▁ c h i p i n d a\n",
            "D-353\t-0.2161097377538681\tgalu wabulauni akudumpha panjira chinthu m chipinda\n",
            "P-353\t-0.1053 -0.0169 -0.0840 -0.0785 -0.2296 -0.1033 -0.0694 -0.6132 -0.1200 -0.0736 -0.0763 -0.0805 -0.0277 -0.0405 -0.0447 -0.0874 -0.1485 -0.0266 -0.1340 -0.1192 -0.0806 -0.1262 -0.0344 -0.0457 -0.1162 -0.1239 -0.6836 -0.1080 -0.2659 -0.0344 -0.0897 -0.0631 -0.1129 -0.1264 -2.5311 -0.1180 -0.1093 -0.0984 -0.5110 -0.0647 -0.1647 -0.2457 -0.4762 -0.1484 -0.7407 -0.1216 -0.0739 -0.6387 -0.2874 -0.3402 -0.0224 -0.1032 -0.3681\n",
            "T-345\tamuna awiri ali mkati akuphika pamoto\n",
            "H-345\t-0.2706027925014496\t▁ a m u n a ▁ a w i r i ▁ a l i ▁ m ▁ k a t i ▁ a k u t h a m a n g i t s a ▁ m o t o\n",
            "D-345\t-0.2706027925014496\tamuna awiri ali m kati akuthamangitsa moto\n",
            "P-345\t-0.1042 -0.1264 -0.2157 -0.0918 -0.0859 -0.1302 -0.0912 -0.1169 -0.0491 -0.0998 -0.0445 -0.1021 -0.1057 -0.1120 -0.0785 -0.0874 -0.0843 -0.0974 -0.7066 -0.1841 -0.3053 -0.1883 -1.2954 -0.1190 -0.3969 -0.1493 -0.0935 -2.0477 -0.2337 -0.1882 -0.1545 -0.1032 -0.2522 -0.1052 -0.9743 -0.2253 -0.2774 -0.1079 -0.3280 -0.2483 -0.4710 -0.4892 -0.0652 -0.3738\n",
            "T-227\tgulu la anthu laima pa chipale chofewa m phiri\n",
            "H-227\t-0.2711072862148285\t▁ g u l u ▁ l a ▁ a n t h u ▁ a n t h u ▁ l a i m a ▁ p a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-227\t-0.2711072862148285\tgulu la anthu anthu laima pa chipale chofewa\n",
            "P-227\t-0.1061 -0.4868 -0.0892 -0.1166 -0.1024 -0.1080 -0.0433 -0.1057 -0.1241 -0.1033 -0.1606 -0.0330 -0.0667 -0.0829 -0.0991 -0.4882 -1.9183 -1.4337 -0.0685 -0.1265 -0.0986 -1.2100 -0.4738 -0.1987 -0.0420 -0.1369 -0.1029 -0.0072 -0.1441 -0.9292 -0.0528 -0.1072 -0.0816 -0.5881 -0.1020 -0.3028 -0.0587 -0.0708 -0.0130 -0.0960 -0.0540 -0.0033 -0.3857 -0.0825 -0.3829 -0.8830\n",
            "T-287\tgalu woyera akusambira m nyanja pamene mbalame ikuuluka\n",
            "H-287\t-0.3748471140861511\t▁ g u l u ▁ l a ▁ o s a m b i r a ▁ m ▁ n j a n j i ▁ a k u y e n d a ▁ p a m e n e ▁ l i k u l u\n",
            "D-287\t-0.3748471140861511\tgulu la osambira m njanji akuyenda pamene likulu\n",
            "P-287\t-0.1129 -0.8728 -0.0501 -0.1025 -0.0989 -0.1158 -0.2358 -1.1260 -0.6418 -0.4599 -1.5418 -0.1053 -0.5726 -0.0194 -0.0571 -0.0789 -0.1034 -0.1276 -0.8086 -0.0967 -0.6155 -0.4641 -0.5377 -0.0823 -0.1117 -0.0912 -0.1243 -1.6596 -0.9619 -0.1764 -0.5652 -0.4226 -0.1323 -0.0551 -1.2035 -0.1413 -0.1554 -0.1740 -1.1422 -0.2527 -0.0695 -0.0519 -0.1189 -1.2967 -0.3520 -0.0139 -0.1096 -0.1256 -0.0352 -0.1724\n",
            "T-264\twoyimba wachimuna wovala zoyera akuimba gitala\n",
            "H-264\t-0.2318381816148758\t▁ w o y i m b a ▁ w a c h i m u n a ▁ w o v a l a ▁ z o v a l a ▁ z o y e r a ▁ a k u i m b a ▁ g i t a l a\n",
            "D-264\t-0.2318381816148758\twoyimba wachimuna wovala zovala zoyera akuimba gitala\n",
            "P-264\t-0.1069 -0.8800 -0.1516 -0.4270 -0.5809 -0.1432 -0.0228 -0.1977 -0.1057 -0.0588 -0.2035 -0.5156 -0.0515 -0.0377 -1.0640 -0.1806 -0.1195 -0.4348 -0.1588 -0.1293 -0.2918 -0.1830 -0.1017 -0.1250 -0.1323 -0.1208 -1.8377 -0.2075 -0.6502 -0.0920 -0.0964 -0.1192 -0.1116 -0.0134 -0.0356 -0.0443 -0.1161 -0.0471 -0.1136 -0.1135 -0.5483 -0.0362 -0.1724 -0.9175 -0.0491 -0.0163 -0.1183 -0.1825 -0.0905 -0.0723 -0.0136 -0.1104 -0.0782 -0.1097 -0.1129\n",
            "T-307\tmwamuna ndi mkazi akupsompsonana pachibowo choyang ana padoko ladzuwa\n",
            "H-307\t-0.28138071298599243\t▁ m w a m u n a ▁ n d i ▁ m k a z i ▁ a k u t s o g o l o ▁ k u t s o g o l o\n",
            "D-307\t-0.28138071298599243\tmwamuna ndi mkazi akutsogolo kutsogolo\n",
            "P-307\t-0.1007 -0.2783 -1.0517 -0.1472 -0.1539 -0.0873 -0.0715 -0.1068 -0.1500 -0.0337 -0.1506 -0.1052 -0.1002 -0.3742 -0.0437 -0.1372 -0.0218 -0.1409 -0.1138 -0.1086 -0.0440 -0.0898 -0.9882 -0.2579 -0.1415 -0.1055 -0.1302 -0.0821 -0.2212 -0.1560 -0.7086 -1.4705 -0.4098 -0.1618 -0.0394 -0.0571 -0.2552 -0.2003 -0.4776 -1.7814\n",
            "T-229\tgalu wabulauniyu akukumba dzenje pomwe pali mbewu pafupi ndi\n",
            "H-229\t-0.42587077617645264\t▁ g a l u ▁ w a b u l a u n i ▁ a k u t h a m a n g a ▁ c h i t h u n z i ▁ p a l i ▁ n d i ▁ m p i r a ▁ p a f u p i\n",
            "D-229\t-0.42587077617645264\tgalu wabulauni akuthamanga chithunzi pali ndi mpira pafupi\n",
            "P-229\t-0.0977 -1.0154 -2.6907 -0.0717 -0.2043 -0.1239 -0.1270 -0.1654 -0.2023 -0.0929 -0.0537 -0.0848 -0.0488 -0.0529 -0.0582 -0.1000 -0.0960 -0.0266 -0.1478 -1.7437 -0.7482 -0.3030 -0.3454 -0.2684 -0.0593 -0.4570 -0.2773 -0.1212 -2.0366 -0.1232 -0.3175 -1.1112 -0.4190 -0.0880 -0.0910 -0.2495 -0.1001 -0.1207 -0.5199 -0.1442 -1.7339 -0.0714 -0.1329 -0.6402 -0.0460 -0.1629 -0.1200 -2.2323 -0.5544 -1.7233 -0.2814 -0.1911 -0.9564 -0.2055 -0.1106 -0.3918 -0.0794 -0.0690 -0.0844 -0.6608\n",
            "T-153\tmunthu wachikulire akuyendetsa ngolo ndi kamnyamata\n",
            "H-153\t-0.1807279884815216\t▁ m u n t h u ▁ a c h i k u l i r e ▁ a k u y e n d e t s a ▁ n g o l o ▁ n d i ▁ k a m n y a m a t a\n",
            "D-153\t-0.1807279884815216\tmunthu achikulire akuyendetsa ngolo ndi kamnyamata\n",
            "P-153\t-0.1116 -0.0678 -0.0380 -0.1058 -0.0370 -0.1147 -0.1178 -0.1233 -0.4431 -0.4382 -0.0511 -0.0995 -0.0447 -0.0599 -0.2848 -0.0899 -0.0409 -0.1514 -0.1057 -0.0699 -0.0445 -0.1390 -0.1396 -0.0814 -0.0984 -0.0204 -0.2869 -0.2146 -0.0709 -0.1273 -0.0692 -1.7238 -0.3441 -0.0607 -0.0559 -0.0423 -0.1083 -0.1949 -0.0509 -0.0849 -0.6494 -0.5100 -0.0938 -0.0812 -0.2265 -0.0165 -0.1314 -0.0188 -0.1185 -0.0191 -0.0892 -0.8904\n",
            "T-402\tmnyamata akupeza mpweya wambiri pa skateboard pa skatepark\n",
            "H-402\t-0.3137974739074707\t▁ m n y a m a t a ▁ a k u k w e z a ▁ m t e n g o ▁ w a ▁ m b i r a ▁ p a ▁ s k a t e b o a r d\n",
            "D-402\t-0.3137974739074707\tmnyamata akukweza mtengo wa mbira pa skateboard\n",
            "P-402\t-0.1028 -0.0802 -0.0592 -0.0333 -0.1141 -0.1145 -0.0950 -0.0427 -0.1144 -0.1167 -0.0701 -0.0475 -0.0807 -2.5686 -0.2385 -0.0497 -0.2928 -0.1393 -0.0883 -0.4781 -1.3354 -0.5556 -0.1279 -0.1812 -0.4135 -0.1098 -0.0706 -0.2463 -0.2469 -0.2480 -1.1326 -0.4011 -0.0795 -1.0581 -0.1549 -0.5342 -0.1695 -0.2393 -0.0294 -0.5963 -0.0709 -0.0556 -0.0537 -0.9212 -0.0330 -0.1037 -0.0283 -0.0960 -1.1571\n",
            "T-401\tbambo akugona pansi galu akugona pachifuwa chake\n",
            "H-401\t-0.32146966457366943\t▁ b a m b o ▁ a k u g o n a ▁ p a n j i n g a ▁ y a k u d a ▁ a k u k w e r a ▁ c h i t h u n z i\n",
            "D-401\t-0.32146966457366943\tbambo akugona panjinga yakuda akukwera chithunzi\n",
            "P-401\t-0.0975 -0.1610 -0.1690 -0.0404 -0.0637 -0.1330 -0.1243 -0.1628 -0.0573 -0.1514 -0.3123 -1.0235 -0.0248 -0.0808 -0.0942 -0.0302 -0.1758 -0.7360 -2.0874 -0.3856 -0.6843 -0.1277 -0.0959 -0.1529 -0.9574 -0.0976 -0.1164 -0.2362 -0.3401 -0.1437 -0.1210 -0.4850 -0.2764 -0.1437 -1.0749 -0.3444 -0.0681 -0.5195 -0.1140 -0.1862 -0.0413 -0.0746 -0.0974 -1.5629 -0.8881 -0.3123 -0.0514 -0.1842 -0.1886 -0.2759\n",
            "T-418\tkayaker wachimuna akuyenda m madzi ovuta\n",
            "H-418\t-0.3826509118080139\t▁ k a y a ▁ k a c h i n y a m a t a ▁ k u y e n d a ▁ m ▁ m a d z i\n",
            "D-418\t-0.3826509118080139\tkaya kachinyamata kuyenda m madzi\n",
            "P-418\t-0.1195 -0.1983 -0.7073 -1.4436 -0.1604 -1.1797 -0.4037 -0.3542 -0.6542 -0.0550 -0.0621 -0.5746 -0.4717 -0.0895 -0.1233 -0.1990 -0.0196 -0.1343 -0.1652 -0.7356 -0.1329 -0.6299 -0.1549 -0.0913 -0.0902 -0.1261 -0.1446 -0.1006 -0.1437 -0.0440 -0.0966 -0.0249 -0.0524 -0.4633 -3.2465\n",
            "T-303\tpali galu wamtundu wapakati pa chipale chofewa\n",
            "H-303\t-0.22184865176677704\t▁ g a l u ▁ w a m n g ▁ o n o ▁ a k u d u m p h a ▁ p a ▁ c h i p a l e ▁ c h o f e w a\n",
            "D-303\t-0.22184865176677704\tgalu wamng ono akudumpha pa chipale chofewa\n",
            "P-303\t-0.1071 -0.2280 -0.0917 -0.0541 -0.0523 -0.1185 -0.1471 -0.3078 -0.2760 -1.0608 -1.8741 -0.0850 -0.1657 -0.1176 -0.2633 -0.1720 -0.8819 -0.1837 -0.0654 -1.0902 -0.0269 -0.0485 -0.0150 -0.0325 -0.0975 -0.1541 -0.0555 -0.1088 -1.2540 -0.0263 -0.0662 -0.1076 -0.0887 -0.0818 -0.0368 -0.0353 -0.0969 -0.0079 -0.0905 -0.0391 -0.0188 -0.0286 -0.0253 -0.0814 -0.0170\n",
            "T-187\tmnyamata ndi mtsikana akuyenda panja pa msika\n",
            "H-187\t-0.1574261635541916\t▁ m n y a m a t a ▁ n d i ▁ m t s i k a n a ▁ a k u y e n d a ▁ p a n s i\n",
            "D-187\t-0.1574261635541916\tmnyamata ndi mtsikana akuyenda pansi\n",
            "P-187\t-0.1021 -0.0605 -0.0387 -0.0362 -0.1104 -0.0578 -0.1032 -0.0319 -0.0963 -0.1192 -0.1587 -0.1338 -0.1083 -0.0989 -0.1178 -0.0932 -0.0396 -0.0427 -0.0250 -0.1189 -0.0359 -0.1299 -0.1164 -0.2336 -0.0190 -0.1026 -0.0530 -0.0498 -0.0391 -0.1479 -0.1366 -0.1201 -0.3296 -0.1642 -0.2460 -0.6976 -0.0660 -1.6018\n",
            "T-79\tamuna awiri akupereka nsapato panja\n",
            "H-79\t-0.3693394064903259\t▁ a m u n a ▁ a w i r i ▁ a k u p e r e k a ▁ m s e w u ▁ p a n j i n g a\n",
            "D-79\t-0.3693394064903259\tamuna awiri akupereka msewu panjinga\n",
            "P-79\t-0.0943 -0.1551 -0.2552 -0.0721 -0.0762 -0.0980 -0.0996 -0.1432 -0.0298 -0.1422 -0.0519 -0.1180 -0.0983 -0.1214 -0.0595 -0.1099 -2.5727 -0.5014 -0.3155 -0.0416 -0.0169 -0.0885 -0.1062 -1.3200 -0.4142 -1.1802 -0.8869 -0.0854 -0.4117 -0.4880 -0.2271 -1.0379 -0.4754 -1.0574 -0.6816 -0.0574 -0.1292 -0.2149\n",
            "T-105\tgalu wabulauni akudumpha m nkhalango\n",
            "H-105\t-0.20892998576164246\t▁ g a l u ▁ w a b u l a u n i ▁ a k u d u m p h a ▁ m u m l e n g a l e n g a\n",
            "D-105\t-0.20892998576164246\tgalu wabulauni akudumpha mumlengalenga\n",
            "P-105\t-0.1076 -0.0063 -0.1003 -0.0560 -0.0674 -0.0964 -0.0625 -0.9000 -1.0455 -0.0720 -0.0990 -0.0934 -0.0456 -0.0706 -0.1235 -0.1127 -0.1733 -0.0343 -0.1369 -0.1691 -0.1540 -0.0525 -0.0679 -0.1165 -0.0892 -0.1557 -0.0633 -1.1706 -0.8321 -0.3314 -0.2415 -0.2183 -0.0167 -0.1565 -0.0328 -0.3718 -0.1546 -0.0183 -0.2933 -0.2476\n",
            " 92% 12/13 [00:24<00:01,  1.55s/it, wps=1604]T-17\tgalu wamng ono wabulauni akudumpha m madzi\n",
            "H-17\t-0.26119422912597656\t▁ g a l u ▁ w a m n g ▁ o n o ▁ w a k u d a ▁ a k u d u m p h a ▁ m ▁ m a d z i\n",
            "D-17\t-0.26119422912597656\tgalu wamng ono wakuda akudumpha m madzi\n",
            "P-17\t-0.1079 -0.1876 -0.1383 -0.0567 -0.0794 -0.1101 -0.1540 -0.0760 -0.8385 -0.0190 -0.0888 -0.0767 -0.0533 -0.0521 -0.0768 -0.1857 -0.2541 -0.3589 -1.1254 -0.8643 -0.6099 -0.0990 -0.0864 -0.7435 -0.4878 -0.1255 -1.7117 -0.0474 -0.0408 -0.0515 -0.0573 -0.0788 -0.3290 -0.1048 -0.1823 -0.0577 -0.3070 -0.0863 -0.3959 -0.0941 -0.1088\n",
            "T-39\tmunthu akuchita zanzeru panjinga pa skatepark\n",
            "H-39\t-0.2703824043273926\t▁ m u n t h u ▁ a k u c h i t a ▁ z a n j i r a ▁ p a n j i n g a ▁ p a ▁ s k a t e b o a r d\n",
            "D-39\t-0.2703824043273926\tmunthu akuchita zanjira panjinga pa skateboard\n",
            "P-39\t-0.1061 -0.1923 -0.6884 -0.0698 -0.0380 -0.0553 -0.1257 -0.1538 -0.5410 -0.0645 -0.0877 -0.8952 -0.0833 -0.1099 -0.0582 -0.1004 -0.0859 -0.0385 -0.1606 -0.9073 -0.0454 -1.7399 -0.2620 -0.0780 -0.1322 -0.0766 -0.1096 -0.7444 -0.0279 -0.4153 -0.1021 -0.0735 -0.1508 -0.1863 -0.1149 -0.1211 -1.0106 -1.4398 -0.4659 -0.0629 -0.0229 -0.0211 -0.1863 -0.0708 -0.1118 -0.0401 -0.0564 -0.5478\n",
            "T-106\tgalu wakuda akuthamanga m munda waudzu\n",
            "H-106\t-0.21459630131721497\t▁ g a l u ▁ w a k u d a ▁ a k u t h a m a n g a ▁ m ▁ m u n d a ▁ w a u d z u\n",
            "D-106\t-0.21459630131721497\tgalu wakuda akuthamanga m munda waudzu\n",
            "P-106\t-0.1006 -0.0509 -0.1012 -0.0481 -0.1155 -0.1036 -1.4762 -0.1162 -0.0475 -0.0935 -0.0831 -0.2085 -0.1202 -0.1780 -0.4998 -0.0825 -0.2019 -0.0767 -0.0903 -0.0358 -0.1142 -0.1428 -0.0286 -0.1279 -0.1198 -0.1100 -0.8316 -1.1778 -0.8285 -0.1624 -0.0135 -0.0875 -0.1780 -0.0942 -0.1077 -0.2607 -0.1626 -0.0443 -0.0730 -0.0886\n",
            "T-138\twosewera mpira wachikazi yemwe wavala chipewa choyera ndi malaya abuluu akuseweretsa okonzeka kumenyanso mpira kwa mdani wake\n",
            "H-138\t-0.5506906509399414\t▁ m n y a m a t a ▁ w o v a l a ▁ t ▁ s h e t i ▁ y o t u w a ▁ a t a k h a l a ▁ p a m p h e p e t e ▁ m w a ▁ n k h o p e ▁ y a k e ▁ a k u y a n g ▁ a n a\n",
            "D-138\t-0.5506906509399414\tmnyamata wovala t sheti yotuwa atakhala pamphepete mwa nkhope yake akuyang ana\n",
            "P-138\t-0.1275 -0.3411 -2.8122 -0.3540 -0.1293 -0.0907 -0.1389 -0.0462 -0.1482 -0.1011 -0.2981 -0.6481 -0.3673 -0.1068 -0.0779 -0.1068 -0.0915 -2.6027 -0.9817 -0.2643 -0.1840 -1.2282 -0.1008 -0.0607 -0.1216 -0.2487 -0.3054 -0.8123 -0.5595 -0.0713 -0.2586 -0.2192 -1.1546 -1.6445 -0.1270 -1.1758 -0.9450 -0.2003 -0.0838 -0.0990 -0.0950 -0.5621 -0.1047 -2.9809 -0.4048 -1.3717 -0.5573 -0.0799 -0.4457 -0.1252 -0.1200 -0.0789 -1.2564 -0.1446 -0.1563 -0.1031 -1.5233 -1.4281 -0.2922 -0.8814 -0.4584 -0.2862 -0.1768 -0.6940 -0.7842 -0.6186 -0.1949 -0.6203 -1.4776 -0.6387 -0.1621 -2.7237 -1.2045 -0.1213 -0.2932 -0.1640 -0.1051 -0.0811 -0.2378 -0.8664\n",
            "2022-12-25 00:19:23 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
            "2022-12-25 00:19:23 | INFO | fairseq_cli.generate | Translated 428 sentences (39,938 tokens) in 22.4s (19.10 sentences/s, 1781.87 tokens/s)\n",
            "Generate test_asr_nya with beam=5: WER: 58.66\n"
          ]
        }
      ],
      "source": [
        "!fairseq-generate /content/zambezi-voice/nyanja/nya \\\n",
        "  --config-yaml config_asr_nya.yaml \\\n",
        "  --gen-subset test_asr_nya \\\n",
        "  --task speech_to_text \\\n",
        "  --path /content/drive/MyDrive/ZambeziVoice/nyanja/saved_asr_checkpoints/checkpoint500.pt\\\n",
        "  --max-tokens 50000 \\\n",
        "  --beam 5 \\\n",
        "  --scoring wer \\\n",
        "  --wer-tokenizer 13a \\\n",
        "  --wer-lowercase \\\n",
        "  --wer-remove-punct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lGEbIjT8j4g"
      },
      "outputs": [],
      "source": [
        "# PART 2 : SPEECH TRANSLATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoLIwXZ183tR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el-I6LoSpR9M",
        "outputId": "536b29f1-f65b-4f7e-b93d-b3bb40dcf3e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fairseq\n",
            "Fetching split train...\n",
            "Extracting log mel filter bank features...\n",
            "0it [00:00, ?it/s]\n",
            "Fetching split dev...\n",
            "Extracting log mel filter bank features...\n",
            "0it [00:00, ?it/s]\n",
            "Fetching split test...\n",
            "Extracting log mel filter bank features...\n",
            "0it [00:00, ?it/s]\n",
            "ZIPing features...\n",
            "0it [00:00, ?it/s]\n",
            "Fetching ZIP manifest...\n",
            "0it [00:00, ?it/s]\n",
            "Generating manifest...\n",
            "0it [00:00, ?it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, long speech (>3000 frames): 0, total 0 filtered, 0 remained.\n",
            "0it [00:00, ?it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 0 remained.\n",
            "0it [00:00, ?it/s]\n",
            "| no speech: 0, short speech (<5 frames): 0, empty sentence: 0, total 0 filtered, 0 remained.\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/tmp/tmpmkp8jnmh --model_prefix=/content/COVOST_ROOT/sv-SE/spm_char_st_sv-SE_en --model_type=char --vocab_size=1000 --character_coverage=1.0 --num_threads=2 --unk_id=3 --bos_id=0 --eos_id=2 --pad_id=1\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /tmp/tmpmkp8jnmh\n",
            "  input_format: \n",
            "  model_prefix: /content/COVOST_ROOT/sv-SE/spm_char_st_sv-SE_en\n",
            "  model_type: CHAR\n",
            "  vocab_size: 1000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 2\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 3\n",
            "  bos_id: 0\n",
            "  eos_id: 2\n",
            "  pad_id: 1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: /tmp/tmpmkp8jnmh\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 0 sentences\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
            "Traceback (most recent call last):\n",
            "  File \"examples/speech_to_text/prep_covost_data.py\", line 277, in <module>\n",
            "    main()\n",
            "  File \"examples/speech_to_text/prep_covost_data.py\", line 273, in main\n",
            "    process(args)\n",
            "  File \"examples/speech_to_text/prep_covost_data.py\", line 238, in process\n",
            "    gen_vocab(\n",
            "  File \"/content/fairseq/examples/speech_to_text/data_utils.py\", line 52, in gen_vocab\n",
            "    sp.SentencePieceTrainer.Train(\" \".join(arguments))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sentencepiece/__init__.py\", line 989, in Train\n",
            "    SentencePieceTrainer._Train(arg=arg, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sentencepiece/__init__.py\", line 945, in _Train\n",
            "    return SentencePieceTrainer._TrainFromString(arg)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sentencepiece/__init__.py\", line 923, in _TrainFromString\n",
            "    return _sentencepiece.SentencePieceTrainer__TrainFromString(arg)\n",
            "RuntimeError: Internal: src/trainer_interface.cc(428) [!sentences_.empty()] \n"
          ]
        }
      ],
      "source": [
        "%cd /content/fairseq\n",
        "!python examples/speech_to_text/prep_covost_data.py \\\n",
        "  --data-root /content/COVOST_ROOT \\\n",
        "  --vocab-type char \\\n",
        "  --src-lang sv-SE \\\n",
        "  --tgt-lang en "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ia8KqOfuZCFc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}